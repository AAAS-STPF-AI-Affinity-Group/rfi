PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 87-p7a1-1zvz
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1209
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Steven Zuber 
General Comment
I am  writing in response to the White House’s Request for Inform ation on the developm ent of an Artificial Intelligence Action Plan. As AI
system s becom e increasingly capable, it is im perative that their developm ent is guided by careful, deliberate planning to ensure alignm ent
with hum an values and long-term  safety.
The potential benefits of AI are im m ense, but so are the risks. One of the m ost pressing concerns is the possibility of m isaligned
superintelligence—AI system s that, due to insufficient oversight or flawed design, could act in ways that are dangerous to hum anity.
Researchers at institutions such as the Machine Intelligence Research Institute (MIRI) (intelligence.org), Center for AI Policy (CAIS)
(safe.ai), and Control AI (controlai.com ) have outlined scenarios in which advanced AI, if not properly controlled, could lead to
catastrophic outcom es. A robust AI Action Plan m ust prioritize technical research into AI alignm ent, as well as policies that ensure AI
system s rem ain interpretable and corrigible.
Additionally, the econom ic im pact of AI-driven autom ation m ust not be overlooked. Large-scale job displacem ent could lead to
significant econom ic instability and social unrest. While autom ation has historically created new types of em ploym ent, the speed at which
AI is progressing m ay outpace our ability to adapt. Policym akers m ust explore strategies such as retraining program s, adjustm ents to labor
laws, and, potentially, new econom ic m odels to support displaced workers.
I urge the adm inistration to approach AI developm ent with a strong com m itm ent to long-term  safety and societal well-being. This m eans
supporting rigorous research into AI alignm ent, creating regulatory fram eworks that prevent reckless AI deploym ent, and preparing for the
econom ic shifts that AI will bring. By taking these concerns seriously now, we can help ensure that AI rem ains a tool for hum an progress
rather than an existential risk.
Thank you for your attention to this critical issue. I appreciate your leadership in shaping a responsible AI future and your solicitation for
thoughts from  your fellow Am ericans. I'm  sure I'm  not alone when I say I welcom e further discussion on these concerns.
Sincerely,
Steven Zuber


