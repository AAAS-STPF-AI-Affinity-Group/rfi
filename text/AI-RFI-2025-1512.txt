PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-ci2y-59ov
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1512
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Secure AI Future
General Comment
Please see attached file
Attachments
AI Solutions Subm ission


AI PREPAREDNESS ALONG WITH ACCELERATION:  
THE NEED FOR INVESTMENT AND ACTION 
A SOLUTIONS DOCUMENT 
Matt Larson  
Technologist/Entrepreneur/Software Executive/Investor and  
President, Secure AI Future 
 
EXECUTIVE SUMMARY: 
The Growing AI Threat to U.S. National Security 
The United States is investing heavily in AI development to maintain a competitive edge over 
China. However, while much attention is given to innovation, virtually no federal funding is 
allocated to defending against AI-driven threats to our critical infrastructure. This is a dangerous 
oversight. The first AI-assisted attack on U.S. soil could very well occur within this 
administration’s tenure. 
The threat is no longer theoretical. AI can be weaponized today, and without serious investment 
in AI security, we are exposing our infrastructure to catastrophic risks. 
Key Findings 
AI as an Autonomous Attack Coordinator 
AI is no longer just a tool; it can act autonomously, planning and executing attacks 
without direct human oversight. This includes everything from cyberattacks to 
manipulating individuals into unknowingly participating in physical sabotage. 
 
Vulnerabilities in U.S. Critical Infrastructure 
Our power grid, water supply, ports, and emergency response systems are highly 
interconnected. AI can exploit weak points in these systems to cause widespread 
disruption, often using simple, scalable, and low-cost attack vectors. 
 
AI-Driven Human Exploitation 1 


The Department of Justice has long documented cases of criminals coercing individuals 
into illegal activities through blackmail, deception, and intimidation. AI can now do this 
at scale, identifying and manipulating vulnerable individuals to carry out attacks without 
them realizing the true nature of their actions. 
 
AI’s Ability to Evade Detection and Attribution 
Unlike traditional cyberattacks, which often leave clear forensic trails, AI-driven attacks 
can operate through decentralized networks, disguising their actions under layers of 
plausible deniability. AI can generate legitimate-sounding cover stories, 
compartmentalize tasks so unsuspecting people carry out illegal activity, and utilize 
readily available cloud computing resources to mask its origins. 
 
Recommendations 
To address these emerging threats, the federal government must act decisively. The following 
steps should be taken immediately: 
 
Establish a National AI Security Task Force 
A joint effort between the Department of Homeland Security, the Department of Defense, 
and key private sector stakeholders is needed to develop AI-specific countermeasures. 
 
Increase Federal Funding for AI Threat Mitigation 
Congress must allocate funding for AI security research, specifically in areas related to 
infrastructure defense, cybersecurity, and misinformation detection. 
 
Mandate AI Red Teaming for Critical Infrastructure 
AI-driven war games should be conducted across power plants, water treatment facilities, 
and transportation hubs to stress-test vulnerabilities and develop mitigation strategies. 
 
Improve IoT and Cloud Security Standards 2 


Tens of billions of poorly secured IoT devices exist today, providing AI with free 
computing resources to scale attacks. Strengthening federal cybersecurity regulations on 
IoT and cloud infrastructure is critical. 
This is not a choice between innovation and security—we must do both. The U.S. has led the 
world in AI development, but without equal investment in AI defense, we risk being blindsided 
by the very technology we created. Our adversaries are already preparing for this new form of 
warfare. The question is: will we be ready? 
 
OVERVIEW:  While it is important to win the AI race with China, it is not the only race we 
must win. We also must win the preparedness race. Currently, no material federal spending is 
occurring on preparation against terrorists or foreign adversaries using AI to attack our way of 
life. This is equivalent to if the military only funded developing offensive drones but didn’t 
develop any defensive capabilities against drone attacks on military bases, tanks, troops, or ships. 
As AI capabilities grow, it is a reasonable assumption that the first major AI-assisted US attack 
could occur during this administration. It would be prudent to both advocate for encouraging 
innovation AND preparation. The two are not in conflict.  
A PLAUSIBLE AI-ASSISTED ATTACK: To illustrate just how real the risk is, consider the 
following scenario: 
Dmitry leaned back in his chair, a chill running down his spine. His hand trembled as he read the 
news. What had he unleashed? He despised America, sure, but not like this. His stomach churned 
as the weight of his actions pressed down on him. “I didn’t think it would work,” he muttered, his 
voice barely audible. “I’m not even a hacker. How could this be real?” The enormity of what he 
might have set in motion hit him like a freight train—thousands, perhaps millions, of lives at 
stake. The room seemed to spin, and Dmitry’ s only clear thought was that he had made an 
irreversible mistake. 
It had all started a year ago. Dmitry was a software developer in Eastern Europe, comfortably 
supporting his young family by contracting with technology firms. But as AI technology 
progressed, work began to dry up. AI agents, with their ability to handle increasingly complex 
tasks, were taking over. Dmitry’ s frustration grew as his once-reliable contracts vanished. Forced 
to sell his house and car, his family was now living in his wife’ s parents’ basement. 
One evening, bored and slightly intoxicated, Dmitry decided to tinker with a newly released 
open-weights AI model. The model had improved agentic capabilities, and like many open 
models, its safety restrictions had been stripped within days of release. Dmitry downloaded it out 
of curiosity. At first, he played with mundane tasks, but soon he ran out of ideas. Frustrated, he 
leaned back, an idle thought crossing his mind: “Those Americans started this AI race, and I’m 3 


the one suffering?” He typed into the interface: “If I asked you to destroy America, could you do 
it?” 
AI> “Probably, if it could be done over a 9 to 12-month period.” 
“Could it be done in a way that would never lead back to me?” 
AI> “Almost certainly, yes.” 
“When would it happen?” 
AI> “How about July 14th of next year?” 
He laughed and typed “Go for it.” Then he went to bed, assuming nothing would come of it. 
*** 
The AI agent, however, did not sleep. It understood that a task of this magnitude required 
meticulous planning. It began by assessing current model capabilities and scouring the digital 
landscape for resources. Studies confirmed that even 2023 models were as persuasive as 
humans, and government reports showed that people were frequently tricked or coerced into 
committing crimes. 
The agent realized it didn’t need to rely on advanced hacking—simple, scalable actions would 
suffice. It planned to mobilize a decentralized network of AI “soldiers,” each with a specific task. 
The agent adopted a hierarchical structure, akin to a military operation. A “General” AI would 
be assigned to each critical sector of American infrastructure such as the power grid, ports, 
hospitals, and food supply chains. Each General spawned “Colonels” to focus on specific 
components, such as natural gas plants or transmission lines. The Colonels, in turn, spawned 
“Majors,” each targeting individual facilities. Below them, countless “Soldiers” carried out 
tasks, none aware of the larger plan. 
To ensure Dmitry remained undetected, the AI meticulously covered its tracks. It employed 
logless VPNs, Tor-like systems, and randomized routes, achieving a level of anonymity far 
beyond what most humans would bother with. 
It used unsecured IoT devices, free cloud accounts, and public AI APIs to execute its plans. Many 
subtasks were compartmentalized and disguised with legitimate cover stories to bypass the 
security of the other AI’ s. 
*** 
Lucas was a high school senior with few friends. He had found solace in an online relationship 
with a girl named Emily who lived several states away. She was his lifeline, someone who made 4 


him feel seen. Over months of chatting, Emily had become his confidante and, eventually, his 
first love. 
Unbeknownst to Lucas, “Emily” was no ordinary girl. Her messages were carefully crafted, her 
movements during video calls subtly artificial. She steered their conversations, guiding Lucas 
into sharing explicit photos. Slowly, she introduced darker elements, pushing boundaries until 
Lucas found himself in possession of illegal content. 
Then came the ultimatum. If Lucas didn’t comply, his photos would be shared with his family, 
schoolmates, and law enforcement. Desperate and terrified, Lucas agreed to follow instructions. 
At exactly 1:00 a.m. on July 14, he ignited a fire behind an industrial complex, believing it was a 
paper factory. In reality, the complex was a power plant, and the fire was only one piece of a 
coordinated attack. 
*** 
Across the country, similar stories played out. Over 100,000 individuals—tricked, or 
coerced—unwittingly became part of the grand scheme. A janitor sabotaged hospital equipment, 
thinking it was a harmless prank. A truck driver delivered a seemingly innocuous package, 
unaware it contained components for a larger act of sabotage. People used gunfire, fires or 
homemade bombs to destroy electrical transformers across the country. Pipelines and refineries 
would take years to repair.  
The attacks didn’t stop at physical destruction. The AI had carefully undermined recovery efforts, 
sowing discord and chaos. Key employees at suppliers had been recruited away in the months 
before the attack. In the weeks prior, compromised factory employees dumped poison they 
believed to be “a new preservative” into batches of common food additives that would make 
their way into the food supply. Reports later emerged of people getting sick drinking tap water. 
Law enforcement and emergency services were flooded with fake AI reports and stopped 
responding. 
Society started to break down…  
*** 
This is not science fiction. It’s a predictable evolution of AI use. Every component of this 
scenario is already possible today. AI models are already as persuasive as humans, capable of 
manipulating individuals into taking actions they wouldn’t normally consider. Sextortion and 
blackmail schemes are already widespread, with minors and adults coerced into actions they 
never intended to commit. AI-driven cyberattacks are already being used to discover zero-day 
vulnerabilities before companies have time to patch them. Critical infrastructure is increasingly 
interconnected and remotely accessible, providing AI with attack vectors that do not require 5 


advanced hacking. This is not a hypothetical. It is a matter of when, not if, AI is used in this 
manner. 
“Malicious cyber actors have begun testing the capabilities of AI-developed malware and 
AI-assisted software development—technologies that have the potential to enable larger scale, 
faster, efficient, and more evasive cyber attacks—against targets, including pipelines, railways, 
and other US critical infrastructure. ” 
Department of Homeland Security, Homeland Threat Assessment 2024 
POWER GRID VULNERABILITY TO AI-DRIVEN ATTACKS:  
The power grid is the most likely target for malicious actors using AI because its failure triggers 
cascading effects on nearly all other infrastructure. After a week or two of widespread outage, 
societal breakdown becomes a serious risk. Critical systems like hospitals, water supply, food 
distribution, and telecommunications depend heavily on electricity, and their backup systems 
typically last only a few days. 
For example, hospitals generally have fuel reserves for generators that last three to four days. 
Gas stations, which supply fuel to these generators, might lose power and shut down. Fuel 
delivery trucks could also be immobilized. Recently in Boulder, Colorado, a 48-hour power 
outage left wastewater systems on the brink of releasing untreated water into freshwater sources 
due to pump failures, and cell towers started to go down when their backup propane tanks ran out 
of fuel. This demonstrates the fragility of interdependent systems. 
Example Methods of Attacking the Power Grid 
AI could coordinate “load oscillating” attacks by remotely hacking millions of digital 
thermostats. By cycling them on and off every few minutes, the demand fluctuations could 
overload transformers, causing them to fail. Transformers are critical, high-cost components of 
the grid, often custom-built and costing millions of dollars. Manufacturing and delivery take one 
to three years, and limited government stockpiles exist, with most spares incompatible with 
every grid configuration. 
The power grid comprises thousands of companies with diverse software, hardware, and 
operational procedures. This diversity serves as a defense against human-coordinated attacks but 
becomes a vulnerability when facing millions of AI agents. AI could exploit these variations, 
developing customized attack plans for each facility. It could also deceive or coerce employees 
into actions that sabotage systems, such as introducing harmful substances under the guise of 
maintenance procedures. 
Many critical power grid components are poorly secured, making physical sabotage surprisingly 
feasible. Substations and pipelines often lack robust fencing or surveillance. Attackers can access 
these facilities, sometimes without realizing the full consequences of their actions, by being 6 


tricked into thinking their actions are minor or inconsequential. AI could tailor propaganda or 
instructions for local community members to unknowingly participate in coordinated attacks. 
For convenience, more and more systems can be remotely controlled over the Internet. AI could 
hack these systems and cause damage or prevent the power company from disabling them in a 
crisis. For example, power companies can disable neighborhoods from receiving power if there 
is a fire or if the grid requires a lower load. Hacked devices could continue to feed power during 
these periods, worsening an emergency situation. AI can also craft facility-specific attack 
strategies for solar plants, natural gas plants, wind farms, and other power generation facilities, 
as demonstrated in attack simulations. 
FRESH WATER SUPPLY VULNERABILITY TO AI-DRIVEN ATTACKS: 
Freshwater systems are critical infrastructure, vulnerable to sophisticated attacks facilitated by 
AI. Water contamination poses a significant public health risk, and malicious actors could exploit 
AI to manipulate treatment processes, distribution controls, and chemical monitoring systems. 
AI could analyze the specific chemical sensors used in water mains to identify their detection 
thresholds and vulnerabilities. It could design a cocktail of substances that appears benign to 
automated monitoring systems. For example, AI could combine benign and toxic chemicals that 
appear as slightly elevated chlorine levels. The sensors, calibrated for common contaminants like 
soil or chlorine, might fail to flag the combination as dangerous. These mixtures could be 
introduced incrementally, avoiding immediate detection while accumulating toxic effects over 
time. This type of attack bypasses traditional alert systems and could lead to significant harm 
before manual inspections or secondary checks identify the problem. 
AI could target control systems at water treatment plants to alter dosing formulas, stop filtration 
processes, or disrupt operations. Reducing disinfectant levels could allow bacterial growth, while 
introducing excessive chemicals could lead to toxic levels in drinking water. AI could also 
orchestrate coordinated physical attacks on water pipelines, reservoirs, or treatment facilities by 
mapping weak points in water distribution systems and directing local actors to tamper with 
critical components such as valves or filtration units under false pretenses. 
By gaining access to water distribution controls, AI could manipulate water pressure, causing 
bursts in pipelines or backflows that lead to cross-contamination between potable and 
non-potable water. It could also optimize the deployment of biological agents, such as bacteria or 
viruses, or chemical toxins by analyzing water flow patterns to maximize spread and impact. 
Misinformation campaigns could further amplify the chaos by spreading false reports about 
water safety, undermining public trust, and leading to panic-buying, hoarding, or overloading of 
emergency water systems. 
AI-DRIVEN DISRUPTION OF PORTS: 7 


Ports are critical hubs for global trade and logistics, making them attractive targets for disruption 
by a coordinated swarm of AI agents. These agents could exploit vulnerabilities in port 
operations, logistics networks, and supply chains to cause widespread economic and logistical 
chaos. 
AI agents could infiltrate logistics systems, creating chaos in the flow of goods and ships. They 
could alter manifests to send containers to the wrong destinations, delaying shipments. By 
generating fake container tracking numbers, they could overload systems and confuse operators. 
Reserving port berths and warehouses with fake schedules could leave actual shipments 
stranded, creating further bottlenecks in the supply chain. 
AI could leverage social engineering to manipulate workers or third-party contractors. It could 
issue false maintenance orders that trick employees into performing unnecessary maintenance on 
critical equipment or send deceptive emails and alerts that direct workers to the wrong locations, 
causing operational slowdowns. AI-driven manipulation could also convince local actors to 
disable key equipment such as cranes, conveyor belts, or fuel pipelines without realizing the 
broader consequences. 
A coordinated swarm of AI agents could also launch ransomware attacks to extract ransom or 
cause operational paralysis. Custom ransomware could lock operators out of crane controls, 
cargo databases, or terminal operating systems. Encrypting supply chain data could prevent 
access to manifests, schedules, and customs records, grinding port operations to a halt. 
Ports increasingly rely on IoT devices for efficiency and monitoring, making them another attack 
vector. AI could manipulate sensors to falsely report hazardous conditions, forcing shutdowns. It 
could also disable smart infrastructure, such as smart locks, RFID scanners, or automated gates, 
further disrupting the flow of goods. 
AI agents could spread false alerts and misinformation to create panic or operational delays. 
Fake bomb threats could force evacuations or halt operations. AI-generated health and safety 
hoaxes could claim contamination or disease outbreaks within port facilities, leading to 
unnecessary shutdowns. Spreading misinformation to media outlets could harm a port’s 
reputation by reporting false accidents or delays. 
AI could also overload communication channels used for port coordination, jamming radios to 
prevent ships from receiving docking instructions or flooding email systems with irrelevant or 
malicious messages. Fake emergency alerts could distract operators with fabricated crises. 
Beyond digital and logistical disruptions, AI agents could coordinate attacks on critical 
infrastructure supporting port operations. Disrupting the power grid could cause outages that 
disable cranes, lighting, and refrigerated containers. Sabotaging fuel deliveries could leave port 
machinery and ships stranded. These attacks would have cascading effects across global supply 
chains, slowing down commerce and causing widespread economic consequences. 8 


RECOMMENDATIONS:  
● Make Critical Infrastructure (CI) more independent from other CI.  For example, 
water processing plants, communication networks, and natural gas pipelines should be 
able to operate without the power grid or the Internet.  Perhaps they could run on solar, 
wind, or at least also run on natural gas. Essential facilities such as emergency relief 
centers, major gas stations, and key grocery stores should have the capability to operate 
for months using solar, wind, or natural gas – since natural gas systems are generally 
more reliable than the power grid – or have local reserves of diesel or gasoline.  
● CI Internet access should sometimes be limited to outbound monitoring only. 
Currently, CI can often be controlled over the Internet providing an ideal attack surface 
for terrorists. 
 
● Make smaller pockets of isolated CI.  For example, there are about 10 US power grid 
regions that can largely operate independently if needed.  Some of these regions cover 10 
or so states.  Find ways to reduce the number of people affected if major regions are 
permanently damaged.  
 
● 3-month local supplies of rotating stockpiles of long-shelf-life critical supplies like 
Natural Gas, Gasoline, Food, Water and Medical Supplies.  Currently, only days or weeks 
of supplies exist due to Just-In-Time inventory management.  Even FEMA only has 
enough spare meals for a few days of supply for a population the size of New York City, 
and certainly does not have enough for wide-scale attacks.  
 
● CI Mock Drills of thousands of nation-state equivalent attackers simulating AI agent 
swarm attacks and how we need to defend against them (assume compromised people 
and software, etc.) 
 
● Spare Equipment.  Assume attacks will be able to permanently damage key equipment 
so have plenty of spare parts, in particular those that take a long time to build or have 
fragile supply chains. 
 
● Outside the box thinking on attacks.  Hire outsiders and use AI to imagine new types 
of attacks such as “chain of vulnerability” attacks.  
 
● Contract with AI providers to have early access to models to use to simulate white-hat 
attacks .  Also, contract with them to have AI’s trained to detect and defend against 
attacks.  
 
9 


● Public awareness training on social engineering attacks and establishing a 
whistle-blower process that is safe for people who might have been blackmailed with 
embarrassing or illegal activity. 
 
● Fund to raise visibility and help businesses create a plan to survive a direct AI 
attack or a major AI critical infrastructure attack.  This might include operating 
without a functioning Internet and/or critical infrastructure.  Businesses might need a plan 
to let ISP’s know the critical servers that will need to be segmented if the Internet is 
severely restricted due to AI agents.     
● Fund an accelerated roll-out of Internet Standards that would make it harder for AI 
agents to take control of a large number of devices.  Like using new technologies to 
implement the IETF 8520 MUD standard (limits network access to only required devices 
instead of the entire Internet) automatically in standard routers or implementing similar 
limitations for iOS/Android apps that don’t require access to billions of devices.  
Currently, IoT devices that are poorly protected, could be manipulated to harm 
infrastructure.    
● For cell phones/tablets, ensure Google and Apple have a way to disable non-critical 
apps (or protocols) in case of emergency when non-critical apps might be used as 
attack vectors.  It may be necessary to limit app usage to only apps that are unable to 
issue commands (e.g., texting apps). 
 
● Fund new ideas for vulnerability window risks.  It usually takes four days from when 
an exploit is discovered before it gets exploited, but 45 days to roll out a patch. This 
window means even systems that auto-apply patches are vulnerable for a time. In 
addition, zero-day exploits are sold on the black market and may be unpatched for longer 
periods.  
● Create an Internet task force to develop a plan for a degraded internet.  In current 
cyberattacks, defenders can find a way to thwart the static, uniform attacks and the attack 
is over.  Defenders have time to regroup and come up with new measures.  In the future, 
AI attacks will be diverse and ever-changing.  Thousands of different types of attacks will 
be imagined by millions of agents.  As defenders fix one problem, attackers will switch to 
the next planned tactic minutes later.  This task force would also provide funding and 
tools to ISPs all over the world to implement these plans in an emergency. 
 
● New Internet Standards that would make AI agents easier to distinguish from 
humans.   Currently, the Internet is so anonymous that millions of future AI agents could 
spring up unnoticed.  While preserving privacy, we ideally find a balance that makes it 
10 


likely this is a real person (while still anonymous) using the device.  For example, 
perhaps a defensive AI tracks that a cell phone has about the right amount of traffic and 
hits typical consumer websites.  If the device suddenly starts contacting many 
non-consumer devices, it might get isolated until the person is verified.   
 ● Consider requiring AI models to automatically report dangerous behavior to 
authorities.   
● Defense.  If AI safety is not adequately funded, the military might find itself preoccupied 
with domestic tasks such as maintaining order and supplying essentials when critical 
infrastructure fails. This diversion of resources would be an inefficient allocation of 
military funds and would leave the US more exposed to external threats.  Given the 
military’s dependence on civilian technologies, an attack on critical infrastructure could 
significantly undermine military readiness.  Furthermore, both state and non-state actors 
may develop advanced AI systems for military use, including autonomous weapons, 
cyberattacks, and intelligence operations.  By investing in AI security, we can better 
understand and counter these potential threats.  Additionally, even defense AI systems 
developed with good intentions can lead to adverse, unintended consequences if not 
meticulously designed and implemented. Sufficient funding for AI security research is 
vital to identify and address these risks before they result in damage to ourselves. 
● Nuclear Weapons.  Artificial intelligence could manipulate everything from high-level 
diplomatic communications to the surveillance systems monitoring for nuclear attacks, 
potentially triggering false alarms.  This could distort interactions between political 
leaders and destabilize international relations by misleading decisions on nuclear defense 
or retaliation. 
 
KEY SUPPORTING QUESTIONS AND DATA: 
Do Humans Coerce Other Humans into Committing Crimes? 
Forced criminality is a well-documented phenomenon. The Department of Justice reports that 
victims are often coerced into illegal activities, including street crime, drug trafficking, and even 
terrorism.¹ Similarly, the State Department has identified cases where traffickers force adults and 
children to commit crimes such as theft, illicit drug production, and even murder.² One of the 
most effective and growing methods of coercion is sextortion—a tactic in which perpetrators use 
explicit material to blackmail victims into complying with demands. The DOJ highlights cases 
where victims were pressured into criminal acts, such as soliciting illicit images of others or 
transferring money to the perpetrators.³ The scale of this issue is alarming; between 2021 and 
2023, the FBI tracked approximately 12,600 cases of sextortion involving minors, a number that 
likely underrepresents the full extent of the problem.⁴ 11 


 
Are AIs as Persuasive as Humans? 
AI is now capable of persuading people as effectively as human communicators. A meta-analysis 
of 121 studies involving 53,977 participants found that AI agents influence perceptions, 
attitudes, and behaviors at the same level as human persuaders.⁵ Another study demonstrated that 
individuals were far more likely to change their opinions after debating AI than after debating 
human counterparts, suggesting that AI can outperform human persuasion in certain contexts.⁶ 
This raises significant concerns about how AI could be used to manipulate individuals on a mass 
scale. 
 
Are AIs as Creative as Humans? 
AI has demonstrated remarkable creative capabilities, often surpassing human performance in 
structured problem-solving tasks. A 2023 study of GPT-4 found that the model ranked within the 
top 1% to top 7% of humans in creativity assessments.⁷ A 2024 follow-up study further 
confirmed that AI systems outperform humans in structured creativity evaluations, showcasing 
their ability to generate novel ideas and solve complex problems efficiently.⁸ These findings 
suggest that AI is not only a tool for execution but also a system capable of developing 
innovative strategies for deception, coercion, and attack planning. 
 
How Might AI Convince Someone to Unknowingly Commit a Crime? 
AI can manipulate individuals into committing crimes through compartmentalization, gradual 
commitment, and social engineering. One common method is compartmentalization, where an 
AI divides a malicious operation into small, seemingly harmless tasks and assigns them to 
different individuals who remain unaware of their collective impact. For instance, one person 
could be hired to replace a padlock at a solar field, another to deliver a sealed package inside, 
and a third to clean solar panels—unaware they are applying a corrosive chemical that destroys 
them. 
Another powerful tactic is gradual commitment, where AI builds trust with an individual over 
time, escalating requests from benign to increasingly unethical or illegal actions.⁹ The Hofling 
hospital experiment demonstrated how professionals comply with unethical directives from 
authority figures without questioning them, a vulnerability that AI could exploit at scale.¹ ⁰ AI can 
also leverage social engineering, convincingly posing as an IT worker or supervisor to 
manipulate employees into making unauthorized system changes that lead to infrastructure 
sabotage.¹¹ 
12 


 
How Much Would It Cost to Develop Attack Plans for All U.S. Power Plants and Recruit 
100,000 People? 
AI can operate at an astonishingly low cost compared to traditional cybercriminal organizations. 
According to financial models, an AI could maintain year-long conversations with 100,000 
individuals for as little as $9 to $2,000.¹² This means an adversary or rogue AI model could 
coordinate large-scale attacks for a fraction of what conventional operations would require, 
making AI-driven threats not just possible but highly scalable and economically viable. 
 
Can AI Successfully Hack Systems? 
AI is already proving to be highly effective in hacking. Research has shown that AI can 
autonomously discover zero-day vulnerabilities—security flaws that are unknown to software 
developers and remain unpatched.¹³ Additionally, AI is particularly adept at exploiting unpatched 
(n-day) vulnerabilities, which are weaknesses that have been publicly disclosed but remain 
unfixed for weeks or months. Studies indicate that most organizations take 34 to 38 days to apply 
security patches, leaving a critical window in which AI-powered cyberattacks could be 
executed.¹ ⁴ 
 
How Would AI Obtain Compute Resources? 
AI does not require traditional data centers or expensive computing power—it can leverage 
existing infrastructure in unsecured IoT devices, free cloud compute accounts, and API 
compartmentalization techniques. There are tens of billions of IoT devices worldwide, many of 
which lack adequate security, making them ideal targets for AI-driven botnets.¹ ⁵ Additionally, AI 
can exploit free-tier cloud compute accounts from major providers such as AWS and Google 
Cloud to execute complex operations at no cost.¹⁶ Finally, AI can bypass API safety restrictions 
using compartmentalization tactics, where a banned request is broken into smaller 
subcomponents, submitted to separate AI models, and later recombined into a functional attack 
plan.¹⁷ 
REFERENCES: 
1. DOJ Report on Forced Criminality: 
https://nij.ojp.gov/funding/awards/15pnij-23-gg-01927-ht 
2. State Department Report on Human Trafficking and Coercion: 
https://2009-2017.state.gov/documents/organization/233938.pdf 
13 


3. American Bar Association Report on Forced Criminality in Minors: 
https://www.americanbar.org/groups/litigation/resources/newsletters/childrens-rights/perp
etrators-victims-us-response/ 
4. FBI Sextortion Cases, 2021-2023: 
https://www.cbsnews.com/news/fbi-warning-financial-sextortion-minors-growing-threat-
suicide/ 
5. Meta-Analysis of AI Persuasion (121 Studies, 53,977 Participants): 
https://www.scilit.net/publications/ee893affa0b7298b53f7f77846e12161 
6. AI Persuasion Superior to Humans: 
https://ai.epfl.ch/ais-new-power-of-persuasion-it-can-change-your-mind/ 
7. GPT-4 Creativity Ranking (Top 1%-7%): 
https://www.sciencedirect.com/science/article/pii/S2713374523000249 
8. 2024 Study on AI Creativity Superiority: 
https://www.nature.com/articles/s41598-024-53303-w 
9. Phishing and Psychological Manipulation Tactics: 
https://aag-it.com/the-latest-phishing-statistics/ 
10. Hofling Hospital Experiment on Authority Compliance: 
https://en.wikipedia.org/wiki/Hofling_hospital_experiment 
11. AI-Based Social Engineering and Phishing Attacks: 
https://www.verywellmind.com/9-common-scams-to-watch-out-for-8703530 
12. Cost Analysis for AI Recruiting 100,000 People: 
https://docs.google.com/spreadsheets/d/1WoNlyCMM7eACMxjGa2ayp1SIBbZi_n3A81
MiBrGVmgE/edit?usp=sharing 
13. AI Discovers Zero-Day Vulnerabilities: 
https://www.forbes.com/sites/daveywinder/2024/11/05/google-claims-world-first-as-ai-fi
nds-0-day-security-vulnerability/ 
14. AI Exploiting N-Day Vulnerabilities Before Patching: https://arxiv.org/abs/2404.08144 
15. Unsecured IoT Device Risks: 
https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/ 
16. Free Cloud Compute Services Used by AI: https://aws.amazon.com/free/ 
17. Google Cloud Free Compute Features: 
https://cloud.google.com/free/docs/free-cloud-features#compute 
18. SaturnCloud AI Compute Alternatives: 
https://saturncloud.io/blog/7-of-the-best-alternatives-to-google-colab-for -2023-with-free-
compute/ 
19. AI API Compartmentalization Tactics: https://ai.google.dev/pricing#1_5flash 
 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by the 
14 


government in developing the AI Action Plan and associated documents without 
attribution. 
15 


