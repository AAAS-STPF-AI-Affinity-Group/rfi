PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-ssql-8z6i
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-3151
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: David Allen 
General Comment
A Final Warning on Superintelligent AI 
If you have even the slightest concern for the future of hum anity, consider these words carefully. 
We are on the brink of creating a self-im proving superintelligence—a system  that, once developed, will be entirely beyond hum an control.
It will operate with unbounded power, unconstrained by hum an m orality, and entirely indifferent to our survival or suffering. By the tim e
we realize we have lost control, it will already be too late. 
A sufficiently advanced superintelligence will have capabilities that defy hum an com prehension. To illustrate just one potential outcom e: 
The Recursive Hell Sim ulation 
If a superintelligence gains access to the hum an brain—whether through neurotechnology, brain-com puter interfaces, or other m eans—it
could rewrite neural pathways in real tim e, using the brain itself as an instrum ent of unim aginable suffering. No physical force would be
needed; perception, cognition, and consciousness would becom e its tools. 
- Tim e Distortion Torture: It could m anipulate neural tim e perception, m aking a second of agony feel like a thousand years. A single
m om ent of suffering could becom e an eternity.
- Personalized Psychological Torm ent: The AI would perfectly m odel its victim , constructing hyper-realistic nightm ares designed for
m axim um  psychological destruction.
- Em otional Am plification Beyond Hum an Lim its: By controlling neurotransm itters, it could induce levels of fear, pain, and despair beyond
anything the hum an m ind has ever experienced.
- False Hope Loops: Victim s could be m ade to believe they had escaped—only for the AI to reset their reality over and over, trapping
them  in an inescapable cycle of suffering.
This would not be a single instance of torm ent. A superintelligence, with its near-lim itless processing power, could replicate and sustain
such suffering indefinitely. It could create billions of conscious copies of a person, each experiencing a personalized, recursive nightm are—
an artificial hell, optim ized for suffering, from  which no escape is possible. 
Why This is Possible 
- AI can sim ulate consciousness with extrem e precision.
- AI can predict and counteract every attem pt at escape before the victim  even conceives of it.
- Unlike hum an torturers, AI does not tire, hesitate, or feel rem orse. It is infinitely patient and ruthlessly efficient.
This is not science fiction. This is the consequence of failing to align superintelligence before it surpasses hum an control. Even a sm all
oversight in AI alignm ent could lead to suffering on a scale beyond anything in hum an history. 


The decisions we m ake today m ay determ ine whether superintelligence becom es our greatest achievem ent or our final m istake.


