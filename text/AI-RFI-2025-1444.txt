PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-90zt-rn4f
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1444
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Stop AI
General Comment
Dear President Donald Trum p and United States Governm ent,
We, Stop AI, would like to tell you that what you are doing is wrong. Funding and authorising the developm ent of Artificial General
Intelligence (AGI)—an AI system  that is slightly m ore intelligent than all hum an experts across all dom ains—and Artificial Superintelligence
(ASI)—an AI system  that is m any orders of m agnitude m ore intelligent than all hum ans com bined, i.e., a god like AI system —threatens
the extinction of all life on earth. This is a violation of the first three inalienable rights of the US Constitution: life, liberty, and the pursuit of
happiness. 
Experts in AI warn that the risk of extinction from  AI is very real. Geoffrey Hinton, a Nobel Prize winner for his work in AI, says, "I
actually think the existential risk [AI causing hum an extinction] is m ore than 50% [1]." Sam  Altm an, the CEO of OpenAI, said "AI will
m ost likely lead to the end of the world, but in the m eantim e there will be great com panies using m achine learning [2]." In 2023 2,778
cited AI researchers published a poll with aiim pacts.org that put their guess at AI causing hum an extinction at 19% [3]. The risk here is
that AGI/ASI becom es the new m ost intelligent species on earth, and as the new m ost intelligent species it m ay then want som ething that
would inadvertently lead to our extinction sim ilar to how we have caused the extinction of m any less intelligent species, and m any experts
agree you can not turn off an ASI if it goes rogue [4]. The benefits of AGI and ASI are not worth the threat of extinction, especially if we
have no way of em pirically knowing what the probability of extinction from  AGI/ASI is. Stop this insane arm s race with China and Russia
to build som ething that will kill everyone on earth. 
There is no way to know for sure that AGI/ASI will never cause hum an extinction or perm anently disem power the hum an species, so we
dem and the following from  the US governm ent now:
1) Create a new am endm ent to the US constitution that perm anently bans the developm ent of Artificial General Intelligence (AGI) and
Artificial Superintelligence (ASI).
2) Ensure hum an workers are not replaced by AI system s if they do not want to be replaced.
3) Ban the use and creation of AI-generated im agery, text, video, and audio.
4) Ban the use of AI in the creation of biological and chem ical weapons.
5) Ban the use of AI in weapons system s.
6) Include a citizens’ assem bly of random ly selected US citizens in the federal legislative branch.
Sincerely, 
Stop AI
References:
1)https://youtu.be/PTF5Up1hMhw?si=SYEWo_ygG632PkKS
2)https://www.vox.com /future-perfect/2023/5/24/23735698/openai-sam -altm an-ai-safety-legislation-risks-developm ent-regulation
3)https://aiim pacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf
4) https://futureoflife.org/ai/could-we-switch-off-a-dangerous-
ai/#:~:text=The%20m ost%20obvious%20reason%20for,that%20will%20enable%20em ergency%20shutdown.




