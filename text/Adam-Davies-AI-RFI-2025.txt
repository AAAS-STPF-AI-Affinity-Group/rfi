Response: Request for Information, AI Action Plan
Adam Davies
Siebel School of Computing and Data Science
The Grainger College of Engineering
University of Illinois Urbana-Champaign
This document contains my (Adam Davies’) response to the Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan issued by the National Science Foundation on February 6, 2025. All stated opinions, beliefs, 
and priorities are my own,  and do not necessarily reflect those of any institution with which I  am affiliated.
This document is approved for public dissemination. The document contains no business-proprietary or confidential infor-
mation. Document contents may be reused by the government in developing the AI Action Plan and associated documents 
without attribution.
Response
In crafting the AI Action Plan, it is essential that the new Trump- Vance administration sustain and enhance our 
nation’s AI dominance by advancing the following priorities:
1.Maintain existing NSF awards. Our nation has established and sustained a significant lead in founda-
tional and applied AI technologies due in no small part to NSF-funded research. Given that a substantial
part of the US’ world-leading research ecosystem is supported by NSF awards, actions such as freezing,
canceling, or otherwise hindering the disbursement of funds for existing awards will lead to a collapse
in this critical ecosystem, carrying significant short- and long-term risks to our national security and
economic competitiveness.
Necessary policy actions:
(a) Continue the lawful disbursement of funds for grants that have already been awarded.
(b) Clearly communicate any new or updated criteria associated with the new administration’s priori-
ties with which grant holders and associated research activities should comply.
2.Prioritize AI safety, security, and trustworthiness. To promote human flourishing, economic com-
petitiveness, and national security, it is essential that we understand, anticipate, and mitigate the safety
and security risks associated with the development and deployment of foundational AI technologies.
Failure to do so may lead to important vulnerabilities when deploying novel AI technologies that could
be exploited by adversaries to attack domestic economic, financial, industrial, medical, educational,
communications, or other critical institutions deploying these unsafe technologies. As such, the admin-
istration should prioritize both (1) advancing our foundational mechanistic understanding of how these
models function internally, allowing us to better anticipate potential vulnerabilities; and (2) developing
applied techniques to mitigate such vulnerabilities and improve safety, security, and alignment with re-
spect to our goals and values.
Necessary policy actions:
(a) Prioritize available resources to support (1) foundational research in AI safety and mechanistic
interpretability; and (2) applied research in AI safety, security, and alignment.
1


