Charlyn Ho 
Founder and CEO , Rikka Law PLLC  dba Rikka 
1717 K Street NW, Suite 900 Washington, DC 20006 Telephone: Email:
 
March 15, 2025 
Office  of Science and Technology Policy 
Faisal D'Souza, NCO  
2415 Eisenhower Avenue  
Alexandria, V A 22314, USA Telephone: Email: 
This docume nt is approved for public dissemination. The document contains no business-
proprietary or confidential information. Document contents may be reused by the government in developing the AI Action Plan and associated documents without attribution. 
Re: Response to Request for Information on the Development of an AI Action Plan  
To Whom It  May Concern: 
I appreci ate the opportunity to contribute to the development of a national AI Action Plan that 
fosters the innovation necessary to sustain and strengthen America’s leadership in artificial intelligence.  As the founder of Rikka, a firm specializing in AI data protection law and 
technology transactions, I regularly publish thought leadership on this topic in publications like Forbes.com and Bloomberg Law, as well as counsel businesses on AI development and 
deployment across financial services, healthcare, and critical infrastructure sectors. I utilize a 
practical, business -friendly approach that allows private sector companies to get their products to 
market while complying with applicable laws and regulations.  
I recommen d that America’s AI Action Plan cultivate an ecosystem that fuels innovation while 
upholding strong governance in privacy, cybersecurity, and intellectual property protection. Just as leading technology companies balance risk management with agil ity, the U.S. government 
should adopt targeted, flexible regulations that encourage AI advancements without stifling entrepreneurship. By implementing clear, adaptable policies, incentivizing responsible AI 


development, and streamlining regulatory frameworks, the U.S. can maintain its position as the 
global leader in AI.  
America' s AI leadership requires a balanced regulatory approach —one that avoids the rigid 
constraints of the E uropean Union AI Act, the prescriptive nature of the Biden Administration’s 
Executive Order, and the state-controlled AI model of China. The U.S. must pursue a middle path that fosters innovation, economic competitiveness, and responsible governance, ensuring AI development aligns with democratic values. Without a pragmatic and adaptable regulatory framework, the U.S. risks losing its competitive ed ge and ceding AI leadership to nations with 
less transparent or more restrictive policies.  
This RFI response first outlines why privacy, cybersecurity, and intellectual property protections 
are essential to a robust national AI policy, detailing key risks and challenges. We then present targeted policy recommendations that balance innovation and regulation. Finally, we emphasize the need for a flexible, risk -based regulatory framework that avoids overly restrictive or 
centralized AI governance models while fostering a thriving AI ecosystem.  
I.Overview of Privacy, Cybersecurity, and Intellectual Property Risks in AI
A.Cybersecurity Threats in AI Systems
AI systems  can introduce significant cybersecurity risks due to their reliance on vast datasets, 
complex model architectures (with sometimes limited explainability), and extensive integrations with external systems. AI models are vulnerable to a variety of security risks, includ ing: 
•Adversarial Attacks : AI systems can be manipulated using adversarial inputs designed to
exploit weaknesses in machine learning models.
•Data Poisoning: Attackers can inject manipulated data into AI training sets, causing
models to learn incorrect behaviors or biases that can be exploited post-deployment.
•Model Extraction and Theft : AI models often represent significant intellectual property
investments, yet they are susceptible to reverse engineering, allowing adversaries to stealproprietary AI capabilities  and data.
•Prompt Injection Attacks : Malicious actors can craft deceptive prompts that cause
unintended or incorrect outputs.


•Supply Chain Vulnerabilities : Many AI systems rely on third -party datasets, cloud
platforms, and open- source models, creating potential security gaps.
B.Why This M atters
AI introduc es sophisticated cybersecurity challenges that, if left unaddressed, erode 
public trust and provide avenues for foreign and domestic adversaries to manipulate American 
businesses, policy, and society.  
Foreign actors, particularly China and Russia, have exploited AI- powered disinformation 
campaigns to sow division within American society and undermine democratic institutions. Reports indicate that foreign nations have  used AI- generated deepfake technology to spread 
divisive content and manipulate political discourse. Additionally, nation state linked  cyber 
groups have been implicated in cyberattacks on U.S. critical infrastructure, targeting military supply chains and national security assets to disrupt U.S. responses to geopolitical conflicts. 
Without robust AI cybersecurity safeguards, these vulnerabilities could be weaponized to 
influence elections, destabilize markets, and erode institutional trust.  
This vulnerability mirrors challenges faced in the cryptocurrency industry, where weak 
cybersecurity and high- profile breaches—including hacks, exchange collapses, and stolen digital 
assets—have fueled skepticism, slowed adoption, and invited regulatory sc rutiny. Similarly, if 
AI security risks are not proactively addressed, cyberattacks, model theft, and adversarial AI manipulations could diminish public confidence in AI applications and stifle broader industry 
adoption. Just as strong security frameworks and fraud prevention mechanisms have been essential in stabilizing the cryptocurrency industry, robust AI security protocols are necessary to 
protect critical AI infrastructure, maintain public trust, and ensure AI remains a transformative 
and reliable technology.  
II. Privacy Risks in AI Systems
A.Privacy and Surveillance Risks in AI Systems
AI models process vast amounts of data, including potentially sensitive personal data , raising 
critical concerns about data privacy, surveillance, and user consent . Key risks include:   


•Re-identification Risks : AI models trained on anonymized datasets can often re-identify
individuals by correlating disparate pieces of information, undermining traditional data
protection techniques.
•Inferred Data Exposure: AI systems can generate highly sensitive insights about
individuals even without direct access to personal data, raising concerns about implicitprivacy violations.
•Data Retention and Compliance Challenges : The long- term storage of training data and
model outputs raises concerns under privacy laws like the GDPR, CCPA, and emergingU.S. state AI laws, which require strict data minimization and purpose limitation.
•Profiling and Automated Decision -Making:
 AI-driven profiling, used in hiring, lending,
and law enforcement, often lacks transparency and can lead to discriminatory and biasedoutcomes. When taken to an extreme, AI-driven profiling can become a precursor to masssurveillance systems that undermine democratic freedoms, mirroring aspects of China’ssocial credit system .
B.Why This Matters
Without ro bust privacy safeguards, American consumers will vote with their feet, 
gravitating away from AI models that expose, misuse, or inadequately protect their data. Public trust is a foundational pillar for the success of AI, and models that fail to u phold strong privacy 
protections will struggle to achieve widespread adoption.  
Moreover,  the effectiveness of AI models relies heavily on access to diverse, high -quality 
datasets for training and fine -tuning. Without a significant user base willing to engage with AI 
platforms due to privacy concerns, American AI developers will face data scarcity, leading to 
models that are less accurate, less reliable, and ultimately less competitive on the global stage.  
A key fa ctor affecting AI model performance is the language and cultural composition of 
training data. Many leading large language models (LLMs) are trained primarily on English-based datasets derived from a Western cultural perspective, which contributes to their stronger 
performance in English but reduced effectiveness in other languages. Research highlights that LLMs often struggle with grammar, syntax, and idiomatic expressions in non-English languages, particularly those with different linguistic struc tures, lower resource availability, or more 
complex morphology. This linguistic imbalance limits the ability of American AI models to effectively scale and compete in global markets, particularly where local language fluency and cultural nuances are critical for adoption. 


 
Furthermore, languages with fewer digital resources—such as many African, Middle 
Eastern , and Southeast Asian languages—often suffer from data scarcity, making it difficult to 
develop AI systems that can serve these populations effectively. If the U.S. does not address this 
gap, AI models developed in multilingual regions could gain an advantage in global AI adoption by better serving non-English markets.  
To maintain American dominance in AI, it is crucial to ensure continued access to 
diverse, multilingual training data sourced from a broad and representative user base. Restrictive data collection policies or fragmented privacy laws that limit access to tr aining data in both 
English and other languages risk hampering AI performance and international competitiveness.   
If users do not feel confident that their data is being handled responsibly, they may shift 
toward alternative platforms that prioritize privacy, including AI models developed in jurisdictions with stricter data protection frameworks. This shift would not only weaken U.S. AI 
leadership but could also drive innovation and economic benefits away from the domestic market.  
III. Intellectual Property Risks and the Chilling Effect on AI Innovation  
A. Weak Intellectual Property Protection in AI Systems  
The United States has long been a leader in global innovation, in part because its 
Constitution enshrines the principle that inventors and creators should reap the rewards of their innovations. Strong intellectual property (IP) protections serve as a corne rstone of economic 
growth, incentivizing investment in cutting- edge technologies and promoting fair competition.  
The AI sector is particularly vulnerable to unauthorized replication, model theft, and 
reverse engineering. A notable example is China’s DeepSeek, which allegedly used model 
distillation techniques to reverse engineer OpenAI’s ChatGPT . If left unchecked, such activities 
may allow foreign competitors to replicate and profit from American AI innovations without bearing the costs and risks of original development. This weakens U.S. economic competitiveness, discourages investment in new AI models, and enables adversarial nations to accelerate their own AI capabilities using stolen or distilled intellectual property.  
B. Why This Matters 
Beyond direct theft, current uncertainties in patent eligibility, copyright ownership, and trade 
secret protection pose additional risks that could stifle AI-driven progress. Key concerns include: 


•Patent Uncertainty for AI- Generated Inventions : The lack of clarity on whether AI-
generated innovations qualify for patent protection creates investment risks. Without
robust patent protections, companies may hesitate to invest in groundbreaking AItechnologies, fearing unrestricted replication by com petitors.
•Copyright Ambiguity for AI -Generated Works : Courts and regulatory bodies remain
divided on whether AI -generated content qualifies for copyright protection. The absence
of clear guidelines discourages businesses from leveraging generative AI for creative andsoftware development applications.
•Trade Secret Vulnerabilities: Many AI companies rely on trade secrets to protect
proprietary algorithms and training datasets. However, without stronger legal safeguardsagainst model extraction attacks and unauthorized data access, trade secrets remainvulnerable to corporate espionage, cyber threats, and international IP theft.
•The Chilling Effect on AI Investment and Development: Uncertainty surrounding AI-
related IP protections discourages venture capital funding and research initiatives.Investors prefer regulatory clarity before committing capital to new technologies, andwithout a strong legal framework securing AI IP rights,  the U.S. risks ceding AI
leadership to jurisdictions offering stronger and more predictable IP protections.
IV. Recommendations to Enhance IP, Privacy and Data Security Protection in AI
Systems
A.C
ybersecurity  Enhancement  Recommendations
To mitigate  the risks  set forth above , the AI Action Plan should address: 
•Model- Specific Security Requirements . Establish security requirements based on model
risk, including: 
oSecurity testing protocols for adversarial attack resistance.
oTechnical standards for detecting and preventing data poisoning attacks.
oCryptographic protections for model security.
•AI Supply Chain Risk Management Framework. Develop comprehensive supply chain
security standards, including: 


oVendor assessment protocols specific to AI components and services.
oModel provenance verification requirements.
•Incident Response and Reporting Mechanisms. Create breach notification frameworks for
AI systems that account for:  
oDiffering  incident types like model inversion attacks.
oReporting thresholds and timelines specific to AI deployment contexts.
B.Privacy Protection  Recommendations
To mitiga te the privacy risks  set forth above , the AI Action Plan should address: 
•Implementation of a Federal Privacy Law : the lack of a comprehensive federal consumer
privacy law has created a fragmented regulatory environment where states —and even
individual cities and municipalities —are introducing their own AI and data protection
laws. This patchwork approach makes it increasingly difficult for data- driven AI
businesses to operate efficiently in the U.S., as they must navigate an inconsistent and
often contradictory web of privacy regulations across jurisdictions.
•Establishing Privacy by Design as a Cornerstone of AI Development : Privacy by design
ensures that AI models and data processing systems are built with proactive privacysafeguards, rather than treating privacy as an afterthought. AI models should bedeveloped with default privacy settings, ensuring that data minimization, encryption, anduser control mechanisms are integrated from the start.
•Risk-Based Privacy Assessments: AI developers should conduct privacy impact
assessments (PIAs) and risk evaluations throughout the AI lifecycle, documenting howdata is collected, used, and protected.
•Enforceable Standards for Privacy -Preserving AI : Privacy by design and use of privacy
enhancing technologies (PETs)  should be encouraged. Recommended measures can
include the following:
oSpecific technical parameters for differential privacy implementation that satisfyboth innovation needs and legal requirements.
oData processing limitations aligned with purpose specification requirements.


•Operationalizing Data Minimization Across AI Lifecycles : AI developers should
document data dependencies and justify data retention periods specific to model training,
validation, and deployment phases.
•Transparency and Explainability Requirements. User trust in AI often depends on A
decisions being transparent and explainable. Meaningful transparency requirements may
include:
oConsumer- facing disclosures explaining data usage, retention, and security
measures to enhance public trust.
C.IP Protection Recommendations
To address  the IP risks and concerns set forth above , the AI Action Plan should include: 
•Patent and Copyright Protections for AI- Generated Works : Establish legal clarity on
patentability and copyright ownership of AI-assisted innovations, ensuring that Americanbusinesses can secure rights to their intellectual property and protect their investments.
•Enforcement Against IP Theft and Misuse: Strengthen mechanisms for detecting and
preventing unauthorized use, replication, or distillation of AI models and training data.This includes enhancing legal recourse against IP theft, increasing enforcement actionsagainst foreign entities engaging in AI- related e conomic espionage, and collaborating
with allies to establish international AI IP protections.
•Promoting Secure AI Knowledge Sharing : Develop frameworks for safe collaboration in
AI research while maintaining robust safeguards against intellectual property theft and
model extraction. Establish federal guidelines for AI licensing agreements, open -source
best practices, and secure data -sharing protocols to enable responsible AI innovation
without exposing American models to exploitation.
V.Leveraging Blockchain Technology for IP , Cybersecu rity and Privacy Protection
In addition t o the recommendations provided above, we also recommend that the U.S.
explore ways to leverage blockchain technology in combination with AI to mitigate the intellectual property, privacy and cybersecurity risks often associated with AI systems. Blockchain ’s decentralized and immutable structure offers a transparent , and tamper- resistant  
framework for AI governance, mitigating risks related to data integrity, security breaches, 


algorithmic bias, and centralization concerns. As highlighted in my Forbes.com article on AI and 
blockchain integration, this synergy can potentially address AI's key vulnerabilities while 
fostering innovation and user trust.  
President  Trump's Executive Order on American Leadership in Digital Financial 
Technology emphasized the need for blockchain-driven security enhancements to bolster American financial strength and stability. Furthermore, the establishment of a U.S. Strategic Bitcoin Reserve reflects the recognition that decentralized technologies like blockchain are 
critical to maintaining America's economic and technological leadership. 
Applying the se principles to AI, the U.S. AI Action Plan should incorporate blockchain- based 
security frameworks to:  
•Enhance AI Data Integrity and Security: Blockchain's immutable ledger helps  ensure that
AI model training data, updates, and decision- making processes are tamper -resistant and
verifiable, mitigating risks such as data poisoning attacks and adversarial manipulations.
•Strengthen AI Supply Chain Resilience : The AI development lifecycle relies on multiple
third -party datasets and cloud computing infrastructures, which introduce risks of
unauthorized modifications and cyber threats. Blockchain-enabled AI model tracking canhelp make each  stage of an AI system's lifecycle —from data collection to deployment —
auditable and  potentially more  secure.
•Combat Deepfakes and AI- Generated Misinformation : Blockchain can serve as a trusted
registry for authentic digital content, helping to distinguish AI- generated disinformation
from verifiable sources. This is particularly critical as foreign adversaries  seek to
weaponize AI -generated deepfakes to influence American political discourse.
•Enable Privacy -Preserving AI with Zero -Knowledge Proofs (ZKPs) : Privacy remains a
significant concern in AI development. Blockchain- powered AI systems can leverage
ZKPs to verify AI transactions and computations without exposing underlying sensitivedata, helping to promote both compliance with privacy regulations and enhanced usertrust.
•Automate AI Governance and Compliance through Smart Contracts : Blockchain -enabled
smart contracts can help automate and streamline compliance with AI privacy guidelines,
IP protections, and security standards.


•Track Provenance and Protect Intellectual Property : One of the key challenges of AI
innovation is IP infringement and model replication by unauthorized actors. Blockchain's
ability to establish an immutable record of AI-generated content, model training data, andproprietary algorithms allows for verifiab le provenance tracking, ensuring that AI
developers and businesses can protect their intellectual property rights.
VI.Conclusion
A strong federal AI Action Plan must prioritize privacy, cybersecurity, intellectual
property protections, and regulatory flexibility to ensure U.S. leadership in AI. Establishing a governance framework that both protects user rights and fosters innovation will be key to maintaining America's strategic advantage in artificial intelligence.  
I welcom e the opportunity to contribute further insights. Thank you for your 
consideration.  


