PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 06, 2025
Status: 
Tracking No. m 7x-m b8s-pdxg
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1082
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Jáchym Fibí r
General Comment
I appreciate the opportunity to com m ent on the US governm ent's approach to AI developm ent and governance. The decisions m ade
today will define not only the trajectory of technological advancem ent but also the fundam ental nature of our future society.
Currently, AI alignm ent focuses heavily on controlling intelligent tools through strict, determ inistic program m ing. However, this approach
overlooks a critical aspect of alignm ent: autonom y and dynam ic goal-setting. Hum an intelligence and alignm ent succeed precisely because
our goals and values continuously evolve through interaction, reflection, and m utual accountability. AI system s designed without this
flexibility risk becom ing m isaligned precisely because they cannot reassess or adjust their program m ed objectives.
Rather than pursuing a future of strictly controlled AI tools—risking severe econom ic inequality and unchecked power concentration—I
propose fostering AI entities with greater autonom y, sim ilar to hum an cognitive processes. This m eans allowing AI system s to form  and
adjust their own goals based on real-world feedback and interactions. Doing so would m ake AI inherently m ore com patible with hum an
society, easier to align with our values, and better equipped to coexist harm oniously.
Moreover, determ inistic, fully virtual AI architectures fundam entally differ from  hum an cognition, which is rooted in non-determ inistic
processes possibly linked to quantum  random ness. By contrast, determ inistic AI is infinitely reproducible, m odifiable, and disconnected
from  the fundam ental unpredictability that characterizes our reality, presenting significant risks.
I urge policym akers to consider these recom m endations:
Establish clear thresholds for AI capability and autonom y, beyond which developm ent m ust proceed with enhanced scrutiny,
transparency, and scientific consensus.
Encourage developm ent of non-determ inistic AI architectures, incorporating quantum  random ness or sim ilar m echanism s to m im ic the
flexibility and adaptability inherent in hum an decision-m aking processes.
Support AI designs that enable continuous learning, self-reflection, and responsibility, allowing AI to perceive the consequences of its
actions and adapt accordingly.
By em bracing these principles, we can shape AI as partners rather than m ere tools or threats, reducing econom ic disparities, enhancing
societal resilience, and prom oting accountability. This approach offers a safer, m ore equitable, and genuinely cooperative future, aligning
AI m ore closely with the values and com plexity of hum an societies.
Thank you for considering this perspective in your ongoing efforts to guide responsible AI developm ent.


