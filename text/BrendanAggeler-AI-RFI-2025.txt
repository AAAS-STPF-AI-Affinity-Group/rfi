From: Brendan Aggeler
To: ostp-ai-rfi
Subject: [External] AI Action Plan (Belated)
Date: Sunday, March 16, 2025 4:51:41 AM
CAUTION: This email originated from outside your organization. Exercise caution when opening
attachments or clicking links, especially from unknown senders.
To whom it may concern, and with apologies for it only being brought to my attention a few hours past the
deadline. I hope you will still hear me regardless.
From:
B. A.Graduate, attempting reely[YOUR ADDRESS OR AT LEAST CITY, STATE]
Re: National Science Foundation’s Request for Information on the Development of an  
Artificial Intelligence (AI) Action PlanI am an everyday American, with a number of artist friends and a hope to break into the  
commissioned art market myself (albeit as a side business). The artist friends and  
acquaintances who make a living with their art have worked for years to develop their skills  
and cultivate a client base, to the point of being able to sustain themselves underThe AI systems made by Big Tech companies like OpenAI (Microsoft) and Google  
threaten to destroy thousands of American small businesses like those of my friends  
with their recent demand to create special carve outs in copyright law.AI systems can only be produced by first training on work made by people. My unique work,  
my more talented friends' work, and the work of hundreds of thousands of other everyday  
American creators was taken and fed into these AI systems without our consent or any  
compensation. They ingest our work, reassemble it, and then sell it back to artists' clients –  
directly competing with us and cutting us out of the marketplace. That's troublesome  
enough for an established artist or even a large company, and even worse for someone  
hoping to enter the market.Now these Big Tech companies are asking this administration to create exceptions and  
loopholes to make this practice of stealing American creators’ copyrighted work legal  
precedent. They are suggesting that if a machine ingests and reproduces copyrighted work,  
it is somehow suddenly “fair use”.
 
They seem to believe that anything and everything on the internet – regardless of who  
owns it – should be theirs for the taking; this is the attitude of an entitled manchild who has  
been told they can't use someone else's art that they found on a Google search without  
permission. The attitude of a lazy college student being told they have to write their own  
essay from scratch instead of taking a prefabricated one from the internet. They claim, as  
all lazy businessmen protesting regulation do, that if this administration does not allow them  
to rewrite the law in this way, it will stifle American innovation.


Instead, it will have the opposite effect. The purpose of American copyright law is to  
protect the incentive to create and innovate.  
If we the American people do not own our creations, and everything we put online will be  
stolen by Big Tech giants, what will be the incentive to create? If everyday Americans  
create a new innovative piece of computer code, a new visual design, or a new piece of  
music only to have it immediately stolen by Google and Microsoft, why bother creating it in  
the first place? How will we possibly make a living doing these things? The tech companies  
themselves will likewise lose any motivation to innovate, as corporations have a pattern of  
taking the path of least resistance wherever possible; this copyright exemption will render  
them directionless and incentivize them to let other people do the real work while they  
simply regurgitate it, and their output will stagnate as a result. This is especially true when  
you consider that with this exemption, there will be nothing to stop tech companies from  
plagiarizing each other's code - it is liable to create a world of degraded copies of degraded  
copies of degraded copies. America is already being left in the dust technologically and  
artistically by countries who can actually  innovate, and this will bring us to a standstill. It will 
be even worse if major creative industry players leave the country for greener pastures  
where their copyrights will be respected.
History has shown that when it comes to corporations, it is restriction and competition  that breeds
innovation - not exemptions. Look at the case of automotive engines, for example. Prior to the
environmental regulations of the seventies, American automotive engines were by and large crude slabsthat could have almost have been hammered out by cavemen because American car companies hadgotten to the point of "good enough" years ago and given up on further refinement; it was only when theneed to meet emissions regulations - and competition from foreign cars that already did - forced theirhands that they began innovating again. Companies without restriction and competition have no goal toaim for, no bar to clear; they become listless, dismotivated, directionless slugs, easily trod on by outsidecompetition.
Want to protect American innovation? Protect American creators. Do not create new 
copyright exemptions that allow Big Tech companies to exploit and steal from  
creators and everyday Americans without permission, compensation, or 
transparency.
This administration’s AI Action Plan should focus not on giving away creator content to Big  
Tech companies, but rather on ensuring a fair marketplace with competition:
First, the government should ensure that creators and everyday Americans give  
effective consent, so that we can decide when and where our work is used by AI 
systems.
Second, the AI Action Plan should encourage a robust licensing marketplace, so 
that the incentive to create for small businesses is preserved. Our work has immense  
economic value, so the value generated by that work should accrue to the original  
creators, not just Big Tech. This has the potential to turn AI from a threat and 
nuisance it presently is to a genuine asset, especially if AI companies have to  


compete to be first to license copyrighted work; that could create a new gold rush!
Finally, the AI Action Plan should require transparency from Big Tech companies, 
requiring them to disclose what material is in their training datasets, and label what  
content is AI generated. This will allow protection of artists' work as well as sensitive  
information, and make it easier to identify shortcomings that bias datasets as well as  
whether foreign interference (or corrupt management) is tampering with the output to  
make it more favorable to them.
I am not anti-technology or even entirely anti-AI. I am impressed by the capabilities of these  
AI systems when they are not being put to ill use, and I can see areas where they would be  
incredibly, genuinely useful. But we should not sacrifice the hard work of hundreds of  
thousands - if not millions - of Americans and give it away to Big Tech by rewriting copyright  
law. Who's going to be able to buy or subscribe to their products if all everyday Americans'  
wallets have in them are moths? And the capabilities of these AI systems will dramatically  
slow down their growth if this exemption is given - they will rapidly plateau and perhaps  
even regress, as the incentive to innovate will disappear.
I would also like to address the claim that this copyright exemption is necesssary for "national security."
This is, at best, an admission that OpenAI et al that they are too inept to compete against foreign AImodels without taking lazy shortcuts that they aren't even willing to pay royalties for (in which case theyare hardly worth the goverment's time in the first place). At worst, it is a complete fabrication designed toscam the American government by pushing a perceived easy button. Either way, it conveniently ignoresthat unchecked AI training actually poses national security risks. For one thing, it encourages a lazy,unfiltered approach to data gathering that will make these AI models susceptible to their training beingsabotaged with floods of garbage input - amusing now, disastrous if they were to see governmental use.For another, the insistence on gathering any and all data they can get their hands on is very likely to leadto misappropriation and even leaking of classified information - especially with Microsoft now trying to useMS Office to scrape people's documents. Even someone like Mr. Musk appears to recognize this threat,considering he expressed concern over OpenAI being integrated into MacOS. And heaven forbid one ofthese companies should have a data breach. This is made all the worse by the lack of oversight implicit inthe exemption. Another major issue is that this exemption would weaken these AI companies' ability todefend their own code from foreign parties (and each other, as stated above); OpenAI is currentlychallenging Deepseek on copyright grounds, but if it is decreed that AI companies have free rein to pilfercopyrighted work then they will have precious little leg to stand on.
Thank you for the opportunity to comment on these important issues, although I did not  
become aware of it until after the deadline.
All e-mails to and from this account are for NITRD official use only and subject to certain disclosurerequirements.If you have received this e-mail in error, we ask that you notify the sender and delete it immediately.


