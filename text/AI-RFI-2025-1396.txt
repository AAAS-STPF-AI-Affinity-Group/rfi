PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-3ldh-zktb
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1396
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  The Joint Com m ission
General Comment
On behalf of The Joint Com m ission, please see the attached letter.
Attachments
2025_03_14_The Joint Com m ission Letter_NITRD NCO_AI Action Plan RFI


March 14, 202 5 
Kirk Dohne , JD, MBA  
Acting Director  
National Coordination Office  
Networking and Information Technology Research and Development 
Office of Science and Technology Policy 2415 Eisenhower Avenue Alexandria, VA 22314  
[Submitted e lectronically to  and at regulations.gov] 
Dear Acting D irector Dohne: 
The Joint Comm ission appreciates the opportunity to provide input to the Office of Science and 
Technology Policy (OSTP) Networking and Information Technology Research and Development National Coordination Office request for information, Development of an Artificial Intelligence 
(AI) Action Plan (“Plan”) . 
The Joint Comm ission Enterprise includes The Joint Commission, Joint Commission Resources, 
Joint Commission International and the National Quality Forum. The Joint Commission is the nation’s oldest and largest health care accreditation organization. Founded in 1951, The Joint Commission’s mission is enabling and affirming the highest standards of health care quality and 
patient safety for all . An independent, not-for- profit organization with a global presence, The 
Joint Commission has programs that accredit or certify more than 2 4,000 health  care 
organizations ( HCOs ) and programs in the United States, including most of the nation’s 
hospitals. Although accreditation is voluntary, more than a dozen Joint Commission programs are recognized by federal and state regulatory bodies, including the Centers for Medicare and Medicaid Services (CMS) , for Medicare and licensure purposes.  
The Joint Commission recommends OSTP’s AI Action Plan address AI in health care. We 
would welcome the opportunity to work with OSTP on this critical area  and to share with 
you our draft Responsible Use of Health AI (RUAI) guidance  and our soon to be 
announced RUAI certification .   
As the nu mber of health care -integrated AI tools proliferates, health systems are using AI tools in 
a variety of ways to enhance clinical care. These  tools help clinicians to improve the quality of 
care, such as to diagnose disease earlier , personalize treatment plans, or identif y patients who 
may need additional follow -up care. For example, an AI tool used to improve diagnosis is the 
Sepsis Prediction and Optimization Therapy (SPOT) tool, which was developed by clinicians at a large health system to enhance sepsis detection within hospital medical/surgical units.  This 
model helped to save an estimated 6,600 lives over a four-year period.
1   
1 J. S. Guy, et al., Accelerating the Clinical Workflow Using the Sepsis Prediction and Optimization of Therapy (SPOT) Tool for Real -
Time Clinical Monitoring, 1 NEJM  CATALYST  3 (2020).  


AI is also helping HCOs to decrease administrative burden through improved scheduling and 
transcription tools that reduc e the time needed for clinicians to document patient encounters. AI  
also accelerates quality improvement efforts by improving the data captured in the electronic 
health record  and automating aspects of the quality reporting. AI -enabled quality measures are 
also being introduced. The National Quality Forum is developing guidance and 
recommendations for evaluating and implementing quality measures that use AI -enabled 
elements.  This guidance will help measure developers, health systems, and quality and 
accountability program owners (state oversight bodies, payers, and health systems) implement the next generation of AI- enabled quality measures.  By utilizing these tools, HCOs are able to 
improve quality and decrease costs through reducing errors and unnecessary care while streamlining administrative processes.  
However, t hese advances also bear some amount of risk. The increased reliance on large data sets 
also increases the possibility of a privacy breach, and algorithms may still yield false  outcomes, 
leading to possible misdiagnosis and ultimately, patient harm . Currently, there is no systematic 
mechanism to evaluate adverse outcomes and other critical AI monitoring needs. The health care 
field would benefit from a framew ork that help s implement guardrails for responsible AI use in 
health care. Providing a systematic approach to implementation and evaluation of tools is a critical driver for accountability and safety within the organization, allowing agile innovation 
without hampering the use and integration of AI tools throughout the organization. A health care 
sector framework could also promote learning  by establish ing best practices for information 
sharing, including monitoring adverse outcomes.  
While the FDA has provided oversight on the subset of AI tools falling  under the medical device 
classification , there are a wide array of AI tools that might be in use across a health care system, 
many of which exist outside of FDA’s jurisdiction. Other federal agencies could play a role as well. However, federal administrative processes and regulatory burden could stifle innovation 
and adoption. A few states have introduced regulations around health AI tools. S tate oversight 
though would mean AI developers and multi- state health care systems will need to navigate 50 
possible regulations, which too would hinder innovation. Therefore, other organizations will 
need to play a role to validate that a responsible AI framework is deployed at the health care 
delivery level. For example, HCOs will need to  monitor algorithms throughout the lifecycle to 
ensure that AI tools are still providing accurate outcomes over time, which may require updates or input from developers to prevent algorithmic drift while still enabling learning AI tools.   
In September  2024, The Joint Commission hosted a convening in Washington, D.C. to gather 
input from patient organizations, community providers, health systems,  health policy experts, 
congressional leaders, including Representative Obernolte (R -CA), who co -chaired the bipartisan 
House Task Force on Artificial Intelligence, and leading AI developers on a Responsible Use of 
Health AI framework. During the meeting, participants identified areas of opportunity, 
knowledge and training gaps, and where consensus is growing around certain governance structures. To further gather input on a framework , The Joint Commission conducted surveys of 
hospitals and health system s we serve on their top uses and concerns regarding AI tools.   


Drawing fro m the convening and HCO surveys, The Joint Commission is working on a draft 
Responsible U se of Health AI guidance and certification , and we would welcome the opportunity 
to share this with you. Our intent is to provide guidance to organizations that would enable them 
to drive innovation in health care and improve quality, while providing common sense guardrails to ensure that HCOs are meeting  their obligations to patients.  
The Joint Comm ission has already operationalized some of the key principles identified during 
the convening as part of its voluntary Responsible Use of Health Data (RUHD ™) certification  
for hospitals and health systems released in Janu ary 2024. Intended to support the responsible 
use and sharing of deidentified data that undergirds algorithm development and quality improvement, the RUHD certification provides HCOs with a blueprint of best practices for safely handling patient data for secondary  purposes. During the certification evaluation, HCOs 
must demonstrate that they have policies and procedures in place regarding governance structure, 
deidentification processes, transparency of use, limitations of use, patient engagement, and algorithm validation.  
As The Joint C ommission continues to collaborate with other thought leaders in the health care 
space, we plan to release guidance and certification on the Responsible U se of Health AI. The 
Joint Commission intends for this guidance and new certification to help HCOs enhance patient 
safety by mitigating and addressing AI safety concerns  while improving patient outcomes by 
leveraging AI’s potential . HCOs should take the lead to proactively  adopt th is framework  
because it  underscores the health care delivery system’s commitment to responsible use of AI , 
decreases the risk of government regulatory burden,  and most importantly , protects their patients 
from adverse events.  
The Joint Commission’s RUHD certification and our soon to be announced RUAI 
certification ensure fundamental guardrails while - consistent with the E xecutive Order - 
facilitating  innovation that can improve productivity, safety, and quality. 
The Joint Comm ission looks forward to an  opportunity to  work with the National Science 
Foundation and the Office of Science and Technology Policy in guiding AI implementation and adoption in the health care field . The Joint Commission will also continue to share what we learn  
with federal partners as well as health care systems to promote safe and high-quality  health care 
supported by AI tools. We are pleased to answer any questions you may have. Please do not 
hesitate to contact me or  Patrick Ross, Associate Director, Public Policy, a t 
 or 
Sincerely,  
Kathryn E. Spat es 
Executive Vice President, Public Policy and Government Relations 


