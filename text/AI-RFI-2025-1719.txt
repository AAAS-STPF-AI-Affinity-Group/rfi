PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 89-s003-7hnr
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1719
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Uber Technologies, Inc.
General Comment
Please see attached com m ents on behalf of Uber Technologies, Inc.
Attachments
Uber Response to OSTP RFI AI Action Plan - March 2025
Uber Response to OSTP AI Action Plan - March 2025


March 15, 2025 
Mr. Michael Kratsios 
Oﬃce Science and Technology Policy 
National Science Foundation 
Executive O ﬃce of the President 
Eisenhower Executive O ﬃce Building 
1650 Pennsylvania Avenue 
Washington, D.C. 20504 
[Submitted electronically via email] 
RE: Request for Information on the Development of an Arti ﬁcial Intelligence (AI) Action Plan 
I. Introduction
Purpose of Response 
Uber appreciates the opportunity to provide input on the development of President Trump’s AI 
Action Plan. As an early adopter of artiﬁcial intelligence for enhancing mobility and delivery 
services, Uber understands the transformative potential of AI when deployed responsibly. AI is 
integral to optimizing transportation, improving marketplace eﬃciency, and ensuring the safety of 
both riders and drivers. However, a fragmented regulatory approach to AI risks sti ﬂing innovation, 
imposing unnecessary compliance burdens, and ultimately limiting the potential bene ﬁts of 
AI-driven technologies. 
Uber is committed to harnessing AI to enhance e ﬃciency, improve safety, and create a seamless 
experience for consumers, drivers, and merchants. And various authorities already contribute to 
that experience. The Uber platform is highly regulated across the globe, in order to provide 
consumer protection and help make every experience feel safe. These Uber-speciﬁc rules 
operate alongside industry-wide rules regulating non-discrimination, privacy, and other important 
protections that should focus any AI rules on bona ﬁde regulatory needs. 
This response outlines key priorities, including the need to avoid overregulating low-risk AI 
applications, address the growing patchwork of state laws, and advocate for cohesive federal 
guidance that provides clarity for businesses and consumers alike. A well-crafted national AI 
framework should protect against harm while maintaining ﬂexibility to encourage responsible AI 
development and deployment. 
Uber’s Use of AI: Enhancing E ﬃciency and Safety 


Artiﬁcial intelligence has contributed to Uber’s platform for over a decade, playing a role in 
optimizing experiences for both earners and riders. AI helps process vast amounts of real-time 
data, allowing Uber to improve trip matching, enhance routing e ﬃciency, and provide seamless 
user experiences. By leveraging AI, Uber has been able to re ﬁne how trips are assigned, reduce 
wait times, and improve tra ﬃc ﬂow across its global network. 
For drivers, AI-driven optimization enables smarter trip o ﬀers that factor in real-time conditions, 
past tra ﬃc patterns, and driver preferences, leading to more e ﬃcient earnings opportunities. 
AI-powered routing dynamically adjusts based on evolving road conditions, reducing delays and 
enabling faster trip completions. AI also plays a key role in dynamic pricing, helping balance 
supply and demand by adjusting incentives during peak times or major events. By making these 
adjustments in real-time, Uber ensures that the marketplace remains eﬃcient, fair, and responsive 
to demand ﬂuctuations. 
For riders, AI enhances safety features, including trip monitoring systems that detect unusual 
events such as prolonged stops. This enables proactive interventions, ensuring that riders and 
drivers feel secure throughout their journeys. AI is also central to Uber’s fraud detection systems, 
identifying and preventing potentially fraudulent activity in real time. 
As AI plays an increasingly critical role in shaping mobility services, Uber remains committed to 
transparency and fairness in AI deployment. The company has invested in robust AI governance 
mechanisms, including dedicated teams that evaluate fairness, assess potential inaccuracies, and 
ensure accountability in AI-driven decisions. Additionally, Uber collaborates with external experts 
and stakeholders to reﬁne its AI systems and ensure responsible deployment. 
II. Addressing the Patchwork of State AI Regulations
The Emerging Patchwork of State AI Laws and the Need for Federal Leadership 
The rapid evolution of AI has led to a surge in state-level AI legislation—with more than 700 
AI-related bills introduced in state legislatures across the U.S. While well-intentioned, these 
eﬀorts are resulting in a fragmented and inconsistent regulatory landscape which leads to 
compliance and interoperability challenges, particularly for companies that operate across 
multiple jurisdictions.  But AI-powered platforms, by their very nature, operate across state lines 
and are eminently ripe for federal regulation.   
For example: 
●More than a dozen states have introduced bills that impose di ﬀerent standards on
AI-driven decision-making to prevent algorithmic discrimination. However, these laws
deﬁne "high-risk" AI di ﬀerently and signi ﬁcantly vary in their approach to addressing risk
mitigation and governance, creating overlapping and con ﬂicting compliance
requirements.


● The "developer vs. deployer" problem: Some bills would require a company like Uber, 
which both develops and deploys AI, to treat itself as two separate entities, resulting in an 
unnecessary compliance cycle where internal teams are forced to exchange paperwork 
and meet redundant administrative requirements. 
A fragmented AI regulatory landscape not only hampers innovation but also creates barriers to 
market entry, particularly for smaller companies and startups that lack the legal resources to 
navigate a complex and duplicative compliance environment. Without federal intervention, 
businesses will be forced to adapt to an unpredictable patchwork of regulations, leading to 
higher operational costs and reduced AI adoption. 
A federal AI framework should provide clear and uniform regulatory guidelines, ensuring that 
businesses do not have to navigate con ﬂicting state laws. AI governance should: 
● Preempt inconsistent state AI laws to prevent a fragmented compliance landscape. 
● Provide clear terminology and risk-based classi ﬁcation to di ﬀerentiate between low-risk AI 
applications (e.g., route optimization) and high-risk applications (e.g., biometric 
identi ﬁcation in hiring). 
● Ensure that regulations are narrowly tailored to address real risks without imposing undue 
burdens on businesses or consumers. 
In the absence of this federal framework, overregulation could hinder operational e ﬃciencies and 
compromise safety, without clear consumer bene ﬁts. 
III. A Call for a T rue Risk-Based Approach to Regulation  
A smart regulatory framework should support transparency without overburdening businesses. AI 
transparency measures should be reasonable and aligned with actual risk levels, rather than 
broad mandates that slow down development. In this respect, Uber recommends that a federal 
approach proceed from the following key premises: 
● Rely on existing background regulatory protections, such as those general rules on 
non-discrimination, consumer protection, and privacy.   
● Make genuine risk-based distinctions, including an appreciation that some AI 
applications involve such de minimis risk as to fall below the need for any special 
regulation.   
On relying on existing background regulatory protections: AI is a tool, like any other tool. 
Current laws, rules, and regulations already prohibit unlawful conduct, including misconduct 
facilitated by AI. These existing legal frameworks, which are supported by well-established 
regulatory and enforcement mechanisms, aim to address and prevent prohibited behavior, 
regardless of the method used to carry it out. In many instances, current legislation already 
provides an eﬀective means of ensuring AI’s safe and responsible use. Additional regulations 


should only be considered where clear gaps in existing regulations have been identi ﬁed. 
Moreover, additional regulations on topics such as explainability should be contextual and not 
onerous for businesses, especially considering that companies should not be required to give 
consumers information that they simply cannot use.   
On making genuine, risk-based distinctions: AI has given rise to public imagination. But the risks 
attendant in some use cases––such as health care, national security, the energy sector, and 
voting integrity––clearly diﬀer from the potential trivial uses such as o ﬀering shopping 
recommendations, or routing suggestions. And just as the risks di ﬀer, so too should the policy 
remedies necessarily di ﬀer. Many AI applications in the mobility industry are low-risk and do not 
involve high-stakes decision making (e.g. predictive demand modeling). If AI usage presents a 
clearly trivial risk, it should not be subject to special AI rules. As such, any federal framework 
should establish a de minimis signiﬁcance threshold, below which any regulatory burden would 
not apply at all. 
When developing new AI regulations, policymakers should take a measured approach to 
governance—one that is risk-based, adaptable to technological advancements, and conducive to 
innovation. Any AI-speciﬁc laws or regulations should target clear gaps in existing law that 
present signi ﬁcant risks to individuals, helping address AI-related harms without sti ﬂing progress. 
IV . Conclusion
Uber supports thoughtful AI governance that promotes innovation while addressing real risks. By 
aligning AI governance at the federal level, policymakers can eliminate regulatory uncertainty, 
reduce compliance costs, and foster responsible AI development. This federal approach is critical 
to avoiding regulatory fragmentation and ensuring the United States remains a leader in AI 
development.  
Thank you for your consideration of this response to the RFI. We look forward to working 
together with the Administration as it ﬁnalizes next steps on the AI Action Plan.  
Sincerely, 
Javier Correoso 
Head of Federal A ﬀairs 
Uber Technologies, Inc. 




March 15, 2025 
Mr. Michael Kratsios 
Oﬃce of Science and Technology Policy 
National Science Foundation 
Executive O ﬃce of the President 
Eisenhower Executive O ﬃce Building 
1650 Pennsylvania Avenue 
Washington, D.C. 20504 
[Submitted electronically via email] 
RE: Request for Information on the Development of an Arti ﬁcial Intelligence (AI) Action Plan 
I. Introduction
Purpose of Response 
Uber appreciates the opportunity to provide input on the development of President Trump’s AI 
Action Plan. As an early adopter of artiﬁcial intelligence for enhancing mobility and delivery 
services, Uber understands the transformative potential of AI when deployed responsibly. AI is 
integral to optimizing transportation, improving marketplace eﬃciency, and ensuring the safety of 
both riders and drivers. However, a fragmented regulatory approach to AI risks sti ﬂing innovation, 
imposing unnecessary compliance burdens, and ultimately limiting the potential bene ﬁts of 
AI-driven technologies. 
Uber is committed to harnessing AI to enhance e ﬃciency, improve safety, and create a seamless 
experience for consumers, drivers, and merchants. And various authorities already contribute to 
that experience. The Uber platform is highly regulated across the globe, in order to provide 
consumer protection and help make every experience feel safe. These Uber-speciﬁc rules 
operate alongside industry-wide rules regulating non-discrimination, privacy, and other important 
protections that should focus any AI rules on bona ﬁde regulatory needs. 
This response outlines key priorities, including the need to avoid overregulating low-risk AI 
applications, address the growing patchwork of state laws, and advocate for cohesive federal 
guidance that provides clarity for businesses and consumers alike. A well-crafted national AI 
framework should protect against harm while maintaining ﬂexibility to encourage responsible AI 
development and deployment. 
Uber’s Use of AI: Enhancing E ﬃciency and Safety 


Artiﬁcial intelligence has contributed to Uber’s platform for over a decade, playing a role in 
optimizing experiences for both earners and riders. AI helps process vast amounts of real-time 
data, allowing Uber to improve trip matching, enhance routing e ﬃciency, and provide seamless 
user experiences. By leveraging AI, Uber has been able to re ﬁne how trips are assigned, reduce 
wait times, and improve tra ﬃc ﬂow across its global network. 
For drivers, AI-driven optimization enables smarter trip o ﬀers that factor in real-time conditions, 
past tra ﬃc patterns, and driver preferences, leading to more e ﬃcient earnings opportunities. 
AI-powered routing dynamically adjusts based on evolving road conditions, reducing delays and 
enabling faster trip completions. AI also plays a key role in dynamic pricing, helping balance 
supply and demand by adjusting incentives during peak times or major events. By making these 
adjustments in real-time, Uber ensures that the marketplace remains eﬃcient, fair, and responsive 
to demand ﬂuctuations. 
For riders, AI enhances safety features, including trip monitoring systems that detect unusual 
events such as prolonged stops. This enables proactive interventions, ensuring that riders and 
drivers feel secure throughout their journeys. AI is also central to Uber’s fraud detection systems, 
identifying and preventing potentially fraudulent activity in real time. 
As AI plays an increasingly critical role in shaping mobility services, Uber remains committed to 
transparency and fairness in AI deployment. The company has invested in robust AI governance 
mechanisms, including dedicated teams that evaluate fairness, assess potential inaccuracies, and 
ensure accountability in AI-driven decisions. Additionally, Uber collaborates with external experts 
and stakeholders to reﬁne its AI systems and ensure responsible deployment. 
II. Addressing the Patchwork of State AI Regulations
The Emerging Patchwork of State AI Laws and the Need for Federal Leadership 
The rapid evolution of AI has led to a surge in state-level AI legislation—with more than 700 
AI-related bills introduced in state legislatures across the U.S. While well-intentioned, these 
eﬀorts are resulting in a fragmented and inconsistent regulatory landscape which leads to 
compliance and interoperability challenges, particularly for companies that operate across 
multiple jurisdictions.  But AI-powered platforms, by their very nature, operate across state lines 
and are eminently ripe for federal regulation.   
For example: 
●More than a dozen states have introduced bills that impose di ﬀerent standards on
AI-driven decision-making to prevent algorithmic discrimination. However, these laws
deﬁne "high-risk" AI di ﬀerently and signi ﬁcantly vary in their approach to addressing risk
mitigation and governance, creating overlapping and con ﬂicting compliance
requirements.


●The "developer vs. deployer" problem: Some bills would require a company like Uber,
which both develops and deploys AI, to treat itself as two separate entities, resulting in an
unnecessary compliance cycle where internal teams are forced to exchange paperwork
and meet redundant administrative requirements.
A fragmented AI regulatory landscape not only hampers innovation but also creates barriers to 
market entry, particularly for smaller companies and startups that lack the legal resources to 
navigate a complex and duplicative compliance environment. Without federal intervention, 
businesses will be forced to adapt to an unpredictable patchwork of regulations, leading to 
higher operational costs and reduced AI adoption. 
A federal AI framework should provide clear and uniform regulatory guidelines, ensuring that 
businesses do not have to navigate con ﬂicting state laws. AI governance should: 
●Preempt inconsistent state AI laws to prevent a fragmented compliance landscape.
●Provide clear terminology and risk-based classi ﬁcation to di ﬀerentiate between low-risk AI
applications (e.g., route optimization) and high-risk applications (e.g., biometric
identi ﬁcation in hiring).
●Ensure that regulations are narrowly tailored to address real risks without imposing undue
burdens on businesses or consumers.
In the absence of this federal framework, overregulation could hinder operational e ﬃciencies and 
compromise safety, without clear consumer bene ﬁts. 
III. A Call for a T rue Risk-Based Approach to Regulation
A smart regulatory framework should support transparency without overburdening businesses. AI 
transparency measures should be reasonable and aligned with actual risk levels, rather than 
broad mandates that slow down development. In this respect, Uber recommends that a federal 
approach proceed from the following key premises: 
● Rely on existing background regulatory protections, such as those general rules on
non-discrimination, consumer protection, and privacy.
● Make genuine risk-based distinctions, including an appreciation that some AI
applications involve such de minimis risk as to fall below the need for any special
regulation.
On relying on existing background regulatory protections: AI is a tool, like any other tool. 
Current laws, rules, and regulations already prohibit unlawful conduct, including misconduct 
facilitated by AI. These existing legal frameworks, which are supported by well-established 
regulatory and enforcement mechanisms, aim to address and prevent prohibited behavior, 
regardless of the method used to carry it out. In many instances, current legislation already 
provides an eﬀective means of ensuring AI’s safe and responsible use. Additional regulations 


should only be considered where clear gaps in existing regulations have been identi ﬁed. 
Moreover, additional regulations on topics such as explainability should be contextual and not 
onerous for businesses, especially considering that companies should not be required to give 
consumers information that they simply cannot use.   
On making genuine, risk-based distinctions: AI has given rise to public imagination. But the risks 
attendant in some use cases––such as health care, national security, the energy sector, and 
voting integrity––clearly diﬀer from the potential trivial uses such as o ﬀering shopping 
recommendations, or routing suggestions. And just as the risks di ﬀer, so too should the policy 
remedies necessarily di ﬀer. Many AI applications in the mobility industry are low-risk and do not 
involve high-stakes decision making (e.g. predictive demand modeling). If AI usage presents a 
clearly trivial risk, it should not be subject to special AI rules. As such, any federal framework 
should establish a de minimis signiﬁcance threshold, below which any regulatory burden would 
not apply at all. 
When developing new AI regulations, policymakers should take a measured approach to 
governance—one that is risk-based, adaptable to technological advancements, and conducive to 
innovation. Any AI-speciﬁc laws or regulations should target clear gaps in existing law that 
present signi ﬁcant risks to individuals, helping address AI-related harms without sti ﬂing progress. 
IV . Conclusion
Uber supports thoughtful AI governance that promotes innovation while addressing real risks. By 
aligning AI governance at the federal level, policymakers can eliminate regulatory uncertainty, 
reduce compliance costs, and foster responsible AI development. This federal approach is critical 
to avoiding regulatory fragmentation and ensuring the United States remains a leader in AI 
development.  
Thank you for your consideration of this response to the RFI. We look forward to working 
together with the Administration as it ﬁnalizes next steps on the AI Action Plan.  
Sincerely, 
Javier Correoso 
Head of Federal A ﬀairs 
Uber Technologies, Inc. 




