PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-20q5-ubh9
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7934
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Nicholad Gotch 
General Comment
I’m  an software engineer at a university. As som eone who uses AI regularly both in m y personal life and m y job I have a reasonable
understanding of it. With that said, I do think regulating som e aspects of the technology m akes sense, m y greatest concern is the use of it
to propagate m isinform ation. On the other side, I am  not concerned about how it ingests inform ation (“learns”). The idea of copyright has
long been to preserve the original creator’s claim  to what they produce so that they m ay earn a fair value for their work. The idea though
is that the value is in the transform ation of that inform ation, along the lines of, “Is what has been produced transform ative”? People, the
sam e as AI albeit in different way, ingest knowledge, transform  it, and output it in a new form . We don’t consider that theft unless the
transform ation is significant enough to pass a (som ewhat vague) bar of originality: that is, enough to call it som ething else, som ething new.
Content creators today all do this: ingesting inform ation and regurgitating it in a different (ideally better) form . When the output is too close
to the original we call it plagiarism , theft, and copyright violation. This determ ination is m ade by com paring the specific output with what
was originally input. On a case by case basis, we m ake these sorts of judgem ents. How the person originally got the inform ation isn’t as
relevant to the judgem ent as how close the work is to the original.
AI does this sam e thing, faster and in a different way, but in the end the question is how unique is the output produced? It seem s that the
way to judge AI generated content should be the sam e as with hum ans: if the output is too sim ilar to the input, it’s plagiarized or a
copyright violation. It seem s to only lim it the potential of AI system s to im pose arbitrary restrictions on what content they can ingest, if the
inform ation is public. If the output is found to be in violation, the prom pter who generated it through the tool is the guilty party.
That all being said, I can see som e value to copyright holders whose inform ation is pay-restricted to have special licensing that
differentiates between hum an audiences and AI ones, m ainly because the price determ ination for hum ans assum es hum an lim itations on
how quickly and how m uch of the content they can actually ingest. It’s reasonable to assum e AI will consum e significantly greater am ounts
than hum ans.
Lastly, the question of who owns AI generated work is not as clear. My initial expectation is that the prom pter using the tool, ie: the first to
see the output of the m achine, gains rights to the work, which would also m ake them  responsible for validating that the work is not in
violation and transform ative enough. Although an argum ent could be m ade to call the output as in the public dom ain, that creates a
dilem m a for when it violates legal copyright. Likewise I would not consider the AI system  owner the owner of the work sim ply because
that would put considerable and unreasonable responsibility on them  while also m aking the system  less valuable to the users.
In short: I favor som e regulations to curb harm , som e regulations to cover access to pay-restricted content, do not support AI system
m akers being responsible for the content their system s produce (with exceptions to lim it harm ful content), and support copyright
ownership belonging to the prom pter of the AI system .


