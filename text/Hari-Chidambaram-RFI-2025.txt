 
   3/12/2025 via FDMS  
Hari Chidambaram   
I think there needs to be consideration of what AGI (Artificial General Intelligence) really means 
and the danger of creating AIs smarter than us in every way. AGI could mean that every human 
is out of a job (given that the AI can do anything that a human can do), and if it is not aligned 
with human interests, could also result in complete extinction. This is in addition to the concerns 
of power dynamics. I suggest global coordination to prevent race dynamics, resulting in safer 
development; banning open so urce AI to prevent dangerous actors from jailbreaking the models 
and any actor from improving it (to potentially dangerous levels); and simple, clear, transparency 
requirements for leading AI labs so we can see what is going on. Nationalization of AI might  be 
needed at some point. Possible further resources: Superintelligence FAQ --
https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence -faq AI Alignment 
video--https://youtu.be/EUjc1WuyPT8?si=Nl3sD6Ybz3KFwrdF Zvi AI posts --
https://www.lesswrong.co m/posts/kqz4EH3bHdRJCKMGk/ai -106-not-so-fast  
 


