From: Harold G. Eder ll
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Wednesday, March 12, 2025 10:18:27 AM
CAUTION: This email originated from outside your organization. Exercise caution when opening
attachments or clicking links, especially from unknown senders.
To Whom It May Concern,
I am submitting this comment in response to the Request for Information (RFI) on the
development of the Artificial Intelligence (AI) Action Plan, with a specific focus on the use,storage, and replication of actors’ and broadcasters’ images, likenesses, and bio-metric data.As AI technologies advance, it is imperative that the AI Action Plan incorporates robustprotections for these individuals, drawing on existing legislative efforts to address theintersection of artificial intelligence, data privacy, and intellectual property rights.
**Actors' and Broadcasters' Image and Likeness Protection:**
 
The rapid evolution of AI has made it increasingly feasible to replicate and manipulate the
images, voices, and likenesses of actors, broadcasters, and other public figures, often withouttheir consent. These attributes are not only integral to their professional identities but alsocritical to their livelihoods. Existing legislative efforts, such as California’s AB 2602 (signedinto law on September 17, 2024), provide a strong foundation by requiring explicit consentand detailed contractual specifications for the use of AI-generated digital replicas of aperformer’s voice or likeness. Similarly, the federal “Nurture Originals, Foster Art, and KeepEntertainment Safe Act” (NO FAKES Act), introduced in the U.S. Senate in July 2024 and theHouse in September 2024, aims to establish a property right over digital replicas, holdingindividuals and platforms liable for unauthorized use. I urge the AI Action Plan to build onthese measures by mandating consent for any AI-generated use of likenesses—whether inentertainment, advertising, or beyond—and by implementing safeguards to prevent misuse,ensuring individuals retain autonomy over their image, voice, and persona.
**Bio-metric Data Usage and Privacy:**
 
The proliferation of AI-driven technologies, such as facial recognition and voice synthesis, has
heightened the risks associated with bio-metric data collection, storage, and replication. Thishighly sensitive data can be exploited, threatening individuals’ privacy, safety, and dignity.Tennessee’s Ensuring Likeness Voice and Image Security (ELVIS) Act, effective July 1,2024, explicitly protects an individual’s voice as a property right, offering a model foraddressing bio-metric data in AI contexts. Additionally, California’s AB 1836 (signed into lawon September 17, 2024) extends posthumous protections by prohibiting unauthorizedcommercial use of deceased performers’ digital replicas without estate consent. The AI ActionPlan should adopt and expand upon these precedents by establishing stringent regulations forbio-metric data, including robust security measures to prevent unauthorized access, clearrights for individuals to access and revoke consent for its use, and mandates for data deletionwhen no longer needed.
**Transparency and Accountability:**
 


Transparency is a cornerstone of ethical AI deployment. Actors and broadcasters must be
informed about how their bio-metric data, images, and likenesses are utilized in AI systems.
The federal “Content Origin Protection and Integrity from Edited and Deep faked Media Act”(COPIED Act), introduced in July 2024, exemplifies this principle by requiring provenancedata to identify AI-generated content, empowering creators to track and control its use.Organizations leveraging such data should be held accountable through clear guidelines on AImodel training and data sourcing, as well as regular audits to ensure compliance with privacylaws and ethical standards. The AI Action Plan should integrate these accountabilitymechanisms to foster trust and responsibility in AI development.
**Conclusion:**
 
The AI Action Plan must prioritize comprehensive protections for actors, broadcasters, and
others whose images and bio-metric data are implicated in AI technologies. By drawing onexisting bills—such as California’s AB 2602 and AB 1836, Tennessee’s ELVIS Act, andfederal proposals like the NO FAKES Act and COPIED Act—policymakers can craft aframework that safeguards individual rights, ensures privacy, and promotes ethical AIinnovation. I appreciate the opportunity to contribute to this vital discussion and stronglyencourage the inclusion of these measures in the AI Action Plan to address the challengesposed by AI in a rapidly changing digital landscape.
References:US state-by-state AI legislation snapshot
bclplaw.com
Governor Newsome signs bills to protect digital likeness of performers | Governor of
Californiagov.ca.govhttps://www.munckwilson.com/news-insights/ai-likeness-protections-legislative-update/
Guarding the Spotlight: Protecting Performers’ Likeness Through AI Legislation |
Published by Villanova Law Reviewvillanovalawreview.com
Protecting the Right of Publicity in the Age of AI
sports-entertainment.brooklaw.edu
Celebrity AI deepfakes are flooding the internet. Hollywood is pushing Congress to fight
back | CNN Businesscnn.com
Removing Barriers to American Leadership in Artificial Intelligence
whitehouse.gov
Comparing California’s AI-Likeness Bills with the Federal NO FAKES Act of 2024
womblebonddickinson.comhttps://www.thewrap.com/gavin-newsom-signs-ai-bills-to-protect-actors-digital-likeness/
Decoding California’s Recent Flurry of AI Laws | Foley & Lardner LLP


foley.com
https://leg.colorado.gov/bills/hb24-1468
AI experts see legislation moving forward in 2023
biometricupdate.com
https://www.pbs.org/newshour/politics/new-bipartisan-bill-would-require-labeling-of-ai-
generated-videos-and-audio
Biometric Privacy in Film, Television, Music, and Gaming
perkinscoie.com
https://www.congress.gov/crs-product/LSB11052
Sincerely,
Harold G. Eder II
3524 Caley Rd
Newtown Square, Pa
19073-3428
Amateur Radio Call Sign: KC3ACC
The information transmitted is intended only for the person(s) or entity to which it is addressed and may contain  
confidential and or privileged material and should be treated as a confidential communication. If the reader of this  
message is not the intended recipient, or the employee or agent responsible for delivering this to the intended  
recipient, you are hereby notified that your access is unauthorized, and any review, dissemination, distribution or  
copying of this message including any attachments is strictly prohibited. If you are not the intended recipient, please  
immediately advise the sender by reply e-mail that this message has been inadvertently transmitted to you and delete  
this e-mail from your system. Thank you for your cooperation.
All e-mails to and from this account are for NITRD official use only and subject to certain disclosure
requirements.If you have received this e-mail in error, we ask that you notify the sender and delete it immediately.


