From: Hudson Gouge
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Thursday, February 6, 2025 10:21:08 AM
CAUTION: This email originated from outside your organization. Exercise caution when opening
attachments or clicking links, especially from unknown senders.
The Trial of Freedom: AI Regulation
Ever since the introduction of transformer architecture in the 2017 paper “Attention Is All You
Need,” AI development has accelerated at an unprecedented pace. New models are releasedalmost weekly, with thousands of companies all over the world contributing to this rapidlyadvancing field. These rapid changes and advancements in artificial intelligence haveprompted governments around the world to consider regulating this transformativetechnology. However, these lawmakers have come to find that this is not nearly as easy as itseems. In fact, AI cannot be effectively regulated; moreover, even if it were possible,regulation would not be a good idea.
Artificial intelligence is reshaping the way people interact with technology, from writing to
creating art and beyond. There are many different AI model architectures and types. A largelanguage model, or LLM, is a statistical engine designed to calculate probabilities for the nextword in a sequence, or, in other words, they predict what word will come next in a piece ofwriting. The statistical nature of these models means that they can be applied for variouspurposes, including emulating human language, predicting responses in conversations, andmuch more. By far, most LLMs utilize the transformer architecture  — in fact, it was the
transformer architecture that revolutionized the field in the first place (Vaswani et al.). Forimage and video generation, diffusion models are the most prominent. Diffusion models workby starting with random noise and gradually converting it into a coherent image or videoguided by a text prompt (Sohl-Dickstein et al.). All AI models work by using mathematicaloperations on an input to produce an output. In the case of LLMs, the input is the current stateof the text, and the output is the probabilities for the following token. During training, thevalues used in these operations are adjusted to produce the correct output given the expectedinput and output from the training data. While AI models can be built and trained on anycomputer with sufficient memory, the larger the model, the more compute required to train it.Thus, the largest models, such as those used for ChatGPT or Stable Diffusion, were trainedusing large data centers or supercomputers. However, once trained, these models can be easilyrun on any computer with sufficient memory, including phones and laptops. For all models,the training data used determines how the model responds, what the model knows, and what itwill be good at. Because LLMs are so versatile and can be used for a variety of applications,many lawmakers want to regulate LLMs to prevent them from doing or assisting withunethical or unlawful behavior. Another concern is that AI models can be used to createdeepfakes, which are fake articles, images, videos, or audio. Deepfakes can be used tomisinform people, provide false evidence, or manipulate public opinion by creating realisticbut fabricated content. All these potentially dangerous use cases drive the movement forgreater regulation in the field.
Regulating AI, however, is extremely difficult. “Open-source AI models are particularly hard
to set guardrails around because the developers could live anywhere in the world. Once a


model is released, any person with access to the internet can change, update, or modify the
model” (Hutton). In addition, anyone can train an AI model as long as their computer has
sufficient memory. While the largest models do indeed require massive amounts of compute,smaller models can be trained on consumer devices. Thus, there is nothing preventingsomeone from using their laptop to train an LLM designed to depress, insult, or spreadconspiracy theories. Even more troubling is that existing LLMs can be prompted to do suchthings without retraining. Remember, LLMs are just statistical engines; given an input, theyproduce probabilities of what may come next. So, if one provides as the input, ‘The followingis a list of insults:,’ the LLM will output probabilities of the insulting words that would beexpected to come after that. LLMs can be trained to do anything. One could even train amodel to answer with an insult, no matter what the input is. Effective regulation of AI isimpractical when scenarios like this are possible.
Even so, many governments have been proposing legislation that would require direct
oversight of AI models, limit the data available for training, or restrict the publication of AImodels. These concepts, while well-meaning, would create monopolies and prevent smallercompanies from competing. Sam Altman, the CEO of OpenAI, the largest AI company in theworld, is a big supporter of strict AI regulations. “Altman’s desire to introduce significant redtape could suppress startup competitors attempting to displace industry heavyweights likeOpenAI, cause a brain drain of engineering talent and lead America to lose its technologicaladvantage over China” (Sharma). The fact that large corporations are the ones pushing forregulation should be a cause for concern. Currently, AI is one of the most open andcompetitive fields of research. The current state of AI development is such that individuals cancompete with large corporations. By requiring government oversight, individuals and smallstartups are, for the most part, prevented from competing. This would solidify major players inthe AI field as monopolies without any direct competition.
The newfound power of AI has made it easier than ever to fabricate fraudulent data, such as
messages, articles, images, videos, and audio recordings. This data is becoming increasinglyrealistic as AI advances, and it has become difficult to distinguish between fake and real. Thisdilemma is not new; techniques to create fraudulent data or alter evidence have existed formany years in the form of digital editing and alteration. AI simply makes this far moreaccessible and easier to do. “Deepfakes are seen as a threat to sow misinformation and executescams on a mass scale. However, users still have the right to create images and other mediathrough AI. ‘Any attempts to regulate the content produced by generative AI, including [AImodels], run the risk of operating broadly to restrict protected expression,’ Esha Bhandari, thedeputy director of the ACLU’s Speech, Privacy, and Technology Project, wrote in a blog post.The ability to lie is constitutionally protected outside of narrowly defined circumstances, sogenerative AI models must be allowed to create the images” (Hutton). Legally, the ability tocreate, train, and use AI models is protected as free speech, similar to software. “In fact, AIsoftware is just like any other software
 … such software can be executed on a primitive Turing
Machine [computer] — just like any other software that people use for many decades”(Krasadakis). Such software is protected as free speech in the U.S. according to a 1995 rulingby the 9th U.S. Circuit Court of Appeals (Hutton). In addition, parodies and lying are both alsoprotected by law in the U.S. Thus, AI models cannot be effectively regulated or bannedwithout a significant reworking of the United States legal system. Many proponents of AIregulation have suggested that since the models themselves and their usage cannot beeffectively regulated, the solution is to have government regulation and censoring of all socialplatforms to ensure misinformation cannot spread (“The Solution”). However, this prompts amuch larger and more controversial debate on the breadth of free speech, and it also would


require significant overhauls to the U.S. Constitution and legal system. Depending on the
country, however, the laws surrounding this may be different. Nevertheless, the idea of
government controlling what programs one can write is scary.
Many argue that the risk of AI is far too great to ignore and that governments must at least try
to regulate it, even if it is ineffective or requires a significant reworking of laws. “The onlyeffective way to stop deepfakes is for governments to ban them at every stage of productionand distribution” (“The Solution”). Not only would this be a violation of free speech, but it isalso impractical. Consider Prohibition in the U.S. The United States government tried to banalcohol, but the effort did not succeed; people still made and consumed alcohol. The sameapplies to AI models and deepfakes — people will still create and use them even if they arebanned. Banning deepfakes will just push their development and usage underground. Peoplewill still train these models, spread them online, and send them to friends. Regulating orbanning deepfakes will only give people a false sense of security. It will only make theproblem worse. Due to the perception that deepfakes are banned, people would likely be morewilling to accept content they find online as accurate, even when that cannot be guaranteed.“‘Enforcing watermarking on all the content that you can enforce it on would actually lendcredibility to the most harmful stuff that’s coming from the systems that we can’t intervenein,’ he [Daniel Leufer, a senior policy analyst at the digital rights organization Access Now]says” (Heikkilä). Instead, it is better to let society adapt on its own. The world has alreadyreached a point where one cannot trust the information or evidence that is seen, and there is nogoing back from it, no matter what is done. It is better to let society adapt on its own ratherthan attempt to intervene. When man learned to fly, aviation was envisioned as anextraordinary development for travel and trade. Yet, even so, it was used to pursue war. Thesame has been true for every new technology since the dawn of creation. Innovation can neverbe contained; the same innovation that brings limitless good at the same time perpetrates athousand crimes.
Change is often perceived as frightening, especially when one does not know what will come
next. Yet through it all, society manages to adapt, and people learn to live in an ever-changingworld. Every new technology has brought with it new paths for deception and harm. Yet thissame technology also brings new ways to make the world a better place. It has always beenthis way and still is. People cannot choose to let fear compromise the resolutions of freespeech and innovation. Regulating AI is a vain endeavor; it cannot be done, and it should notbe done. Lawmakers and leaders must understand these things so that the world may remainopen and forever free. In the transformer architecture, one finds the beginning of a trial for theworld that will test humanity’s commitment to freedom.
The key to American leadership in the field of AI is open source research. That is what got
this field going in the first place, and that is what drives competition in the market.
 
Open Source AI: Fueling Innovation and Competition in America
In recent years, artificial intelligence has emerged as a pivotal force reshaping industries, societies, and economies


globally. To ensure that America remains at the forefront of AI development, it is imperative to embrace open
source research and open weights models. These methodologies have proven to be the cornerstone of innovation and
competition, providing an efficient framework for collaborative growth and ingenuity.
The concept of open source research in AI pertains to openly sharing code, data, and methodologies. This openness
facilitates a collective pooling of intellectual resources, allowing researchers, developers, and organizations to buildupon each other’s work. By breaking down barriers to entry, open source research democratizes access to cutting-edge technology, enabling even small startups and individual developers to participate in AI advancements. Thiscollaborative environment fosters a vibrant ecosystem where diverse ideas can thrive, leading to breakthroughinnovations.
Open weights models, which involve releasing the trained parameters of AI models to the public, are another crucial
component in driving AI progress. By providing access to these models, developers can refine and tailor them forspecific applications without having to start from scratch. This not only accelerates the pace of innovation but alsoensures that resources are allocated more efficiently, promoting a sustainable growth environment.
One of the most significant benefits of open source research is the enhanced transparency and accountability it
provides. With open access to methodologies and data, researchers and developers can scrutinize and improve uponexisting models, ensuring that ethical standards and biases are addressed collaboratively. This transparency iscritical in building public trust in AI technologies and their applications across various sectors.
Moreover, open source research and open weights models are pivotal in maintaining a competitive edge in the
global AI landscape. By fostering an environment of collaboration and shared learning, America can attract toptalent from around the world, positioning itself as a hub for AI excellence. This influx of expertise will furthercatalyze innovation, creating a self-sustaining cycle of growth and development.
The government’s call for information and ideas for an AI Action Plan underscores the importance of leveraging
open source methodologies to ensure continued leadership in the AI domain. By prioritizing open collaboration andresource sharing, America can harness the full potential of its creative and intellectual capital, driving unprecedentedadvancements in AI technology.
In conclusion, open source research and open weights models are indispensable tools for fostering innovation and
competition in America. By embracing these methodologies, the nation can continue to lead in AI development,paving the way for a future characterized by technological prowess and economic vitality. The commitment toopenness and collaboration will not only drive scientific progress but also reinforce the values of freedom andingenuity that define the American spirit.
Sincerely,
Hudson Gouge


All e-mails to and from this account are for NITRD official use only and subject to certain disclosure
requirements.If you have received this e-mail in error, we ask that you notify the sender and delete it immediately.


