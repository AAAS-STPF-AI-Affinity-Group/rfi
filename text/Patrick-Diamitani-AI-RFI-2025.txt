Response to the National Science Foundation and Office of Science & Technology 
Policy’s Request for Information on the Development of an Artificial Intelligence Action 
Plan 
90 Fed. Reg. 9088 (Feb. 6, 2025), Docket No. NSF_FRDOC_0001  
Submitted: March 15, 2025  
Patrick Diamitani, Founder and CEO, GPTPAT 
Executive Summary  
This proposal outlines three activities to sustain and enhance U.S. AI leadership: an opt-in data 
contribution system for Large Language Models (LLMs), a national AI credit fund for equitable 
access, and an AI Safety Protocol for risk management. These initiatives align with the goals of 
President Trump’s AI Executive Order on January 23, 2025, to promote human flourishing, 
economic competitiveness, and national security (Removing Barriers to American Leadership in 
Artificial Intelligence). Introduction  
The United States stands at the forefront of AI innovation, and it is imperative to maintain and 
enhance our global leadership. The recent RFI, as part of the AI Action Plan directed by 
Executive Order 14179, seeks input on priority actions to ensure AI promotes human flourishing, 
economic competitiveness, and national security, while avoiding burdensome regulations on 
private sector innovation. My proposal addresses data ethics, access equity, and safety, aligning 
with the RFI’s focus on hardware, data centers, energy consumption, and AI governance. Activity 1: Opt-In Data Contribution System for LLMs  
Concept: Create a voluntary platform where individuals contribute personal data (e.g., writings, 
expertise) to train LLMs, receiving compensation. 
Rationale: Current AI training often relies on unconsented datasets, raising privacy and equity 
concerns. This system, inspired by AI data marketplaces like Defined.ai (Defined.ai - Home 
page) and Trainspot (This startup is creating an AI training data marketplace), empowers citizens to monetize data, fostering an ethical economy for encryption and security. It aligns with 
the RFI’s emphasis on data privacy and security throughout the AI lifecycle. 
Implementation Steps: 
●Conduct a feasibility study in 2025 to assess legal and technical requirements.


●Partner with NIST in 2026 to develop encryption standards, ensuring compliance with
GDPR and CCPA.
●Launch a blockchain-based marketplace with firms like xAI in 2027, offering
micro-payments (e.g., $0.01 per kilobyte) based on data utility.
●Pilot with 100,000 participants in 2028, refining based on feedback, with quality control
measures like ratings from AI trainers.
Expected Impact: Enhances AI diversity, boosts individual income (projected market
size: $10 billion by 2030, per AI Training Dataset Market report (AI Training Dataset
Market worth $9.58 billion by 2029)), and sets global ethical standards, reducing bias in
AI models. 
Activity 2: National AI Credit Fund Subsidy  
Concept: Subsidize usage tokens for AI services to ensure broad access, treating AI as a utility 
like electricity. 
Rationale: High costs could exclude many from AI benefits, mirroring early internet disparities. 
This aligns with government subsidies for technology, like the Tech Hubs program (Biden-Harris 
Administration Awards Additional $210 Million Tech Hub Grants), but focuses on individual access. It addresses the RFI’s goal of promoting innovation and competition.  
Implementation Steps: 
●Allocate $50 million annually via NSF in 2026, funded by repurposing 1% of federal R&D
budget ($1.8 billion in 2024 terms) and a 0.5% tax on AI firms’ profits.
●Offer $500 monthly credits per eligible small business or researcher, based on average
AI service costs (estimated at $1,000/month), scaling to 50% adoption by 2030.
●Partner with AI providers like AWS and Microsoft to accept credits, ensuring distribution
in 2027.
Expected Impact: Reduces digital inequality, drives innovation across sectors, and
ensures U.S. citizens lead in AI fluency, mirroring post-WWII infrastructure investments.
Activity 3: AI Safety Protocol  
Concept: Develop ethical guidelines and technical safeguards for managing advanced AI risks, 
including AI alignment research and emergency response plans. 
Rationale: While speculative, AI safety is critical, as seen in initiatives like the U.S. AI Safety 
Institute (U.S. Artificial Intelligence Safety Institute | NIST ) and the International Network of AI 
Safety Institutes (FACT SHEET: U.S. Department of Commerce & U.S. Department of State 
Launch the International Network of AI Safety Institutes). This prepares for scenarios where AI poses existential threats, aligning with the RFI’s focus on technical and safety standards.  


Implementation Steps: 
●Form a multidisciplinary committee in 2025, including ethicists, engineers, and
policymakers under DARPA oversight, to draft protocols.
●Conduct public consultations and international collaborations in 2026, leveraging the
AISI network, focusing on AI alignment and risk assessments.
●Implement by 2028, embedding in federally funded projects, with a decentralized
shutdown key requiring multi-party authorization.
Expected Impact: Mitigates catastrophic risks, builds public trust, and positions the
U.S. as a leader in responsible AI governance, inspired by Asimov’s Three Laws
adapted for modern contexts.
Conclusion  
These activities collectively ensure U.S. AI leadership, promoting equity, safety, and innovation. 
By empowering individuals, ensuring access, and preparing for risks, the U.S. can lead the 
world toward an AI future defined by justice, prosperity, and coexistence. I am committed to 
refining this vision, collaborating with stakeholders, and driving implementation to realize these 
goals. Respectfully submitted,  
Patrick Diamitani  
GPTPAT  
March 15, 2025 
Addendum: Detailed Analysis of Proposed Activities 
This addendum provides deeper insights into each activity, demonstrating a thorough 
understanding and commitment to the proposed solutions, enhancing your expertise and the 
proposal’s feasibility. 
Opt-In Data Contribution System for LLMs 
●Economic Model: Contributors earn micro-payments (e.g., $0.01 per kilobyte) based on
data utility, funded by AI firms licensing the dataset. Projected market size: $10 billion by
2030, per AI Training Dataset Market report (AI Training Dataset Market worth $9.58
billion by 2029).
●Legal Framework: Amend the Privacy Act to recognize data as intellectual property,
with opt-in consent enshrined, inspired by Creative Commons but with monetary
incentives and stringent security measures, aligning with GDPR and CCPA compliance(AI Data Marketplaces | What is an AI Data Marketplace? | Monda).


●Quality Control: Implement ratings from AI trainers and validation tests to ensure
high-quality, relevant data, reducing bias in AI models, as highlighted by the Apple Card
bias case (AI Training Dataset Market worth $9.58 billion by 2029).
National AI Credit Fund Subsidy 
●Funding Source: Repurpose 1% of federal R&D budget ($1.8 billion in 2024 terms) and
supplement with a 0.5% tax on AI firms’ profits, similar to subsidies for data centers (Big
Tech Eyes Billions in Public Subsidies for AI, Cloud Computing - Good Jobs First).
●Use Case: A small business owner uses credits to access GPT-5 for market analysis,
boosting revenue without upfront costs, bridging the digital divide, akin to broadband
subsidies.●Global Edge: Mirrors post-WWII infrastructure investments, ensuring U.S. citizens
outpace rivals in AI fluency, aligning with Tech Hubs program goals (Biden-Harris
Administration Awards Additional $210 Million Tech Hub Grants).
AI Safety Protocol 
●Technical Design: Decentralized shutdown key requiring multi-party authorization
(government, industry, academia), paired with an AI “ethics module” trained on human
values, inspired by Asimov’s Three Laws, adapted for diverse cultural norms (AI safety -
Wikipedia).
●Philosophical Basis: Focus on AI alignment research, ensuring AI shares human
goals, supported by initiatives like the Center for AI Safety (Center for AI Safety (CAIS))
and U.S. AI Safety Institute (U.S. Artificial Intelligence Safety Institute | NIST ).
●Test Case: Simulate a rogue AI scenario in 2028, refining protocols based on outcomes,
leveraging international collaboration through the AISI network (FACT SHEET: U.S.
Department of Commerce & U.S. Department of State Launch the International Network
of AI Safety Institutes).
Key Citations 
●Removing Barriers to American Leadership in Artificial Intelligence
●This startup is creating an AI training data marketplace to help creators and companies
buy and sell licensed content
●Defined.ai - Home page
●Biden-Harris Administration Awards Additional $210 Million Tech Hub Grants
●U.S. Artificial Intelligence Safety Institute | NIST
●FACT SHEET: U.S. Department of Commerce & U.S. Department of State Launch the
International Network of AI Safety Institutes
●AI Training Dataset Market worth $9.58 billion by 2029
●AI Data Marketplaces | What is an AI Data Marketplace? | Monda
●Big Tech Eyes Billions in Public Subsidies for AI, Cloud Computing - Good Jobs First
●Center for AI Safety (CAIS)
●AI safety - Wikipedia


