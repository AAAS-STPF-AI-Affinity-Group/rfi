PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-3cpm -rk5n
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-9024
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Erin Jones
Em ail:  
General Comment
I work in a physical science field and have been part of discussions about the use of AI in m y field for the past 6-7 years. I have watched
it grow from  a new concept in m y field to som ething that is regularly used. I know the technology has a lot of potential uses, and I also
know that relying on it too m uch and too quickly is im prudent and potentially dangerous.
AI system s are only as good as how they are trained. I think a lot of people view AI as a solution to a lot of problem s, but they forget or
fail to realize that it's incredibly difficult (or potentially im possible) to train AI/ML with a dataset that contains all possible scenarios or
outcom es; it's arguable that m ost or all inform ation in a training dataset will represent som ething within the bulk of a statistical distribution,
but m ay fail to capture inform ation about instances that exist in the tails of the distribution. It's these instances that are often the m ost
im pactful on hum ans or hum an society, because they are so rare. This m ay be som ething like a powerful earthquake, a very strong storm ,
a significant societal event... if sim ilar occurrences of these rare events are not in the AI's training dataset, how is the AI system  supposed
to accurately anticipate them ? 
It's for this reason that hum ans m ust also continually oversee AI/ML operation; the AI system  does not operate considering any rules or
physical laws or anything else, and it can put forth solutions that are nonsensical or unlikely. Hum an oversight is required as a m eans to
quality control AI output. This is som ething that m ight be easily overlooked if we begin to rely too m uch on AI; we risk brain drain (e.g.
losing our understanding of the processes we are using AI to represent), and we could begin to fail to catch instances where AI is
providing obviously wrong answers. This could be devastating; an obvious scenario like this would be a passenger in a self driving car
failing to hit the brakes when the AI operating the car can't identify a road hazard. The idea that we don't need hum ans if we have AI is
false.
In addition to needing good training and continual oversight from  hum ans, AI system s also often need to be continually updated or re-
trained. We live in a constantly evolving society on a constantly evolving planet. What is "norm al" today m ay not have been "norm al" 5
years ago, and will likely not be "norm al" 5 years in the future. AI/ML system s, like m ost other m odels, need frequent updating and
m aintenance. They can't just be set up, left to do their thing, and then be expected to continually work.
There are likely m any m ore reasons why AI needs to be treated carefully and with m uch consideration. It would be ill advised to m ove
too quickly to com pletely abandon the non-AI m ethods of doing things that have served us well for years in favor of AI-only solutions. AI
is a tool, and it should m ost often be used in conjunction with other m ethods for accom plishing goals. If we over-rely on it, we risk
throwing the proverbial baby out with the bathwater. And if we do this to replace hum an labor, we also risk causing widespread societal
unrest. The hum an population continues to grow exponentially, and we continue to exist in a society where one m ust pay m oney to be
alive. No one asks to be born, and the m ore we replace hum an jobs with com puters and m achines, the m ore we will see hum an beings
struggle to earn the m oney they need to pay to live the lives they never asked for.


