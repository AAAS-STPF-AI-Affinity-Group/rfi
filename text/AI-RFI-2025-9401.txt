PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-3erf-w4ju
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-9401
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Public Knowledge
General Comment
See attached file(s)
This docum ent is approved for public dissem ination. The docum ent contains no business-proprietary or confidential inform ation.
Docum ent contents m ay be reused by the governm ent in developing the AI Action Plan and associated docum ents without attribution.
Attachments
PublicKnowledge_Com m ent_2025 AI Action Plan
Public Knowledge Com m ent_2025 AI Action Plan


Date:  March 15, 2025  
T o:  Of ﬁce of Science and T echnology Policy (OSTP);  
Networking and Information T echnology Research and Development (NITRD) 
National Coordination Of ﬁce (NCO)  
From:  Nicholas P. Garcia, Senior Policy Counsel, Public Knowledge  
Re:  Request for Information on the Development of an AI Action Plan 
Dear Administration Of ﬁcials, 
Public Knowledge is grateful for the call for public comments and the opportunity to 
provide input on this Request for Information (RFI) on the Development of an 
Arti ﬁcial Intelligence (AI) Action Plan. Public Knowledge is a non-pro ﬁt, non-partisan, 
public interest organization that advocates for technology policies that promote free 
expression, protect consumer rights, and prevent monopolization of emerging 
digital markets.1  
Innovation through openness and competition. 
As AI technology advances, ensuring its development remains open, transparent, 
and competitive is paramount. The Trump Administration has emphasized 
innovation as a key policy priority for “sustaining and enhancing America's AI 
dominance in order to promote human ﬂourishing, economic competitiveness, and 
national security.”2 These goals align with Public Knowledge’s core mission, and our 
work on AI policy has always aimed at promoting AI innovation and ensuring its 
value is realized by the American people. Our analysis of the AI industry, economic 
landscape, and history of technology shows that the best path to AI innovation is 
through openness and competition, rather than control by a few dominant ﬁrms. 
T o ensure an open and competitive AI sector, we propose ﬁve key policy priorities: 
1. Protect the rights to read and learn that make AI training possible.
2. Support open-source, collaborative research and development.
3. Build and maintain public physical and digital AI infrastructure to prevent
monopolization and private enclosure.
4. Develop standards and sensible rules around AI explainability and
transparency to ensure trust and adoption.
These policy priorities will not only secure American competitiveness in AI, but help 
create a truly competitive and innovative AI industry in the United States. 
2 RFI, https:/ /www.federalregister.gov/ d/2025-02305/ p-11. 1 https:/ / publicknowledge.org/ about-us/  


Protect the Rights to Read and Learn that Make AI Training Possible 
At the center of our vision for a creative and connected future for all are the rights to 
read, learn, and share knowledge. These rights not only underpin our shared 
commons of knowledge but also drive innovation by fostering an ecosystem where 
ideas and knowledge can circulate freely and openly. The protection of these rights 
against restrictive intellectual property rights expansions is crucial for maintaining 
the dynamism of the open research ecosystem that has historically propelled 
technological and creative advancements. This is particularly important for our 
burgeoning AI research ecosystem because of the critical role the collection and 
analysis of data plays in modern machine learning techniques. 
Our stance is clear: the existing copyright framework, while not ﬂawless, is suf ﬁciently 
robust to handle the new dynamics introduced by generative arti ﬁcial intelligence 
(GAI) and breakthroughs in machine learning. As we have previously written, AI 
training on copyrighted material should be permissible under our existing law.3 Our 
copyright system—and its limitations and exceptions—is designed to balance 
between protecting creators and fostering public access to new knowledge. Any 
overreach in copyright reforms would disrupt this delicate balance, hindering the 
innovative potential of AI technologies and also exacerbating existing economic 
disparities within creative industries. 
The Risks of Copyright Expansion 
An in ﬂuential consortium of media companies, buoyed by popular concerns over the 
real risks of economic disruption and labor displacement created by AI, has agitated 
for expanded copyright protections in response to the advent of new AI technologies. 
However, expansion risks impairing the very mechanisms of learning and sharing 
that are critical, not just for generative AI development, but for all forms of 
computational research and analysis, as well as forms of human learning and 
knowledge sharing. Expanding the interpretation of copyright to restrict how we can 
read and learn from creative works would undoubtedly limit the essential activities of 
fair use and free expression which are crucial for a healthy intellectual and creative 
economy.  
Moreover, expanding copyright does not address the root economic challenges 
faced by creators; rather, it will entrench the interests of powerful entities at the 
expense of smaller players and innovators. Requiring expensive licensing regimes for 
AI training will drive up the barriers to entry for AI research and development, driving 
3 https:/ / publicknowledge.org/ policy/ usco-ai-and-copyright-comments/; 
https:/ / publicknowledge.org/ generative-ai-is-disruptive-but-more-copyright-isnt-the-answer/ 
2 


small businesses and nonpro ﬁt actors out of the sector. Similarly, media companies 
being able to bargain over their troves of copyrighted content will only incentivize 
further media consolidation, exacerbating the monopsonistic quality of creative 
industries and further increasing the economic precarity and disempowerment of 
creative workers.  
Thus, expanding copyright protection to cover AI training would contradict the 
principles of competition and innovation that should guide our approach to AI policy. 
AI Training is Noninfringing 
The application of our current copyright laws to the practice of AI training con ﬁrms 
that these activities align well with the objectives of copyright, which aims to 
stimulate creativity and promote the public good.  
AI training involves creating massive datasets from digitized content, transforming 
these materials from their original purposes to serve as inputs for machine 
learning—a use that is fundamentally different from their original consumption and 
does not compete in the original marketplace. This data gathering exempliﬁes the 
principle of transformation, by repurposing copyrighted content in a way that adds 
value to society without displacing the original works.  
Similarly, the process of training itself results in a new artifact, the AI model, which 
has a generalized and distinct use from any of the individual works used in its 
creation. While an AI model can be used to create new work similar to the works 
used in its training, this is the same kind of market competition that arises from 
anyone reading, learning from, and subsequently embarking on a similar enterprise. 
Finally, the concern that AI might infringe on creative rights through mimicking or 
stylistic replication is not best addressed through the lens of copyright law. Copyright 
protection only extends to the speciﬁc expressive elements of a work. Instead, AI 
models—as well as human creators in ﬂuenced by the work of others—leverage the 
underlying ideas, styles, or methods which are free for all to use. This critical 
limitation is core to the constitutionality of copyright law, protects free expression, 
and thus promotes innovation and vibrant creativity. 
In sum, we encourage the administration to approach copyright law in the context of 
AI by prioritizing the freedoms that support innovation and competition. Protecting 
the rights to read, learn, and develop new technologies ensures that the AI 
landscape remains dynamic and inclusive. By resisting unnecessary expansions of 
copyright that could stiﬂe these freedoms, we can foster an environment where AI 
enhances societal, creative, and economic opportunities for all. This balanced 
3 


approach not only aligns with the principles underlying our copyright system but 
also supports the broader objectives of promoting innovation and competitive 
fairness in the burgeoning ﬁeld of arti ﬁcial intelligence. 
Support Open-Source, Collaborative Research and Development 
The advancement of arti ﬁcial intelligence through open-source methodologies is a 
strategic necessity in today’s technology landscape. Open-source AI development 
fosters a collaborative environment that is essential for innovative breakthroughs and 
ensures widespread sharing of those breakthroughs to advance the state of the art. 
This approach aligns with Public Knowledge’s long-standing advocacy for policies 
that promote technological openness and transparency, as detailed in our 
comments submitted to the National T elecommunications and Information 
Administration (NTIA) proceeding on Widely Available Model W eights (WAMW 
Comment).4 
Advantages of Openness in AI 
Open-source AI development is instrumental for driving safety, innovation, and 
competition within the tech industry. Open-source AI models allow for widespread 
scrutiny by researchers and developers across the globe, which enhances the safety 
of these technologies by exposing potential ﬂaws and vulnerabilities that closed 
systems might conceal. This transparency not only leads to more robust AI systems 
but also accelerates the pace of innovation by allowing developers to build upon 
each other's work without the barriers imposed by proprietary technologies. 
The competitive advantages of open-source AI are signi ﬁcant. By lowering barriers to 
entry, open-source AI allows startups and smaller tech companies to compete with 
larger entities, thereby preventing market monopolies and encouraging a diverse 
technological ecosystem. This diversity is crucial for spurring creative solutions to 
complex problems and for preventing any single entity from establishing too much 
control over AI technologies. Openness on a Spectrum 
Recognizing that openness exists on a spectrum is vital for understanding the varied 
beneﬁts that different degrees of openness can provide. As noted in our WAMW 
Comment, openness should be de ﬁned for AI systems to promote free, open, and 
accessible technology and AI policy should recognize a broad spectrum of openness 
for AI systems.5 This nuanced view acknowledges that while full openness is ideal for 
5 WAMW Comment at pg. 6-7. 4 https:/ / publicknowledge.org/ policy/ ﬁnal-ntia-comments/ 
4 


maximizing the aforementioned bene ﬁts, any move towards greater transparency 
can yield signi ﬁcant advantages. 
For instance, even partial openness, such as sharing model weights or training 
dataset information, can contribute positively to the AI community. This level of 
openness can help balance proprietary interests with public bene ﬁts, providing a 
gateway for more companies and individuals to engage with and contribute to AI 
advancements. 
Encouraging More Openness 
T o foster an environment where more openness in AI is encouraged, it is crucial to 
support policies that facilitate access to public datasets, open APIs, and collaborative 
platforms. As discussed further below, investing in public infrastructure that supports 
open-source AI—such as cloud services, computing power, and storage—can 
democratize access to the necessary tools for open-source AI development. 
Furthermore, government and educational institutions can play a pivotal role by 
advocating for and adopting open-source AI solutions, setting a standard for 
transparency and collaboration. 
Moreover, creating incentives for companies to adopt open-source practices can 
accelerate the shift towards a more open AI landscape. These incentives could 
include tax breaks, grants, or public recognition for companies that contribute to 
open-source projects or that make their proprietary technologies partially open. In conclusion, supporting open-source and collaborative AI development is essential 
for ensuring that AI technologies are safe, innovative, and competitive. By advocating 
for more openness, whether complete or partial, we can cultivate an AI ecosystem 
that is not only technologically advanced but also equitable and accessible to all. This 
commitment to openness will underpin the continued growth and success of the AI ﬁeld, ensuring it remains a positive force for technological progress in society. 
The Government Should Tackle the Physical and Digital Public 
Infrastructure Obstacles to American AI Innovation and Leadership 
Arti ﬁcial intelligence has the potential to transform industries, drive economic 
growth, and enhance public services in ways that parallel some of the most 
consequential technological advancements in history. However, realizing AI’s full 
promise requires a strong foundation—one that is currently lacking in the United 
States due to a lack of public investment in essential AI infrastructure. Just as past 
infrastructure projects in electriﬁcation, transportation, and telecommunications laid 
the groundwork for American leadership in the industrial and digital economies, the 
5 


federal government must now invest in “Public AI” infrastructure to ensure the 
nation remains at the forefront of innovation and competition.6 
Without decisive action, AI development will remain concentrated in the hands of a 
few dominant corporations, reinforcing monopolistic control over computing power, 
data resources, and development expertise. This concentration of AI capabilities 
stiﬂes competition, inhibits broader participation in AI research, and risks ceding 
strategic technological leadership to other nations that are already making 
signiﬁcant public investments. A robust Public AI infrastructure strategy can 
counteract these trends by creating a competitive and innovative AI ecosystem that 
beneﬁts businesses, researchers, and the public at large. 
Historical Precedents for Public Infrastructure Investments 
The federal government has historically played a pivotal role in fostering 
technological advancements through large-scale public investments. The 
electri ﬁcation of America in the early 20th century was not merely a product of 
private enterprise but a result of government-supported initiatives like the Rural 
Electriﬁcation Act.7 Similarly, the construction of the interstate highway system in the 
1950s—one of the largest public works projects in history—enabled the rapid 
expansion of the automotive industry and facilitated economic growth across the 
country.8 These investments did not “pick winners and losers” in the private sector 
but instead created a level playing ﬁeld that allowed businesses of all sizes to thrive. 
AI requires a similar commitment to public infrastructure. Just as roads, bridges, and 
power grids are essential for economic activity, AI development depends on a robust 
foundation of computing resources, data availability, and research capabilities. 
However, unlike previous infrastructure projects, Public AI infrastructure must 
account for both physical (compute and hardware) and digital (data and software) 
elements. Most importantly, these investments must be truly public, with robust 
public accessibility and public accountability mechanisms, ensuring that taxpayer 
dollars actually provide long-term beneﬁts rather than merely subsidizing 
private-sector expansion. 
The Risks of Privatized Digital Infrastructure 
A cautionary tale can be found in the privatization of the internet. While the U.S. 
government initially supported the research and development of the internet 
through national laboratories and public institutions,9 much of the internet’s physical 
9 https:/ /www.nsf.gov/impacts/internet  8 https:/ /www.archives.gov/ milestone-documents/ national-interstate-and-defense-highways-act 7 https:/ /livingnewdeal.org/ glossary/ rural-electri ﬁcation-act-1936/ 6 See, https:/ / publicai.network/whitepaper/  
6 


infrastructure was later privatized, leading to monopolization in broadband 
deployment. The result has been a market characterized by slow speeds, limited 
competition, and high costs for consumers.10 The failures of broadband 
policy—including uneven access, weak customer protections, and underinvestment 
in infrastructure—serve as a stark warning for AI. In a sector where there is already 
considerable market entrenchment in terms of compute power and data access, an 
AI strategy that does not strongly emphasize public infrastructure will follow an even 
sharper downward trajectory, leading to re-entrenchment and concentrated power 
in the hands of a few dominant Big T ech ﬁrms. 
T o avoid repeating these mistakes, the federal government must take proactive steps 
to ensure key AI infrastructure remains a public good, rather than an exclusive asset 
controlled by a handful of ﬁrms. This means making strategic investments that build 
public AI infrastructure while ensuring broad access to essential AI capabilities. 
Three Key Areas for Public Investment 
T o foster a more open, competitive, and innovative AI ecosystem, the federal 
government should invest in three critical areas: public compute resources, open 
data infrastructure, and Public AI model development. These investments will 
provide the essential building blocks for AI research and development, ensuring that 
AI innovation is not limited to well-funded tech giants. 
1. Public Compute Infrastructure: A Smarter Approach Than Simply Subsidizing
Private Data Centers
One of the most pressing challenges in AI development is access to computational 
power. The cost of training frontier AI models is one of the primary bottlenecks in the 
industry, with the leading AI ﬁrms spending billions on proprietary data centers. 
Without access to similar compute resources, startups, research institutions, and 
smaller companies struggle to compete, leading to further industry consolidation at 
the whims of Big T ech hyperscalers. 
Instead of offering subsidies or regulatory support to private tech ﬁrms to expand 
their existing infrastructure, the government should invest directly in public 
compute resources. This could take the form of national AI research compute centers 
housed within federal agencies, universities, or national laboratories or even state 
and local programs to develop community-based compute resources through digital 
anchor institutions like schools and libraries. By leveraging existing federal resources 
and research facilities, the government can create public alternatives to 
10 See e.g., https:/ /www.npr.org/transcripts/899472976 
7 


private-sector compute monopolies, ensuring that AI capabilities remain accessible 
to a diverse range of innovators and users. 
Public compute initiatives like the National AI Research Resource (NAIRR) represent 
an important step in this direction for expanding access for academics and 
researchers and administration support for the broadly bipartisan CREATE AI Act 
would be an excellent starting place, but more ambitious efforts are needed. The 
Trump Administration should go further and develop policy pilots that expand 
compute capacity and access to entrepreneurs, small businesses, and individuals. 
 Similar to how public roads enabled private sector growth without picking corporate 
winners, publicly accessible compute infrastructure will provide a baseline level of 
access to AI resources, fostering competition and accelerating AI research across 
multiple sectors. 
2. Open Data Resources: Strengthening National AI Research Capacity
Data is the lifeblood of AI. Y et, access to high-quality, well-curated datasets is 
restricted by cost and fears about copyright liability risk. This creates an uneven 
playing ﬁeld where only the biggest (or most reckless) companies can access the 
data required to develop competitive AI models. This concern is particularly 
important given the ongoing race for AI dominance with China: data access, though 
the details remain opaque, has been cited as one of the primary advantages for 
Chinese AI developers.11 
T o address these imbalances, the government should expand support for public data 
repositories, ensuring that high-quality datasets are available for academic and 
commercial research. Again, the NAIRR provides a strong starting point, but 
additional efforts could include expanding the role of the Library of Congress in 
curating publicly available digital datasets, developing AI-ready datasets through 
partnerships with universities and research institutions, and ensuring that copyright 
law does not restrict the ability to use publicly available information for AI training. 
Unnecessary expansions of copyright law that restrict access to factual information 
would not only hinder AI development but would also undermine the broader 
principles of knowledge-sharing and scientiﬁc progress. 
By investing in open data infrastructure, the government can prevent AI knowledge 
from becoming the exclusive property of a few corporations, ensuring that publicly 
funded data resources remain accessible to all. 
11 See e.g.,  
https:/ /www.brookings.edu/ articles/how-to-tackle-the-data-collection-behind-chinas-ai-ambitions/ 
8 


3. Building Instead of Buying: Developing Publicly-Owned AI Models and
Applications
For decades, the federal government has played a crucial role in advancing 
technological innovation, often laying the foundation for private-sector 
breakthroughs. However, in artiﬁcial intelligence, the government has largely limited 
its role to procurement rather than direct development, creating unnecessary 
dependence on private vendors and exposing critical public functions to 
monopolistic control. Expanding the government’s capacity to develop AI models 
through national laboratories, universities, and federal agencies is essential to 
ensuring that AI development remains transparent, accountable, and aligned with 
national interests. Initiatives like the Department of Energy’s FASST (Fair, 
Accountable, Secure, and Safe T echnology) AI program demonstrate that publicly 
funded research can produce cutting-edge AI systems designed for public beneﬁt 
rather than private pro ﬁt.12 Strengthening these efforts will ensure that AI remains an 
accessible and equitable technology rather than a privatized asset controlled by a 
few dominant ﬁrms.   
Relying on private-sector AI procurement poses several risks. First, private AI models 
are driven by pro ﬁt incentives, often neglecting applications that serve critical public 
needs such as scienti ﬁc research, healthcare, and equitable access to AI-driven 
services. Dependence on private ﬁrms also leads to vendor lock-in, reducing 
government ﬂexibility and increasing long-term costs. Once locked into proprietary 
systems, agencies face high barriers to switching providers or modifying models to 
meet evolving public needs. Additionally, private-sector AI systems often lack 
transparency, making it dif ﬁcult for regulators and the public to scrutinize their 
decision-making processes, ensure fairness, and prevent discriminatory outcomes. 
On the other hand, developing publicly owned AI models enhances transparency 
and oversight, ensuring that government-deployed AI aligns with democratic values 
and public accountability standards. Federally developed models can incorporate 
rigorous data governance, algorithmic transparency, and auditing mechanisms, 
particularly for sensitive applications such as law enforcement or public health. 
Public investment in AI model development can also foster competition by providing 
alternatives to dominant private models, reducing barriers to entry for startups, 
academic researchers, and smaller ﬁrms that lack access to commercial models. 
Government-developed models can be open-sourced or otherwise be made publicly 
available to ensure that there are low-cost, public options for AI models in order to 
create stable alternatives to private offerings. 
12 https:/ / publicknowledge.org/ policy/ comments-in-response-to-doe-request-for-information-on-fasst/ 
9 


Beyond competition and transparency, public investment in government  AI 
research strengthens the federal workforce and enhances government expertise in 
AI governance. Expanding AI research and development within national labs and 
federal agencies cultivates a skilled public-sector workforce capable of managing, 
deploying, and regulating AI technologies effectively. Programs like FASST provide a 
framework for building internal AI capacity, reducing reliance on private contractors 
and ensuring that AI policies and models remain under democratic oversight.  Public AI initiatives should span the entire AI technology stack, from compute 
resources to datasets and pretrained models, ensuring that critical bottlenecks are 
identiﬁed and addressed. By investing in AI model development rather than simply 
purchasing proprietary systems, the government can prevent monopolization, 
reduce dependency on opaque private models, and build the expertise in AI 
technology that our government and workforce needs. 
Explainability and transparency standards are essential for AI 
innovation and adoption. 
The widespread adoption of arti ﬁcial intelligence requires public con ﬁdence in its 
fairness, reliability, and accountability. Without clear mechanisms to understand, 
audit, and assess AI models, both innovation and public trust in AI technologies will 
be severely limited. Standards for AI transparency and explainability—established 
through voluntary, consensus-driven processes and coordinated by the federal 
government through agencies like the National Institute of Standards and 
T echnology (NIST) and the U.S. Arti ﬁcial Intelligence Safety Institute (AISI)—are 
essential for ensuring that AI systems are both safe and effective. By setting clear 
expectations for transparency and explainability, these standards can serve as the 
foundation for trust in AI-driven products and services, ultimately accelerating AI 
adoption across industries. 
Transparency as a Prerequisite for AI Accountability 
Transparency in AI should go beyond basic disclosures and include structured 
accountability mechanisms that provide meaningful insights into how AI models 
function, what data they rely on, and how they impact users. Public Knowledge has 
consistently emphasized that AI systems must not operate as black boxes but should 
be subject to rigorous transparency and explainability requirements to ensure 
accountability and fair outcomes. 
AI transparency is a key component of consumer protection and business 
con ﬁdence. When AI models in ﬂuence decisions in hiring, lending, healthcare, and 
10 


other critical domains, affected individuals and businesses should have access to 
clear, understandable explanations of how those decisions are made. Public 
disclosure of AI decision-making criteria, model training data sources, and 
algorithmic biases fosters trust and prevents discriminatory or harmful outcomes. 
Moreover, transparency should, at a minimum, be a strongly incentivized industry 
norm, reinforced through structured reporting standards, third-party audits, and 
disclosure mechanisms. By establishing voluntary and consensus-driven transparency standards through 
NIST and AISI, the federal government can help businesses and developers adopt 
best practices that increase consumer con ﬁdence without sti ﬂing innovation. 
Transparency empowers users, regulators, and businesses alike by providing the 
information necessary to assess risks, identify biases, and ensure AI systems are 
functioning as intended. 
Explainability as a Foundation for AI Safety and Innovation 
Similarly, explainability is critical for both users and developers to understand how AI 
systems operate and why they make certain decisions. A well-calibrated 
explainability framework ensures that AI is not only interpretable to experts and 
regulators but also comprehensible to end users who interact with AI-powered tools. 
Without explainability, AI models risk being seen as opaque, unaccountable, and 
untrustworthy, limiting their adoption in key sectors such as ﬁnance, healthcare, and 
legal decision-making. 
For businesses, explainability serves as a competitive advantage—companies that 
can offer clear, understandable AI systems will be better positioned to attract 
customers and comply with evolving regulatory expectations. For developers, 
explainability improves the ability to debug, reﬁne, and enhance AI models, leading 
to more reliable and adaptable AI systems over time. Y et proof of these capabilities 
remains technically challenging. Further developing research into AI explainability 
and developing an accountability environment that can validate AI behavior should 
be a priority of this administration. Public Knowledge has emphasized that AI 
accountability mechanisms—including certiﬁcations, audits, assessments, and 
testing—should be more than just “trust seals”. Instead, they must be meaningful, 
enforceable, and integrated into broader safety and consumer protection 
frameworks.13 
T o ensure effective AI adoption, both explainability and transparency standards 
should be developed in coordination with industry leaders, researchers, and 
consumer advocacy groups, ensuring that they are both technically feasible and 
13 https://publicknowledge.org/policy/ntia-ai-accountability/ at pg. 3. 
11 


aligned with public interests. Agencies like NIST and AISI should play a leading role in 
establishing best practices, testing explainability methodologies, and guiding 
businesses toward responsible AI deployment. AI innovation and adoption will only 
reach their full potential if businesses, consumers, and regulators trust that AI 
systems operate fairly, make accountable decisions, and can be independently 
assessed. V oluntary and consensus-driven standards-setting efforts led by NIST and 
AISI will provide the framework needed to ensure transparency and explainability 
while maintaining ﬂexibility for industry advancement. These standards should 
encourage widespread disclosure, independent testing, and structured auditing 
mechanisms that enhance both AI safety and public con ﬁdence. By prioritizing 
transparency and explainability, the U.S. can position itself as a leader in responsible 
AI governance, ensuring that AI-driven technologies remain trustworthy, 
competitive, and aligned with democratic values. 
Conclusion 
Arti ﬁcial intelligence presents extraordinary opportunities for economic growth, 
scienti ﬁc discovery, and public bene ﬁt, but its continued success depends on 
maintaining an ecosystem that is open, competitive, and accountable. T o ensure that 
AI innovation is aligned with public interest, this administration should take proactive 
steps to protect the rights to read and learn, support open-source AI development, 
invest in public infrastructure, and develop transparency and explainability standards 
that build trust in AI systems.  
T o ensure innovation and American AI leadership on the global stage, Public 
Knowledge urges the administration to prioritize policies that foster competition, 
encourage collaboration, and prevent industry consolidation from stiﬂing the 
potential of this potentially revolutionary technology.  
By embracing competition and openness, and taking a bold lead with Public AI 
infrastructure investment, the U.S. will ensure it continues to lead the world in AI 
innovation. Public Knowledge looks forward to opportunities to advise the 
administration on developing an AI Action Plan and policies that ensure AI beneﬁts 
all Americans. 
This document is approved for public dissemination. The document contains no 
business-proprietary or con ﬁdential information. Document contents may be 
reused by the government in developing the AI Action Plan and associated 
documents without attribution. 
12 


13 


Date:  March 15, 2025  
T o:  Of ﬁce of Science and T echnology Policy (OSTP);  
Networking and Information T echnology Research and Development (NITRD) 
National Coordination Of ﬁce (NCO)  
From:  Nicholas P. Garcia, Senior Policy Counsel, Public Knowledge  
Re:  Request for Information on the Development of an AI Action Plan 
Dear Administration Of ﬁcials, 
Public Knowledge is grateful for the call for public comments and the opportunity to 
provide input on this Request for Information (RFI) on the Development of an 
Arti ﬁcial Intelligence (AI) Action Plan. Public Knowledge is a non-pro ﬁt, non-partisan, 
public interest organization that advocates for technology policies that promote free 
expression, protect consumer rights, and prevent monopolization of emerging 
digital markets.1  
Innovation through openness and competition. 
As AI technology advances, ensuring its development remains open, transparent, 
and competitive is paramount. The Trump Administration has emphasized 
innovation as a key policy priority for “sustaining and enhancing America's AI 
dominance in order to promote human ﬂourishing, economic competitiveness, and 
national security.”2 These goals align with Public Knowledge’s core mission, and our 
work on AI policy has always aimed at promoting AI innovation and ensuring its 
value is realized by the American people. Our analysis of the AI industry, economic 
landscape, and history of technology shows that the best path to AI innovation is 
through openness and competition, rather than control by a few dominant ﬁrms. 
T o ensure an open and competitive AI sector, we propose ﬁve key policy priorities: 
1. Protect the rights to read and learn that make AI training possible.
2. Support open-source, collaborative research and development.
3. Build and maintain public physical and digital AI infrastructure to prevent
monopolization and private enclosure.
4. Develop standards and sensible rules around AI explainability and
transparency to ensure trust and adoption.
These policy priorities will not only secure American competitiveness in AI, but help 
create a truly competitive and innovative AI industry in the United States. 
2 RFI, https:/ /www.federalregister.gov/ d/2025-02305/ p-11. 1 https:/ / publicknowledge.org/ about-us/  


Protect the Rights to Read and Learn that Make AI Training Possible 
At the center of our vision for a creative and connected future for all are the rights to 
read, learn, and share knowledge. These rights not only underpin our shared 
commons of knowledge but also drive innovation by fostering an ecosystem where 
ideas and knowledge can circulate freely and openly. The protection of these rights 
against restrictive intellectual property rights expansions is crucial for maintaining 
the dynamism of the open research ecosystem that has historically propelled 
technological and creative advancements. This is particularly important for our 
burgeoning AI research ecosystem because of the critical role the collection and 
analysis of data plays in modern machine learning techniques. 
Our stance is clear: the existing copyright framework, while not ﬂawless, is suf ﬁciently 
robust to handle the new dynamics introduced by generative arti ﬁcial intelligence 
(GAI) and breakthroughs in machine learning. As we have previously written, AI 
training on copyrighted material should be permissible under our existing law.3 Our 
copyright system—and its limitations and exceptions—is designed to balance 
between protecting creators and fostering public access to new knowledge. Any 
overreach in copyright reforms would disrupt this delicate balance, hindering the 
innovative potential of AI technologies and also exacerbating existing economic 
disparities within creative industries. 
The Risks of Copyright Expansion 
An in ﬂuential consortium of media companies, buoyed by popular concerns over the 
real risks of economic disruption and labor displacement created by AI, has agitated 
for expanded copyright protections in response to the advent of new AI technologies. 
However, expansion risks impairing the very mechanisms of learning and sharing 
that are critical, not just for generative AI development, but for all forms of 
computational research and analysis, as well as forms of human learning and 
knowledge sharing. Expanding the interpretation of copyright to restrict how we can 
read and learn from creative works would undoubtedly limit the essential activities of 
fair use and free expression which are crucial for a healthy intellectual and creative 
economy.  
Moreover, expanding copyright does not address the root economic challenges 
faced by creators; rather, it will entrench the interests of powerful entities at the 
expense of smaller players and innovators. Requiring expensive licensing regimes for 
AI training will drive up the barriers to entry for AI research and development, driving 
3 https:/ / publicknowledge.org/ policy/ usco-ai-and-copyright-comments/; 
https:/ / publicknowledge.org/ generative-ai-is-disruptive-but-more-copyright-isnt-the-answer/ 
2 


small businesses and nonpro ﬁt actors out of the sector. Similarly, media companies 
being able to bargain over their troves of copyrighted content will only incentivize 
further media consolidation, exacerbating the monopsonistic quality of creative 
industries and further increasing the economic precarity and disempowerment of 
creative workers.  
Thus, expanding copyright protection to cover AI training would contradict the 
principles of competition and innovation that should guide our approach to AI policy. 
AI Training is Noninfringing 
The application of our current copyright laws to the practice of AI training con ﬁrms 
that these activities align well with the objectives of copyright, which aims to 
stimulate creativity and promote the public good.  
AI training involves creating massive datasets from digitized content, transforming 
these materials from their original purposes to serve as inputs for machine 
learning—a use that is fundamentally different from their original consumption and 
does not compete in the original marketplace. This data gathering exempliﬁes the 
principle of transformation, by repurposing copyrighted content in a way that adds 
value to society without displacing the original works.  
Similarly, the process of training itself results in a new artifact, the AI model, which 
has a generalized and distinct use from any of the individual works used in its 
creation. While an AI model can be used to create new work similar to the works 
used in its training, this is the same kind of market competition that arises from 
anyone reading, learning from, and subsequently embarking on a similar enterprise. 
Finally, the concern that AI might infringe on creative rights through mimicking or 
stylistic replication is not best addressed through the lens of copyright law. Copyright 
protection only extends to the speciﬁc expressive elements of a work. Instead, AI 
models—as well as human creators in ﬂuenced by the work of others—leverage the 
underlying ideas, styles, or methods which are free for all to use. This critical 
limitation is core to the constitutionality of copyright law, protects free expression, 
and thus promotes innovation and vibrant creativity. 
In sum, we encourage the administration to approach copyright law in the context of 
AI by prioritizing the freedoms that support innovation and competition. Protecting 
the rights to read, learn, and develop new technologies ensures that the AI 
landscape remains dynamic and inclusive. By resisting unnecessary expansions of 
copyright that could stiﬂe these freedoms, we can foster an environment where AI 
enhances societal, creative, and economic opportunities for all. This balanced 
3 


approach not only aligns with the principles underlying our copyright system but 
also supports the broader objectives of promoting innovation and competitive 
fairness in the burgeoning ﬁeld of arti ﬁcial intelligence. 
Support Open-Source, Collaborative Research and Development 
The advancement of arti ﬁcial intelligence through open-source methodologies is a 
strategic necessity in today’s technology landscape. Open-source AI development 
fosters a collaborative environment that is essential for innovative breakthroughs and 
ensures widespread sharing of those breakthroughs to advance the state of the art. 
This approach aligns with Public Knowledge’s long-standing advocacy for policies 
that promote technological openness and transparency, as detailed in our 
comments submitted to the National T elecommunications and Information 
Administration (NTIA) proceeding on Widely Available Model W eights (WAMW 
Comment).4 
Advantages of Openness in AI 
Open-source AI development is instrumental for driving safety, innovation, and 
competition within the tech industry. Open-source AI models allow for widespread 
scrutiny by researchers and developers across the globe, which enhances the safety 
of these technologies by exposing potential ﬂaws and vulnerabilities that closed 
systems might conceal. This transparency not only leads to more robust AI systems 
but also accelerates the pace of innovation by allowing developers to build upon 
each other's work without the barriers imposed by proprietary technologies. 
The competitive advantages of open-source AI are signi ﬁcant. By lowering barriers to 
entry, open-source AI allows startups and smaller tech companies to compete with 
larger entities, thereby preventing market monopolies and encouraging a diverse 
technological ecosystem. This diversity is crucial for spurring creative solutions to 
complex problems and for preventing any single entity from establishing too much 
control over AI technologies. Openness on a Spectrum 
Recognizing that openness exists on a spectrum is vital for understanding the varied 
beneﬁts that different degrees of openness can provide. As noted in our WAMW 
Comment, openness should be de ﬁned for AI systems to promote free, open, and 
accessible technology and AI policy should recognize a broad spectrum of openness 
for AI systems.5 This nuanced view acknowledges that while full openness is ideal for 
5 WAMW Comment at pg. 6-7. 4 https:/ / publicknowledge.org/ policy/ ﬁnal-ntia-comments/ 
4 


maximizing the aforementioned bene ﬁts, any move towards greater transparency 
can yield signi ﬁcant advantages. 
For instance, even partial openness, such as sharing model weights or training 
dataset information, can contribute positively to the AI community. This level of 
openness can help balance proprietary interests with public bene ﬁts, providing a 
gateway for more companies and individuals to engage with and contribute to AI 
advancements. 
Encouraging More Openness 
T o foster an environment where more openness in AI is encouraged, it is crucial to 
support policies that facilitate access to public datasets, open APIs, and collaborative 
platforms. As discussed further below, investing in public infrastructure that supports 
open-source AI—such as cloud services, computing power, and storage—can 
democratize access to the necessary tools for open-source AI development. 
Furthermore, government and educational institutions can play a pivotal role by 
advocating for and adopting open-source AI solutions, setting a standard for 
transparency and collaboration. 
Moreover, creating incentives for companies to adopt open-source practices can 
accelerate the shift towards a more open AI landscape. These incentives could 
include tax breaks, grants, or public recognition for companies that contribute to 
open-source projects or that make their proprietary technologies partially open. In conclusion, supporting open-source and collaborative AI development is essential 
for ensuring that AI technologies are safe, innovative, and competitive. By advocating 
for more openness, whether complete or partial, we can cultivate an AI ecosystem 
that is not only technologically advanced but also equitable and accessible to all. This 
commitment to openness will underpin the continued growth and success of the AI ﬁeld, ensuring it remains a positive force for technological progress in society. 
The Government Should Tackle the Physical and Digital Public 
Infrastructure Obstacles to American AI Innovation and Leadership 
Arti ﬁcial intelligence has the potential to transform industries, drive economic 
growth, and enhance public services in ways that parallel some of the most 
consequential technological advancements in history. However, realizing AI’s full 
promise requires a strong foundation—one that is currently lacking in the United 
States due to a lack of public investment in essential AI infrastructure. Just as past 
infrastructure projects in electriﬁcation, transportation, and telecommunications laid 
the groundwork for American leadership in the industrial and digital economies, the 
5 


federal government must now invest in “Public AI” infrastructure to ensure the 
nation remains at the forefront of innovation and competition.6 
Without decisive action, AI development will remain concentrated in the hands of a 
few dominant corporations, reinforcing monopolistic control over computing power, 
data resources, and development expertise. This concentration of AI capabilities 
stiﬂes competition, inhibits broader participation in AI research, and risks ceding 
strategic technological leadership to other nations that are already making 
signiﬁcant public investments. A robust Public AI infrastructure strategy can 
counteract these trends by creating a competitive and innovative AI ecosystem that 
beneﬁts businesses, researchers, and the public at large. 
Historical Precedents for Public Infrastructure Investments 
The federal government has historically played a pivotal role in fostering 
technological advancements through large-scale public investments. The 
electri ﬁcation of America in the early 20th century was not merely a product of 
private enterprise but a result of government-supported initiatives like the Rural 
Electriﬁcation Act.7 Similarly, the construction of the interstate highway system in the 
1950s—one of the largest public works projects in history—enabled the rapid 
expansion of the automotive industry and facilitated economic growth across the 
country.8 These investments did not “pick winners and losers” in the private sector 
but instead created a level playing ﬁeld that allowed businesses of all sizes to thrive. 
AI requires a similar commitment to public infrastructure. Just as roads, bridges, and 
power grids are essential for economic activity, AI development depends on a robust 
foundation of computing resources, data availability, and research capabilities. 
However, unlike previous infrastructure projects, Public AI infrastructure must 
account for both physical (compute and hardware) and digital (data and software) 
elements. Most importantly, these investments must be truly public, with robust 
public accessibility and public accountability mechanisms, ensuring that taxpayer 
dollars actually provide long-term beneﬁts rather than merely subsidizing 
private-sector expansion. 
The Risks of Privatized Digital Infrastructure 
A cautionary tale can be found in the privatization of the internet. While the U.S. 
government initially supported the research and development of the internet 
through national laboratories and public institutions,9 much of the internet’s physical 
9 https:/ /www.nsf.gov/impacts/internet  8 https:/ /www.archives.gov/ milestone-documents/ national-interstate-and-defense-highways-act 7 https:/ /livingnewdeal.org/ glossary/ rural-electri ﬁcation-act-1936/ 6 See, https:/ / publicai.network/whitepaper/  
6 


infrastructure was later privatized, leading to monopolization in broadband 
deployment. The result has been a market characterized by slow speeds, limited 
competition, and high costs for consumers.10 The failures of broadband 
policy—including uneven access, weak customer protections, and underinvestment 
in infrastructure—serve as a stark warning for AI. In a sector where there is already 
considerable market entrenchment in terms of compute power and data access, an 
AI strategy that does not strongly emphasize public infrastructure will follow an even 
sharper downward trajectory, leading to re-entrenchment and concentrated power 
in the hands of a few dominant Big T ech ﬁrms. 
T o avoid repeating these mistakes, the federal government must take proactive steps 
to ensure key AI infrastructure remains a public good, rather than an exclusive asset 
controlled by a handful of ﬁrms. This means making strategic investments that build 
public AI infrastructure while ensuring broad access to essential AI capabilities. 
Three Key Areas for Public Investment 
T o foster a more open, competitive, and innovative AI ecosystem, the federal 
government should invest in three critical areas: public compute resources, open 
data infrastructure, and Public AI model development. These investments will 
provide the essential building blocks for AI research and development, ensuring that 
AI innovation is not limited to well-funded tech giants. 
1. Public Compute Infrastructure: A Smarter Approach Than Simply Subsidizing
Private Data Centers
One of the most pressing challenges in AI development is access to computational 
power. The cost of training frontier AI models is one of the primary bottlenecks in the 
industry, with the leading AI ﬁrms spending billions on proprietary data centers. 
Without access to similar compute resources, startups, research institutions, and 
smaller companies struggle to compete, leading to further industry consolidation at 
the whims of Big T ech hyperscalers. 
Instead of offering subsidies or regulatory support to private tech ﬁrms to expand 
their existing infrastructure, the government should invest directly in public 
compute resources. This could take the form of national AI research compute centers 
housed within federal agencies, universities, or national laboratories or even state 
and local programs to develop community-based compute resources through digital 
anchor institutions like schools and libraries. By leveraging existing federal resources 
and research facilities, the government can create public alternatives to 
10 See e.g., https:/ /www.npr.org/transcripts/899472976 
7 


private-sector compute monopolies, ensuring that AI capabilities remain accessible 
to a diverse range of innovators and users. 
Public compute initiatives like the National AI Research Resource (NAIRR) represent 
an important step in this direction for expanding access for academics and 
researchers and administration support for the broadly bipartisan CREATE AI Act 
would be an excellent starting place, but more ambitious efforts are needed. The 
Trump Administration should go further and develop policy pilots that expand 
compute capacity and access to entrepreneurs, small businesses, and individuals. 
 Similar to how public roads enabled private sector growth without picking corporate 
winners, publicly accessible compute infrastructure will provide a baseline level of 
access to AI resources, fostering competition and accelerating AI research across 
multiple sectors. 
2. Open Data Resources: Strengthening National AI Research Capacity
Data is the lifeblood of AI. Y et, access to high-quality, well-curated datasets is 
restricted by cost and fears about copyright liability risk. This creates an uneven 
playing ﬁeld where only the biggest (or most reckless) companies can access the 
data required to develop competitive AI models. This concern is particularly 
important given the ongoing race for AI dominance with China: data access, though 
the details remain opaque, has been cited as one of the primary advantages for 
Chinese AI developers.11 
T o address these imbalances, the government should expand support for public data 
repositories, ensuring that high-quality datasets are available for academic and 
commercial research. Again, the NAIRR provides a strong starting point, but 
additional efforts could include expanding the role of the Library of Congress in 
curating publicly available digital datasets, developing AI-ready datasets through 
partnerships with universities and research institutions, and ensuring that copyright 
law does not restrict the ability to use publicly available information for AI training. 
Unnecessary expansions of copyright law that restrict access to factual information 
would not only hinder AI development but would also undermine the broader 
principles of knowledge-sharing and scientiﬁc progress. 
By investing in open data infrastructure, the government can prevent AI knowledge 
from becoming the exclusive property of a few corporations, ensuring that publicly 
funded data resources remain accessible to all. 
11 See e.g.,  
https:/ /www.brookings.edu/ articles/how-to-tackle-the-data-collection-behind-chinas-ai-ambitions/ 
8 


3. Building Instead of Buying: Developing Publicly-Owned AI Models and
Applications
For decades, the federal government has played a crucial role in advancing 
technological innovation, often laying the foundation for private-sector 
breakthroughs. However, in artiﬁcial intelligence, the government has largely limited 
its role to procurement rather than direct development, creating unnecessary 
dependence on private vendors and exposing critical public functions to 
monopolistic control. Expanding the government’s capacity to develop AI models 
through national laboratories, universities, and federal agencies is essential to 
ensuring that AI development remains transparent, accountable, and aligned with 
national interests. Initiatives like the Department of Energy’s FASST (Fair, 
Accountable, Secure, and Safe T echnology) AI program demonstrate that publicly 
funded research can produce cutting-edge AI systems designed for public beneﬁt 
rather than private pro ﬁt.12 Strengthening these efforts will ensure that AI remains an 
accessible and equitable technology rather than a privatized asset controlled by a 
few dominant ﬁrms.   
Relying on private-sector AI procurement poses several risks. First, private AI models 
are driven by pro ﬁt incentives, often neglecting applications that serve critical public 
needs such as scienti ﬁc research, healthcare, and equitable access to AI-driven 
services. Dependence on private ﬁrms also leads to vendor lock-in, reducing 
government ﬂexibility and increasing long-term costs. Once locked into proprietary 
systems, agencies face high barriers to switching providers or modifying models to 
meet evolving public needs. Additionally, private-sector AI systems often lack 
transparency, making it dif ﬁcult for regulators and the public to scrutinize their 
decision-making processes, ensure fairness, and prevent discriminatory outcomes. 
On the other hand, developing publicly owned AI models enhances transparency 
and oversight, ensuring that government-deployed AI aligns with democratic values 
and public accountability standards. Federally developed models can incorporate 
rigorous data governance, algorithmic transparency, and auditing mechanisms, 
particularly for sensitive applications such as law enforcement or public health. 
Public investment in AI model development can also foster competition by providing 
alternatives to dominant private models, reducing barriers to entry for startups, 
academic researchers, and smaller ﬁrms that lack access to commercial models. 
Government-developed models can be open-sourced or otherwise be made publicly 
available to ensure that there are low-cost, public options for AI models in order to 
create stable alternatives to private offerings. 
12 https:/ / publicknowledge.org/ policy/ comments-in-response-to-doe-request-for-information-on-fasst/ 
9 


Beyond competition and transparency, public investment in government  AI 
research strengthens the federal workforce and enhances government expertise in 
AI governance. Expanding AI research and development within national labs and 
federal agencies cultivates a skilled public-sector workforce capable of managing, 
deploying, and regulating AI technologies effectively. Programs like FASST provide a 
framework for building internal AI capacity, reducing reliance on private contractors 
and ensuring that AI policies and models remain under democratic oversight.  Public AI initiatives should span the entire AI technology stack, from compute 
resources to datasets and pretrained models, ensuring that critical bottlenecks are 
identiﬁed and addressed. By investing in AI model development rather than simply 
purchasing proprietary systems, the government can prevent monopolization, 
reduce dependency on opaque private models, and build the expertise in AI 
technology that our government and workforce needs. 
Explainability and transparency standards are essential for AI 
innovation and adoption. 
The widespread adoption of arti ﬁcial intelligence requires public con ﬁdence in its 
fairness, reliability, and accountability. Without clear mechanisms to understand, 
audit, and assess AI models, both innovation and public trust in AI technologies will 
be severely limited. Standards for AI transparency and explainability—established 
through voluntary, consensus-driven processes and coordinated by the federal 
government through agencies like the National Institute of Standards and 
T echnology (NIST) and the U.S. Arti ﬁcial Intelligence Safety Institute (AISI)—are 
essential for ensuring that AI systems are both safe and effective. By setting clear 
expectations for transparency and explainability, these standards can serve as the 
foundation for trust in AI-driven products and services, ultimately accelerating AI 
adoption across industries. 
Transparency as a Prerequisite for AI Accountability 
Transparency in AI should go beyond basic disclosures and include structured 
accountability mechanisms that provide meaningful insights into how AI models 
function, what data they rely on, and how they impact users. Public Knowledge has 
consistently emphasized that AI systems must not operate as black boxes but should 
be subject to rigorous transparency and explainability requirements to ensure 
accountability and fair outcomes. 
AI transparency is a key component of consumer protection and business 
con ﬁdence. When AI models in ﬂuence decisions in hiring, lending, healthcare, and 
10 


other critical domains, affected individuals and businesses should have access to 
clear, understandable explanations of how those decisions are made. Public 
disclosure of AI decision-making criteria, model training data sources, and 
algorithmic biases fosters trust and prevents discriminatory or harmful outcomes. 
Moreover, transparency should, at a minimum, be a strongly incentivized industry 
norm, reinforced through structured reporting standards, third-party audits, and 
disclosure mechanisms. By establishing voluntary and consensus-driven transparency standards through 
NIST and AISI, the federal government can help businesses and developers adopt 
best practices that increase consumer con ﬁdence without sti ﬂing innovation. 
Transparency empowers users, regulators, and businesses alike by providing the 
information necessary to assess risks, identify biases, and ensure AI systems are 
functioning as intended. 
Explainability as a Foundation for AI Safety and Innovation 
Similarly, explainability is critical for both users and developers to understand how AI 
systems operate and why they make certain decisions. A well-calibrated 
explainability framework ensures that AI is not only interpretable to experts and 
regulators but also comprehensible to end users who interact with AI-powered tools. 
Without explainability, AI models risk being seen as opaque, unaccountable, and 
untrustworthy, limiting their adoption in key sectors such as ﬁnance, healthcare, and 
legal decision-making. 
For businesses, explainability serves as a competitive advantage—companies that 
can offer clear, understandable AI systems will be better positioned to attract 
customers and comply with evolving regulatory expectations. For developers, 
explainability improves the ability to debug, reﬁne, and enhance AI models, leading 
to more reliable and adaptable AI systems over time. Y et proof of these capabilities 
remains technically challenging. Further developing research into AI explainability 
and developing an accountability environment that can validate AI behavior should 
be a priority of this administration. Public Knowledge has emphasized that AI 
accountability mechanisms—including certiﬁcations, audits, assessments, and 
testing—should be more than just “trust seals”. Instead, they must be meaningful, 
enforceable, and integrated into broader safety and consumer protection 
frameworks.13 
T o ensure effective AI adoption, both explainability and transparency standards 
should be developed in coordination with industry leaders, researchers, and 
consumer advocacy groups, ensuring that they are both technically feasible and 
13 https://publicknowledge.org/policy/ntia-ai-accountability/ at pg. 3. 
11 


aligned with public interests. Agencies like NIST and AISI should play a leading role in 
establishing best practices, testing explainability methodologies, and guiding 
businesses toward responsible AI deployment. AI innovation and adoption will only 
reach their full potential if businesses, consumers, and regulators trust that AI 
systems operate fairly, make accountable decisions, and can be independently 
assessed. V oluntary and consensus-driven standards-setting efforts led by NIST and 
AISI will provide the framework needed to ensure transparency and explainability 
while maintaining ﬂexibility for industry advancement. These standards should 
encourage widespread disclosure, independent testing, and structured auditing 
mechanisms that enhance both AI safety and public con ﬁdence. By prioritizing 
transparency and explainability, the U.S. can position itself as a leader in responsible 
AI governance, ensuring that AI-driven technologies remain trustworthy, 
competitive, and aligned with democratic values. 
Conclusion 
Arti ﬁcial intelligence presents extraordinary opportunities for economic growth, 
scienti ﬁc discovery, and public bene ﬁt, but its continued success depends on 
maintaining an ecosystem that is open, competitive, and accountable. T o ensure that 
AI innovation is aligned with public interest, this administration should take proactive 
steps to protect the rights to read and learn, support open-source AI development, 
invest in public infrastructure, and develop transparency and explainability standards 
that build trust in AI systems.  
T o ensure innovation and American AI leadership on the global stage, Public 
Knowledge urges the administration to prioritize policies that foster competition, 
encourage collaboration, and prevent industry consolidation from stiﬂing the 
potential of this potentially revolutionary technology.  
By embracing competition and openness, and taking a bold lead with Public AI 
infrastructure investment, the U.S. will ensure it continues to lead the world in AI 
innovation. Public Knowledge looks forward to opportunities to advise the 
administration on developing an AI Action Plan and policies that ensure AI beneﬁts 
all Americans. 
This document is approved for public dissemination. The document contains no 
business-proprietary or con ﬁdential information. Document contents may be 
reused by the government in developing the AI Action Plan and associated 
documents without attribution. 
12 


