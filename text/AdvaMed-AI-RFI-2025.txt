1301 Pennsylvania Avenue, NW 
Suite 400 
Washington, D.C. 20004  
P :: 
F :: 
W:: AdvaMed.org 
March 14, 2025 
National  Science Foundation 
Networking and Information Technology Research and Development (NITRD), National Coordination 
Office (NCO)  
Re: AI Action Plan , Request for Information  
To Whom it  May Concern, 
The Advanc ed Medical Technology Association (AdvaMed) appreciate s the opportunity to submit 
comments in response to your February 6, 2025 request for information (RFI) on the development of an 
artificial intelligence (AI)  action plan1.  
AdvaMed is  the world's largest association representing manufacturers of medical devices, diagnostic 
products, and medical technology. AdvaMed's member companies range from the largest to the smallest 
medical product innovators and manufacturers, with nearly 70 percent of our members generating less than $100 million in annual sales. AdvaMed's member companies produce innovations that transform healthcare through earlier disease detection, less invasive procedures, and more effective treatments. AdvaMed advocates for a legal, regulatory , and economic environment that advances global healthcare 
by assuring worldwide patient access to the benefits of medical technology. The Association promotes 
policies that foster the highest ethical standards, timely  product authorization, appropriate 
reimbursement, and access to international markets. 
We recogni ze AI as a transformational tool with the potential to improve health outcomes, enhance 
efficiency of patient care, lower costs, and make advancements in healthcare. Right- sized policies can 
promote the development, deployment, and adoption of innovative and trustworthy AI- enabled 
solutions. AdvaMed  is uniquely well -positioned to provide feedback on frameworks and policy 
considerations regarding AI because our members have been developing and deploying AI -enabled 
medical devices  that support patient care for over 25 years . 
We appreciate the opportunity to submit our high- level recommendations  on priority policy actions 
needed to sustain and enhance AI innovation in the medical device industry.  
1 https://www.federalregister.gov/documents/2025/02/06/2025-02305/request -for-information- on-the -development -of-an-artificial-
intelligence -ai-action -plan 


Regulatory Oversight of AI -enabled Medical Devices   
All medical devices , including AI -enabled devices,  are subject to the Food and Drug Administration’s 
(FDA)  comprehensive and robust risk -based regulatory framework that provides for oversight of the 
device across the total product lifecycle. The FDA ’s premarket evaluation  includes an assessment of  
device performance, reliability, and safety . After the devices are authorized for sale,  device 
manufacturers are subject to post-market requirements including implementing robust quality 
management systems, device monitoring, and reporting of serious adverse events. Collectively, FDA ’s 
regulatory framework and guidance ensure that safety and performance considerations unique to AI -
enabled medical devices are evaluated and implemented with the appropriate context and oversight.  
As discussions about oversight of AI technologies across industries continue to evolve, it is crucial to 
distinguish between the different applications of AI (e.g., medical devices vs. self-driving cars) and ensure that regulations are sector -specific and appropriately tailored to the respective uses and needs. 
Legislation or regulation that attempts to address  AI across  all industries  has the potential to introduce 
redundant or conflict  requirements with existing medical device regulations, slowing innovation and 
delaying timely patient access to important medical devices.  Overly broad and burdensome regulations 
risk stifling innovation, diminishing patient care  and adversely impacting global competitiveness.  
FDA  should remain the lead regulator responsible for overseeing the safety and effectiveness of AI-
enabled medical devices.  The existing FDA regulatory framework remains well suited for AI -enabled 
medical devices and FDA  has the best understanding of the unique considerations and risks specific to 
AI-enabled medical devices. We encourage the U.S. government to  continue to leverage FDA’s existing 
capabilities  and regulatory framework to avoid duplication or contradiction in regulatory approaches.  
FDA Reso urces 
While p ublic discussion regarding AI has increased in recent years, the utilization of AI is not new for 
the medical device industry, which has been developing and deploying FDA -regulated AI-enabled 
medical devices for more than 25 years2. As of December 2024, the FDA  has authorized over one 
thousand AI- enabled devices  across a variety of medical specialties including radiology, oncology, 
cardiology, and neurology. This number is only expected to grow , especially as the number of clinical  
applications expands and their clinical importance continues to be demonstrated. Therefore, it is 
critically important to safeguard  the process of getting the latest and most promising medical 
technologies into the hands of U.S.  doctors and patients. An effective FDA is an essential element of 
that process.  Insufficient staffing and skills at FDA will slow -down product review times, reducing the 
ability of America to be first in the world to benefit from the most innovative products, including AI-
enabled medical devices . An efficient, transparent, and effective FDA is enabled through user fee 
agreements that ensure it is adequately staffed with the technical expertise necessary to keep pace with 
innovation. 
2 https://www.fda.gov/medical-devices/software-medical -device-samd/artificial-intelligence -and-machine-learning -aiml -enabled -medical -
devices    


Performance Assurance  & Safety Standards 
In recent years, healthcare stakeholders have begun exploring the creation of third-party quality 
assurance labs  focused on performance monitoring. However, we have concerns about the suitability 
and practicality of this approach for regulated medical devices . Given FDA’s existing oversight of AI-
enabled medical devices , third -party labs for regulated medical devices are redundant. If third -party labs 
were linked to the regulatory process, their use would effectively become mandatory, increasing costs 
and burdens for manufacturers who already evaluate their devices  in accordance with  best practices like 
those cataloged  in FDA -recognized  international consensus standards.  
We are also  concerned that t hird-party evaluators, such as assurance labs,  may utilize proprietary 
methods and metrics that would lack transparency to developers, patients , and providers. There are also 
significant concerns about their handling of sensitive  training and testing data. Mandating manufacturers 
to share proprietary information about AI- enabled devices with external labs raises confidentiality, 
intellectual property  (IP), and security issues as v ariability in lab security practices for third -party labs 
could expose or jeopardize sensitive manufacturer or patient information.  Implementing a third -party 
framework of labs creates, at best, redundancy with existing FDA oversight while potentially increasing costs, slowing innovation, and limiting access to valuable medical devices, without clear benefit to clinicians or patients.   
Rather than create a new framework of third -party evaluators, p olicymakers should continue to 
encourage FDA to participate in the development and timely recognition of accredited and consensus-
based standards for safety and quality assurance processes.  The longstanding practice of relying on 
collaboratively developed, international consensus standards promotes a deeper understanding of both 
the benefits and risks of these technologies while  improving transparency. Enabling manufacturers to 
utilize consensus standards allows for robust quality and safety assurance that maintains data security and IP confidentiality. This approach supports patient safety and innovation by minimizing the need for external assessments, which could introduce added costs, regulatory delays, and potential security vulnerabilities.   
International Collaboration 
AdvaMed members support a globally harmonized regulatory approach for AI- enabled medical devices. 
We support the recent collaborative efforts between FDA, Health Canada, and UK MHRA to establish a common perspective on good machine learning (ML) practices for medical device development
3, PCCP  
(Predetermined Change Control Plans) for ML -enabled medical devices4, and transparency for ML-
3 https://www.fda.gov/medical-devices/software-medical -device-samd/good-machine-learning -practice-medical -device-development -
guiding-principles  
4 https://www.fda.gov/medical-devices/software-medical -device-samd/predetermined -change -control -plans -machine-learning -enabled -
medical -devices -guiding -principles  


enabled medical devices5.  We encourage FDA and policymakers to continue to consider policies and 
practices that support global alignment, where practical.      
FDA must ensure the tools and processes it has under its existing authority are implemented and, where 
appropriate, adapted to keep pace with emerging technologies. As AI technology matures, international 
consensus standards specific to medical devices should be the foundation for safe, effective, and 
responsible AI model development and deployment. It is critical that FDA prioritize the development, revision, and timely recognition of such standards to promote industry-wide adoption of these best 
practices . Prioritizing  international consensus standards would support consistency in FDA’s 
expectations for AI- enabled medical technologies  while harmonizing with globally recognized best 
practices . 
Payment/R eimbursement  
Appropriate reimbursement for the adoption and use of AI- enabled medical technologie s is critical to 
ensuring patients have timely access to and benefit from these innovations. As the nation’s largest payer 
of health care, Medicare’s policies on coverage and payment for AI -enabled medical  technologies are 
especially critical, applying to the millions -strong Medicare population, and because private payers and 
state Medicaid plans often look to Medicare as they establish their own coverage policies.  
We believe Medicare has regulatory authority to expand access to AI- enabled medical  technologies. 
However, its regulatory framework currently lacks the specificity and clarity to provide coverage and 
payment for digital health technologies broadly and for AI-enabled medical technologies and software specifically. The result has been incremental, technology-specific policy changes, with many AI and software innovators struggling to find pathways to coverage and reimbursement for new technologies. 
There is no “one size fits all” reimbursement policy for every AI- enabled medical  technology. Instead, 
appropriate payment mechanisms vary depending on the kind of technology in question and the clinical 
setting in which it is used. Regardless, accurately capturing the cost and value of these technologies is critical to ensuring appropriate reimbursement.   
American patients  deserve access to safe, proven effective medical technology that can improve their 
health outcomes and meet underserved clinical needs, such as mental health services. Patients  stand to 
gain greatly from the development and adoption of digital health and AI- enabled medical technologies 
that improve the diagnosis and treatment of illness and disability, promote healthy behaviors, and support population health management. Appropriate reimbursement policies will enable doctors, hospitals, and other caregivers to adopt AI- enabled medical technologies  into their practices, improving 
the care they can give patients.   
Data Access & Data Privacy  
AI is distinguished from other health technologies by its ability to analyze vast datasets to assist physicians in diagnosis and treatment, supplement and enhance the clinical process, and offer 
5 https://www.fda.gov/medical-devices/software-medical -device-samd/transparency -machine-learning -enabled -medical -devices -guiding-
principles  


personalized health care solutions. AI can provide insights that may not otherwise be available via 
conventional health care technologies or techniques and rapidly process data to produce clinical support and recommendations that can be used to inform care decisions.  
Large, diverse data sets are needed by AI medical device developers to train and validate trustworthy 
algorithms. Unlocking the potential of AI- driven health care solutions is linked to the availability of 
high-quality data to build and evaluate these technologies. Challenges such as the fragmented nature of 
health care data, non -standardized data formats, difficulty accessing data across different health systems, 
and the lack of interoperability between platforms impede the pace of innovation. Flexibility to pursue 
different approaches to obtaining and utilizing data is crucial to ensuring innovation is not limited by 
data access.  
Data aggregation and access processes are currently siloed and complex to navigate. Data needed to 
produce valuable health care insights is spread across many different data aggregators and third-party data vendors whose data is not standardized, leading to disparate data quality and utility. Additionally, there are only a handful of commercial vendors that provide services needed to link data (e.g., for purposes of tokenization and expert determination).  
In undertaking data collection, it is crucial to address the data protection requirements for the large- scale 
processing of health data that powers AI models. Safeguarding patient privacy and ensuring robust data 
security are vital to protecting sensitive health information. Moreover, informed notice and patient 
autonomy are important to meaningful patient involvement in AI- driven health care decisions.  
While AdvaMed supports robust privacy and security protections for patient data, current federal laws 
pose difficulties for AI developers to access and utilize large- scale datasets with intact metadata which 
are needed to provide solutions for patients. The Health Insurance Portability and Accountability Act of 
1996 (HIPAA) required the creation of national standards to protect sensitive patient health information 
from being disclosed without the patient's consent or knowledge. HIPAA and its implementing  
regulations impose strict requirements on the collection, storage, use, and disclosure of patient health 
data resulting in challenges for developers to access sufficient training data, especially when it has 
undergone anonymization. 
Data quality and provenance are important considerations for AI medical device developers in the 
training and validation of AI models. Privacy law requirements for de- identification and/or minimization 
of personal data or metadata can be inconsistent and at tension with these important considerations. These restrictions may  impact the ability of AI medical device developers to: 
• access, store and retain training and validation datasets (and metadata) over a certain period of 
time to meet FDA’s recommendations; and  
 
• demonstrate that the dataset used to train and tune the device is robust and representative of the intended patient population. To conduct a bias analysis, for example, patient demographic and 
health information may be required (e.g., ethnicity, sex, gende r, age, and any relevant clinical 


indications). This information can be hard to obtain, or it may be difficult to negotiate retention 
periods or data use rights. 
As such, we respectfully request that the National Science Foundation consider the following when drafting an artificial intelligence (AI) action plan: 
•Ensure data protection without stifling innovation . Develop  a pragmatic approach for AI in
health care that promotes the development of privacy-preserving techniques, balancing
innovation and the development of AI solutions with the need to protect sensitive health data.
oAdvance comprehensive federal legislation with strong preemption that differentiateshealth data from general consumer data due to its unique role in patient safety, care
coordination, and innovation.
•Evaluate updating HIPAA for the AI era and provide clear guidance for health data use in AI
development.  Ensure that HIPAA standards allow for the sharing of the datasets needed to train,
test, validate, and re-train AI models while preserving patient privacy. The current HIPAA de-
identification methods (authorization, safe harbor, and expert determination) stifle the high -
volume data usage and sharing that can optimize the development of safe and accurate AImodels.
•Develop appropriate guidelines around patient notice and authorization for the data used to
develop AI . More data will allow for the creation of better, more accurate AI models , ultimately
leading to better outcomes for patients. Patient notice and authorization should be at the center of
additional data accessibility. New frameworks for health data regulation should consider anydata limitations presented by HIPAA and other privacy laws.
We recogni ze that the pace of innovation is fast. As federal legislators seek to ensure AI -enabled 
products in all industries are used safely , we appreciate the opportunity to provide feedback on policy 
priorities and recommendations related to medical devices. AdvaMed member companies take seriously 
the level of trust placed in them by patients and have consistently taken action to self-identify best 
practices that  balance innovation with patient protections. Thank you for the opportunity to submit these 
comments. Please consider AdvaMed as a resource on med -tech regulatory, data stewardship, 
reimbursement, and privacy matters as you consider policies  related to AI and medical devices.   
Statem ent provided in accordance with the RFI Instructions: This document is approved for public 
dissemination. The document contains no business-proprietary or confidential information. Document contents may be reused by the government in developing the AI Action Plan and associated documents without attribution.  


Respect fully Submitted,  
Terry Cha ng, M.D.  
Vice President  
Privacy and Legal  
Zack Hornbe rger   
Senior Director, Digital Health & Imaging Technology 
AdvaMed Medical Imaging Division 
Geeta Pamid imukkala , M.S.   
Vice President  
Technology and Regulatory Affai rs 
Kirsten T ullia, J.D., MPH   
Senior Vice President  
Payment and Reimbursement 


