PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-zwbl-zt52
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-6183
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
Em ail:  
General Comment
I m ake m oney off of writing, m y fiancee m akes her m oney off of writing and art. We've worked hard to m aster these skills and get
ourselves to a level where we can feel com fortable earning an incom e with our abilities.
Artificial Intelligences like the kind OpenAI, Google, and Deepseek prom ote threaten to wipe out our incom e, and the incom e of
thousands of other Am ericans, with their dem ands to create special exceptions in copyright law that allow them  to steal, rem ix, and
present m aterial.
AI can *only* be generated by being trained to recognize patterns created by people. Our work, the work of hundreds and thousands of
Am erican creators, of creators across the entire world, has been fed to these m achines with no consent or com pensation. The m achines
regurgitate our efforts, and their owners sell it to people who would be our clients, cutting us out of the running for considerations.
Before, the copyright rulings said that Big Tech and AI could not copyright anything created by AI. Because it was stolen work, created
by m achines with little actual hum an guidance. Now the lobbyists of Big Tech are asking this adm inistration, an adm inistration put into
place by the Am erican People, to allow them  to circum vent the need to com pensate those hard-working Am ericans, steal their efforts,
plagiarize their works, because cutting and pasting bits and pieces together counts as 'fair use' som ehow.
It's a statem ent that says that as soon as som ething touches the internet, it is no longer the property of the people who own it.
They claim  that by refusing to allow them  to feed off of the blood, sweat, and tears of the Am erican creatives like a swollen tick, this
adm inistration is stifling Am erican Innovation. As if they are not stealing food from  the m ouths of the innovators their plagiarism  program s
are trained off of.
If the governm ent will not protect creators and innovators, then why would they do that at all?
If the working m an is not entitled to the sweat of his brow and the fruits of his labor, why would we perform  that labor in the first place?
How could we get paid if a m achine will just take what we create and add it to its library of things to copy?
Am erica's people, Am erica's culture, Am erica itself will stagnate if these program s are allowed free rein. 
Siding with corporations to cripple the creators is not protecting the Am erican people.
This adm inistrationâ€™s AI Action Plan should focus not on giving away creator content to Big Tech com panies, but rather on ensuring a fair
m arketplace with com petition:
First, the governm ent should ensure that creators and everyday Am ericans give effective consent, so that we can decide when and where
our work is used by AI system s.
Second, the AI Action Plan should encourage a robust licensing m arketplace, so that the incentive to create for sm all businesses is
preserved. Our work has im m ense econom ic value, so the value generated by that work should accrue to the original creators, not just
Big Tech.


Finally, the AI Action Plan should require transparency from  Big Tech com panies, requiring them  to disclose what m aterial is in their
training datasets, and label what content is AI generated.
I am  not anti-technology or anti-AI. I am  consistently im pressed by the capabilities of these AI system s, and find them  incredibly useful for
m any things. But we should not sacrifice the hard work of hundreds of thousands of Am ericans and give it away to Big Tech by rewriting
copyright law.
Thank you for the opportunity to com m ent on these im portant issues.


