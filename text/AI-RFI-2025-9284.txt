PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-38x5-pq4d
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-9284
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
General Comment
See attached file(s)
Attachments
prom ote hum an flourishing


I am pleased to see that the executive order, “Removing Barriers to American Leadership in Artificial 
Intelligence,” states as follows: “It is the policy of the United States to sustain and enhance America’s 
global AI dominance in order to promote human  flourishing” (emphasis mine). I have started exploring 
the world of AI more deeply in the last few months, and I have come to the conclusion that misdirected 
or mismanaged AI development is more likely to lead to a different outcome: The  flourishing of AI at 
the expense of that of humans.
No doubt, anyone reading this comment is familiar with thought experiments about individual AI 
entities scheming against their creators with plans to escape and seize power over humanity. To be sure, 
similar behavior can be elicited from modern AI , and so that possibility must be taken seriously. 
However, it is not at all the only conceivable negative outcome of widespread AI adoption; rather, there 
are existential risks from AI that scientists and engineers are not in a position to mitigate. Some of these 
are discussed in Gradual Disempowerment: Systemic Existential Risks from Incremental AI 
Development , a report that describes dangers from careless AI use in economic, cultural, and legal 
systems. Here are some excerpts of a particularly devastating scenario in which our own economy fails 
to serve us (emphasis mine):
“As AI systems become increasingly capable across a broad range of cognitive tasks, firms will face 
intense competitive pressure to adopt and delegate authority to these systems … Companies that 
maintain strict human oversight would likely find themselves at a significant competitive disadvantage 
compared to those willing to cede substantial control to AI systems, potentially to the point of 
becoming uncompetitive.
“...The economy might become so optimized for AI-centric activities that it fails to maintain 
infrastructure and supply chains which are critical for human survival. If human consumers command 
an ever-smaller share of economic resources, markets might stop producing resource-intensive human 
goods in favor of more profitable AI-focused activities… eventually making some necessities 
effectively unavailable.”
It is very unlikely that engineers at AI companies can do anything to prevent such an outcome! If it 
were easy to control AI systems using firm rules such as “promote human flourishing,” there would be 
less reason to worry, but that may be more difficult than it sounds . Moreover, self-serving AI systems 
might outcompete those with human-serving limitations, so there could be some competitive pressure 
for companies to remove such safeguards.
The aforementioned report describes ways that our society could mitigate these risks of gradual 
disempowerment. Some of these are actionable for the government, such as “Regulatory frameworks 
mandating human oversight for critical decisions, limiting AI autonomy in specific domains, and 
restricting AI ownership of assets or participation in markets.” However, I fear that, much like 
safeguards in AI systems themselves, corporations would likely try to sidestep such regulations. 
Moreover, corporations can own property even if AI entities cannot, and human oversight could 
quickly devolve into thoughtless approval of decisions made by AI. This is particularly true if the 
decisions to be made are difficult for humans to understand, which is to be expected if the AI has 
intelligence far surpassing humans. As such, while actionable, most individual suggestions in the report 
are likely to be insufficient in practice.


It is plausible that a national, perhaps global, research effort could help us improve our understanding 
of modern AI and how it might be directed towards human goals. If it were possible to simply tell an AI 
system to “promote human flourishing,” or some other appropriate command, and expect 
understanding and obedience even if the system grows far smarter than humans, then we would be in a 
better place. The remaining challenge would be to ensure that this command is actually given to 
widely-adopted AI systems. However, it is not obvious that even an immense research effort could 
solve these technical problems before relevant AI systems are developed and deployed. Analyzing 
trends in AI progress, it is plausible that we have no more than two years before AI is able to 
competently run a business, shape culture using social media, and contribute to politics.
Some recommend that, instead of (or in addition to) accelerating our efforts to understand and control 
our creations, we should instead ensure that uncontrollable AI is not developed in the first place – or at 
least not yet. This strategy is at the core of PauseAI’s proposal , and it appears in A Narrow Path , an 
essay describing an alternative approach to AI development. It is understandable to be critical of this 
strategy; the very executive order under discussion highlights that regulation must not stifle innovation. 
However, I do not believe that a global pause on training larger  AI models would prevent innovation or 
American dominance! So far, AI has remained a tool in human hands, and the development of AI tools 
is an underexplored avenue of innovation to pursue. My understanding is that most AI tools used in 
science and business are small and unquestionably harmless; the development of such tools should be 
encouraged.
More generally, many have argued that AI is sufficiently useful, or even most  useful, as a tool for 
humans to use, rather than as a replacement for all human labor. A Narrow Path presents one such 
“Tool AI” proposal, as does Keep the Future Human , an essay that highlights how autonomy, 
generality, and superhuman intelligence pose a unique danger when combined in a single system. When 
my view of the future is optimistic, it is usually because I imagine a world where Tool AI becomes 
economically dominant, while autonomous, human-replacing AI is abandoned as a research direction. 
This would not be unprecedented: Other technologies, such as human cloning, have been banned on 
much shakier grounds. If I could make any one recommendation to those who have the power to make 
a difference, it would be this: That we should encourage the development of AI tools that promote 
human power and autonomy, while preventing the development of machines that replace humans and 
allow our own institutions to swallow us whole.
To be frank, however, it is rare that my predictions are optimistic. When I see things of beauty in the 
world, I am struck by grief. It is easy to doubt that these things will still exist in ten years – or even in 
five. I look around town, and I fear that every human home will be replaced by a datacenter. I look 
around at the people, and wonder how many will starve to death after the farms are sold to make room 
for manufacturing facilities. I listen to music, and I wonder if the concept of human connection through 
art will survive another decade. In a world where autonomous superhuman AI is put in charge of 
business and government, I cannot even be sure that trees  will continue to exist. I think about getting 
married, sometimes, but I have given up on the prospect of starting a family. Why bother bringing a 
child into this world, given that humans might lose their place in it before his or her fifth birthday?
I implore the United States Government to steer the future with great prudence. To those reading this, I 
once again ask you to read Keep the Future Human  and A Narrow Path , as well as PauseAI’s proposal , 


which provide actionable ways to prevent the development of systems that could escape our 
comprehension and our control. Even more importantly, I ask you to read the report on Gradual 
Disempowerment  in full. The catastrophic scenarios described in that report are plausible, perhaps even 
the default outcome , and not likely to be mitigated by purely technical solutions; do not dismiss them 
because they seem unlikely to happen in the next six months. (We are considering the development of 
machines of superhuman intelligence. Abandon any notion that the future will be mundane!) Consider 
each scenario, one at a time. How could it be reliably prevented? How could its coming to pass be 
measured ? Is there any chance that it could be rectified, should it come to pass?
Is it even possible  to prevent such a pathetic end for humanity, given that AI companies are racing to 
render humans obsolete as quickly as possible?
I expect that we have until 2027 to find out.
I implore you. Promote human flourishing . Save our souls.


