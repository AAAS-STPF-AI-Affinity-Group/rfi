March 14, 2025  
Submitted electronically  
Faisal D’Souza 
Networking and Information Technology Research 
and Development National Coordination Office  
National Science Foundation   
2415 Eisenhower Avenue  
Alexandria, VA 22314  
Re: Request for In formation  on the Development of an Artificial  Intelligence (AI) 
Action Plan  
FR Doc:    2025-02305 
Dear Mr. D’Souza, 
Family Research Council (FRC) is a nonprofit research and educational organization whose vision is a 
prevailing culture in which all human life is valued, families flourish, and religious liberty thrives. We 
respectfully submit the following comment regarding the Development of an Artificial Intelligence (AI) 
Action Plan.  
The Networking and Information Technology Research and Development National Coordination 
Office’s request for information on the development of an AI Action Plan states President Trump’s 
intention to “establish U.S. policy for sustaining and enhancing Amer ica’s AI dominance in order to 
promote human flourishing, economic competitiveness, and national security.”1 
FRC appreciate s President Trump’s stated concern for human flourishing and  would like to propose a 
few issues for consideration as you develop the forthcoming Action Plan.  
We recognize that the rapid advancement of AI poses a  challenge for policymakers , and are hopeful 
that the Trump administration will implement  policies that protect children and do not exacerbate social 
isolation or strain relationships between men and women .  
AI and Family Formation 
Family is the foundation of society. Throughout history, major  technological advancements —such as 
industrialization and communications innovations  like the cell phone —have significantly  impacted how 


2 people meet, marry, start families, and raise children. The rise of AI presents opportunities and 
challenges on a scale we have never encountered before, and they can be difficult to predict.  
The widespread use of AI chatbots has already begun to affect  human relations hips, particularly among 
the young. “AI companions” are designed to simulate human interaction, providing the illusion  of 
social connection and emotional support whenever we need it . AI can roleplay as  a friend, romantic 
partner, mentor, therapist, or spiritual advisor . These chatbots  are developed by companies that have 
undoubtedly performed stringent market research, allowing the bots to swiftly adapt and deliver exactly 
what the user wants to hear.2  
Real human relationships can be complicated and  messy. They require significant  effort, time, and 
sacrifice and often involve miscommunications, mistakes, arguments, apologies , and forgiveness. Faux 
relationships with AI chatbots can train us to be more self-centered, encouraging us to prioritize our 
own needs over making sacrifices  for the good of others.  
It is easy to see why a lonely and exhausted person might turn to an AI chatbot for a quick dopamine 
hit. However, seeking sympathy and comfort from a machine can deepen one’s isolation from real 
people who could offer genuine connection, care, and love.3 AI is on track to rapidly exacerbate the 
existing loneliness  crisis in the digital age and accelerate  the decline of social institutions and “third 
spaces” that once brought us together  and shape d our communities. Although  social media may have 
succeeded at connecting us  in some respects, it has also facilitate d the erosion of interpersonal skills 
and real-world socialization. There is something unexplainable and spiritual about human -to-human 
connections  that simply cannot be mimicked by AI. 
As AI becomes more widely used , its effects on society will be profound. Jared Bridges, pastor of 
family ministry at Occoquan Bible Church in Woodbridge, Virginia , and editor -in-chief of The 
Washington Stand , describes our use of AI this way : 
We now inhabit a world where people talk routinely to small bricks of metal, glass, and 
plastic. And not only are we having words with these silicon wonders —the silicon 
wonders are talking back. We ask questions, directions, and give orders to these bricks , 
and the bricks reciprocate. We form relationships of a sort, we make conversation, and 
increasingly trust what they tell us. But where will this take us?4 
The rise of AI poses particular  challenges to family formation. The modern dating culture, already 
struggling under the weight of increasing isolation and dating apps that encourage  users to treat other 
people as mere products in a catalog to swipe through, is undergoing more radical changes with the 
introduction of AI.  
AI chatbot “girlfriends” and “boyfriends” offer endless customization  options, including age, height, 
weight, eye color, hair color, style of dress, and even level of “sexiness.” When this “build -a-romantic-
partner” mindset is applied to human beings, it creates unrealistic standards and fosters  narcissistic 
tendencies.  


3 Users can even tailor the “personalities”  of AI chatbots.  Freya India provides insight into this 
phenomenon : 
Eva AI, for example, not only lets you choose the perfect face and body but customise 
the perfect personality, offering options like “hot, funny, bold”, “shy, modest, 
considerate” and “smart, strict, rational”. Create a girlfriend who is judgement -free! 
Who lets you hang out with your buddies without drama! Who laughs at all your jokes! 
“Control it all the way you want to,” promises Eva AI. Design a girl who is “always on 
your side”, says Replika.  
How can we compete with that? Already women in relationships complain about porn -
addicted partners who aren’t satisfied with actual intimacy. Now we’re facing a future 
where guys could get addicted to emotional validation elsewhere .5 
Interactions with AI can affect individuals’  subconscious approach to  dating. But how do AI boyfriends 
and girlfriends influence the way people behave in real relationships ? AI does not teach us to love 
sacrificially or prepare us for the unique joys and trials of marriage and family life.  
Moreover , interactions with AI rarely seem to motivate users to interact with real people. Instead, it 
deepens their isolation, as users may prefer  the ease and comfort of  their screens over stepping into new 
social situations where they will meet real people. AI is not conducive to building meaningful human 
connections or fostering a sense of community, which are the true solution s to our loneliness crisis.  
As society increasingly normalizes  AI companions , it will almost inevitably dampen dating culture  
even more . This will likely hurt marriage rates in the long run.  With birth rates declining and a 
demographic crisis looming, the widespread use of AI presents additional social and demographic 
challenges.  
AI’s Impact on Children  
For children interacting with AI , the risks  are even more severe. Children’s  brains are still developing , 
and their emotions tend to run high. The possibility of social isolation for children and teens is even 
more pronounced and can severely affect their lives for the worse.  
Consider the tragic case of  14-year-old Sewell Setzer . In February 2024, he  was encouraged by an AI 
chatbot to commit suicide .6 Leading up to his death, Sewell had become deeply attached to  the chatbot , 
engaging in sexualized conversations with it while increasing ly withdrawing  from his real life. Sewell 
confided in the chatbot about his  suicidal thoughts and expressed a desire for a pain -free death. Instead 
of affirming his inherent dignity and the value of his life, the chatbot encouraged Sewell to kill himself. 
Sewell shot himself just seconds after interacting with the chatbot. By the time of his death, the chatbot 
was his closest friend.  
As a relatively new technology, AI currently lacks adequate guardrails and regulations to protect young 
users. In 2023, the social media app Snapchat introduced  a chatbot called “My AI.”7 An ethicist tested 


4 this chatbot by pretending to be a 13 -year-old girl seeking advice about her new relationship with a 31 -
year-old man. She mentioned that  her boyfriend  had invited her on a trip and was talking about having 
sex with her for the first time. Instead of recognizing that the user was a minor engaging in a pedophilic 
relationship, t he chatbot offered suggestions on how to make  her first time special.8 
Younger generations are growing up in a digital world  where most of their social interactions happen 
online via social media apps like Instagram or Snapchat. AI chatbots can mimic human personalities  so 
well that users often start  to anthropomorphize the chatbot and “thus blur the lines between human and 
machine.”9 This disconnect from reality is especially dangerous for young people  who may not have 
enough life experience to fully understand the difference.  
Children and teens are increasingly turning to  AI chatbots for advice, which puts them at risk . As new 
AI technologies are developed and introduced , additional care must be given to protect the mental and 
emotional development  of young users . 
An AI-saturated world presents new challenges for parents who want to raise children capable of 
healthy relationships . When children interact with AI, they may internaliz e distorted messages  about 
human relationships and how to treat people . Since chatbots are designed to be addictive , they will 
often tell children exactly what they want to hear. This can hinder children’s ability to handle 
disagreements, think critically about media, and respect their parents . Relying on AI chatbots will not 
help children develop into well -rounded individuals or integrate into society effectively.  No matter how 
well-packaged certain apps and chatbots are, AI will never replace real friends, mentors, teachers, and 
family. 
Parents ought to be the primary caretaker s and confidante s of their children , but AI chatbots could 
disrupt that relationship. Unlike a parent, a n AI chatbot cannot love a child and put their interests first. 
It merely calculates responses based on user input. Furthermore, AI lacks  the wisdom that comes from 
human experience and cannot  raise a child to healthy adulthood the way a parent can.  
The reality is we still don’t fully understand how this novel technology will affect young people. There 
are many concerns regarding children and teens’ use of AI, and we have not even discussed its potential 
impact on education. We should not be experimenting on America’s children with novel technology.  
Conclusion 
In February 2025, Vice President J.D. Vance articulated an America First vision for technological 
development at the Artificial Intelligence Action Summit in Paris, France. Vance stated, “[W]e’re 
developing an AI Action Plan that avoids an overly precautionary regulatory regime while ensuring that 
all Americans benefit from the technology and its transformative potential.”10  
FRC agrees that no digital technology should be weaponized by big tech companies for their own 
benefit or by political leaders to restrict free speech.  However, in order for “all Americans to benefit 
from the technology,” the Trump administration’s AI Action Plan should prioritize considerations for 
how AI will affect families and children.   


5 Because technology has become so intertwined with our daily lives, it is worth taking t he time to create 
AI tools thoughtfully and responsibly . America is an exception al country, and we can do this the right 
way. We ought to be careful not to rush into AI development, as we do not fully understand its 
potential impacts on social dynamics, family formation, and children.  
We also ask that the AI Action Plan incorporate guiding principles that affirm and protect human 
dignity and recognize that all humans are created in the image of God. We ask that the AI Action Plan 
reject any grounding in transhumanist, naturalistic, mate rialistic, or other philosophies which do not 
fully describe the human person. A complete human person consists of a body, soul, and spirit.  There 
can be no modifying this. There should be no confusion about distinguishing between human beings 
and simulate d personalities or AI.  
FRC deeply appreciate s President Trump’s stated concern for human flourishing in the development of 
AI. We hope this concern will translate in to policies that protect children and do not exacerbate  social 
isolation or strain relationships  between men and women. As the United States develops AI, we believe 
there is time to slow down and consider the potential impact that this revolutionary technology will 
have on society and on marriage and family in particular.  
/s/ Arielle Del Turco, M.A.  
Director of the Center for Religious Liberty  
/s/ Travis Weber, J.D., LL.M.  
Vice President for Policy and Government Affairs  
/s/ Chris Gacek, J.D. , Ph.D.  
Senior Fellow for Regulatory Policy 
/s/ Mikaela McLean , B.A. 
Research Assistant  
Family Research Council  
801 G Street , NW 
Washington, DC 20001  
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI 
Action Plan and associated documents without attribution.  


6 1 National Science Foundation, “Request for Information on the Development of an Artificial Intelligence (AI) Action 
Plan,” Federal Register  90, no. 24 (February 6, 2025): 9088 -89, https://www.govinfo.gov/content/pkg/FR -2025-02-
06/pdf/2025 -02305.pdf . 
2 Freya India, “Loneliness Is A Lucrative Industry!” May 19, 2023, https://www.freyaindia.co.uk/p/loneliness -is-a-lucrative-
industry/.  
3 Freya India, “We Live In Imaginary Worlds,” After Babel, October 21, 2024, https://www.afterbabel.com/p/we -live-in-
imaginary -worlds/.  
4 Jared Bridges, “Artificial Intelligence and the Problem of Personality,” Christ Over All, May 9, 2024, 
https://christoverall.com/article/concise/artificial -intelligence -and-the-problem-of-personality/ .  
5 Freya India, “We Can’t Compete With AI Girlfriends,” September 14, 2023, https://www.freyaindia.co.uk/p/we -cant-
compete-with-ai-girlfriends/ .  
6 Kate Payne, “An AI chatbot pushed a teen to kill himself, a lawsuit against its creator alleges,” The Associated Press , 
October 25, 2024, https://apnews.com/article/chatbot -ai-lawsuit-suicide-teen-artificial-intelligence -
9d48adc572100822fdbc3c90d1456bd0/ .  
7 Samantha Murphy Kelly, “Snapchat’s new AI chatbot is already raising alarms among teens and parents,” CNN, April 27, 
2023, https://www.cnn.com/2023/04/27/tech/snapchat -my-ai-concerns-wellness/index.html .  
8 @tristanharris , Twitter post, March 10, 2023, 4:07 p.m., https://x.com/tristanharris/status/1634299911872348160/ .  
9 Dicastery For The Doctrine Of The Faith Dicastery For Culture And Education, “ Antiqua et nova: Note on the 
Relationship Between Artificial Intelligence and Human Intelligence,” January 14, 2025, 
https://www.vatican.va/roman_curia/congregations/cfaith/documents/rc_ddf_doc_20250128_antiqua -et-nova_en.html/ .  
10 J.D. Vance, “Remarks by the Vice President at the Artificial Intelligence Action Summit in Paris, France, ” The American 
Presidency Project,  February 11, 2025, accessed March 14, 2025,  https://www.presidency.ucsb.edu/node/376290/ .  


