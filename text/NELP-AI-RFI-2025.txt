Faisal  D'Souza  
Technical  Coordinator,  NCO  
Networking  and Information  Technology  Research  and Development  (NITRD)  Program 
2415 Eisenhower Avenue  
Alexandria,  VA 22314  
Submitted  via email  to 
RE: Request  for Information  on the Development  of an  Artificial  Intelligence  (AI) Action  Plan 
Dear Mr. D’Souza,  
On behalf  of the National  Employment  Law Project,  please  find attached  our submission  to the 
Office  of Science  and Technology Policy’s Request  for Information on the  Development  of an 
Artificial Intelligence (AI) Action Plan.  
Founded  in 1969,  the National  Employment  Law Project  (NELP)  is a nonprofit  advocacy 
organization dedicated to building a just and inclusive economy where all workers have  
expansive  rights  and thrive  in good  jobs.  Together  with local,  state,  and national  partners,  NELP 
advances its mission through transformative legal and policy solutions, research, capacity - 
building,  and communications.  
Attached to  this letter  are documents  NELP  submitted  to the OSTP  in 2023  and the  Department 
of Labor in 2024. The ideas raised in these submissions remain relevant and we urge the  
administration to  consider them  as it develops  the action  plan.  
With  any questions,  please  feel free to reach  out to Josh Boxerman,  Government  Affairs 
Manager, at 
Sincerely,  
National  Employment  Law Project  


June  28, 2023  
Comments  in Response  to Office  of Science  and  Technology  Policy  (“OSTP”), 
Docket OSTP_FRDOC 0001 -0004  
Submitted  via https://www.regulations.gov/document/OSTP_FRDOC_0001 -0008  
To Whom  It May  Concern:  
The National Employment Law Project (NELP) submits these comments in response to the 
Request  for Information  (RFI)  on Automated  Worker  Surveillance  and Management  initially 
published by the White House Office of Science and Technology Policy (OSTP) on May 1, 
2023.  
NELP is a nonprofit research and policy organization with over 50 years of experience 
advocating  for the employment  and labor  rights  of underpaid  workers.  We seek  an equitable, 
good jobs economy by advancing policies that ensure jobs pay well, provide ample benefits, 
foster health and safety, and decrease racial income disparities; we also champion robust 
unemployment insurance for those unable to work. NELP recognizes that corporate respect 
for worker autonomy, responsiveness to worker voice and judgment, and equitable and 
transparent decision -making are essential foundations of any good job. Accordingly, we 
support policies that foster  workplace democracy  and encourage workers to join together  to 
improve working conditions. NELP works closely with worker centers and other  
community -based  organizations  with  members  who  are subject  to workplace  surveillance 
and algorithmic management, and we base our comments in part on understandings we 
have developed through those relationships.  
In recent  years,  corporations  have  vastly  expanded  automated  or electronic  surveillance  of 
workers and reliance on data -driven or algorithmic management. These two practices are 
distinct, though both pose harms to workers and threaten to degrade working conditions, 
particularly for workers of color as we explain below. For the purposes of our comments, 
however, NELP will largely follow the approach of the RFI and refer to both practices 
together as “Automated Worker Surveillance and Management” (AWSM). Our comments 
discuss our concern with how corporate adoption of AWSM can exacerbate existing 
challenges to an equitable, good jobs economy. Specifically, our comments highlight that:  
1. AWSM  can enable  discrimination  in recruitment  and hiring,  and can perpetuate
occupational segregation;
2. AWSM  enables  corporations  to mask  control  and deny  accountability,  degrading
working conditions and fostering racial income and wealth disparities;  
3. AWSM  can increase  barriers  to organizing  and bargaining  collectively,  particularly
in industries with disproportionately high percentages of Black and immigrant
workers;  
4. AWSM  can combine  with  other  health  and safety  hazards  to amplify  unhealthy  and
unsafe work environments;
5. AWSM  is often  used  to discipline  and terminate  workers  without  transparency  or
meaningful processes to contest decisions, increasing precarity and potentially
amplifying race inequities; and
6. AWSM  facilitates  unfair,  unpredictable,  and discriminatory  pay.  
We conclude  by highlighting  the need  to deliberately  incorporate  worker  voice,  and we 
recommend policy reforms.  


2 1. Data -driven,  automated  recruitment  and  hiring  systems  can be discriminatory  and  perpetuate
occupational segregation.
Workers’ access to jobs is increasingly mediated by opaque digital hiring systems. In recent years, employers 
including Amazon, Target, and Hilton, have begun to use data -driven, automated tools to recruit, screen, and 
select job candidates. These systems often draw on data covering multiple facets of candidates’ personal and 
professional lives and use artificial intelligence to make predictions about candidate  job fit and performance.  The 
systems reflect the biases of the people and management regimes that design them, and the biased data they are 
fed,1 and can create barriers to employment for people from protected groups, for workers whom employers 
determine are likely to exercise organizing and collective bargaining rights, and for people with arrest and 
conviction records.2 Because of this “bias in, bias out” problem, scholars caution that automated hiring processes 
“challenge  the American  bedrock  ideal  of equal  opportunity  in employment,  as such  automated  practices  may  not 
only be deployed to exclude certain categories of workers but may also be used to justify the inclusion of other 
classes as more ‘fit’ for the job.”3 Moreover, unregulated algorithmic hiring creates risks of algorithmic 
repudiation where the same applicants experience repeated discrimination due to employers’ ability to retain or 
even  share  applicant  profiles.4 A recent  study  by Cambridge  University  researchers  found  that  these  systems  may 
“unintentionally entrench cultures of inequality and discrimination” and reproduce, rather than neutralize, 
biases.5 
For workers seeking jobs on digital labor platforms, on -demand jobs are allocated by secret algorithms. Job 
assignments,  including  the determination  of which  worker  receives  a job when  more  than  one worker  is awaiting 
work in the same location, may be determined by biased data, such as customer ratings.6 
Further, a study of job recruitment involving social media ad -targeting found that delivery -optimization 
algorithms  on the company’s  platform  were  perpetuating  occupational  segregation  by gender  and race.  When 
researchers examined the audience for broadly targeted job positions, they found that the audience was 85 
percent women for supermarket cashier positions and 75 percent Black for taxi driver positions.7 
2. AWSM  enables  corporations  to avoid  accountability;  this  degrades  wages  and  working  conditions  and
fosters racial wealth and income inequality.
Increasingly, corporations are turning to AWSM to manage and control workers even as they deny any 
responsibility for their wages or working conditions. AWSM empowers corporations to surveil workers more 
easily,  collect  data  for secret  algorithms,  and use those  algorithms  to determine  the terms  and conditions  of work. 
This  growing  reliance  on AWSM  enables  corporations  to mask  their  significant  control  even  as they  strip  workers 
of core employment and labor rights such as the right to minimum wage, overtime, or the right to organize or be 
free from discrimination. Corporations have used AWSM to shed responsibility in at least two ways: first, by  
1 Aaron  Rieke  & Miranda  Bogen,  Help  Wanted:  An Examination  of Hiring  Algorithms,  Equity,  and Bias , UPTURN , Dec. 
10, 2018,  available  at https://www.upturn.org/work/help -wanted/ . See also  Ifeoma  Ajunwa,  An Audit  Imperative 
for Automated Hiring Systems , 34 H ARVARD  J. OF LAW & TECH 622,  684 (Spring 2021) (“automated decision -making 
cannot be fully disentangled from human decision -making”), available at 
https://jolt.law.harvard.edu/assets/articlePDFs/v34/5. -Ajunwa -An-Auditing -Imperative -for-Automated -Hiring - 
Systems.pdf#page=64 . 
2 Miranda  Bogen,  All the Ways  Hiring  Algorithms  Can Introduce  Bias , HARV. BUS. REV., May  6, 2019,  available  at 
https://hbr.org/2019/05/all -the-ways -hiring -algorithms -can-introduce -bias . 
3 Ajunwa,  Audit  Imperitive , supra  n. 1 at 623.  
4 Id. at 681 -82. 
5 Eleanor  Drage  and Kerry  Mackereth,  Does  AI Debias  Recruitment?  Race,  Gender,  and AI’s “Eradication  of 
Difference . PHILOS . TECHNOL . 35, 89 (2022), available at https://doi.org/10.1007/s13347 -022 -00543 -1. 
6 Alex  Rosenblatt  et al., Discriminating  Tastes:  Customer  Ratings  as Vehicles  for Bias , DATA  & SOC’Y (October  2016), 
https://datasociety.net/pubs/ia/Discriminating_Tastes_Customer_Ratings_as_Vehicles_for_Bias.pdf . 
7 Muhammad  Ali, et al., Discrimination  through  optimization:  How  Facebook's  ad delivery  can lead  to skewed 
outcomes , COMPUT . AND SOC’Y (Sept. 12, 2019), https://arxiv.org/pdf/1904.02095.pdf . 


3 falsely  insisting  that  workers  are independent  contractors  rather  than  employees;  and second,  by facilitating 
subcontracting to third parties over which they are able to use AWSM to maintain significant control.  
AWSM  is used  to obscure  corporate  control  and enable  corporations  to mislabel  employees  as 
independent  contractors  in underpaid  industries  with  disproportionate  numbers  of Black  and 
immigrant workers . 
The corporate  adoption  of AWSM  as a means  of exerting  non-transparent  control  is well  documented.  As the 
Federal Trade Commission noted in the context of digital labor platform workers:  
[They]  often  do not have  the information  they  need  to know  when  work  will be available,  where 
they will have to perform it, or how they will be evaluated. Behind the scenes, ever -changing 
algorithms may dictate core aspects of workers’ relationship with a given company’s platform, 
leaving them with an invisible, inscrutable boss.8 
This “invisible, inscrutable boss” may also use algorithmic pay formulas to personalize wages, which are neither 
negotiated  nor transparent.9 Likewise,  these  bosses  employ  algorithmic  rating  systems  that  they  use to discipline 
or terminate workers, leaving the workers at constant risk of sudden and potentially devastating economic 
consequences.10 The adoption of AWSM is particularly prevalent in corporations that use app -based labor 
platforms, where companies like Uber use gamified in -app reward systems, variable pay, and selective “surge - 
pricing” to effectively control where workers go, how long they work, and what kinds of trips they accept.  
Yet many of the digital labor platform corporations that use AWSM as a hidden boss —to assign tasks, determine 
pay,  and discipline  or terminate  workers —simultaneously  insist  that  their  workers  are autonomous  independent 
contractors, i.e., that the workers are in business for themselves.11 In so doing, they strip their workers’ of rights 
to minimum wage, overtime, workers’ compensation, unemployment insurance, health and safety protections, 
and protections from harassment and discrimination. They also shift the costs and risks of running a business to 
the workers and undermine the competition by reducing payroll costs. Corporate reliance on AWSM to facilitate 
mislabeling workers as independent contractors therefore undermines access to bedrock employment and labor 
law protections and social insurance programs.12 It also enables unfair competition and helps starve programs 
such as Medicare, unemployment insurance, and workers’ compensation.13
8 FED. TRADE  COMM ’N, POLICY  STATEMENT  ON ENFORCEMENT  RELATED  TO GIG WORK  8 (Sept.  15, 2022),  
https://www.ftc.gov/system/files/ftc_gov/pdf/Matter%20No.%20P227600%20Gig%20Policy%20Statement.pdf  
. 
9 See, e.g ., Zephyr Teachout, Algorithmic Personalized Wages , FORHAM L. LEGAL STUD. RSCH, NO. 4358817,  2023 
(forthcoming  2023),  available  at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4358817# . See also  Section 
6, infra . 
10 See generally  Fired  by an App:  The Toll of Secret  Algorithms  and Unchecked  Discrimination  on California  Rideshare 
Drivers , ASIAN AMERICANS ADVANCING JUSTICE , RIDESHARE DRIVERS UNITED (Feb. 2023), available at  
https://www.drivers -united.org/fired -by-app. See also  Alex  Rosenblat,  Opinion,  When  Your  Boss  is an Algorithm , 
N.Y.  TIMES , Oct. 12, 2018,  available  at https://www.nytimes.com/2018/10/12/opinion/sunday/uber -driver - 
life.html?smid=tw -nytopinion&smtyp=cur . See also Section 5, infra . 
11 Aiha Nguyen, The Constant Boss: Work Under Constant Surveillance , DATA & SOC’Y at 10 (May 19, 2021), 
https://datasociety.net/wp -content/uploads/2021/05/The_Constant_Boss.pdf  (“Data -centric systems have 
allowed employers to exert control over workers while claiming workers enjoy greater autonomy.”). See also 
Kathryn  Zickuhr,  Workplace  Surveillance  is Becoming  the New  Normal  for U.S. Workers , WASH. CTR. FOR  EQUITABLE
GROWTH (AUG. 18, 2021),  available  at https://equitablegrowth.org/research -paper/workplace -surveillance -is- 
becoming -the-new -normal -for-u-s-workers/ . 
12 Sarah  Leberstein  and Catherine  Ruckelshaus,  Independent  Contractor  v. Employee:  Why  Misclassification  Matters 
and What we can do to Stop It , NAT’L EMP. L. PROJECT (May 2016), https://s27147.pcdn.co/wp - 
content/uploads/Policy -Brief -Independent -Contractor -vs-Employee.pdf . See also, e.g. , Rebecca Smith & Sarah 
Leberstein, Rights on Demand : Ensuring Workplace Standards in the On -Demand Economy , NAT’L EMP. L. PROJECT
(Sept. 2015), https://s27147.pcdn.co/wp -content/uploads/Rights -On-Demand -Report.pdf . 
13 Leberstein,  Why  Misclassification  Matters , supra  n. 12. 


4 Meanwhile,  workers  in industries  where  their  employers’  independent  contractor  misclassification  is prevalent — 
including  those  corporations  that  use AWSM  to control  the work —earn  poverty  wages  and tend  to make less  than 
their employee counterparts. For example, a 2019 analysis by the Economic Policy Institute found that the  
average Uber  driver’s wage was just $9.21 per hour after deducting fees and expenses, putting them in the lowest 
ten percent of wage earners, and earning lower than the minimum wage in many states and in the three largest 
cities.14 Similarly, a national study of workers hired via a digital labor platform (including delivery, ride -hail, and 
domestic workers) found that 1 in 7 workers earned less than the federal hourly minimum wage, and 30 percent 
of digital platform workers received a Supplemental Nutrition Assistance Program benefit, compared to 15 
percent of employees in comparable service -sector jobs.15 Most recently, a study of the economic costs of 
misclassification  to workers  in 11 high -violation  industries  found,  for example,  that  “a typical  home  health  aide,  as 
an independent contractor, would lose out on as much as $9,529 per year in income and benefits compared with 
what they would have earned as an employee.”16 
The impact of AWSM -supported misclassification of employees as independent contractors on communities of 
color is deeply disturbing. Persistent occupational segregation means that such misclassification 
disproportionately harms Black, Latinx, and Asian workers. As a group, workers of color —Black, Latinx, 
Asian/Pacific Islander, and Native American workers —are overrepresented in high -violation industries such as 
construction, trucking, delivery, home care, agricultural, personal care, ride -hail, and janitorial and building 
service  occupations  by over  40 percent;  they  comprise  just over  a third  of workers  overall,  but make  up between 
47 and 91 percent of workers in these occupations.17 In digital labor platform work where AWSM is prevalent, 
Black and Latinx workers are overrepresented by 45 percent —more even than in more traditional 
misclassification -prone sectors.18 Thus, AWSM -supported independent contractor misclassification fosters a 
second -tier workforce comprised predominantly  of workers  of color stripped  of core  employment  protections.19
Because it also comes with the significant wage and benefit penalties noted above, adoption of AWSM to 
perpetuate independent contractor misclassification also exacerbates racialized income and wealth inequities.  
Lead  firms  in subcontracted  work  relationships  use AWSM  to exercise  control  while  denying  
employer responsibility . 
AWSM is not only used to enable corporations to mask control as they mislabel workers as independent 
contractors  but is also  used  to control  subcontracted  work  structures.  A prime  example  is Amazon’s  last-mile 
delivery model, in which Amazon uses subcontractor middle -managers to mediate its employment of some 
275,000 delivery drivers, responsible for realizing the company’s two -day shipping guarantee.20 Although  
14 Lawrence  Mishel,  Uber  and the Labor  Market:  Uber  Drivers’  Compensation,  Wages,  and the Scale  of Uber  and the 
Gig Economy , ECON. POL’Y INST. at 13 (May 2019), https://files.epi.org/pdf/145552.pdf . 
15 Ben  Zipperer,  et al., National  Survey  of Gig Workers  Paints  a Picture  of Poor  Working  Conditions,  Low  Pay, ECON. 
POL’Y INST. (Jun. 2022), available at https://www.epi.org/publication/gig -worker -survey/ . 
16 John  Schmitt,  et al., The Economic  Costs  of Worker  Misclassification , ECON. POL’Y INST. (Jan.  25, 2023), 
https://files.epi.org/uploads/The -economic -costs -of-worker -misclassification -1.pdf . 
17 NELP  analysis  of March  2022  Current  Population  Survey  Annual  Social  and Economic  Supplement  microdata. 
For underlying data, see CPS Annual Social and Economic Supplement , U.S. Census Bureau, available at 
https://data.census.gov/mdat/#/search?ds=CPSASEC2022 . 
18 See U.S. Bureau of Lab. Statistics, Electronically Mediated Work: New Questions in the Contingent Worker 
Supplement , U.S.  DEP’T OF LAB., MONTHLY LABOR REVIEW (Sept. 2018), available at 
https://www.bls.gov/opub/mlr/2018/article/electronically -mediated -work -new -questions -in-the-contingent - 
worker -supplement.htm  (noting over -representation of Black and Latinx workers).  
19 See, e.g., Veena  Dubal,  The New  Racial  Wage  Code , 15 HARV. L. & POL. REV. 511  (2022)  (arguing  that  gig-worker 
carve outs are made possible by and reproduce racial subjugation).  
20 See Anna Kramer, Amazon’s Entrepreneur Dream is Closer to a Nightmare for Many , PROTOCOL , Mar. 7, 2022, 
available  at https://www.protocol.com/workplace/amazon -delivery -program -trap ; see also  How  Amazon’s  DSP 
Program has Created $26 billion in Revenue for Owners , Amazon Corporate Website, Aug. 19, 2022, available at 
https://www.aboutamazon.com/news/transportation/how -amazons -dsp-program -has-created -26-billion -in- 
revenue -for-owners . 


5 delivery drivers are on the payroll of the subcontractor “delivery service partner,” (DSP) Amazon effectively 
controls the work through its smartphone app: setting daily routes, van color and Amazon logo signage, delivery 
quotas, and delivery deadlines for drivers by communicating through the app.21 Although directly employed by a 
DSP, drivers are required to sign “Biometric consent” forms allowing Amazon’s constant surveillance and related 
performance control via AI -powered cameras as a condition of work.22 The e -commerce giant installs these video 
cameras  in the vans  of the DSP  drivers,  sometimes  using  inaccurate  data  to penalize  drivers  or deny  DSPs  bonuses 
they may need to make vehicle repairs or enhance driver pay.23 
In the wireless telecommunications industry, large carriers like AT&T, Verizon, and T -Mobile are increasingly 
outsourcing  retail  operations  to third -party  “authorized  retailers.”  A 2022  survey  of workers  at those  authorized 
retailers revealed that large carriers often exert operational control over authorized retailers via digital 
performance tracking systems. Workers reported that, through those systems, carriers establish and frequently 
change performance benchmarks that determine pay for the commission -driven work.24 
In short, AWSM has frequently been deployed by corporations to obscure their control and manage their 
workforces while insisting that their workers are independent contractors or outsourcing the work to third 
parties. By coopting the technology for their benefit, these corporations strip a disproportionately high 
percentage  of Black  and Latinx  workers  of bedrock  rights  and protections,  degrade  wages  and working  conditions 
and foster racial wealth and income inequality.  
3. AWSM  often  increases  barriers  to organizing  and  bargaining  collectively,  particularly  in industries
with disproportionately high percentages of Black and immigrant workers.
As the National Labor Relations Board (NLRB) General Counsel recently cautioned, AWSM can infringe upon 
workers’ Section 7 rights under the National Labor Relations Act (NLRA). She noted in particular, “the potential 
for omnipresent  surveillance  and other  algorithmic -management  tools  to interfere  with  the exercise  of Section  7 
rights by significantly impairing or negating employees’ ability to engage in protected activity and keep that 
activity confidential from their employer, if they so choose.”25 
The use of AWSM to interfere with NLRA rights is not simply theoretical. Workers at Walmart discovered the 
company  monitors  online  conversations  about  the union.26 HelloFresh  tracks  social  media  posts  about  the union 
by employees, and other corporations monitor work emails to identify what a former chair of the NLRB called  
21 Lauren  K. Gurley,  Amazon  Drivers  Are Instructed  to Drive  Recklessly  to Meet  Delivery  Quotas , VICE  MOTHERBOARD , 
May 6, 2021, available at https://www.vice.com/en/article/xgxx54/amazon -drivers -are-instructed -to-drive - 
recklessly -to-meet -delivery -quotas . 
22 James Vincent, Amazon delivery drivers have to consent to AI surveillance in their vans or lose their jobs , THE
VERGE , Mar.  24, 2021,  available  at https://www.theverge.com/2021/3/24/22347945/amazon -delivery -drivers -ai- 
surveillance -cameras -vans -consent -form . 
23 See Lauren K. Gurley, Amazon’s AI Cameras Are Punishing Drivers for Mistakes They Didn’t Make , VICE 
MOTHERBOARD , Sept. 20, 2021, available at https://www.vice.com/en/article/88npjv/amazons -ai-cameras -are- 
punishing -drivers -for-mistakes -they -didnt -make . See also David Hanley & Sally Hubbard, Eyes Everywhere: 
Amazon’s Surveillance Infrastructure and Revitalizing Worker Power , OPEN MARKETS (Sept. 2020), 
https://static1.squarespace.com/static/5e449c8c3ef68d752f3e70dc/t/5f4cffea23958d79eae1ab23/159888177  
2432/Amazon_Report_Final.pdf . 
24 See Broken  Network:  Workers  Expose  Harms  of Wireless  Telecom  Carriers'  Outsourcing  to “Authorized  Retailers,” 
NAT’L EMPL. L. PROJECT , COMMC ’NS WORKERS OF AM. (Feb. 2023), https://cwa -union.org/sites/default/files/2023 - 
02/20230206_BrokenNetwork.pdf . 
25 Office  of the General  Counsel,  Memorandum  GC 23—2, Electronic  Monitoring  and Algorithmic  Management  of 
Employees Interfering with the Exercise of Section 7 Rights , NAT’L. LAB. REL. BD., October, 2022, available at 
https://www.nlrb.gov/guidance/memos -research/general -counsel -memos . 
26 Susan  Berfield,  How  Walmart  keeps  an eye on its massive  workforce , BLOOMBERG  BUSINESS , Nov.  24, 2015,  available 
at https://www.bloomberg.com/features/2015 -walmart -union -surveillance/ . 


6  “pre -union activity, employee discontent.”27 Further, corporations have used AWSM to gauge the likelihood that 
workers would organize. For example, Amazon -owned Whole Foods used a combination of data concerning the 
poverty  levels  of workers’  neighborhoods,  an index  to measure  the potential  for racial  solidarity,  and measures  of 
employee “loyalty” to identify stores where workers may support forming a union.28 
 
AWSM  has also  enabled  corporations  to maintain  high  levels  of control  over  their  labor  force  while  denying  labor 
rights under the NLRA. They do this through subcontracts that demand AWSM while denying their status as a 
joint employer. For example, just last month, drivers who were directly employed by a DSP at an Amazon 
fulfillment center in Southern California formed a union with the Teamsters, gaining voluntary recognition from 
the DSP.29 Amazon responded by announcing its intention to cut its contract with that subcontractor, effectively 
terminating the employment of the unionized drivers because they had exercised their Section 7 rights.30 Other 
lead firms that adopt AWSM  to manage the work of their subcontracted labor  may  see this as a lesson  and follow 
Amazon’s lead, adopting AWSM while denying responsibility for NLRA violations.  
 
But these  obvious  efforts  to chill  organizing  are not the only  threat  that  unregulated  AWSM  poses.  AWSM  can also 
chill or undermine workers’ exercise of their legal rights to organize in myriad other ways.  
Corporate  use of AWSM  echoes  slavery -based  management  and reinforces  systemic  bias. 
Data -driven, algorithmic management is premised on quantifying work and work outcomes, and thus is readily 
applied to jobs where tasks are easily measured like retail, food service, warehousing, logistics, agriculture, 
hospitality,  domestic  work,  and health  care.31 Many  of these industries  have  low levels  of workers  represented  by 
unions32 and high percentages of Black and immigrant workers.33 Unregulated corporate use of AWSM can 
intensify the harms associated with unfairness and lack of transparency in the “at will” economy, undermining 
workers’ ability to speak up about mistreatment and perpetuating racial inequities.34 Low union density and 
increased  surveillance  can also  be mutually  reinforcing  systems:  suppressing  workers’  power  to insist  on fair and 
transparent  adoption  and implementation  of AWSM  enables  corporations  to unilaterally  and opaquely  use it; and 
the constant pressure on workers to meet algorithmic demands under increased surveillance increases workers’ 
feeling of precarity and limits their ability to express power.35 
 
 
27 Jo Constanz, ‘ They were spying on us’: Amazon, Walmart Use Surveillance Technology to Bust Unions , NEWSWEEK , 
Dec.  13, 2021,  available  at https://www.newsweek.com/they -were -spying -us-amazon -walmart -use-surveillance - 
technology -bust -unions -1658603 . 
28 Daniel A. Hanley and Sally Hubbard, Eyes Everywhere: Amazon’s Surveillance Infrastructure and Revitalizing 
Worker Power , OPEN MARKETS (Sept. 2020), 
https://static1.squarespace.com/static/5e449c8c3ef68d752f3e70dc/t/5f4cffea23958d79eae1ab23/159888177  
2432/Amazon_Report_Final.pdf.  
29 Luis  Feliz  Leon,  Teamsters  Begin  Major  Amazon  Fight , AMERICAN  PROSPECT , May  4, 2023,  available  at 
https://prospect.org/labor/2023 -05-04-teamsters -begin -major -amazon -fight/.  
30 Id. See also  Unfair  Labor  Practice  Charge  Against  Amazon  Logistics,  Inc., NLRB  Board  Region  31 (filed  May  2, 
2023), https://teamster.org/wp -content/uploads/2023/05/5323ULPChargeAgainstAmazon.pdf . 
31 Nguyen,  Constant  Boss , supra  n. 11. 
32 U.S. Bureau  of Lab.  Statistics,  Union  Members  – 2022 , News  Release  USDL -23-0071,  U.S. DEP’T. OF LAB., Jan. 19, 
2023, https://www.bls.gov/news.release/pdf/union2.pdf . 
33 See U.S. Bureau of Lab. Statistics, Labor Force Statistics from the Current Population Survey , U.S.  DEP’T. OF LAB., 
available  at https://www.bls.gov/cps/cpsaat18.htm  (last  visited  May  25, 2023)  (showing  employed  persons  by 
detailed industry, sex, race, and Hispanic or Latino ethnicity).  
34 Irene Tung, et al., Just Cause Job Protections: Building Racial Equity and Shifting the Power Balance Between 
Workers and Employers , NAT’L EMPL. L. PROJECT (Apr. 30, 2021), available at 
https://www.nelp.org/publication/just -cause -job-protections -building -racial -equity -and-shifting -the-power - 
balance -between -workers -and-employers . 
35 U.S. Congress,  The Electronic  Supervisor:  New  Technology,  New  Tensions , OFFICE  OF TECHNOLOGY  ASSESSMENT , OTA - 
CIT-333  (1987),  https://files.eric.ed.gov/fulltext/ED299406.pdf ; see also  Nguyen,  Constant  Boss , supra  n. 11, at 5. 


7 This disempowering feedback loop is an extension of bosses’ long -standing use of work quotas and related 
distrust  of Black  and immigrant  workers,  whose  worth  was  historically  based  on their  ability  to meet  such  quotas. 
It is a form  of management  rooted  in the U.S. enslavement  economy,  where  slavers  ranked  and attached  monetary 
value to workers based on their productivity even as they surveilled based on racist beliefs about dishonesty, 
laziness, and trustworthiness.36 Using AWSM to code workers as good or bad mirrors the codes used to label 
Black and immigrant people in the carceral system (“high risk/low risk”), in the granting of social insurance 
(“worthy/unworthy”), and in access to the consumer credit markets (“excellent/good/poor”).37 Once attached to  
a worker,  these  codes  can reify  stereotypes  about  workers  of color  among  management  and determine when  they 
are scheduled, what types of job tasks they are assigned, whether they are meeting standards, and whether they 
keep their job.38 If terminated as a result of such codes, quotas or algorithms, a workers’ access to critical 
unemployment insurance benefits may also be jeopardized.  
Adoption of AWSM to code workers allows corporations to practice a form of just -in-time staffing where the 
algorithm  itself  determines  who  should  be fired  to minimize  costs  and maximize  profits.39 And  by pushing  AWSM 
across companies and even industries, corporations can create a sense that always being watched is simply the 
normative condition at work, making it very difficult for employees to prove that any particular instance of 
surveillance was an effort to stymie protected concerted action.40
Constant  and opaque  use of AWSM  increases  worker  perceptions  of precarity  and decreases  
solidarity among co -workers . 
In a unionized workplace, workers may be able to negotiate provisions in a collective bargaining agreement to 
address  data  collection,  data  sharing,  and data  use,  and if a worker  suspects  unfair  use of data  to justify  discipline 
or termination there would be a procedure in place to grieve the decision.41 But in most private workplaces 
without a recognized union, corporations can adopt AWSM in a “black box,” where workers have no voice or 
insight into how it was programmed, how it was put in place, or how the data is used. Trying to maintain 
algorithm -created productivity standards or understanding changing quota systems may leave workers too 
physically tired or demoralized to compare thoughts about working conditions.42 In some settings, productivity 
data may literally be used to pit workers one against the other; worker scores may be shared publicly on 
“leaderboards” comparing each worker’s progress toward the quotas to others.43 
36 Slavery’s  Capitalism:  A New  History  of American  Economic  Development  (Sven  Beckert  & Seth  Rockman,  eds.: 
2016); Simone Browne, Dark Matters: On the Surveillance of Blackness (Duke U. Press: 2015).  
37 Virginia  Eubanks,  Want  to Predict  the Future  of Surveillance?  Ask Poor  Communities , THE AMERICAN  PROSPECT , 
January 15, 2014, available at https://prospect.org/power/want -predict -future -surveillance -ask-poor - 
communities./ . Danielle Keats Citron and Frank A Pasquale, The Scored Society: Due Process for Automated 
Predictions , 89 W ASH. L. R EV. 1 (2014), available at 
https://scholarship.law.bu.edu/cgi/viewcontent.cgi?article=1611&context=faculty_scholarship.  
38 Esther  Kaplan,  The Spy Who  Fired  Me, HARPER ’S MAGAZINE , March  2015,  available  at 
https://harpers.org/archive/2015/03/the -spy-who -fired -me/ . 
39 See Peter Cappelli, Stop Overengineering People Management , HARVARD BUS. REV., Sept. 2020, available at 
https://hbr.org/2020/09/stop -overengineering -people -management  (this  occurs  where  the corporation  does  not 
believe it is constrained by a collective bargaining agreement).  
40 Zickuhr,  supra  n. 11 at 21, Workplace  Surveillance . 
41 Lisa Kresge, Union Collective Bargaining Agreement Strategies in Response to Technology , U.C.  BERKELEY L. CTR. 
(Nov. 2020), https://laborcenter.berkeley.edu/wp -content/uploads/2022/01/Working -Paper -Union -Collective - 
Bargaining -Agreement -Strategies -in-Response -to-Technology -v2.pdf . 
42 See Charlotte  Garden,  Labor  Organizing  in the Age of Surveillance , 62 ST. LOUIS  U. L. J. 55 (2018),  available  at 
https://digitalcommons.law.seattleu.edu/cgi/viewcontent.cgi?article=1817&context=faculty . 
43 Annette Bernhardt, et al., Data and Algorithms at Work: The Case for  Worker Technology Rights , U.C.  BERKELEY L. 
CTR. (Nov. 3, 2021), available at https://laborcenter.berkeley.edu/data -algorithms -at-work/#s -19; The Daily 
Podcast, The Rise of Workplace Surveillance , N.Y.  TIMES , Aug. 24, 2022, available at 
https://www.nytimes.com/2022/08/24/podcasts/the -daily/workplace -surveillance -productivity -tracking.html . 
See also Nick Stat, Amazon expands gamification program that encourages warehouse employees to work harder , 


8 Other forms of AWSM may discourage physical proximity of workers and therefore chill concerted activity. GPS 
trackers that allow employers to assess worker movements through a warehouse or a janitor’s progress in 
cleaning an office building can also reveal whether groups of workers are exercising their right to discuss 
conditions or potential unionization. High automated productivity quotas may discourage workers from taking 
legally permitted breaks where they could have encountered one another in a break room or a restroom. In other 
cases,  worker  awareness  of corporate  surveillance  may  compel  organizing  efforts  to remain  closely  held,  fostering 
a sense of wrongdoing when exercising legal rights. “If it’s too secret, too confidential, then it starts to feel illicit,” 
notes Saint Louis University School of Law Professor Matthew Bodie. “It’s like, oh, we shouldn’t be doing this.”44 
4. AWSM  combines  with  other  health  and  safety  hazards  to amplify  unhealthy  and  unsafe  work
environments.
AWSM often combines with extant workplace hazards to exacerbate already dangerous working conditions. For 
example, warehouse workers subject to AWSM -related pressure to increase work speed do so in an environment 
already  rife with  multiple  health  and safety  hazards.  Workers  toil in heat  without  training  to recognize  heat  stress 
symptoms; they are exposed to chemicals i n plastic with little information about potential health impacts; and 
they operate machinery with little or no personal protective equipment or training. These hazards, combined  
with AWSM -related pressure to meet quotas, dramatically increase the likelihood of injury or illnesses .45 
Significant health and safety hazards are also common in underpaid industries such as warehousing , agriculture, 
and logistics .46 Because  of occupational  segregation,  Black, Latinx,  and immigrant workers  are overrepresented in 
these more precarious, underpaid industries, therefore making injury rates higher for workers of color.47
Furthermore, hazards caused by increased pace of work quotas and surveillance are rooted in this country's 
history of slavery, capitalism, and cotton production.48 Thus, Black and immigrant workers disproportionately 
experience  the brunt  of the legacy  of quotas  and increased  pace  of work  through  their  overrepresentation  in some 
of the most precarious industries.  
Reliance  on AWSM  to increase  pace  of work  can undermine  worker  health  and safety . 
AWSM poses a risk to workers’ health and safety when it is used to increase the pace of work.49 For example, 
regulators  have  noted  that  the high  rates  of serious  injury  at Amazon  are directly  attributable  to the way  that  the 
THE VERGE , MAR. 15, 2021,  available  at https://www.theverge.com/2021/3/15/22331502/amazon -warehouse - 
gamification -program -expand -fc-games . 
44 Constanz,  supra  n. 27, ‘They  were  spying ’. 
45 Warehouse Workers United and Deogracia Cornelio, Shattered Dreams Broken Bodies: A Brief Review of the 
Inland Empire Warehouse Industry , U.C.L.A.  LAB. OCCUPATIONAL SAFETY AND HEALTH PROGRAM (June 30, 2011), 
https://warehouseworkers.org/wp -content/uploads/2014/06/Shattered_Dreams_and_Broken_Bodies718.pdf . 
46 U.S. Bureau of Lab. Statistics, Labor Force Statistics from the Current Population Survey , U.S.  DEP’T OF LAB., 
available  at https://www.bls.gov/cps/cpsaat18.htm  (showing  employed  persons  by detailed  industry,  sex, race, 
and Hispanic or Latino ethnicity), last visited May 25, 2023.  
47 Kate  Bahn  and Carmen  Sanchez  Cummings,  Factsheet:  U.S. occupational  segregation  by race,  ethnicity,  and 
gender , CTR. FOR EQUITABLE Growth (July 2020), available at  
https://equitablegrowth.org/factsheet -u-s-occupational -segregation -by-race -ethnicity -and-gender/ ; Michael 
Grabell, The Expendables: How The Temps Who Power Corporate Giants Are Getting Crushed , PRO PUBLICA , July 13, 
2013, available at https://www.propublica.org/article/the -expendables -how -the-temps -who -power -corporate - 
giants -are-getting -crushe ; Seth A. Seabury , Sophie Terp , Leslie I. Boden , Racial and Ethnic Differences in the 
Frequency  of Workplace  Injuries  and the Prevalence  of Work -Related  Disability , 36 HEALTH  AFFAIRS  NO. 2 (Feb.  2017), 
available at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6198680/ . 
48 Nikole  Hannah  Jones,  1619  Podcast:  Episode  2 The Economy  That  Slavery  Built , N.Y.  TIMES , August  30, 2019, 
available at https://www.nytimes.com/2019/08/30/podcasts/1619 -slavery -cotton - 
capitalism.html?showTranscript=1.  See also Section 3, supra.  
49 The Public Health Crisis Hidden in Amazon Warehouses , HUMAN IMPACT PARTNERS AND WAREHOUSE WORKERS
RESOURCE  CENTER  (Jan.  2021),  https://humanimpact.org/wp -content/uploads/2021/01/The -Public -Health -Crisis - 


9  company  manages  its workforce  using  AWSM.50 And  when  Amazon  temporarily  suspended  some  of its 
productivity tracking and disciplinary policies in 2020, injury rates dropped significantly.51 
 
Meatpacking is another industry that has introduced AWSM in recent years. For example, some of the largest 
employers in that industry —which have a track record seeking to increase the speed of work even when it 
endangers the health and safety of frontline workers —have begun to use smart watch technology that “uses 
sensors to constantly collect data on the force, rotation, speed and directional movement of a worker’s arm as 
they perform the same motion over and over.”52 These watches are marketed by third party vendors as tools to 
improve  worker  health  and safety;  however,  they  allow  employers  to much  more  closely  track  and surveil  worker 
productivity and pose a potential risk to workers’ health and safety, especially in the absence of regulatory 
standards limiting their use.  
 
AWSM  designed  to monitor  individual  health  risks  may  harm  workers  and enable  discrimination  in 
the absence of guardrails on data collection . 
Current  evaluation  for heat  stress, wildfire smoke  exposure,  and extreme  cold  exposure  for workers is primarily 
based  on broad  environmental  assessments  and does  not account  for individual  physiological  responses  to these 
inputs. In response, some health and safety experts have suggested wearable data -collection devices to 
individually monitor workers for possible illness or injury from exposure to environmental extremes. For 
instance, Chevron has implemented a skin patch that measures sweat levels and electrolyte loss while other 
companies are using a third -party sensor that measures heart rate, body temperature, and skin temperature.53 
Individual biometric data could allow each worker to assess her own body’s responses in real time and take 
action to protect herself from illness or injury.54 However, without regulation this kind of data collection and 
surveillance raises significant privacy and potential discrimination concerns.  
 
While  manufacturers  tout  the ability  for supervisors  to use aggregated  data  to determine  the best  times  for rest 
breaks and claim that individualized data is only available to the individual worker, it is unclear how the data  
 
Hidden -In-Amazon -Warehouses -HIP-WWRC -01-21.pdf . See also  Jodi  Kantor  and Arya  Sundaram,  The Rise  of the 
Worker Productivity Score , N.Y.  TIMES , Aug. 14, 2022, available at 
https://www.nytimes.com/interactive/2022/08/14/business/worker -productivity -tracking.html . 
50 Will Evans, Amazon’s warehouse quotas have been injuring workers for years. Now, officials are taking action , 
REVEAL  NEWS, May  16, 2022,  available  at https://revealnews.org/article/amazons -warehouse -quotas -have -been - 
injuring -workers -for-years -now -officials -are-taking -action/ . 
51 Amazon has resumed policies that penalize workers for taking too many breaks, just in time for Prime Day , CNBC, 
October  14, 2020,  available  at https://www.cnbc.com/2020/10/14/amazon -resumes -policy -that -dings -workers - 
for-taking -too-many -breaks.html . See also The Injury Machine: How Amazon’s Production System Hurts Workers , 
THE STRATEGIC ORGANIZING CENTER (April 2022), https://thesoc.org/wp -content/uploads/2022/04/The -Injury - 
Machine_How -Amazons -Production -System -Hurts -Workers.pdf . 
52 Shayla Thompson and Debbie Berkowitz, USDA Allows Poultry Plants to Raise Line Speeds Exacerbating Risk of 
Covid 19 Outbreaks , NAT’L EMPL. L. PROJECT (June 2020), available at https://www.nelp.org/publication/usda - 
allows -poultry -plants -raise -line-speeds -exacerbating -risk-covid -19-outbreaks -injury/ . See also Madison McVan, 
JBS, Tyson  Foods  invest  in smartwatch  app that  monitors  workers , INVESTIGATE  MIDWEST , October  13, 2022,  available 
at https://investigatemidwest.org/2022/10/13/jbs -tyson -foods -invest -in-smartwatch -app-that -monitors - 
workers/ . 
53 Skin patch could help offshore workers avoid heat stress, CHEVRON PRESS RELEASE , July 18, 2022, available at 
https://www.chevron.com/newsroom/2022/q3/skin -patch -could -help -offshore -workers -avoid -heat -stress ; 
“Wearable biometric sensor bring better data on heat -related illness in construction ,” ENGINEERING NEWS-RECORD , 
Dec.  29, 2020,  available  at https://www.enr.com/articles/50929 -wearable -biometric -sensor -brings -better -data - 
on-heat -related -illness -in-construction . 
54 Sean  R. Notley,  et al., On the use of wearable  physiological  monitors  to assess  heat  strain  during  occupational  heat 
stress , APPLIED  PHYSIOLOGY  NUTRITION  AND  METABOLISM  (May  2018),  https://www.researchgate.net/profile/Andreas - 
Flouris/publication/324964363_On_the_use_of_wearable_physiological_monitors_to_assess_heat_strain_during_o  
ccupational_heat_stress/links/642bd4cdad9b6d17dc33da45/On -the-use-of-wearable -physiological -monitors -to- 
assess -heat -strain -during -occupational -heat -stress.pdf . 


10 collection might be regulated or how health information privacy rights like those in the Health Insurance 
Portability  and Accountability  Act can be enforced  when  employers  are not subject  to the privacy  rule.  Indeed,  in 
a survey of safety engineers, the most often cited concern with the use of wearable data -collection, evaluation, 
and performance tracking devices worn by workers, in the workplace was protecting employee privacy and 
confidentiality. These respondents were concerned that even the perception of employer surveillance of such 
personal data could lead to ineffective use of the wearable devices and intentional lack of compliance by 
employees.55 
To date, studies on the efficacy of these types of wearable devices as a health and safety tool have been largely 
limited to higher income countries and urban settings, occasionally on outdoor workers but often on younger 
students,  athletes,  and military  enrollees.  Significantly,  among  the studies  that  were  addressing  occupational  heat 
stress, several found associations between sex, age, body mass index, and education and physical responses to 
heat stress.56 NELP is concerned that improper use of this data could facilitate discrimination against workers 
who are perceived to have pre -existing conditions or chronic health conditions or against workers with 
disabilities;  because Black  and immigrant  workers  often  have less  access  to preventive  care  and experience  some 
chronic health problems at a higher ratio than white workers, this type of health data collection could also have 
civil rights and Equal Employment Opportunity Commission implications or lead to violations of the Americans 
with Disabilities Act.57 
At the same  time,  it is important  for policymakers  to recognize  that  other  concerns  such  as data  accuracy,  worker 
access to data, and workplace safety may sometimes overshadow privacy concerns for workers. For example, a 
recent study showed that during the COVID -19 pandemic many essential workers indicated that health data 
transparency from their employer was a higher priority for them than their personal health data privacy.58 
5. AWSM  is used  to discipline  and  terminate  workers  without  transparency  or meaningful  processes  to
contest decisions, degrading working conditions and potentially amplifying race inequities.
Corporations also use AWSM to discipline or fire workers.59 Its use frequently decreases disciplinary 
transparency and limits workers’ access to human managers. For example, Amazon has “replaced its middle 
management  and human  resources  workers  with  artificial  intelligence  to determine  when  a worker  has outlived 
their usefulness and needs to be let go. There is no human to appeal to…”60 Workers have also reported having 
little recourse when AWSM systems have incorrectly or inaccurately disciplined them.61
55 Mark  C. Schall,  et al., Barriers  to the Adoption  of Wearable  Sensors  in the Workplace:  A Survey  of Occupational  
Safety and Health Professionals , HUM. FACTORS (May 2018), available at 
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9307130/ . 
56 Mara  Koch,  et. al., Wearables  for Measuring  Health  Effects  of Climate  Change -Induced  Weather  Extremes:  Scoping 
Review , JMIR  MHEALTH UHEALTH (September 2022), available at https://mhealth.jmir.org/2022/9/e39532 . 
57 Privacy,  Data  Security,  & Workplace  Wearables:  Best  Practices  for Employers,  JD SUPRA (January  2022),  available 
at: https://www.jdsupra.com/legalnews/privacy -data -security -workplace -6466197/ . 
58 Livia  Garofalo,  et al., Essentially  Unprotected:  Health  Data  and Surveillance  of Essential  Workers  During  the 
COVID -19 Pandemic, DATA & SOC’Y (April 2023), available at: https://datasociety.net/library/essentially - 
unprotected/ . 
59 Ugo Okere, et al., Secure Jobs, Safe Workplaces and Stable Communities: Ending At -Will Employment in Illinois , 
NAT’L EMPL. L. PROJECT , RAISE THE FLOOR ALLIANCE , (2021), available at: https://www.nelp.org/publication/secure - 
jobs -safe -workplaces -stable -communities -ending -will-employment -illinois/ . See also: Jodi Kantor and Arya 
Sundaram, The Rise of the Worker Productivity Score , N.Y.  TIMES , (Aug. 14, 2022), available at : 
https://www.nytimes.com/interactive/2022/08/14/business/worker -productivity -tracking.html , and Fired by an 
App, supra n. 10.  
60 Jessa Crispin, Welcome to Dystopia: Getting fired from your job as an Amazon worker by an app,” THE GUARDIAN , 
July 5, 2021,  available  at https://www.theguardian.com/commentisfree/2021/jul/05/amazon -worker -fired -app- 
dystopia . 
61 Lauren  K. Gurley,  Amazon’s  AI Cameras  Are Punishing  Drivers  for Mistakes  They  Didn’t  Make , VICE  MOTHERBOARD , 
Sept. 20, 2021, available at : https://www.vice.com/en/article/88npjv/amazons -ai-cameras -are-punishing - 
drivers -for-mistakes -they -didnt -make . 


11  Lack  of access  to a human  manager  can adversely  affect  workers’  experience  of “organizational  justice,”  or “the 
role of fairness perceptions, e.g.,…the fairness of decision -making processes, and the fairness in interpersonal 
interactions.” Such experiences can degrade working conditions. Studies have shown that deficits in 
organizational justice itself can increase job stress and the risk of work -related musculoskeletal disorders.62 
 
Corporate use of AWSM for discipline or termination can also magnify the existing power imbalance between 
employers and workers, especially in an at -will employment relationship. By providing second -to-second 
monitoring  of workers’  actions,  surveillance  technologies  can detect  and record  a momentary  pause  on the part  of 
a worker  and give  employers the  option  of turning  it into an  infraction leading  to discipline  or termination.  In this 
way, AWSM  can greatly increase  the volume  of disciplinary  actions,  which has the  potential  to make it much more 
difficult for workers to contest unfair, discriminatory, or retaliatory disciplinary action or discharges.63 
 
On the surface  AWSM  can lend  the appearance  of fairness  in workplace  discipline  by subjecting  every  worker  to a 
uniform interface with a non -human management system. In reality, aspects of AWSM have the effect of making 
discipline and firing processes more opaque, arbitrary, and unfair. Workers may have no ability to input or 
correct data, meaning that the data collected about their work performance may not reflect factors out of their 
control such as equipment malfunctions or a chance event.64 And when workers are disciplined incorrectly or 
inappropriately by AWSM for circumstances outside of their control, they may have little recourse or access to 
human decision makers.65 
Finally,  employer  adoption  of AWSM  may  also  amplify  existing  inequities  in workplace  discipline.  Research  shows 
that employers scrutinize Black workers more than other workers and are less likely to give Black workers a 
chance to improve before terminating them.66 AWSM may exacerbate those dynamics by providing employers 
additional inexpensive and non -transparent means to engage in that kind of scrutiny.  
 
6. AWSM  facilitates  unfair,  unpredictable,  and  discriminatory  pay.  
As corporations turn to AWSM as a means of managing and controlling their workforces, they are also 
increasingly  relying  on algorithms  to set wages,  in many  cases  perpetuating  wage  discrimination  based  on biased 
customer reviews or through algorithms that are personalized to individual workers, thereby paying workers 
unequally for equal work.  
 
For example, ride -hail drivers for corporations like Uber and Lyft are currently paid according to black -box 
algorithms that are opaque to both workers and consumers. Up until a few years ago, ride -hail companies set 
customer  fares  and worker  pay with  a relatively  straightforward  calculation,  according  to a fixed  per-minute  and 
 
 
62 Raphael  M. Herr,  et al., Three  job stress  models  and their  relationship  with  musculoskeletal  pain  in blue - and 
white -collar workers , JOURNAL OF PSYCHOSOMATIC RESEARCH (November 2015), a vailable at: 
https://www.sciencedirect.com/science/article/abs/pii/S0022399915005140 . 
63 Amazon issued 13,000 disciplinary notices at a single U.S. warehouse , CNBC, July 12, 2022, available at : 
https://www.cnbc.com/2022/07/12/amazon -issued -13000 -disciplinary -notices -at-a-single -us-warehouse.html . 
64 Chip  Cutter,  et al., You’re  Working  From  Home,  but Your  Company  Is Still Watching  You,  WALL  ST. J., April  18, 2020, 
available  at https://www.wsj.com/articles/youre -working -from -home -but-your -company -is-still-watching -you- 
11587202201 . 
65 Spencer Soper, Fired by Bot at Amazon: ‘It’s You Against the Machine’ , BLOOMBERG , June 18, 2021, available at: 
https://www.bloomberg.com/news/features/2021 -06-28/fired -by-bot-amazon -turns -to-machine -managers - 
and-workers -are-losing -out. See also : Lauren K. Gurley, Amazon’s AI Cameras Are Punishing Drivers for Mistakes 
They Didn’t Make , VICE M OTHERBOARD , Sept. 20, 2021, available at 
https://www.vice.com/en/article/88npjv/amazons -ai-cameras -are-punishing -drivers -for-mistakes -they -didnt - 
make . 
66 Costas  Cavounidis  & Kevin  Lang,  Discrimination  and Worker  Evaluation , NBER  WORKING  PAPERS  (October  2015),  
available  at https://www.nber.org/papers/w21612 . 


12 per-mile  rate,  and then  sometimes  with  “surge”  multipliers  applied  to the total.67 Then  a couple  years  ago,  Uber 
fully uncoupled customer fares and worker pay, setting both according to complex and invisible algorithms, 
meaning that there is no longer any necessary connection between what a customer pays and what a driver is 
paid.68 
One result has been a pattern of skyrocketing consumer fares while driver pay continues to fall or stagnate. 
Another result has been that work as a ride -hail driver —or on -demand work more generally —is increasingly 
unstable and unpredictable. Workers whose wages are determined by an obscure, complex system may make 
dramatically  different  amounts  on different  days  for the same  amount  of work.69 Therefore,  corporate  adoption  of 
AWSM increases precarity; workers are unable to predict or understand their constantly changing, frequently 
declining compensation, and many struggle to plan financially.70
More troublingly, because driver pay is not fixed according to any set of objective criteria, company algorithms 
can pay two drivers different amounts for identical trips. A recent video uploaded to YouTube, by the hosts of a 
popular  show  about  working  as a ride -hail driver  demonstrates  what  this looks  like in practice:  two Uber  drivers, 
sat next  to each  other  on a couch  at one of their  homes  in Chicago,  log onto  the app at the same  time  and watch  as 
they are presented identical trips at different fares.71 Because those algorithms are tightly held, it is currently 
impossible for anyone outside of Uber to understand what determines the different fares. But, as one scholar 
exploring this issue has put it, it seems highly likely that on -demand companies like Uber are “offer[ing] 
vulnerable workers lower wages based on their willingness to accept work at lower prices.”72 In other words, 
AWSM threatens to pave the way for a new labor management practice: using individualized worker data to 
identify exactly the wage at which a given worker will accept work, and then paying them that amount. The 
upshot is that poor workers, Black workers, immigrant workers, and women workers may be paid less for doing 
equal work.  
And by no means are these trends limited only to ride -hail workers. As companies in industries like retail, food 
service, and medical care adopt the labor management technologies pioneered by Uber, the practice of 
algorithmic wage discrimination is spreading.73 For example, a company that has branded itself “Uber for 
Hospitals”  has developed  AI staffing  software  that  uses  “smart  technology”  to allocate  work  tasks  and to judge  the 
performance of porters, nurses, and nurse practitioners. The technology company’s “performance analysis” is 
then used to determine the pay for these healthcare workers.74 Absent strong policy interventions, workers  
67 Dara  Kerr,  Secretive  Algorithm  Will  Now  Determine  Uber  Driver  Pay in Many  Cities , MARKUP , Mar  1, 2022,  available 
at https://themarkup.org/working -for-an-algorithm/2022/03/01/secretive -algorithm -will-now -determine - 
uber -driver -pay-in-many -cities . 
68 Faiz  Siddiqui,  You May  Be Paying  More  for Uber,  but Drivers  Aren’t  Getting  their  Cut of the Fare  Hike , WASH. POST, 
Jun. 10, 2021,  available  at https://themarkup.org/working -for-an-algorithm/2022/03/01/secretive -algorithm - 
will-now -determine -uber -driver -pay-in-many -cities . 
69 Veena  Dubal,  On Algorithmic  Wage  Discrimination , U.C. SAN FRANCISCO  RESEARCH  PAPER at 14 (forthcoming  2023),  
available  at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4331080 . 
70 Id. at 7. 
71 2 Uber  Drivers:  Same  Requests  DIFFERENT  PAY!  You Won’t  Believe  This! , THE RIDESHARE  GUY YOUTUBE  CHANNEL
(Mar 1, 2023), available at https://www.youtube.com/watch?v=UADTiL3S67I . 
72 Dubal, supra n. 69, at 40 (“As a labor management practice, algorithmic wage discrimination allows firms to 
personalize  and differentiate  wages  for workers  in ways  unknown  to them,  paying  them  to behave  in ways  that  the 
firm desires, perhaps as little as the system determines that they may be willing to accept.”); Id. at 6.  
73 See, e.g., Lauren  K. Gurley,  Target’s  Delivery  App Workers  to Be Paid  by a Blackbox  Algorithm  Nationwide , VICE, 
Sept.  11, 2020,  available  at https://www.vice.com/en/article/qj49jv/targets -delivery -app-workers -to-be-paid - 
by-a-blackbox -algorith . See also  E. Tammy  Kim,  The Gig Economy  is Coming  for Your  Job, N.Y.  TIMES , Jan. 10, 2020, 
available at https://www.nytimes.com/2020/01/10/opinion/sunday/gig -economy -unemployment - 
automation.html . 
74 For more  information  on this company,  see Nicky  Godding,  Oxford  Tech  Raises  £9 Million  for ‘Uber  for Hospitals’ 
AI Platform , BUSINESS INNOVATION MAGAZINE , May 21, 2020, available at 
https://www.businessinnovationmag.co.uk/oxford -tech -raises -9-million -foruber -for-hospitals -ai-platform/ . 


13  across  the economy  could  be paid  according  to opaque  and personalized  algorithms  that  obscure  systemic  wage 
discrimination along protected lines of race and gender.75 
 
7. Policy  recommendations  to address  the harms  of unregulated  corporate  adoption  of AWSM.  
 
As detailed above, corporate adoption of AWSM is creating new barriers to employment (both finding and 
keeping jobs), employer accountability, workplace democracy, health and safety, and fair compensation, 
particularly  for Black,  immigrant,  and women  workers.  Mitigating  the risks  and harms  posed  by corporate  AWSM 
practices will require deliberate worker engagement, ongoing evaluation, updates to administrative policies and 
legislation, and significant investments in enforcement.  
1. The Administration  should  support  policies  that  expand  worker  voice  and worker  power,  which  are 
fundamental to eliminating the harmful effects of AWSM . 
 
Workers must have a voice in the adoption of AWSM at work and play a central role in evaluating its use. They 
should  have  institutional  power  to develop  and enforce  policies  that  eliminate  or minimize  the AWSM’s  harmful 
impacts.  
 
x The Bureau  of Labor  Statistics  (BLS)  should  develop  a new  Current  Population  Survey  (CPS)  module 
asking workers how AWSM impacts their employment and job quality.  
x Unions provide workers with a voice on the use of AWSM by their employers.76 Recognizing this, the 
White  House  should  work  with  Congress  to advance  the Protecting  the Right  to Organize  Act to expand 
organizing and collective bargaining protections. Workers should be able to bargain freely over the 
adoption, use, limitations of, as well as protections from, AWSM in any contract.  
x To help  ensure  AWSM  is not used  to silence  organizing,  the NLRB  should  formally  adopt  the framework 
established by the General Counsel’s memo on unlawful electronic surveillance and automated 
management practices. Specifically, the Board should adopt a presumption that the use of AWSM is a 
violation of privacy and of the right to organize, absent compelling justification.77 
x The Administration  or the NLRB  should  consider  adopting  rules  to require  employee  consent  to 
electronic surveillance and can look to state law models.78 
 
2. The Administration  should  establish  ongoing  evaluation  on corporate  use of AWSM.  
 
Given  the skyrocketing,  opaque,  and largely  unregulated  adoption  of AWSM,  the Administration  should  develop 
policies and procedures to ensure regular and transparent evaluation of its impact on workers.  
 
x The BLS should  field  the CPS module  mentioned  above  regularly  to ensure  that  the Department  of Labor 
(DOL) and worker advocates stay abreast of AWSM impacts on workers.  
x To account for the fact that  workers may  not be privy to the extent of their employers’ use of AWSM, the 
Administration should  work  with  the BLS,  the DOL  Inspector General,  and the Commerce  Department  to 
survey  and audit  businesses  regarding  their  adoption  and use of AWSM.  Following  the examples  of some 
states, the Administration should explore requiring regular and public disclosure of what information is  
 
 
 
75 Teachout, supra n. 9, Algorithmic Personalized Wages (“Uber drivers’ experiences [of wage discrimination] 
should  be understood  not as a unique  feature  of contract  work,  but as a preview  of a new  form  of wage  setting  for 
large employers: individualized pay, schedules, benefits, and individualized behaviorally based incentive 
structures.”).  
76 Kresge,  Union  Collective  Bargaining , supra  n. 41. 
77 See NAT’L. LAB. REL. BD. memo,  supra  n. 25, at 8. 
78 See, e.g., California law rendering it a misdemeanor to use electronic tracking of an employee without her 
consent.  Kendra  Rosenberg,  Location  Surveillance  by GPS:  Balancing  an Employer’s  Business  Interest  with  Employee 
Privacy , 6 W ASH. J. L. T ECH. & A RTS  143, 149 (2010).  


14 collected, where it is stored and for how long, how it is used, and if it is shared.79 Relatedly, because 
AWSM  is currently  developed  and implemented  largely  in secret,  robust  worker  notice  and transparency 
measures should be developed.80
x The White  House  should  work  with  the Commerce  Department  to examine  the patenting  process  and to 
ensure that the worker impact assessments are incorporated.  
x The Administration  should  work  to ensure  that  patents  for technologies  with  workplace  applications 
ensure jobs aligned with the DOL’s Good Job Principles.  
3. The Administration  should  establish  a Privacy  and Technology  Division  at the DOL  to help  protect
workers from the harms of AWSM.
NELP supports the proposal put forth in the Stop Spying Bosses Act of 2023 (S. 262) to establish a Privacy and 
Technology Division at the Department of Labor to enforce and regulate workplace surveillance, with annual 
reporting  to Congress  on workplace  surveillance  and employer  actions  to control  workers,  including  how  and to 
what extent AWSM systems harm workers.81 The White House should work with Congress to advance this 
legislation which would additionally require any employer engaging in surveillance and collecting data on 
employees or applicants to disclose such information in a timely and public manner; prohibit employers from 
collecting sensitive data on workers such as off -duty data collection or data collection that interferes with 
organizing; and create robust rules around the usage of automated decision systems.  
4. The Administration  should  issue  guidance  and invest  in enforcement  to eliminate  the use of AWSM  as a tool
for evading employer accountability .
Many  of the harms  inflicted  by widespread  corporate  adoption  of AWSM  are the result  of the way  AWSM  enables 
the violations of other laws, particularly how it helps strip workers of core employee and labor protections.  
Accordingly,  NELP  recommends  that  the Administration  use its existing  authority  to promulgate  guidance  and use 
strategic enforcement to protect and restore employee rights. NELP recommends the following:  
x The DOL’s proposed rule on independent contractor classification under the Fair Labor Standards Act 
(FLSA)  should  be finally  promulgated  to ensure  broad  access  to minimum  wage  and overtime  protections 
Congress intended under the FLSA. The DOL’s express consideration of surveillance and technology 
should be retained and strengthened in the final rule to specifically identify algorithmic control as a form 
of technological  control  weighing  in favor  of employee  status.  The rule should  recognize  that  control  over 
the work, even if exercised by algorithmic management on a smartphone or electronic surveillance, is 
probative evidence of an employment relationship.  
x The DOL  should  issue  guidance  clarifying  what  constitutes “compensable  time”  for individuals  working 
on labor  platforms  that  currently  use AWSM  to deny  pay for a significant  portion  of workers’  time,  such 
as when a ride -hail driver is returning from a drop off or waiting for a passenger.82 
x The NLRB’s  rulemaking  to restore  “joint  employer”  accountability  under  the NLRA  should  address  the 
role of AWSM in preventing or chilling worker organizing. It should recognize the use of AWSM as an 
indicator of an employment relationship and restore accountability for labor law violations by 
corporations —like Amazon —that  use AWSM  to control  their  subcontractors  and workers  throughout  
79 Connecticut  and Delaware  both  require  disclosure  to employees  of surveillance  practices.  See Conn.  Gen.  Stat.  § 
31-48d(b)(1); Del. Code Ann. tit. 19, § 705.
80 See Emlyn  Brottomley,  Data  and Algorithms  in the Workplace:  An Overview  of Current  Public  Policy  Strategies ,
U.C. BERKELY  L. CTR. (Nov.  17, 2020),  available  at 
https://escholarship.org/content/qt14c251kn/qt14c251kn.pdf?t=rq6hdy .
81 Stop  Spying  Bosses  Act, US Senate,  S. 262,  Senate  Committee  on Health,  Education,  Labor,  and Pensions , available
at: https://www.congress.gov/bill/118th -congress/senate -bill/262/text .
82 See, e.g., Rebecca Bellan, U.C. Berkeley finds gig workers could earn  $4.82 per hour if MA ballot proposal passes ,
TECH  CRUNCH , Sept.  29, 2021,  available  at https://techcrunch.com/2021/09/29/uc -berkeley -finds -gig-workers - 
could -earn -4-82-per-hour -if-ma-ballot -proposal -passes/  (noting  that  ‘engaged  time’  is only  67%  of actual  work
time).  


15  their  fissured  workforce.  Specifically,  the Board  should  clarify  that  employers’  use of AWSM  is indicia  of 
an employer’s  “authority  to control”  and suggests  direct  or indirect  “power  to control”  under  the NLRA.  
 
5. The Administration  should  establish  standards  for disciplinary  transparency  and fairness  for federal  
contractors using AWSM.  
 
The enormous power of AWSM should be decoupled to the greatest extent possible from the processes of 
workplace discipline and termination to guard against abuses and reduce the increased power imbalance 
between workers and employers. Curbing the use of AWSM for the purposes of discipline and termination, 
together with greater protection against abrupt and arbitrary firings, would help diminish harm to workers and 
the erosion  of job quality.  The Administration  should,  at a minimum,  begin  this work  with  its federal  contractors, 
by implementing the following standards:  
x Federal  contractors  should  be prohibited  from  using  the most  invasive  forms  of AWSM  (such  as biometric 
monitoring or apps installed on personal devices) for the purposes of discipline and termination. These 
employers should also be required to meet standards of fairness and transparency when using AWSM to 
discipline or terminate workers. Such standards could include requiring employers to use the least 
invasive surveillance method available and to provide justification and third -party certification for any 
surveillance they plan to use for the purposes of discipline or termination. These provisions are included 
in a bill recently introduced in the New York City Council.83 
x Federal contractors’ use of electronic monitoring in relation to productivity tracking and pace of work 
should be restricted. Measures could include, for example: banning continual “time off task monitoring” 
allowing it only as part of a periodic pre -announced performance review;84 and limiting the time 
increments  in which  quotas  can be measured,  i.e., allowing  for quotas  to be measured  by the day,  and not 
by shorter increments of time such as the hour or minute.  
x The Administration should require federal contractor disclosure of performance standards and fair 
processes for discipline and termination. Any attempt to regulate the use of electronic monitoring will 
have  a limited  effect  in the absence  of baseline  legal  protections  related  to discipline  and termination.  For 
example, policies that require disclosure of AWSM use, access to data collected by AWSM, or that impose 
broad blanket bans on AWSM (such as the proposed Stop Spying Bosses Act of 2023 —S. 262 that bans 
surveillance that threatens employees’ mental or physical health) will be less effective in an at -will 
employment context. If enacted in the absence of required disclosure of performance standards, 
disciplinary policies, warnings, fair processes, and reasons for discharge, employers will continue to use 
AWSM in opaque ways that leave workers little recourse when they are unfairly discharged based on  
data  from  AWSM.  As such,  the Administration  should  consider  establishing  “just  cause”  protections  for all 
employees  of federal  contractors.85 The Administration  should  consider  how  best  to expand  these  federal 
policies to the private sector in keeping with its Good Jobs Principles and for the benefit of all workers.  
 
* * * * 
 
 
As detailed  above,  NELP  is concerned  with  unregulated  and opaque  corporate  adoption  of AWSM  and its impacts 
on employment, compensation, health and safety, discrimination, and worker power, particularly for Black and 
immigrant workers. Corporate adoption of AWSM without worker input, voice, transparency, and evaluation 
threatens to erode employer accountability, increase barriers to collective action, amplify unsafe or unhealthy 
working conditions,  facilitate unpredictable and discriminatory pay, increase racial income inequality, and leave  
 
83 Wrongful  Discharge  from  Employment,  N.Y.  City  Council,  Int. 0837 -2022,  Committee  on Consumer  and Worker 
Protection, available at https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=5958217&GUID=44D72CEC - 
FE82 -4A43 -BA31 -4BB15FBC15EB&Options=ID%7CText%7C&Search=s%3D%3D . 
84 Id. 
85 Karla  Walter,  Service  Contract  Workers  Deserve  Good  Jobs,  CTR. FOR  AM. PROGRESS , (Apr.  9, 2021),  available  at 
https://www.americanprogressaction.org/article/service -contract -workers -deserve -good -jobs/ . 


16 workers  without  recourse  for unfair  and opaque  discipline  or termination.  NELP  appreciates  the opportunity  to 
comment on this important topic.  
Sincerely,  
Anastasia Christman, Senior Policy Analyst 
Sally Dworak -Fisher, Senior Staff Attorney 
Nicole  Marquez,  Director  of Social  Insurance 
Daniel Ocampo, Legal Fellow  
Maya  Pinto,  Senior  Researcher  and Policy  Analyst 
Irene  Tung,  Senior  Researcher  and Policy  Analyst  


March  1, 2024  
To: The Honorable Julie Su 
Acting  Secretary  of Labor 
Department of Labor  
200 Constitution  Avenue  N.W. 
Washington, DC 20210  
From:   Data  & Society  
National  Employment  Law Project 
Upturn  
RE: Principles  and Best Practices  for Employers  – AI, Protected  Activity, and Compensation  
Under  President  Biden’s  “Executive  Order  on the Safe,  Secure,  and Trustworthy  Development  and Use of 
Artificial Intelligence,” the Department of Labor is tasked with developing principles and best practices 
for employers. On behalf of Data & Society, the National Employment Law Project, and Upturn, we 
welcome the opportunity to provide input to the Department on this subject. Data & Society is an 
independent nonprofit research institute that studies the social implications of data, automation, and 
artificial intelligence (AI), producing empirical research to ground informed public debate about  
emerging technology. NELP is a nonprofit research and policy organization with over 50 years of 
experience  advocating  for the employment  and labor  rights  of underpaid  workers. Upturn  advances  equity 
and justice in the design, governance, and use of technology. While our organizations are  concerned  with 
many facets of AI in the workplace, this memo will focus on the implications for compensation and 
protected activity.  
When developing principles and best practices, as called for in the Executive Order, the Department 
should  account  for the myriad  ways  automated  decision  systems  (ADSs)  and electronic  surveillance  and 
automated management (ESAM) systems in the workplace can inhibit efforts to build a good jobs 
economy, think expansively about what it would require for employers to restrict the use of these 
technologies to only the most responsible and equitable uses, and present an alternative vision for the 
future.  
We recommend  including  the following  as principles  or best practices:  
●Workers  must  have  a voice  in whether  and how automated  systems  are used in their workplaces
and play an ongoing role in evaluating their impact, including on wages, scheduling, job
responsibilities, discipline, and collective activity. Workers must have institutional power to
develop and enforce policies that eliminate or minimize any harmful impacts stemming from
these technologies, including through collective bargaining agreements.
●The use of ESAM and ADSs should be constrained to legitimate and strictly necessary business
purposes that account for the rights and concerns of workers. Round the clock surveillance, for
example,  is unlikely  to be strictly  necessary  for an employer  to analyze  worker  productivity  to the
degree required to carry out its business needs.
●Relatedly,  the Department  should  stress  the importance  of data minimization  as an employer  best
practice —collecting only the data that is strictly necessary for a legitimate purpose.


2 ●Algorithmic  systems  for determining  compensation  should  be anchored  around  the principle  of
equal pay for equal work, and provide stable, predictable pay for hours worked.
●Workers  must  have  access  to fair processes  with human  input  to dispute  algorithmically  driven
employment decisions, especially relating to discipline and termination.
●Employers  must  not utilize  ESAM  in ways  that discourage  or disrupt  worker  access  to their right
to organize and bargain collectively, and engage in concerted activity related to their working
conditions. The Department should consider both the overt and subtle ways these systems
function to prevent worker organizing.
●Employers  should  not utilize  ADS  and ESAM  systems  in ways  that increase  worker  instability,
precarity, stress, and inability to access bedrock protections and social insurance programs.
●Employers must be transparent when they use or intend to use an ADS or ESAM system in the
workplace,  including  by disclosing  to workers  a meaningful  description  of the system  to be used,
how the employer  uses or intends  to use such a system,  and how workers  may appeal  algorithmic
decisions that impact them.
●When deploying an ADS, employers should ensure that the system has undergone pre - 
deployment  testing,  including  for bias and disparate  impact,  and validation  of the system’s
claimed efficacy.
Additionally,  similar  to the NLRB  memo  on electronic  monitoring,  the Department  should  foreground  its 
employer best practices with a detailed description of how employers’ use of ADSs and ESAM systems 
exacerbates worker instability, precarity, stress, and inability to access bedrock protections and social 
insurance programs.  
Introduction  
Much of the public conversation around AI  and the workplace has focused on the potential  displacement 
of workers. A prominent AI pioneer at Google’s DeepMind even characterized AI systems as 
“fundamentally labor replacing tools” if left completely to the market to develop and implement.1 But 
beyond displacement, it is just as critical for policymakers to consider how employer use of AI systems 
and other  digital  tools  shape the nature of  work  and worker  experiences  on the job – and that these  issues 
are not confined to a nebulous “future of work.” For many workers, ADSs and ESAM systems, now 
undergirded by artificial intelligence, already impact their experience of recruitment, hiring, retention, 
supervision, promotion, discipline, termination, and beyond.  
AI, amplifying the digital technologies that came before it, enables unprecedented expansion in the 
volume and kinds of information collected about workers. Today, employers amass data from 
technologies such as security cameras, wearables, mobile  apps, computer software, and other surveillance 
tools. As tech companies push for the wide adoption of commercial and business -use AI, more and more 
employers  will have  the ability  to analyze  large  datasets  to make  broad  and at times  speculative  inferences 
about workers’ productivity, their future behavior, their interactions with other people and machines,  and 
more.2 
1 Lucas  Ropek,  DeepMind  Co-Founder:  AI is Fundamentally  a ‘Labor  Replacing  Tool,’  Gizmodo,  Jan. 19, 2024, 
https://gizmodo.com/deepmind -founder -ai-davos -mustafa -suleyman -openai -jobs-1851176340.  
2 See generally  Alexandra  Mateescu,  Data  & Society,  Explainer:  Challenging  Worker  Datafication,  Nov.  8, 2023, 
https://datasociety.net/library/challenging -worker -datafication/.  


3 These systems can enable corporations to mask control and avoid accountability, degrading working 
conditions and fostering racial income and wealth disparities. They can increase barriers to organizing  
and bargaining collectively, particularly in industries with disproportionately high percentages of Black 
and immigrant workers. Employers can use AI systems to discipline and terminate workers without 
transparency  or meaningful  processes  to contest  decisions,  increasing  precarity  and potentially  amplifying 
racial inequities. And ESAM and ADSs can facilitate unfair, unpredictable, and discriminatory pay.  
Algorithms and machine learning systems make inferences or decisions after being trained on large 
datasets, and rely on a continuous stream of new data in order to perform their functions for employers. 
But no matter the size of the dataset or the sophistication of the algorithm, these systems are still subject 
to the biases  of the technologists  who design  them,  the employers  who implement  them,  and the data that 
they are fed.3 These systems often present employers with the tantalizing prospect that a piece of new 
technology will allow them to optimize for efficiency and cut costs without any tradeoffs – based in a 
“received wisdom of the objectivity of automated decision -making.”4 But in fact, absent careful and 
sustained policymaking and oversight, the widespread adoption of these technologies will exacerbate 
existing challenges to building an equitable, good jobs economy and has the potential  to lower standards 
for workers across the board and lead our economy towards a race to the bottom.  
Employer best practices from the DOL can help shape norms around surveillance and data collection 
practices and draw the connection between ESAM and declining job quality. Best practices can help 
employers and workers better integrate new technologies into the workplace to complement — not 
replace  — worker  skills  and expertise,  minimize  transition  costs,  and avoid  disruption  to workers’  jobs 
and their job quality.5 
Corporations  use ESAM tools to sidestep accountability  while maintaining  control. 
Employers are increasingly turning to AI -powered ESAM systems to manage and  control workers, even 
as they deny  responsibility  for their wages  and working  conditions.  These  systems  empower  corporations 
to surveil workers more easily and intrusively, collect data for black -box algorithms, and utilize those 
algorithms to determine the terms and conditions of work. This growing reliance on automated systems 
enables  corporations to mask their significant  control  even as they strip workers of core  employment  and 
labor rights such as the right to minimum wage, overtime, or the right to organize or be free from 
discrimination.  
These tools have facilitated the growth of the gig economy, wherein corporations have falsely insisted 
that their workers  are independent  contractors  and prevented  them  from  accessing  bedrock  employment 
and labor law protections and social insurance programs. In fact, the experience of gig work is best 
described as it was by the Federal Trade Commission – as being subject to “an invisible, inscrutable  
3 Aaron  Rieke  & Miranda  Bogen,  Upturn,  Help  Wanted:  An Examination  of Hiring  Algorithms,  Equity,  and Bias,  Dec. 10, 2018, 
https://www.upturn.org/work/help -wanted . 
4 Ifeoma  Ajunwa,  An Audit  Imperative  for Automated  Hiring  Systems , 34 HARVARD  J. OF LAW  & TECH  622, 684 (Spring 
2021) (“automated decision -making cannot be fully disentangled from human decision -making”), 
https://jolt.law.harvard.edu/assets/articlePDFs/v34/5. -Ajunwa -An-Auditing -Imperative -for-Automated -HiringSystems.pdf . 
5 See, e.g., Alexandra  Mateescu  & Madeleine  Clare  Elish,  Data  & Society,  AI in Context:  The Labor  of Integrating  New 
Technologies, Jan. 30, 2019, https://datasociety.net/wp -content/uploads/2019/01/DataandSociety_AIinContext.pdf . 


4 boss.”6 Functionally, even in app -based systems like Uber where workers nominally have flexibility, 
corporations can effectively control where workers go, how long they work, and  what kinds of jobs they 
accept  – while  simultaneously  shifting  many  of the costs  and risks  of their operations  onto those  workers. 
Moreover, Black and Latinx workers are overrepresented  by 45 percent in the gig labor market, meaning 
that these practices further exacerbate inequities in the labor market.7 
Meanwhile, workers in industries where independent contractor misclassification is prevalent — 
including  workers  for corporations  that use ESAM  to control  the work — earn poverty  wages  and tend to 
make less  than counterparts  who are afforded  full “employee” status.  For example,  a 2019  analysis  by the 
Economic Policy Institute found that the average Uber driver’s wage was just $9.21 per hour after 
deducting fees and expenses, putting them in the lowest 10 percent of wage earners, and earning lower 
than the minimum wage in many states and in the three largest cities.8 Similarly, a national study of 
workers  hired  via a digital  labor platform  (including  delivery,  ride-hail, and domestic  workers)  found  that 
one in seven workers earned less than the federal hourly minimum wage, and 30 percent of digital 
platform  workers received a  Supplemental  Nutrition Assistance Program  benefit, compared to 15 percent 
of employees in comparable service -sector jobs.9 Most recently, a study of the economic costs of 
misclassification to workers in eleven industries with high volumes of misclassification found, for 
example, that “a typical home health aide, as an independent contractor, would lose out on as much as  
$9,529  per year  in income  and benefits  compared  with what  they would  have  earned  as an employee.”10 
Automated systems also make it easier for corporations to manage large workforces of subcontracted 
workers and evade accountability for their working conditions even as their software effectively controls 
the work. Amazon, for  example, uses subcontractor middle -managers to mediate its employment of some 
275,000 delivery drivers.11 Although directly employed by a “delivery service provider” (DSP), drivers 
are required to sign “Biometric consent” forms allowing Amazon’s constant surveillance and related 
performance control via AI -powered cameras as a condition of work.12 The e -commerce giant installs 
these  video  cameras  in the vans of the DSP drivers,  sometimes  using  inaccurate  data to penalize  drivers  or 
deny DSPs bonuses they may need to make vehicle repairs or enhance driver pay.13 
6 FED.  TRADE  COMM’N,  POLICY  STATEMENT  ON ENFORCEMENT  RELATED  TO GIG WORK  8 (Sept.  15, 2022),  
https://www.ftc.gov/system/files/ftc_gov/pdf/Matter%20No.%20P227600%20Gig%20Policy%20Statement.pdf . 
7 See U.S. Bureau  of Lab. Statistics, Electronically  Mediated  Work:  New Questions  in the Contingent  Worker  Supplement , U.S. 
DEP’T OF LAB., MONTHLY LABOR REVIEW (Sept. 2018), https://www.bls.gov/opub/mlr/2018/article/electronically - 
mediated -work -new-questions -in-the-contingent -worker -supplement.htm  (noting over -representation of Black and Latinx 
workers).  
8 Lawrence  Mishel,  Uber  and the Labor  Market:  Uber  Drivers’  Compensation,  Wages,  and the Scale  of Uber  and the Gig 
Economy , ECON. POL’Y INST. at 13 (May 2019), https://files.epi.org/pdf/145552.pdf . 
9 Ben Zipperer,  et al., National  Survey  of Gig Workers  Paints  a Picture  of Poor  Working  Conditions,  Low Pay, ECON.  POL’Y  
INST. (Jun.  2022),  https://www.epi.org/publication/gig -worker -survey/ . 
10 John  Schmitt,  et al., The Economic  Costs  of Worker  Misclassification,  ECON.  POL’Y  INST.  (Jan.  25, 2023), 
https://files.epi.org/uploads/The -economic -costs -of-worker -misclassification -1.pdf . 
11 See Anna Kramer, Amazon’s Entrepreneur Dream is Closer to a Nightmare for Many , PROTOCOL, Mar. 7, 2022, 
https://www.protocol.com/workplace/amazon -delivery -program -trap; see also How  Amazon’s  DSP Program  Has Created  $26 
Billion in Revenue for Owners , Amazon Corporate Website, Aug. 19, 2022, 
https://www.aboutamazon.com/news/transportation/how -amazons -dsp-program -has-created -26-billion -inrevenue -for-owners . 
12 James  Vincent,  Amazon  delivery  drivers  have  to consent  to AI surveillance  in their  vans or lose their  jobs, THE  VERGE,  Mar. 
24, 2021, https://www.theverge.com/2021/3/24/22347945/amazon -delivery -drivers -aisurveillance -cameras -vans-consent -form . 
13 See Lauren K. Gurley, Amazon’s AI Cameras Are Punishing Drivers for Mistakes They Didn’t Make , VICE 
MOTHERBOARD, Sept. 20, 2021, https://www.vice.com/en/article/88npjv/amazons -ai-cameras -arepunishing -drivers -for- 
mistakes -they-didnt -make . See also David  Hanley  & Sally  Hubbard,  Eyes  Everywhere:  Amazon’s  Surveillance  Infrastructure  and 
Revitalizing Worker Power , OPEN MARKETS (Sept. 2020),  


5  As tech vendors seek to sell their AI products to all kinds of employers for workforce management 
purposes, they are setting the conditions for businesses to escape accountability while making work less 
secure  and more  demanding.  Worker  displacement  is about  more  than just machines  replacing  workers – 
it’s also about workers in once -decent jobs being replaced by workers in ever more precarious, 
exploitative, and underpaid structures.  
 
ADSs and ESAM facilitate unfair, unpredictable,  and discriminatory  pay. 
 
Constant, minute surveillance and data collection enable employers to use ESAM systems to supervise, 
evaluate, and discipline workers beyond what they could previously accomplish through other, less 
invasive forms  of control.14 Because it  permits  an exacting  degree of  control  and scrutiny  over workers  in 
an opaque fashion, ESAM degrades job quality, worker dignity, and collective worker voice. AI  is likely 
to accelerate the use of automated scheduling systems, which algorithmically predict labor needs and 
match  staffing  needs  at an “optimal,” i.e.  labor -minimizing,  level.15 Already,  management  consultants  are 
positioning  AI to “solve  workforce -planning  challenges.”16 This trend  has played  out in retail,  hospitality, 
and food service industries, where employers have scheduled workers by algorithms that make decisions 
based on data like sales patterns, customer trends, worker performance, and local weather.17 Automated 
scheduling systems enable employers to adjust schedules on very short notice and to allocate shifts in 
smaller increments. For workers, this means increasingly unpredictable and erratic schedules, making it 
difficult for workers, particularly hourly and part -time, to plan for other aspects of their lives, such as 
childcare.18 People of color — especially women of color — working in retail and food service jobs are 
more likely to experience canceled shifts and on -call shifts than their white counterparts, even within the 
same company.19 
 
Algorithmic systems, including employers’ use of AI, disrupt work quality by undermining wage 
predictability.20 This is currently most  prevalent  in the app -based or gig industry, but  is likely to increase 
as employers deploy AI  in the service of algorithmically  managing workers. AI -driven systems also help 
corporations  use algorithms  to directly  set wages.  In many cases,  this can perpetuate  wage  discrimination 
based on biased customer reviews or by personalizing offers to individual workers – paying workers 
unequally for equal work.  
 
https://static1.squarespace.com/static/5e449c8c3ef68d752f3e70dc/t/5f4cffea23958d79eae1ab23/159888177  
2432/Amazon_Report_Final.pdf . 
14 Katherine  C. Kellogg,  Melissa  A. Valentine,  and Angéle  Christin, Algorithms  at Work:  The New Contested  Terrain  of Control , 
Academy of Management Annals 14, no. 1 (Jan. 2020): 366 –410, https://doi.org/10.5465/annals.2018.0174 . 
15 https://datasociety.net/wp -content/uploads/2019/02/DS_Algorithmic_Management_Explainer.pdf , citing  Steven  Greenhouse,  A 
Part-Time Life, as Hours Shrink and Shift for American Workers , New York Times (Oct. 27, 2012), 
https://www.nytimes.com/2012/10/28/business/a -part-time-life-as-hours -shrink -and-shift-for-american -workers.html . 
16 See, e.g., Jorge Amar, et al. , Smart Scheduling: How to Solve Workforce Planning Challenges with AI , Nov. 1, 2022, 
https://www.mckinsey.com/capabilities/operations/our -insights/smart -scheduling -how-to-solve -workforce -planning -challenges - 
with-ai. 
17 See, e.g., Kaye  Loggins,  Here’s  What  Happens  When  an Algorithm  Determines  Your  Work  Schedule , Motherboard:  Tech  by 
Vice,  Feb. 24, 2020,  https://www.vice.com/en/article/g5xwby/heres -what -happens -when -an-algorithm -determines -your-work - 
schedule . 
18 See, e.g., Alexandra  Mateescu  & Aiha  Nguyen,  Data  & Society,  Explainer:  Algorithmic  Management  in the Workplace,  10 
n.31, Feb. 2019, https://datasociety.net/wp -content/uploads/2019/02/DS_Algorithmic_Management_Explainer.pdf . 
19 National  Women’s  Law Center,  Collateral  Damage:  Scheduling  Challenges  for Workers  in Low-Paid  Jobs and Their 
Consequences , September 2023, https://nwlc.org/wp -content/uploads/2020/12/Collateral -Damage -9.14.23v1.pdf  
20 For more  on this important  and disturbing  trend,  see Veena  Dubal, On Algorithmic  Wage  Discrimination , 123 Colum.  L. Rev. 
7 (2023) https://columbialawreview.org/content/on -algorithmic -wage -discrimination/ . 


6 Because  app-based  employers  need  to scale worker availability  to customer demand — while at  the same 
time making  invisible  their own means  of control  over “independent  contractors” — companies  like Uber 
do not directly order workers to go somewhere at a specific time. Instead, these companies use wage 
manipulators to shift worker behavior. Such wage manipulators, which may lead to variable and 
unpredictable wages among workers, may  appear as bonuses available only to workers who meet certain 
metrics, “surge” pay that later disappears, and incentives to keep workers on the app.21 Drivers for Uber 
have reported deep dissatisfaction with their employer’s digital trickery.22 While these systems of 
algorithmic pay manipulation are most prevalent in the delivery and transportation sectors, they may 
spread as more industries seek to use new AI technologies to “gig out” their workforce to lower labor 
costs.23 
For example, ride -hail drivers for Uber and Lyft are paid according to black -box algorithms that are 
opaque to both workers and  consumers. The companies had originally set fares according to a fixed per - 
minute and per -mile rate, but there is now no relationship between customer fares and worker pay, 
allowing the companies to extract additional profit from surging customer fares and stagnating worker 
pay.24 Work as a ride -hail driver and on -demand work in general has as a result become increasingly 
unstable and unpredictable. Workers may make dramatically different amounts on different days for the 
same amount of work.25 And even more troublingly, algorithms can offer to pay two workers different 
amounts  for the same job.  In one test,  two Uber drivers  sitting  next to each other logged  onto the app  and 
watched  as they were presented  with offers  to take on  identical  trips at the same time for  different  fares.26 
It seems likely that companies like Uber are “offer[ing] vulnerable workers lower wages based on their 
willingness to accept work at lower prices.”27 In other words, the implementation of increasingly 
sophisticated and AI -backed ESAM systems threatens to pave the way for a new labor management 
practice: using individualized worker data to identify exactly the wage at which a given worker will 
accept work, and then paying them that amount. The upshot is that poor workers, Black workers, 
immigrant workers, and women workers may be paid less for doing equal work.  
These  practices  increasingly  impact  industries  well beyond  ride-hailing.  As companies  in industries  like 
retail, food service,  and medical care adopt the labor management technologies pioneered by Uber, the 
practice of algorithmic wage discrimination is spreading.28 For example, a company that has branded 
itself “Uber for Hospitals” has developed AI staffing software that uses “smart technology” to allocate 
work tasks and to judge the performance of porters, nurses, and nurse practitioners. The technology  
21 Id. 
22 Id. at 33 -42. 
23 See, e.g., Lauren Hilgers, When Your Boss Is an App , N.Y. Times Magazine (Apr. 13, 2023), 
https://www.nytimes.com/2023/04/13/magazine/gig -jobs-apps.html ; E. Tammy  Kim,  The Gig Economy  Is Coming  for Your  Job, 
N.Y.  Times  (Jan.  10, 2020),  https://www.nytimes.com/2020/01/10/opinion/sunday/gig -economy -unemployment - 
automation.html . 
24 Faiz Siddiqui, You May Be Paying  More  for Uber,  but Drivers  Aren’t  Getting  their  Cut of the Fare  Hike , WASH.  POST,  Jun. 
10, 2021, https://themarkup.org/working -for-an-algorithm/2022/03/01/secretive -algorithmwill -now-determine -uber-driver -pay- 
in-many -cities . 
25 See Dubal,  supra  note 21. 
26 2 Uber  Drivers:  Same  Requests  DIFFERENT  PAY!  You Won’t  Believe  This!,  THE  RIDESHARE  GUY  YOUTUBE 
CHANNEL (Mar. 1, 2023), https://www.youtube.com/watch?v=UADTiL3S67I . 
27 Dubal,  supra  note 21. 
28 See, e.g., Lauren  K. Gurley,  Target’s  Delivery  App Workers  to Be Paid  by a Blackbox  Algorithm  Nationwide , VICE,  Sept.  11, 
2020, available at https://www.vice.com/en/article/qj49jv/targets -delivery -app-workers -to-be-paidby -a-blackbox -algorith . See 
also E. Tammy Kim, supra note 24.  


7  company’s “performance analysis” is then used to determine the pay for these healthcare workers.29 
Absent strong policy interventions, workers across the economy could be paid according to opaque and 
personalized  algorithms  that obscure  systemic  wage  discrimination  along  protected  lines,  such as race and 
gender.30 
 
The intensity of automated  surveillance  creates additional  stress on the job and decreased  power 
for workers.  
 
The rise of data -driven AI  systems is increasing the  economic value employers can derive  from  mass  data 
collection. This means that data -extractive practices, like  near-constant electronic surveillance, are  almost 
certain to become more invasive and more prevalent as more employers deploy AI. The DOL should  
focus  on these  underlying  management  practices,  which  are already  known  to reduce  job quality  and harm 
workers.  
 
Surveillance  — essentially  the practice  of employers  gaining  informational  advantages  over workers — is 
most prevalent in low -wage industries where managers can easily measure and quantify workers’ tasks.31 
Such surveillance is often hidden from workers. While some workers may expect their employer to 
observe their performance through  a traditional camera, a  multitude of opaque data sources now drive AI 
and ADSs. Modern covert surveillance systems, such as the use of employer -required apps on workers’ 
personal phones, can monitor workers without their knowledge.32 And, of course, app -based workers are 
subject to constant algorithmic monitoring baked into the structure of their work.  
 
Increasingly, employers are extending ESAM to jobs where work is not as easily quantifiable. In white - 
collar jobs, surveillance may occur through keystroke and mouse monitoring, productivity scores, and 
photos taken on workers’ computer webcams.33 Since the COVID -19 pandemic, as more workers began 
working  from  home,  employers  are applying  such remote  surveillance to  workers’  home  activity.  Because 
these tools cannot account for work that cannot easily be quantified, such as ideation or contemplation, 
workers feel pressure to perform to metrics rather than their job responsibilities.34 
 
ESAM is also often used to discipline or fire workers, frequently resulting in decreased disciplinary 
transparency and limiting workers’ access to human managers. For example, Amazon has “replaced its 
middle  management  and human  resources  workers  with artificial  intelligence  to determine  when  a worker 
has outlived  their usefulness  and needs  to be  let go. There  is no human  to appeal  to.”35 Workers  have  also 
 
 
 
29 See Nicky Godding, Oxford Tech Raises £9 Million for ‘Uber for Hospitals’ AI Platform , BUSINESS INNOVATION 
MAGAZINE,  May 21, 2020,  https://www.businessinnovationmag.co.uk/oxford -tech-raises -9-million -foruber -for-hospitals -ai- 
platform/ . 
30 Zephyr  Teachout,  Algorithmic  Personalized  Wages , Politics  & Society,  51(3),  436-458 
(2023),  https://doi.org/10.1177/00323292231183828 . 
31 Aiha  Nguyen,  The Constant  Boss:  Work  Under  Digital  Surveillance , Data  & Society  (May  2021), 
https://datasociety.net/library/the -constant -boss/ . 
32 Id. 
33 Jodi Kantor  & Arya  Sundaram,  The Rise of the Worker  Productivity  Score , N.Y.  Times  (Aug.  14, 2022), 
https://www.nytimes.com/interactive/2022/08/14/business/worker -productivity -tracking.html . 
34 Id. 
35 Jessa  Crispin,  Welcome  to Dystopia:  Getting  Fired  from  Your  Job as an Amazon  Worker  by an App, THE  GUARDIAN,  July 5, 
2021 https://www.theguardian.com/commentisfree/2021/jul/05/amazon -worker -fired -appdystopia . 


8 reported  having  little recourse  when  automated  systems  have  incorrectly  or inaccurately  disciplined 
them.36 
These systems impose second -to-second monitoring of workers’ actions, meaning that if the system 
detects and records, for example, a momentary pause on the part of a worker, it can give employers the 
option  of considering  the pause an  infraction  leading  to discipline and  termination – even  if the pause was 
due to an event out of the worker’s control. In this way, these systems can greatly increase the volume of 
potential infractions and disciplinary actions, magnifying the power imbalance between workers and 
management, and making it difficult for workers to contest unfair, discriminatory, or retaliatory 
disciplinary action or discharges.37 And increased adoption  of ADSs may  also amplify existing biases and 
inequities in workplace discipline. Employers scrutinize Black workers more than other workers and are 
less likely to give Black workers a chance to improve before terminating them.38 AI-driven ESAM 
systems, subject to the biases in their design and training, may exacerbate those dynamics by providing 
employers additional inexpensive and non -transparent means to engage in that kind of scrutiny. While on 
the surface these systems can lend the appearance of fairness in workplace discipline by taking human 
managers out of the equation, in reality these systems often have the effect of making these processes 
more opaque,  arbitrary,  and unfair.  As discussed  above,  maximizing  the volume of  data collected  does not 
necessarily result in more reasonable or equitable outcomes.  
ESAM often raises  barriers to organizing  and bargaining  collectively.  
As discussed above, black box algorithms obscure the precise mechanisms of data collection, analysis, 
and decision -making, exacerbating power imbalances between workers and bosses. This opacity allows 
employers  to leverage  even  greater  control  over workers.  With  little information  about  how decisions  are 
made, workers have less power to speak up for themselves, challenge decisions, and identify systemic 
harms in order to take collective action.  
National Labor Relations Board (NLRB) General Counsel Jennifer Abruzzo has cautioned that ESAM 
can infringe upon workers’ Section 7 rights under the National Labor Relations Act  (NLRA). She noted 
in particular that “the potential for omnipresent surveillance and other algorithmic management tools to 
interfere  with the exercise  of Section  7 rights  by significantly  impairing  or negating  employees’  ability  to 
engage in protected  activity and keep that activity confidential from their employer, if they so choose.”39 
Corporations are already taking advantage of these tools to monitor and disrupt protected concerted 
activity.  Companies  monitor  workers’  online  conversations,  track  social  media  posts,  and even  analyze  
36 See, e.g. , Lauren K. Gurley, Amazon’s AI Cameras Are Punishing Drivers for Mistakes They Didn’t Make , VICE 
MOTHERBOARD,  Sept.  20, 2021,  https://www.vice.com/en/article/88npjv/amazons -ai-cameras -are-punishingdrivers -for- 
mistakes -they-didnt -make  
37 See, e.g. , Amazon Issued 13,000 Disciplinary Notices at a Single U.S. Warehouse , CNBC, July 12, 2022, 
https://www.cnbc.com/2022/07/12/amazon -issued -13000 -disciplinary -notices -at-a-single -us-warehouse.html.  
38 Costas  Cavounidis  & Kevin  Lang,  Discrimination  and Worker  Evaluation,  NBER  WORKING  PAPERS  (Oct.  2015), 
https://www.nber.org/papers/w21612 . 
39 Office  of the General  Counsel,  Memorandum  GC 23—2, Electronic  Monitoring  and Algorithmic  Management  of Employees 
Interfering  with the Exercise  of Section  7 Rights , NAT’L.  LAB.  REL.  BD.,  Oct. 2022,  https://www.nlrb.gov/guidance/memos - 
research/general -counsel -memos . 


9  emails and worker communications to identify “pre -union activity.”40 For example, Amazon -owned 
Whole Foods used a combination of data concerning the poverty levels of workers’ neighborhoods, an 
index  to measure  the potential  for racial  solidarity,  and measures  of employee  “loyalty”  to identify  stores 
where workers may support forming a union.”41 These systems can also be used to discourage physical 
proximity of workers  and therefore chill concerted activity. GPS trackers that  allow employers to assess 
worker movements through a warehouse or a janitor’s progress in cleaning an office building can also 
reveal whether groups of workers are exercising their right to gather to discuss conditions or potential 
unionization.  High  automated  productivity  quotas  may discourage  workers  from  taking  legally  permitted 
breaks where they could have encountered one another in a break room or a restroom. In other cases, 
worker awareness of corporate surveillance may compel organizing efforts to remain closely held, 
fostering a sense of wrongdoing and chilling efforts to exercise legal rights. Combined with the ease at 
which corporations can find infractions to justify discipline and termination, these systems also offer 
companies an avenue to target and retaliate against union leaders and workers engaging in protected 
activity.  
 
Automated systems also facilitate the ability of corporations to maintain control of their workers while 
distancing themselves from accountability, including through worker organizing and collective 
bargaining. As discussed above, these systems simplify the transfer of work from directly employed 
workers to gig workers, “independent contractors,” and subcontractors. Gig workers, if misclassified as 
independent contractors, cannot access the protections of the NLRA. And corporations may deny their 
joint employer obligations to subcontracted workers who attempt to organize. When workers at an 
Amazon -affiliated DSP gained voluntary recognition from their direct employer, Amazon responded by 
announcing  its intention  to cut its contract  with the subcontractor,  effectively  terminating  the employment 
of the unionized drivers because they had exercised their Section 7 rights.42 
 
Conclusion  
 
AI-augmented  automated  systems  in the workplace  represent  a new frontier,  with corporations  able to use 
these tools to collect and weaponize huge amounts of data to make decisions that impact their workers.  
Sometimes, and especially by their developers, these systems are  framed as  an opportunity to reduce bias 
and increase  fairness.  In practice,  though,  the systems  are subject  to many  biases.  And we have  often  seen 
employers use AI and other digital tools to push their workers into more underpaid, more stressful, and 
more precarious work structures, sidestepping accountability, and depriving workers of access to labor 
and employment protections and social insurance programs.  
 
While  AI-driven  technologies  are new,  many  of the issues  raised  are not. Worker  instability  and precarity, 
exploitative and underpaid work structures, and union -busting have been features of our economy for 
generations. As the DOL considers principles and best practices as well as other actions around AI, we  
 
40 See, e.g. , Jo Constanz, ‘They Were Spying on Us’: Amazon, Walmart Use Surveillance Technology to Bust Unions , 
NEWSWEEK,  Dec. 13, 2021,  https://www.newsweek.com/they -were -spying -us-amazon -walmart -use-surveillancetechnology - 
bust-unions -1658603 . 
41 See Daniel  A. Hanley  and Sally  Hubbard,  Eyes  Everywhere:  Amazon’s  Surveillance  Infrastructure  and Revitalizing  Worker 
Power, OPEN MARKETS (Sept. 2020),  
https://static1.squarespace.com/static/5e449c8c3ef68d752f3e70dc/t/5f4cffea23958d79eae1ab23/159888177 
2432/Amazon_Report_Final.pdf.  
42 Luis Feliz  Leon,  Teamsters  Begin  Major  Amazon  Fight , AMERICAN  PROSPECT,  May 4, 2023, 
https://prospect.org/labor/2023 -05-04-teamsters -begin -major -amazon -fight/ . 


10 urge the Department to consider how broader solutions can play a role. Employee misclassification, 
corporate  evasion  of joint employer  obligations,  a lack of worker  voice,  occupational  segregation,  and 
widespread at -will employment create many of the conditions for the misuse of automated systems.  
Comprehensively  addressing  these  and other  issues  will go a long way towards  building  a good  jobs 
economy for all.  
We commend the administration for its focus on this issue and appreciate the opportunity to share our 
views.  With  any questions,  please reach  out to Brian  Chen  (Data &  Society)  at 
Josh Boxerman (NELP) at  and Mitra Ebadolahi (Upturn) at 
Sincerely,  
Data  & Society  
National  Employment  Law Project  
Upturn  
CC: Muneer  Ahmad  
Diana Boesch 
Raj Nayak 
Patrick  Oakford 
Olivia Rogal 
Valeria Treves  


