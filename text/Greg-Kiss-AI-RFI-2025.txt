From: Greg Kiss
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Monday, March 17, 2025 9:18:29 AM
CAUTION: This email originated from outside your organization. Exercise caution when opening
attachments or clicking links, especially from unknown senders.
Elon Musk has consistently given his estimate of the chances that unregulated AI that
is smarter than all of humanity combined will literally exterminate life on earth as 20%.A wide array of experts give similar probabilities, going all the way up to 99%. I urgeDonald Trump to become the most important leader in world history by addressingthe most serious threat our species has ever faced, as only someone with hisboldness and decisiveness could. China should be contacted with a proposition tomutually slow progress on frontier AI systems. With their disadvantage, they will bemotivated to accept. Progress should be halted or slowed until Musk is ready with hisNeuralink to control strong AI,
 or at least until more work on  safety can be done. This
will also mitigate the serious risks of catastrophic widespread job loss. This matter isof the absolute utmost importance.
All e-mails to and from this account are for NITRD official use only and subject to certain disclosure
requirements.If you have received this e-mail in error, we ask that you notify the sender and delete it immediately.


