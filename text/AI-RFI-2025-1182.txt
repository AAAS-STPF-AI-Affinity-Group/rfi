PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 87-hh6d-9v64
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1182
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  SIFMA
General Comment
See attached file(s)
Attachments
SIFMA AI Response National Science Foundation March 13 2025 final


New York 120 Broadway, 35th Floor | New York, NY 10271  
Washington 1099 New York Avenue, NW, 6th Floor | Washington, DC 20001  
www.sifma.org  
March 13, 2025  
Submitted via federalregister.gov  
AI Action Plan  
Attn: Faisal D'Souza  
NCO  
National Science Foundation  
2415 Eisenhower Ave . 
Alexandria, VA 22314, USA  
Re: Request for Information on the Development of an Artificial Intelligence (AI) 
Action Plan  
Dear Mr. D’Souza : 
The Securities Industry and Financial Markets Association and its Asset Management Group 
(collectively , “SIFMA”)1 welcome the opportunity to respond  to the request for information on the 
Office of Science and Technology Policy (OSTP)  AI Action Plan .2  SIFMA believes  AI has and will 
continue to offer many benefits to US investors, financial markets, and financial institutions , but the 
impacts of unnecessary la ws and regulation  on AI will have an irreversible negative impact  on the 
competitiveness of US financial markets .  
1 SIFMA is the leading trade association for broker -dealers, investment banks, and asset managers operating in the U.S. 
and global capital markets.  On behalf of our members, we advocate for legislation, regulation, and business policy 
affecting retail and  institutional investors, equity and fixed income markets, and related products and services.  We serve 
as an industry coordinating  body to promote fair and orderly markets, informed regulatory compliance, and efficient 
market operations and resiliency.  We also provide a forum for industry policy and professional development. SIFMA, 
with offices in New York and Washington,  D.C., is the U.S. regional member of the Global Financial Markets 
Association (GFMA).  
SIFMA’s Asset Management Group ( “SIFMA AMG ”) brings the asset management community together to provide 
views on U.S. and global policy and to create industry best practices . SIFMA AMG’s members represent U.S. and global 
asset management firms that manage more than 50% of global assets under management.  The clients of SIFMA AMG 
member firms include, among others, tens of millions of individual investors, registered investment companies, 
endowments, public and private pension funds, UCITS and private funds such as hedge funds and private equity funds . 
For more information, visit http://www.sifma.org/amg . 
2 Request for Information on the Development of an Artificial Intelligence (AI) Action Plan
https://www.federalregister.gov/documents/2025/02/06/2025 -02305/request -for-information -on-the-development -
of-an-artificial -intelligence -ai-action -plan.


2 Any new l aw and regulation  should be designed to address  and minimize  tangible risks that 
are not otherwise covered by existing requirements . To date, there have been no identified  risks 
associated with the u se of AI by financial institutions that are not otherwise covered by existing laws 
and regulations. Until such risks present themselves,  any new law or rule should be carefully 
considered so as to avoid unnecessarily stifl ing the development of AI technology .  
As such, SIFMA is deeply concerned that the proliferation of state legislation and regulations 
purporting to govern the development and use of AI  will severely inhibit SIFMA members ’ (1) 
continued  use of AI applications that have been in use for decades (including non -generative AI 
applications) , and (2 ) ability to develop and/or deploy new AI technology or  new use cases for AI. 
As we have clearly seen for privacy  laws, conflicting state laws can create obstacles  to responsible 
technology development in the United States. Accordingly, SIFMA supports federal legislation that 
would preempt state AI laws.  
SIFMA’s white paper, Promoting Investor Success, Industry Innovation, and Efficiency with AI , offers 
useful insights into the challenges  of regulating any specific technology  particularly AI  and other 
emerging technologies . A copy of this white paper is attached and can also be found on our 
website.3 
* * * 
SIFMA would be pleased to discuss  the views  expressed here or in the attached  white paper 
if that would assist your deliberations  on this issue . Please feel free to contact us at 
 or  if you would like to discuss these issues further.  
Since rely, 
Melissa MacGregor  
Meliss a MacGregor   
Deputy General Counsel & Corporate Secretary  
SIFMA   
 Kevin Ehrlich  
Kevin Ehrlich  
Managing Director & Associate General Counsel  
SIFMA AMG  
Attachment : SIFMA White Paper : Promoting Investor Success, Industry Innovation, and Efficiency with AI  
3 SIFMA White Paper available  at https://www.sifma.org/wp -content/uploads/2024/09/AI -Whitepaper -Promoting -
Investor -Success -Industry -Innovation -and-Efficiency -with-AI.pdf   


Page | 1 
SIFMA & SIFMA Asset Management Group 
Promoting Investor Success, Industry Innovation, 
and Efficiency with AI 
September 2024 


Page | 2 SIFMA is the leading trade association for broker-dealers, investment banks, and asset managers operating in the U.S. 
and global capital markets. On behalf of our members, we advocate for legislation, regulation, and business policy 
affecting retail and institutional investors, equity and fixed income markets, and related products and services. We serve 
as an industry coordinating body to promote fair and orderly markets, informed regulatory compliance, and efficient 
market operations and resiliency. We also provide a forum for industry policy and professional development. SIFMA, with 
offices in New York and Washington, D.C., is the U.S. regional member of the Global Financial Markets Association 
(GFMA). For more information, visit http://www.sifma.org. 
SIFMA’s As set Management Group (SIFMA AMG) brings the asset management community together to provide views on 
U.S. and global policy and to create industry best practices. SIFMA AMG’s members represent U.S. and global asset 
management firms that manage more than 50% of global assets under management. The clients of SIFMA AMG member 
firms include, among others, tens of millions of individual investors, registered investment companies, endowments, public 
and private pension funds, UCITS and private funds such as hedge funds and private equity funds. For more information, 
visit http://www.sifma.org/amg. 
This report is subject to the Terms of Use applicable to SIFMA’s website, available at http://www.sifma.org/legal. 
Copyright © 2022 


Page | 3 Contents 
Executive Summary ................................................................................................................................................................ 4  
Background ............................................................................................................................................................................. 5  
Encouraging AI Innovation Benefits Market Participants ........................................................................................................ 5  
Existing Laws and Regulations Address the Use of AI in the Financial Services Industry ..................................................... 6  
It Is Unnecessary to Develop a Specific Definition of “AI” ...................................................................................................... 7  
Firms’ Internal Risk-Management Frameworks Appropriately Address the Use of AI ................................................................. 8  
Policymakers and Regulators Should Assess Whether AI Poses Novel Risks Not Addressed by Existing Governance 
Frameworks ............................................................................................................................................................................. 8  
Fragmented AI Regulation Risks Creating Compliance Challenges and Stifling Innovation in the Financial Services 
Industry .................................................................................................................................................................................... 9  
Policymakers and Regulators Should Consider Strategies for Addressing Potential Gaps in Existing Laws and Regulations 
Related to AI.......................................................................................................................................................................... 10  
Conclusion ............................................................................................................................................................................. 11  
Appendix 1:  Existing Technology-Neutral Functional Policy Areas Applicable to AI ........................................................... 12  


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
   
Page | 4  
 Executive Summary 
The development and adoption of artificial intelligence (“AI”) in the financial services industry has garnered significant 
attention in recent years.  As federal and state policymakers and regulators continue to assess the potential impact of AI 
in the financial services industry, the Securities Industry and Financial Markets Association and its Asset Management 
Group (collectively, “SIFMA”) have developed this white paper to highlight key points that it believes will be useful to 
consider as part of the ongoing discussions related to the use of AI in the industry.   
These key points can be summarized as follows: 
 Laws and regulations governing the financial services industry should remain focused on addressing activities and 
outcomes.  This technology-neutral approach encourages innovation within the industry without sacrificing the safety 
of financial markets. 
 Existing laws and regulations governing the financial services industry have proven effective in addressing the use of 
emerging technologies in the industry, including AI.   
 There is no need to adopt a precise definition of AI at this time because AI is an evolving technology, and adopting a 
technology-neutral approach to the use of AI will likely render a definition unnecessary.     
 Policymakers and regulators should collaborate with firms in the financial services industry to understand the uses of 
AI and its related benefits and risks.  Additional regulatory action should only be considered if the existing laws and 
regulations do not address novel risks that are identified.   
 Any regulatory action should be flexible enough to continuously adapt to evolving technology.  Prescriptive rules can 
lead to inconsistent regulations across jurisdictions and will also deter innovation that could benefit all market 
participants, including investors.   
 Existing laws and regulations recognize that management at financial services firms are best positioned to identify 
emerging risks and the impact they could pose to their businesses.  Firms should continue to retain this flexibility 
when determining how to address the use of AI and other emerging technologies. 
 Policymakers should assess how other existing areas of law and regulation apply to the use of AI in the financial 
services industry and consider strategies for mitigating potential risks, including in the areas of federal data privacy 
legislation and copyright ownership.  
  


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 5 Background 
The use of AI in the financial services industry is not new—AI and related technologies have been used by market 
participants for many years to improve efficiency and accuracy in a variety of tasks.  But advancements in AI, particularly 
in generative AI, have heightened interest and concerns about the use of such technology in the financial services 
industry.  Although these developments warrant consideration, the existing legal and regulatory frameworks that govern 
the financial services industry are designed to be risk-based, technology neutral, and flexible enough to address the use 
of AI and other emerging technologies.  These existing laws and regulations are intended to apply to activities and 
outcomes regardless of the specific technology used.  In turn, financial services firms have established risk-management 
frameworks to ensure compliance with these laws and regulations that are continuously reviewed and updated to address 
emerging technologies, including AI.   
Although there has been an increased focus on AI by policymakers and regulators globally, it is critical to avoid hasty 
reactions that will needlessly deter innovation.  Future action should only be considered if novel risks are identified that 
these frameworks do not address.  Accordingly, a risk-based and technology-neutral approach is warranted for any 
regulation in the financial services industry.   
Encouraging AI Innovation Benefits Market Participants 
AI and related technologies are already used by firms in the financial services industry across a variety of applications, 
including fraud detection, data analytics, risk management, investment analysis, compliance, and cybersecurity.  This has 
resulted in significant benefits to both financial services firms and investors.  For example, financial services firms are 
using AI to more efficiently and accurately analyze large volumes of data, predict market trends, identify risks, and devise 
optimal investment strategies.  These uses of AI can benefit investors by providing, among other things, expanded access 
to certain financial services and products, lower costs, and enhanced customer service and risk management 
capabilities.1  
Based on the capabilities it currently offers—and those that have yet to be recognized—AI has the potential to further 
transform the financial services industry and yield widespread benefits to investors.  To maximize this potential, any legal 
or regulatory response to AI should be aimed at facilitating the responsible use of AI.  As described in more detail below, 
while technological advancements can be accompanied by potential risks, those risks can be appropriately addressed 
without stifling innovation.  1 See Written Statement of Daniel S. Gorfine to the U.S. Senate Committee on Banking, Housing, and Urban Affairs, Artificial 
Intelligence in Financial Services , at 2-4 (Sept. 20, 2023), https://www.banking.senate.gov/download/gorfine-testimony-9-20-23 
(“Gorfine Testimony”); see also FINRA, Artificial Intelligence (AI) in the Securities Industry: Key Challenges and Regulatory 
Considerations (June 2020), https://www.finra.org/rules-guidance/key-topics/fintech/report/artificial-intelligence-in-the-securities-
industry/key-challenges (highlighting potential benefits AI-based applications offer to both investors and firms).  


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 6 Existing Laws and Regulations Address the Use of AI in the Financial Services 
Industry 
Existing legal and regulatory frameworks apply to the use of AI in the financial services industry.  Accordingly, any 
additional regulatory action should only be considered if gaps are identified that these existing frameworks cannot 
address.2    
While policymakers and regulators have developed laws and regulations in response to technological developments in the 
financial services industry, these frameworks generally apply to conduct and activities, rather than the technology itself.  
Such technology-neutral frameworks have been effective in ensuring the responsible adoption and use of emerging 
technologies.  Although all emerging technologies must be evaluated for novel risks, there does not appear to be anything 
inherently different about the use of AI that would make these frameworks inadequate.  Policymakers should, therefore, 
closely examine how existing laws and regulations apply to and can continue to evolve to address unique risks that may 
arise from the use of AI in the financial services industry before considering further legislation or regulation. 
As seen in attached Appendix 1, a wide range of existing legal and regulatory frameworks that already apply to financial 
services firms would also apply to their use of AI.  These frameworks apply to areas such as market and investor 
protection, governance structures, risk monitoring and management, cybersecurity, model risk management, third-party 
risk management, data privacy, and operational resilience and business continuity.3  These existing frameworks are 
generally designed with the flexibility to evolve to apply to the use of emerging technologies like AI and to mitigate 
associated risks that may apply in the financial services industry, regardless of the technology used.4  In addition to laws 
2 See, e.g. , National Institute of Standards and Technology, Artificial Intelligence Risk Management Framework (AI RMF 1.0) (Jan. 
2023), https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf (providing an AI risk management framework to “to offer a resource to the 
organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustworthy and 
responsible development and use of AI systems”) (“NIST AI RMF 1.0”). 
3 See, e.g. , Gorfine Testimony, supra note 1, at 6-8 (citing the applicability to AI of the Equal Credit Opportunity Act, the Truth in 
Lending Act, the Fair Housing Act, the Fair Credit Reporting Act, Regulation Best Interest, SEC and FINRA marketing rules, and more); 
Remarks by Under Secretary for Domestic Finance Nellie Liang, Artificial Intelligence in Finance  (May 22, 2024), 
https://home.treasury.gov/news/press-releases/jy2383 (citing the applicability to AI of model risk management and third-party risk 
management frameworks, as well as consumer protection and securities laws) (“Liang Remarks”); see also FINRA, Frequently Asked 
Questions About Advertising Regulation , FAQ D.8.1 (posted May 10, 2024), https://www.finra.org/rules-
guidance/guidance/faqs/advertising-regulation#d8 (“Firms are responsible for their communications, regardless of whether they are 
generated by a human or AI technology.  Accordingly, firms must ensure that AI-generated communications they distribute or make 
available comply with applicable federal securities laws and regulations and FINRA rules.”).  
4 See, e.g. , U.S. Department of Treasury, Managing Artificial Intelligence-Specific Cybersecurity Risks in the Financial Services Sector , 
at 21 (2024), https://home.treasury.gov/system/files/136/Managing-Artificial-Intelligence-Specific-Cybersecurity-Risks-In-The-Financial-
Services-Sector.pdf (“Financial regulatory agencies generally do not issue regulations or guidance on specific technologies, but instead 
address the importance of effective risk management, governance, and controls regarding the use of technology, including AI, and the 
business activities that those technologies support.”) (“Treasury AI Remarks”); CFTC, Statement of Commissioner Kristin N. Johnson: 
Articulating an Agenda for Regulating AI  (May 2024), https://www.cftc.gov/PressRoom/SpeechesTestimony/johnsonstatement050224 


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 7 and regulations, financial regulators issue guidance designed to ensure the responsible adoption of new technology, 
which would also be applicable to AI use.5   
Existing enforcement mechanisms have also proven capable of addressing conduct related to the use of AI.  For example, 
the SEC has charged investment advisers in so-called “AI-washing” cases for making false and misleading statements 
about their alleged use of AI in connection with providing investment advice.6  Such cases make clear that existing laws 
and regulations provide regulators with the necessary tools to address AI-related risks and enforce against violations. 
Criminal laws also allow law enforcement and regulators to pursue wrongdoers regardless of the technology that they use 
to carry out scams, frauds, and thefts. 
It Is Unnecessary to Develop a Specific Definition of “AI” 
SIFMA does not believe that any regulatory approach requires the adoption of a precise definition of AI.  As an initial 
matter, any definition would likely become outdated in the near term due to the evolving nature of technology.  If a 
definition of AI is considered, SIFMA encourages the adoption of a broadly accepted definition developed by a standard-
setting body.7  Ultimately, however, any definition of AI that policymakers or regulators choose to adopt should not make a 
difference, because existing laws and regulations apply to any technology that is used to engage in regulated conduct in 
the financial services industry.   
(stating that the CFTC’s “approach to mitigating the risks associated with the use of AI in our markets should be principles-based, 
retaining adaptability and remaining technology neutral”); FINRA Reg. Notice 24-09,  FINRA Reminds Members of Regulatory 
Obligations When Using Generative Artificial Intelligence and Large Language Models , (June 27, 2024) , https://www.finra.org/rules-
guidance/notices/24-09 (“FINRA intends for its rules and guidance to be technologically neutral and to function dynamically with 
evolutions in technology and member firms’ processes.  The rules apply when member firms use AI, including Gen AI or similar 
technologies, in the course of their business, just as they apply when member firms use any other technology or tool.”) (“FINRA AI Reg 
Notice”). 
5 See, e.g. , Supervisory Guidance on Model Risk Management , Federal Reserve SR Letter 11-7, OCC Bulletin 2011-12, and FDIC FIL-
22-2017 (“MRM Guidance”); see also OCC, Comptroller’s Handbook: Model Risk Management Version 1.0  (Aug. 2021),
https://www.occ.treas.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/pub-ch-model-
risk.pdf (adopting updated MRM Guidance and specifically addressing AI); FINRA AI Reg Notice, supra note 4.
6 See SEC, SEC Charges Two Investment Advisers with Making False and Misleading Statements About Their Use of Artificial 
Intelligence  (Mar. 18, 2024), https://www.sec.gov/newsroom/press-releases/2024-36. 
7 See NIST AI RMF 1.0, supra note 2 (defining an “AI system” as “an engineered or machine-based system that can, for a given set of 
objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments”); Executive 
Office of the President, Executive Order 14110:  Safe, Secure, And Trustworthy Development And Use Of Artificial Intelligence , 88 FR 
75191 (Oct. 30, 2023), https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-andtrustworthy-development-
and-use-of-artificial-intelligence (adopting a similar definition of AI). 


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 8 Firms’ Internal Risk-Management Frameworks Appropriately Address the Use of AI 
To ensure that the use of emerging technologies complies with existing regulatory frameworks described above, firms in 
the financial services industry have developed internal risk-management frameworks.8  Firms continuously review and 
update these frameworks to address the use of emerging technologies, including AI.  As a result, the frameworks 
effectively address many of the risks often associated with the use of AI.9 
Firms’ internal risk-management frameworks provide strong accountability measures to reduce unnecessary risk, while 
also providing room for innovation, by requiring firms to: (1) identify specific risks a company should consider when 
assessing level of risk posed by the activity; (2) consider risk-mitigation controls and processes; and (3) identify activities 
that carry unacceptable risks and should not be pursued. 
The effectiveness of this type of tailored-yet-flexible approach has been illustrated by how financial services firms have 
approached the adoption of AI.  As regulators themselves have recognized, financial services firms have generally been 
proceeding cautiously in pursuing the use of AI, especially for higher-risk use cases.10  By establishing governance 
structures around the use of AI (including testing and controls), financial services firms have shown that they are 
approaching the use of AI in accordance with their existing risk-management frameworks. 
A continued reliance on this risk-based approach provides the necessary flexibility to balance the potential benefits of 
using AI with the relevant risks.     
Policymakers and Regulators Should Assess Whether AI Poses Novel Risks Not 
Addressed by Existing Governance Frameworks 
Laws and regulations should not be based on speculative or hypothetical future risks.  Instead, policymakers and 
regulators should carefully evaluate how financial services firms are using AI and if those uses pose any novel risks that 
are not addressed by the existing legal and regulatory frameworks.   
To do this, policymakers and financial regulators should work collaboratively with financial services firms—and amongst 
themselves—to understand the uses, benefits, and potential risks posed by the use of AI in the financial services industry. 
This approach would allow firms and regulators to identify new fact patterns that may present novel risks to the industry.  
Only if such novel risks are identified should potential regulatory action be considered, which could include financial 
8 See MRM Guidance, supra note 5. 
9 See Appendix 1. 
10 See, e.g. , Treasury AI Remarks, supra note 4, at 2 (“[F]inancial institutions appear to be moving slowly in adopting expansive use of 
emerging AI technologies.”); see also Liang Remarks, supra note 3 (“[F]irms are pursuing a wide range of strategies for how to use new 
AI tools.  They appear to be proceeding cautiously, especially when experimenting with GenAI, and at the same time making changes 
to internal governance.”). 


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 9 regulators providing further guidance on regulatory expectations.11  Otherwise, policymakers and regulators risk stifling 
innovation and deterring the adoption of new technologies in the industry.    
By engaging in ongoing collaboration with the financial services industry, policymakers and regulators can balance the 
need for safeguards with the importance of creating an environment where financial services firms are confident in their 
development and adoption of AI or other emerging technologies.12   
Fragmented AI Regulation Risks Creating Compliance Challenges and Stifling 
Innovation in the Financial Services Industry 
The above discussion focuses on the potential for AI-specific laws and regulations to stifle innovation in the financial 
services industry to the detriment of market participants, including investors.  This risk is amplified if different jurisdictions 
take conflicting or inconsistent approaches to regulating AI.   
A fragmented AI regulatory landscape will present significant compliance challenges for firms subject to numerous 
regulatory regimes.  Numerous jurisdictions (domestically and globally), along with regulators with overlapping 
jurisdictional reach, have adopted, or are seeking to adopt, their own AI-specific laws, regulations, and frameworks, yet 
the content and scope of those requirements can vary broadly.  There is also an increasing risk of a patchwork of state 
laws regulating AI, not unlike what has happened with privacy legislation.  A fragmented approach to AI regulation should 
therefore be discouraged, as it could deter financial services firms from leveraging AI and ultimately prevent market 
participants from receiving its many benefits.   
These difficulties will only be further exacerbated if policymakers or regulators introduce AI-specific regulations for the 
financial services industry.  Such an overly restrictive approach poses a risk that firms will be dissuaded from innovating 
or creating new technologies like AI for U.S. markets, leading to other countries or jurisdictions—which are adopting a 
more flexible approach—becoming the preferred destinations for companies that are developing new technologies.    
These concerns highlight the importance of applying existing principles-based and technology-neutral legal and regulatory 
frameworks to manage the risks presented by the use of AI in the financial services industry.  Relying on existing 
frameworks that have proven effective in addressing emerging technologies will ensure a consistent approach to 
managing AI risks that promotes innovation and maximizes its potential benefits to market participants. 
11 See MRM Guidance, supra note 5 (noting that further guidance will continue to be issued as necessary to identify novel areas of 
risk). 
12 See Gorfine Testimony, supra note 1, at 9-10. 


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 10 Policymakers and Regulators Should Consider Strategies for Addressing 
Potential Gaps in Existing Laws and Regulations Related to AI 
SIFMA believes there are a few key areas where policymakers and regulators should assess how existing laws and 
regulations apply to the use of AI in the financial services industry and consider strategies for mitigating potential risks, 
which are summarized below: 
Establish Federal Data Privacy Legislation that Considers the Use of AI in the Financial Services Industry.  If
Congress determines a legislative response to AI is appropriate, it should establish federal privacy legislation that
addresses data privacy, cybersecurity, and establishes safeguards regarding financial services firms’ use of personal
data.  Concerns have been raised regarding the data used by AI models, and appropriate legislation would ensure
that consumers have adequate privacy and personal data protections, both in connection with use in AI models and
more broadly in the financial services industry.  The United States Senate’s Bipartisan AI Working Group has likewise
called for federal privacy laws that offer such protections.13
Moreover, any such legislation should include strong state preemptions.  Consumers should be entitled to the same
level of privacy protections regardless of the jurisdiction in which they live, and in an increasingly digital world, state-
based protections are often inefficient, costly, and potentially unworkable.14  Federal privacy legislation is critical to
avoiding a patchwork approach to data regulation, which will only lead to conflicts of law and undue costs and
burdens related to AI use.
Clarify Copyright Ownership for AI-Produced Works.  Congress should consider amending existing copyright laws
to address issues related to artificial intelligence, including ownership of AI-produced works.  In 2023, the U.S.
Copyright Office announced that works created with the assistance of AI “may be copyrightable,” provided the work
involves sufficient “human authorship.”15  However, the human authorship requirement has been the source of
numerous challenges in recent years, as there are generally no copyright protections for AI-generated works created
without human involvement.16  This has resulted in AI ownership rights remaining ambiguous under existing copyright
laws, which demonstrates the need for existing copyright laws to be revised to reflect the modern realities of creative
works generated in a manner that falls outside the established legal definitions in this space.  Moreover, the U.S.
13 The Bipartisan Senate AI Working Group, Driving U.S. Innovation in Artificial Intelligence: A Roadmap for Artificial Intelligence Policy 
in the United States Senate , at 14 (May 2024), https://www.schumer.senate.gov/imo/media/doc/Roadmap_Electronic1.32pm.pdf.  
14 See Gorfine Testimony, supra note 1, at 13. 
15 See U.S. Copyright Office, Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence , 88 Fed. 
Reg. 16,190 (Mar. 16, 2023) ( to be codified at  37 C.F.R. § 202). 
16 Evan Gourvitz & S. Lara Ameri, Can Works Created with AI Be Copyrighted? Copyright Office Issues Formal Guidance , Ropes & 
Gray (Mar. 17, 2023), https://www.ropesgray.com/en/insights/alerts/2023/03/can-works-created-with-ai-be-copyrighted-copyright-office-
issues-formal-guidance.  


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 11 Copyright Office is examining copyright issues raised by AI and the sufficiency of existing legal protections which 
should be considered in any legislative approach to this issue.17      
Conclusion 
The adoption and use of AI in the financial services industry can offer significant benefits to market participants.  It also 
can ensure that U.S. firms remain globally competitive and that our markets remain at the forefront of technological 
development.  Given existing laws and regulations that apply to firms, along with internal risk-management frameworks, a 
principles-based and technology-neutral approach will appropriately ensure accountability and trust in connection with AI 
and other emerging technologies.  Such an approach will also avoid stifling innovation or wasting resources on low-risk AI 
applications at the expense of work that needs to be done to ensure that high-risk applications are meaningfully reviewed 
and effectively mitigated.  
While AI and other new technologies may present certain risks, financial services firms are subject to well-established 
legal and regulatory governance frameworks designed to address these risks, which apply regardless of the technology 
used.  Accordingly, policymakers and regulators should seek to apply existing risk-based rules and guidance to the 
deployment of AI and other new technologies in the markets, rather than engaging in any technology-specific rulemakings 
that will likely be outdated before they are finalized. 
17 See U.S. Copyright Office, Copyright and Artificial Intelligence, Part 1: Digital Replicas  (July 2024), 
https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-1-Digital-Replicas-Report.pdf (calling for new federal protection 
for unauthorized digital replicas). 


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 12 Appendix 1:  
Existing Technology-Neutral Functional Policy Areas Applicable to AI 
This appendix serves as an illustrative snapshot of the wide range of existing functional policy areas, sorted on a thematic 
basis, that already apply to financial services firms.  This appendix is not exhaustive; all technology-neutral functional policy 
areas in any jurisdiction already apply to the use of AI.  However, it provides the existing policy areas that may be used to 
assess and address potential impacts from AI to overall financial stability. 
Please note that the policy areas listed in this appendix do not apply universally across financial services firms, and that 
firms’ requirements will differ depending on the nature of their businesses and the regulatory regimes to which they are 
subject. 
No. Functional 
Policy Area Application to AI 
1. Market & Investor
ProtectionFinancial services firms that use AI systems in connection with providing services to 
investors may find that their use of AI is subject to the requirements of various market and 
investor protection laws, rules, and regulations that apply to various areas, for example: 
Manipulation and fraud in trading activity
Pre-trade controls and post-trade analysis mechanisms
Mitigation of the trading volatility and market disruptions
Investor advertising and engagement
Conflicts of interest, including ensuring investment advice and recommendations are in the 
“best interest” of the investor.  
2. Governance
StructuresFinancial services firms should have effective risk-management governance structures in 
place to identify, understand and manage risks associated with applications of AI systems. 
This includes having oversight of the full model development cycle, from proposal to 
deployment and ongoing monitoring.  While the risks stemming from AI can be novel, the 
need for effective governance structures is not a new concept.   
3. Risk Monitoring &
ManagementThere are a wide range of risks that can arise from an application of AI; it is important to 
have an effective risk monitoring and management framework in place to help ensure that 
such risks are identified and addressed accordingly. However, while there are potentially 
some novel risks to consider from the use of AI, identifying, addressing, and monitoring AI-
related risks need not be fundamentally different to firm’s existing risk management 
frameworks.   
4. Cybersecurity As financial services firms consider integrating AI systems into their business practices, 
they must consider the cybersecurity of their valuable data and operational significance.  In 
particular, data poisoning, data leakage, and data integrity attacks are particularly 
important risks to be mindful of given AI systems’ dependency on the data used to train 
and test it.  In addition to the cybersecurity risks presented from the use of AI, financial 
services firms also need to be aware of how threat actors may use AI to increase the 
propensity and sophistication of existing cybersecurity threats.  For example, AI-generated 
spearfishing messages, social engineering attacks that are executed through AI-generated 
deep-fakes and using GenAI to conduct parallel disinformation campaigns alongside a 
targeted cybersecurity attack.   


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 13 No. Functional 
Policy Area Application to AI 
5. Model Risk
ManagementTraditional model-risk management frameworks are applicable to the development, 
validation, implementation, and use and governance of models, including AI systems, and 
which consider model explainability and data integrity as key considerations.  
6.Third Party Risk
ManagementThird-party risk management is of high importance for AI as financial services firms may 
elect to purchase AI systems (either in part or in whole) from third-party vendors versus 
building the AI system in-house.  
There are broadly three categories of AI-related third parties: (1) vendors providing AI 
software; (2) vendors of software that includes AI features; and (3) other traditional 
vendors who may use AI in connection with their provision of services to the client.  The 
risks and requirements are slightly different for each category. 7. Data Privacy Due to the broad definition of “personal data” under many jurisdictions’ data privacy laws, 
the data entered into or associated with AI systems (as training, prompt or reference data) 
may involve personal data that is subject to, and protected by, such laws.   
Additionally, AI systems may be used to collect and use the personal data of individuals or 
monitor their behavior for customer service or fraud detection purposes, for example.  This 
could involve monitoring websites or app usage, geolocation, or voice data.  Again, such 
activities would likely be subject to the requirements of applicable data privacy laws.  8. Operational 
Resilience & 
Business 
Continuity Operational resilience requirements help improve the stability and reliability of services, 
including those that are completed by, or in connection with, AI systems so financial 
services firms can continue to operate in the event the AI system is disrupted, becomes 
un-operational, or otherwise stops operating as intended.  As firms consider deploying AI 
systems, firms’ operational resilience posture in connection with those AI systems is a key 
consideration.  


Promoting Investor Success, Industry Innovation, and Efficiency with AI 
Page | 14 Melissa MacGregor 
Deputy General Counsel & Corporate Secretary, SIFMA 
Kevin Ehrlich 
Managing Director & Associate General Counsel, SIFMA AMG 
Alyssa Pompei 
Vice President & Assistant General Counsel, SIFMA 


