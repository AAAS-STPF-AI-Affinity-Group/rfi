1 
 
   
 
March 1 4, 2025  
 
Via Electronic Mail  
 Networking and Information Technology Research and Development Program  
National Coordination Office  
2415 Eisenhower Avenue , Alexandria, VA 22314  
Attention : Faisal D'Souz a 
 
Re:
  Request  for Information on the Development of an Artificial Intelligence (AI) Action 
Plan  
 Ladies  and Gentlemen:  
The Bank Policy Institute
1 is writing to respond to  the Request for Information on the 
Development of an Artificial Intelligence (AI) Action Plan issued by the Networking and 
Information Technology Research and Development National Coordination Office and National Science Foundation on behalf of the Office of Science and Technology Policy.
2 We welcome the 
opportunity to contribute to the development of an AI Action Plan for President Trump’s second 
Administration.3  
 
BPI and its member banks are strongly committed to  using artificial intelligence  to improve 
the efficiency and sophistication of their systems and thereby advance the interests of U.S. 
consumers and businesses. As the  Bipartisan House Task Force on Artificial Intelligence noted , 
 
1 The Bank Policy Institute is a nonpartisan public policy, research and advocacy group that represents universal 
banks, regional banks, and the major foreign banks doing business in the United States. The Institute produces 
academic research and analysis on regulatory and monetary policy topics, analyzes and comments on proposed 
regulations, and represents the financial services industry with respect to cybersecurity, fraud, and other information 
security issues.  
2 Request for Information on the Development of an Artificial Intelligence (AI) Action Plan , 90 Fed. Reg. 9,088 (Feb. 6, 
2025), https://www.federalregister.gov/documents/2025/02/06/2025- 02305/request -for-information -on-the-
development -of-an-artificial -intelligence -ai-action -plan .  
3 This document is approved for public dissemination. The document contains no business -proprietary or confidential 
information. Document contents may be reused by the government in developing the AI Action Plan and associated 
documents without attribution.  


2 
 
 “the financial services sector has employed artificial intelligence technologies for decades ” across 
a variety of applications.4 
 
Among AI’s most critical uses in the U.S. banking system  is to counter  the efforts of 
malicious foreign and domestic actors . Last year, the House Committee on Financial Services’ 
Bipartisan Working Group on Artificial Intelligence noted  that fraud detection has been financial 
services’ top AI use case .5 In certain  instances , AI has reduced fraud activity6 and investigation 
time7 by half. Additionally, Treasury  has emphasize d AI’s significant benefits in anti -money 
laundering , countering the financing of terrorism, and sanctions compliance .8 Overly burdensome 
AI examination of banks has significantly hindered these efforts to use AI to defend the U.S. 
financial system and thus ma de it more difficult to combat foreign threats.   
 
Banks’ use of AI goes beyond risk mitigatio n and benefits banks and their customers . 
Recently, BPI cataloged bank use cases of traditional and generative AI, such as using generative 
AI to scan news articles to assist employees  in creat ing thematic investing indexes or using 
traditional AI to recommend the best action or product for customers based on historical and other relevant data.
9 The BPI membership continues to develop cutting -edge use cases, such as 
considering partnerships to use agentic AI for consumer loan origination and generative AI to simplify commercial card requests.  
 Banks have long made risk management a core pillar of their operations, integrating it into 
financial, operational, cyber, and emerging technology strategies. Their robust governance structures and independent risk functions ensure continuous oversight thr ough internationally 
recognized frameworks. This extends to IT risk management, including AI, where banks apply rigorous third -party risk protocols, cybersecurity measures, and compliance mechanisms. AI -
 
4 Report on Artificial Intelligence , BIPARTISAN H. TASK FORCE ON ARTIFICIAL INTELLIGENCE , 118th Cong., at xviii (Dec. 2024), 
https://republicans -science.house.gov/_cache/files/a/a/aa2ee12f -8f0c -46a3 -8ff8-
8e4215d6a72b/6676530F7A30F243A24E254F6858233A.ai -task- force -report -final.pdf  (“House AI Report”).  
5 AI Innovation Explored: Insights into AI Applications in Financial Services and Housing, Staff Report, BIPARTISAN 
WORKING GROUP ON ARTIFICIAL INTELLIGENCE , H. COMM . ON FIN. SERVS., 118th Cong ., at 15 (July 18, 2024),  
https://financialservices.house.gov/uploadedfiles/bipartisan_working_group_on_ai_staff_report.pdf  (“HFSC AI 
Report”).  
6 Managing Artificial Intelligence -Specific Cybersecurity Risks in the Financial Services Sector , U.S.  DEP'T OF THE TREASURY , 
at 3 (Mar. 2024), https://home.treasury.gov/system/files/136/Managing -Artificial- Intelligence -Specific- Cybersecurity -
Risks- In-The-Financial -Services -Sector.pdf .  
7 HFSC AI Report, supra  note 5, at 10.  
8 House AI Report, supra  note 4, at 229.  
9 See Joshua Smith, Comment on U.S. Treasury Request for Information on Uses, Opportunities, and Risks of Artificial 
Intelligence in the Financial Services Sector, BANK POLICY INSTITUTE , at 4 –8 (Aug. 12, 2024), https://bpi.com/wp-
content/uploads/2024/08/BPI -Treasury -AI-RFI-Response -2024- 4878- 9975- 4705- v10.pdf .  

3 
 
 related risks —such as bias, fairness, and explainability —are managed within established 
enterprise risk frameworks, just as banks handle credit, market, and operational risks .10 
When banks use AI, whether traditional or generative, or any  other emerging technolog y, 
they must adhere to a n oppressive  regulatory and supervisory framework that does not exist for 
other industries. Federal Reserve Governor Michelle Bowman recently state d that, though AI “is 
on the frontier of technology, it does not operate outside the existing legal and regulatory 
framework”; in fact, “[w]hen AI is deployed in a bank, an even broader  set of requirements may 
apply.”11 While this framework can help effectively manage risks, its cumulative effect can stifle 
innovation and overlook the risks of not innovating and deploying new technology fast enough. As 
Vice President J.D. Vance noted, “[E]xcessive regulation of the AI sector could kill a transformative 
industry just as it’s taking off. ”12 Eliminating government mandates that divert bank resources 
away from managing  material risks and driving innovation should be part of the Administration’s 
campaign “to encourage pro -growth AI policies.”13  
Banking services  underlie a significant portion of economic activity and are essential to the 
commercial transactions and financial relationships that support U.S. economic  growth and 
national security. A ny comprehensive plan for U.S. AI dominance must recognize banks’ central 
role in national success. To maintain and strengthen U.S. AI dominance, banks must not only 
adopt AI without excessive controls but have the freedom  and incentives to drive AI  innovation.  
Therefore , we urge the Administration to adopt the following as high -priority policy actions for its 
AI Action Plan.  
 
I. The Administration should direct the federal banking regulators  to encourage rather 
than discourage banks’ AI use . 
Few sets of regulation are more burdensome than those covering banks ; furthermore, 
unlike other industries, the U.S. banking system  is both regulated and subject to on- site 
examinations  from numerous regulators, including the Federal Reserve, Office of the Comptroller 
of the Currency, the Federal Deposit Insurance Corporation, and the Consumer Financial Protection Bureau.  Those a gencies  look to  whether a given bank’s  adoption of novel technologies 
such as AI complies with law, regulation, and safe and sound practice , and  federal supervisors 
 
10 For a discussion of banks’ extensive AI risk management, see Navigating Artificial Intelligence in Banking, BITS, BANK 
POLICY INSTITUTE  (April 8, 2024), https://bpi.com/navigating- artificial -intelligence -in-banking/ .  
11 Gov. Michelle Bowman, Artificial Intelligence in the Financial System , Remarks at the 27th Annual Symposium on 
Building the Financial System of the 21st Century, FEDERAL RESERVE  (Nov. 22, 2024), 
https://www.federalreserve.gov/newsevents/speech/bowman20241122a.htm ; see also  House AI Task Report, supra  
note 4, at 229 (“The use of AI does not absolve regulated entities from complying with applicable laws and 
regulations.”)  
12 Vice President J.D. Vance, Remarks by the Vice President at the Artificial Intelligence Action Summit in Paris, France , 
AMERICAN PRESIDENCY PROJECT  (Feb. 11, 2025), https://www.presidency.ucsb.edu/documents/remarks -the-vice-
president -the-artificial -intelligence -action -summit -paris- france .  
13 Id.  

4 
 
 draw upon unique model risk management guidance14 (“MRM guidance”) that directs banks how 
to use models, including certain  AI models. MRM guidance and related authorities review inputs 
and assumptions, outputs, bias, precision, accuracy, robustness, stability, and reliability; model 
validation, development, testing, and use; governance, including board oversight and personnel 
requirements; relevant third -party relationships; and more.15 In relation  to their use of AI, banks 
are also subject to  consumer protection and fair lending laws, privacy and data protection laws, 
and general requirements to, at all times and in all cases, operate in a safe and sound manner.16  
 Despite the extraordinary time banks spend on compliance matters  and the voluminous 
banking regulations already applicable to AI described above , Gov. Bowman observes  that bank 
examiners  often adopt “a ‘more is better’ approach to regulation and guidance” that “fails to 
address […] the perception (and perhaps reality?) that regulators have been overly hostile to 
innovation, including […] the use of artificial intelligence.”
17 She rightfully recommends that 
regulators should  instead “prioritize understanding the risks and benefits of new technologies 
 
14 See Guidance on Model Risk Management , SR 11- 7, FEDERAL RESERVE  (Apr. 4, 2011) 
https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm ; Supervisory Guidance on Model Risk 
Management , OCC 2011- 12, OFFICE OF THE COMPTROLLER OF THE CURRENCY  (Apr. 4, 2011), 
https://www.occ.treas.gov/news- issuances/bulletins/2011/bulletin -2011 -12a.pdf ; Adoption of Supervisory Guidance 
on Model Risk Management , FDIC FIL -22-2017, FEDERAL DEPOSIT INSURANCE CORPORATION  (June 7, 2017), 
https://www.fdic.gov/news/financial -institution -letters/2017/fil17022.html; Model Risk Management, Comptroller’s 
Handbook, OFFICE OF THE COMPTROLLER OF THE CURRENCY  (Aug. 2021), https://www.occ.gov/publications -and-
resources/publications/comptrollers- handbook/files/model- risk-management/pub- ch-model- risk.pdf ; Interagency 
Statement on Model Risk Management for Bank Systems Supporting Bank Secrecy Act/Anti -Money Laundering 
Compliance , FEDERAL RESERVE , OFFICE OF THE COMPTROLLER OF THE CURRENCY , FEDERAL DEPOSIT INSURANCE CORPORATION  (April 9, 
2021). Under the term “MRM Guidance,” we also include other related materials. 
15 Even when AI tools do not meet the formal definition of a “model” under MRM guidance, banks are still expected 
to apply “rigorous control[s]” to their use of technology. Model  Risk Management, Comptroller’s Handbook , OFFICE 
OF THE COMPTROLLER OF THE CURRENCY, at 2 (Aug. 2021), https://www.occ.gov/publications -and-
resources/publications/comptrollers- handbook/files/model- risk-management/pub- ch-model- risk.pdf .  
16 As one indicator of the extraordinary volume of U.S. banks ’ ultimate compliance burdens, a BPI survey found that 
such burdens have surged among member banks since 2016, with C -suite time devoted to compliance matters 
increasing by 75 percent, board time by 63 percent, and compliance staffing by 62 percent.  By 2023, management 
teams were spending 42 percent of their time and boards 44 percent on regulatory and supervisory compliance . See 
generally, Joshua Smith and Benjamin Gross, Survey Finds Compliance is Growing Demand on Bank Resources , BANK 
POLICY INSTITUTE  (Oct. 29, 2024), https://bpi.com/survey- finds -compliance -is-growing -demand- on-bank -resources . The 
survey defined “regulatory or supervisory compliance” as “compliance with law, regulation, guidance or other 
governmental mandate, including responding to mandates and recommendations from federal and state banking 
agencies, CFPB, SEC and other U.S. market and prudential regulatory agencies.” By c ontrast, the survey defined “risk 
management” as “risk management in the ordinary course unrelated to prudential regulatory or supervisory 
requirements.” By example, the survey noted that “credit underwriting is an ordinary risk management practice for 
any business lending money, regardless of any prudential regulatory or supervisory requirements.”  
17 Gov. Michelle Bowman, Bank Regulation in 2025 and Beyond, Remarks at the Kansas Bankers Association 
Government Relations Conference, FEDERAL RESERVE  (Feb. 05, 2025), 
https://www.federalreserve.gov/newsevents/speech/bowman20250205a.htm .  

5 
 
 before developing a supervisory posture, especially when applying rules and using the ‘soft’ 
power of supervision to discourage its use.”18  
 
The Administration has made clear that it will take an active role in ensuring alignment 
across the federal government, including regulatory agencies, with its priorities .19 Therefore,  the 
Administration should direct leadership  at the Agencies  to take the following actions  that ensure 
bank examiners focus on ultimate risk  to safety and soundness . 
 
1. An activity is not inherently riskier because it employs a particular technology, 
including machine learning, traditional AI, generative AI, or emerging innovations like 
agentic AI. Each activity requires a fact -specific risk assessment. In some cases, saf e 
and sound banking practices may even necessitate  AI adoption. For example, in certain 
instances, AI -driven fraud prevention tools have significantly reduced risk.  
2. Deployments of AI should not be held to an unrealistic standard of perfection that exceeds expectations for traditional technology deployment or human decision-making.  
3. Examination  of AI tools should encourage banking innovation and focus on risks that 
are material to a bank’s  safe and sound operation. In order to ensure that innovation is 
not hampered by bank examiners applying an overbroad standard of safety and 
soundness, the Agencies should codify  that an “unsafe or unsound practice” is, 
consistent with leading case law, one that “threaten[s] the financial integrity of the 
institution,”
20 as BPI has advocated elsewhere.21  
 
18 Id. See also Vice Chair Michael Barr, Artificial Intelligence: Hypothetical Scenarios for the Future, Remarks at the 
Council of Foreign Relations , FEDERAL RESERVE  (Feb. 18, 2025), 
https://www.federalreserve.gov/newsevents/speech/barr20250218a.htm  (“The financial regulatory community 
should approach the changing landscape with agility and flexibility.”)  
19 Ensuring Accountability for All Agencies , Executive Order, T HE WHITE HOUSE  (Feb. 18, 2025), 
https://www.whitehouse.gov/presidential -actions/2025/02/ensuring- accountability -for-all-agencies/ .  
20 Johnson v. OTS , 81 F.3d 195, 204 (D.C. Cir. 1996); see also  Gulf Federal Savings & Loan Association v. Federal Home 
Loan Bank Board, 651 F.2d 259 (5th Cir. 1981) (“The breadth of the ‘unsafe or unsound practice’ formula is restricted 
by its limitation to practices with a reasonably direct effect on an association’s financial soundness.”);  Seidman v. 
Office of Thrift Supervision , 37 F.3d 911 (3d Cir. 1994) (“The imprudent act must pose an abnormal risk to the financial 
stability of the banking institution…. Contingent, remote harms that could ultimately result in ‘minor financial loss’ to 
the institution are insufficient to pose the danger that warrants cease and desist proceedings.”);  Hoffman v. FDIC , 912 
F.2d 1172, 1174 (9th Cir. 1990) (requiring “abnormal risk or loss or damage to an institution, its shareholders, or the 
agencies administering the insurance funds”).   
21 See, e.g., Joshua Smith, Comment on Regulatory Publication and Review Under the Economic Growth and 
Regulatory Paperwork Reduction Act of 1996, Dec. 2024 notice , BANK POLICY INSTITUTE  (March 11, 2025), Sec. II.C., 
https://bpi.com/bpi -addresses -rising -compliance -responsibilities- for-banks -in-egrpra -response/ . Additionally, a 
“matter requiring attention” should be defined as either an unsafe or unsound practice or a violation of law with 
material consequences  that must be remediated . The Agencies should also strengthen due process in enforcement 
 

6 
 
 4. Banks are subject to robust compliance and risk management frameworks  that address 
their use of AI , including the  MRM guidance, which was drafted before the advent of 
many of the recent advances in AI. The agencies should  reform that guidance to be fit 
for purpose and remind examiners that , as codified in the Code of Federal Regulations, 
“[e]xaminers will not criticize […] a supervised financial institution for, and the 
[agencies ] will not issue an enforcement action on the basis of, a ‘violation ’ of or ‘non -
compliance ’ with supervisory guidance .”22 Therefore, banks should have the discretion 
and flexibility to apply risk management practices appropriate to the specific risks of a 
particular AI use . No bank should be told that it cannot take an AI approach until its 
examiner “gets comfortable” with the technology; examination should focus on whether that system, once adopted, presents a safety and soundness problem or constitutes a violation of law. The risk of misplaced priorities would ultimately stifle 
innovation and threaten the long -term health and utility of the banking system.  
5. To remain competitive, banks must be able to lever age the latest AI tools. F ull 
transparency into the processes by which certain models  generate outputs is not 
attainable for every  organization . Therefore,  examiners should focus on material risks 
to safety and soundness by looking to whether a  bank understands  where 
transparency is limited , has assessed  the associated  risks, and has implemented  
appropriate controls . The Administration should ensure that banks  are encouraged to 
explore new AI techniques , such as by developing and implementing  novel, low -risk 
use case s, to support U.S. innovation and competitiveness . 
6. Examiners should ensure that new risk management approaches  that are specifically 
adopted for emerging technologies like generative AI are not retroactively applied to 
established AI systems, such as machine learning, which banks have already adopted 
responsibly.
 For example, overly broad definitions of AI that would include established 
analytical methods , such as linear regression, must  be avoided.  The Administration  
 
proceedings and, most critically, guarantee judicial review of administrative actions. These reforms will help ensure 
that examinations of banks’ use of AI do not stifle innovation through unchallengeable overreach or undue focus on 
immaterial risks.  
22 See Role of Supervisory Guidance , 86 Fed. Reg. 18,173 (April 8, 2021), 
https://www.federalregister.gov/documents/2021/04/08/2021- 07146/role -of-supervisory -guidance  (Federal 
Reserve); 86 Fed. Reg. 9,253 (Feb. 12, 2021), https://www.federalregister.gov/documents/2021/02/12/2021-
01499/role -of-supervisory -guidance  (Office of the Comptroller of the Currency); 86 Fed. Reg. 12,079 (March 2, 2021), 
https://www.federalregister.gov/documents/2021/03/02/2021- 01537/role -of-supervisory -guidance  (Federal Deposit 
Insurance Corporation;  86 F ed. Reg. 9,261 (Feb. 12, 2021), 
https://www.federalregister.gov/documents/2021/02/12/2021- 01524/role -of-supervisory -guidance  (Consumer 
Financial Protection Bureau). Such proscribed criticism should include the  issuance of matters requiring attention, 
matters requiring immediate attention, matters requiring board attention, documents of resolution, and supervisory 
recommendations . Additionally, the Agencies should ensure examiners understand that an AI aspect to a tool does 
not automatically qualify that tool as a model subject to MRM guidance. For example, MRM guidance states that a 
model includes a reporting component that “process[es] input data into quantitative estimates,”  Comptroller’s 
Handbook , supra note 15 . A bank could reasonably take the position that an AI tool with a qualitative output like text 
does not meet this definition  

7 
 
 should primarily focus on g enerative AI and other emerging technologies , because 
traditional AI, such as machine learning, has reached a mature stage and is generally 
well-governed.  
II. The Administration should ensure that banks are fairly situated with respect to third 
parties. 
The Administration should ensure that banks are able c ontribute to AI innovation and 
competition just as well as technology providers and other nonbanks. Currently, however, banks 
face outsized regulatory hurdles to AI innovation, and these should be removed.  
 
A. Banks should not be required to indirectly regulate AI companies . Banks operate under 
regulatory frameworks that govern their use of third- party services, including AI tools.23 
While banks must conduct due diligence and ensure third- party tools adhere to applicable 
regulations, they often have limited visibility into proprietary third -party AI models. A 
bank’s ability to secure contractual obligations and protections that ensure  compliance 
with their regulatory obligations will vary according to its negotiating power. Large technology companies, which are not subject to the same technology oversight requirements as banks, can often resist disclosing critical information about the ir AI 
systems that is necessary for a bank’s own compliance obligations.
24 Yet avoiding third-
party AI services would likely render a bank unable to provide the services customers 
expect, the products non-bank competitors offer, or the systems needed to defend against 
bad actors.  
It gets worse.  “Fourth party vendor management” has now entered the examination 
lexicon — that is a requirement that banks conduct due diligence on their vendors’ 
vendors’ vendors .  Such a requirement is impractical and a diversion of resources from 
true risks.  
 Therefore , policymakers should explore whether existing authorities can be leveraged to 
allow the banking regulators to address their concerns directly with third- party AI 
providers, rather than placing the burden on banks to ensure their vendors meet those 
standards . For example, the Bank Service Company Act authorizes the banking regulators 
to regulate and examine entities performing services for banks “to the same extent as if 
 
23 See, e.g., Interagency Guidance on Third- Party Relationships: Risk Management , 88 Fed. Reg. 37,929 (June 9, 2023), 
https://www.federalregister.gov/documents/2023/06/09/2023- 12340/interagency- guidance -on-third -party -
relationships- risk-management  (“Conducting due diligence on third parties before selecting and entering into third-
party relationships is an important part of sound risk management. […] Due diligence includes assessing the third 
party's ability to: perform the activity as expected, ad here to a banking organization's policies related to the activity, 
comply with all applicable laws and regulations, and conduct the activity in a safe and sound manner.”)  
24 Such information could include, among others, the type and timeframe of data used to train the system, limitations 
of the data or system, appropriate and  inappropriate use  cases,  what the system does with  data presented to it ( e.g., 
whether input data is used for secondary purposes), as well as other technical information helpful to evaluating the 
model and related  risks.  

8 
 
 such services were being performed by” the bank itself.25 As Gov. Bowman notes, the 
statute “gives the federal banking agencies significant regulatory authority over 
outsourced banking services.”26 She rightfully states, “In a world where third parties are 
providing far more of these services […] these providers should bear more responsibility to 
ensure the outsourced activities are performed in a safe and sound manner.”27 
 
B. Banks should not be subject to AI requirements that exceed those for similarly situated 
nonbanks . Increased competition will ultimately drive AI innovation and help maintain U.S. 
dominance in AI, but fair competition requires that all parties be subject to similar regulatory rules. Therefore, t o ensure competitive equity, the Administration should work 
with the a gencies , and other relevant regulatory agencies , to ensure similar activities with 
similar risks are sensibly subject to similar regulation, regardless of whether a given 
activity is conducted by a bank or nonbank. Achieving a level playing field may require 
applying equivalent standards to nonbanks or reducing regulatory and supervisory requirements imposed on banks.  
III. Any future AI policy steps affecting banks should be sector -specific, technology -neutral, 
principles - and risk -based , compatible  with the current framework, and subject to 
extensive industry engagement. 
The Administration should ensure policy  reflects the following principles . 
 
A. To avoid policy fragmentation, AI policy for banks must be set  by federal regulators with 
direct expertise in the U.S. banking system . The House AI Task Force has correctly 
recommend ed a “sectoral approach […] to financial services regulation” that ensures  
“primary regulators” can “leverage their expertise.”28 We agree  that any future AI -related 
policies  should originate  from the a gencies  and remain consistent with the standards set 
forth in Sec. I  above . AI policy applicable to banks should not be dictated by  state 
legislatures,  state agencies, or broadly  applicable federal law s or re gulations that do not 
reflect direct expertise in bank regulation and supervision.29 Any AI-related laws or 
regulations at the federal, state, or local level should provide an entity -level exemption for 
 
25 12 U.S.C. 1867(a).  
26 Gov. Michelle Bowman, Welcoming Remarks , Remarks at the Midwest Cyber Workshop, F EDERAL RESERVE , (Feb. 15, 
2023) https://www.federalreserve.gov/newsevents/speech/bowman20230215a.htm . 
27 Id. 
28 House AI Report, supra note 4, at 240.  
29 See, e.g., Tara Payne, California Privacy Proposal Overreaches, Undermines Federal Framework , BANK POLICY INSTITUTE  
(Jan. 14, 2025), https://bpi.com/california -privacy- proposal -overreaches -undermines -federal- framework/ .  

9 
 
 banks already subject to federal oversight.30 The Administration should explore methods 
to avoid harmful fragmentation in AI policy, including federal preemption.  
B. The banking regulators should c ontinue to support a technology -neutral , principle s- and 
risk-based  approach  that is compatible  with the current framework. The House AI Report 
correctly affirms  a “technology- neutral approach” and a “principles -based regulatory 
approach” to AI in financial services.31 This approach supports innovation because it “can 
accommodate rapid technological changes ,” like those occurring in AI .32 A risk-based 
approach also sensibly tailors risk management requirements to underlying risk , with high-
risk systems requiring greater controls and low- risk systems requiring fewer. Finally , to the 
extent possible, future  policy approaches  should not conflict with, or should be 
implemented through, existing governance frameworks . The Administration should  avoid 
excessive governance or redundancy  with existing requirements . 
C. Any additional policy steps  should rely on significant industry engagement. Any further AI 
policy clarification from the a gencies , including guidance, should follow a formal notice -
and- comment process to ensure it reflects current technology, industry practices, and 
consumer interests.  Additionally, s tandards bodies with technical expertise and deep 
industry engagement, such as the National Institute for Standards and Technology , should 
lead the development of globally interoperable  technical standards and AI best practices . 
NIST is best situated to develop, in consultation with industry, best practices on critical and 
developing topics, such as Retrieval -Augmented Generation.  
IV. The Administration should continue to engage in public -private partnerships to advance 
AI. 
The Administration, banks operating in the United States, and the American public all 
benefit from public -private partnerships that foster collaboration between financial institutions 
and regulators. BPI, through its technology division BITS, has led significant industry -wide efforts 
with Treasury and the banking regulators  to address large -scale issues that require public -private 
initiatives beyond a single firm. Much of this critical work occurs through the Financial Services 
Sector Coordinating Council33 in conjunction with its public sector counterpart, the Financial and 
Banking Information Infrastructure Committee ,34 which ha ve several workstreams to tackle 
identified challenges and  opportunities, including AI explainability and AI-related fraud issues. We 
 
30 As an example, BPI is seeking an exemption from proposed California rulemaking for “financial institutions that are 
subject to examination or supervision by a federal prudential regulator and their affiliates as defined under the Bank 
Holding Company Act, 12 U.S.C. § 1841(k).” See, Joshua Smith, Comments on Proposed Cyber, Risk, and ADMT Rules , 
BANK POLICY INSTITUTE , at 24  (Jan. 14, 2025), https://bpi.com/wp- content/uploads/2025/01/BPI -CPPA -cyber -privacy-
and-AI-rulemaking -comment -2025.pdf .  
31 House AI Report , supra note 4, at vi; xix.  
32 Id. at xix.  
33 See About FSSCC , FINANCIAL SERVICES SECTOR COORDINATING COUNCIL , https://fsscc.org/ . 
34 See About FBIIC , FINANCIAL AND BANKING INFORMATION INFRASTRUCTURE COMMITTEE , https://www.fbiic.gov/   

10 
 
 recommend that the Administration participate in this ongoing collaboration. Additionally,  the 
Administration should support the creation of an industry framework and controls aligned with 
the NIST AI Risk Management Framework to ensure that AI risk management practices in the 
financial sector are both effective and consistent with regulatory expectations.  
 
* * * * * 
 
The Bank Policy  Institute  appreciates  the opportunity  to comment . If you have any 
questions, please contact me by phone at (202) 589- 2534 or by email at joshua.smith@bpi.com.  
 
 
Respectfully  submitted,  
 
 /s/ Joshua Smith  
 Joshua Smith  
Vice President, Assistant General Counsel Bank Policy Institute  
 

