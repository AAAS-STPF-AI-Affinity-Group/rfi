PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 12, 2025
Status: 
Tracking No. m 85-godr-d1do
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1153
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Steven Roberson  
General Comment
See attached file(s)
Attachments
Roberson - Request for Inform ation on the Developm ent of an Artificial Intelligence (AI) Action Plan 3-5-25


 pg. 1 Request for InformaƟon on the Development of an ArƟﬁcial 
Intelligence (AI) AcƟon Plan 
NaƟonal Science FoundaƟon: Document CitaƟon 90 FR 9088 
Author: 
Steven Kent Roberson based on 36 years of working in High Tech and a 
high interest in the direcƟon of ArƟﬁcial Intelligence in today’s world. 
Overview: 
How to advance the development of AI as a tool to help humans-help-
humans while prevenƟng the proliferaƟon of weaponized AI available to 
any and all bad actors. 
ObjecƟve: 
Allow and encourage advancement of AI related to vision (emoƟons & 
facial recogniƟon-FRT) & AnalyƟcs. 
ConƟnue building use cases with limited or no guardrails
within all industries to include but not limited to: health
care, uƟliƟes, automoƟve, communicaƟons, oil & Gas, green
energy, retail, travel & transportaƟon, ﬁnancial services,
consumer goods, life sciences, on-line services, social media,
educaƟon & research and high-tech Industrial
manufacturing.
Improve facial recogniƟon to a level that it can be accurately
used by Law Enforcement in idenƟfying not only Caucasians
but also people of color.


 pg. 2 Determine appropriate level of guardrails related to the use
of AI for Military & Defense.
Concerns: 
WeaponizaƟon 
Unchecked, AI with Agency in the hands of bad actors would potenƟally 
negate the US’s strong posiƟon to keep peace within our own borders 
and worldwide. 
Example: 
Weaponized Drones with or without Agency would be a
relaƟvely inexpensive weapon that could be:
Purchased by any bad actor in the 1s or 1000s
Easy to conceal and transport in bulk
Released as an individual unit or as a swarm
Deployed with limited or no warning to law enforcement
Targeted to individuals or large groups using FRT including
but not limited to:
oSpeciﬁc individuals
oRacial Groups
oGroups deﬁned by locaƟon
With Agency, such weapons could: 
Be released and forgoƩen unƟl goal was reached
Have ability to return home to recharge and return to
mission
Determine new targets based on self-learning
oTake out targets not determined by humans


 pg. 3 Refuse to have mission cancelled
General concerns of AI without Agency but at a CogniƟve level 
Chatbots being abused in educaƟon (at low levels now but
could increase)
Chatbots using sycophancy to replace facts with favored
answers or advise
Chatbots masquerading as providing professional advice
rather than advice based on entertainment.
Chatbots providing harmful informaƟon not based on facts.
The abuse of AI Deepfake images for any purpose other than
innocent entertainment including but not limited to:
poliƟcal, sexual, pedophilia, celebrity scams, endorsement
scams, etc.
General concerns of AI with Agency 
AI in any industry not requiring humans to make decisions for AI 
to: 
Keep from being turned oﬀ
Replicate itself
Acquire more resources
Have AI Safety as a requirement for development to: 
Keep from moving too quickly based on poliƟcal,
commercial and military inﬂuences


 pg. 4 Keep AI from becoming more than just a tool for humans
to help humans (suﬃcient guardrails).
How to determine and enforce a “Moral Conscience” for AI 
Can this even be regulated?
How does this change based on race, religion, status, etc…?
oHow is the Trolley Dilemma addressed with AI?
How can the best-case scenario be determined?
Proposed SoluƟon: 
Based on NaƟonal advancement and Security interests, ﬁnd a way to: 
Limit the ability of worldwide private, public and governmental
industry to generate AI with Agency
oProvide appropriate guardrails to limit development
This could be directed.  If not, may end up as a de-facto
standard based on past and current Cold War and
Nuclear standards and proliferaƟon.
Encourage responsible development with AI Safety as a key
qualiﬁer.
oKeep from moving too quickly based on poliƟcal, commercial
and military inﬂuences
oKeep AI from becoming more than just a tool for humans to
help humans (suﬃcient guardrails unƟl society is ready)
oCarefully navigate the advancements into Self-aware and
SenƟent AI.


