Response to Request for Information: Development of an 
Artificial Intelligence (AI) Action Plan 
Date: March 15, 2025 
Submitted to: Office of Science and Technology Policy (OSTP) and NITRD National Coordination Office. 
Submitted by: SecureBio, Inc. 
SecureBio is a nonprofit organization conducting technical research and developing tools to promote safe 
biotechnological innovation, composed of biologists, machine learning engineers, and software developers. Our AIxBio 
team focuses on AI capabilities research and evaluations. We collaborate with government agencies and most of the 
major LLM developers, providing expertise on measuring AI capabilities. 
SecureBio is available to brief stakeholders on AI capabilities in biology, including our non-public evaluations showing 
that AIs have begun to reach expert-level and beyond. 
Summary 
Part 1: USG should have an entity that is the world leader in the measurement of AI model capabilities. 
● Understanding the capabilities, limitations, and risks of newly produced leading-edge models helps policymakers 
understand the potential of the technology. This will enable USG to have access to the best possible intelligence 
on the rapidly changing landscape of what AIs can do now and in the future. 
● Therefore, dedicating resources to understanding AI capabilities is crucial for the United States to remain at the 
cutting edge of AI development and will help realize a vast array of benefits in tech, medicine, manufacturing, 
finance, and other domains. ● US AISI in NIST is already making very strong contributions on this front, and we recommend that they be 
strengthened to continue that work. 
Part 2: Prepare for a near future in which AI has caused a proliferation of bioweapon-relevant expertise. 
● SecureBio has shown that leading AIs can provide practical assistance on tasks that can enable bioweapon 
development. Leading models now outperform PhD researchers in several such areas. 
● This capability transfer is substantially reducing the expertise barrier that has historically prevented malicious 
actors from acquiring and deploying biological weapons. 
● Given evidence that certain AI systems pose national security risks, testing and evaluation mandates for frontier 
models are essential to mitigate such risks. 
● Near-future AI models will be even more capable, and would enable malicious actors to develop augmented and 
novel bioweapons. 
● USG should immediately create guidelines to address these capabilities, invest in biosurveillance, and improve our 
resilience to possible bioweapon attacks. 


Part 1: USG should have an entity that is the world leader in measuring AI 
capabilities. 
The pace of AI progress continues to accelerate, and capabilities are expanding across domains from reasoning to specialized 
expertise. To maintain America's competitive edge, USG requires world-leading capacity to measure and understand these 
evolving capabilities. 
Recommendations 
1. Empower US AISI to continue work in this domain 
○ Provide sufficient funding and computing resources for regular evaluation of frontier models. 
○ Staff the office with top technical talent through competitive compensation packages. 
○ If AISI is restructured, the successor entity should have an enshrined statutory remit of being a world 
leader in evaluating AI systems. 
2. Direct US AISI to create recommended standards and best-practices for evaluation
○ Work with AI labs, non-profits, and academic researchers to create standards for structuring and 
running AI evaluations. 
○ Prioritize evaluation of pre-release frontier models, through collaboration with leading AI developers. 
○ Develop secure protocols for evaluating proprietary systems while protecting intellectual property. 
Expected benefits 
1. Intelligence advantage: Provide U.S. decision-makers with high-quality data and insights into the global AI 
landscape, creating a critical intelligence advantage in monitoring both domestic and foreign AI development. 
2. Economic leadership: Enable targeted investment in areas where U.S. capabilities require strengthening, 
ensuring continued American leadership in AI innovation. 
3. Safety assurance: Identify potentially harmful capabilities before deployment, allowing for proactive 
development of appropriate safeguards and regulations. 
4. National security: Maintain awareness of dual-use capabilities that may present national security risks if 
leveraged by adversaries. 


Part 2: Prepare for a near future in which AI has caused a proliferation of 
bioweapon-relevant expertise 
Our research team has conducted extensive evaluation of how current AI systems can transfer expertise in virology and 
other dual-use research. The findings indicate that leading AI models now exceed the capabilities of human experts in 
providing practical guidance in bioweapon-relevant work. This is substantially reducing the expertise barrier that has 
historically prevented malicious actors from acquiring and deploying biological weapons. Near-future AI models will 
demonstrate even greater capabilities, enabling the development of novel or augmented bioweapons by actors who 
previously lacked the necessary expertise. We expect such capabilities to arrive in 2026 or 2027. 
Recommendations 1. Evaluations conducted by USG should identify models with strong bio-capabilities 
○ Some of these evaluations can include sensitive information. 
2. Establish biosecurity-focused AI governance for high-priority models
○ Develop specialized guidelines for AI systems that provide dual-use biological expertise. 
○ Create clear standards for when companies must implement additional safeguards on models with 
bioweapon-relevant capabilities. 
3. Classify key AI capabilities as dual-use technologies 
○ Expert-level AI assistance for virology should be regulated as a dual-use technology, subject to similar 
controls as physical biological materials and equipment. 
○ Incentivize Know-Your-Customer (KYC) verification mechanisms for AI systems capable of expert-level 
guidance on particularly important bioweapon-relevant methods. 
4. Enhance monitoring systems
○ Fund development of specialized red-teaming focused on bioweapon capabilities. 
○ Create secure channels for researchers to report concerning capabilities. 
5. Promote international coordination
○ Lead development of international standards for preventing misuse of AI in biological domains. 
○ Share assessment methodologies with allies while restricting sensitive details. 
Conclusion 
The United States stands at a critical juncture in AI development. By establishing world-leading capabilities in AI 
assessment while addressing emerging biological security risks, America can maintain its technological leadership position 
while ensuring these powerful technologies advance human flourishing rather than creating new threats. The 
recommendations outlined in this response should be prioritized in the AI Action Plan to support sustained American 
leadership in artificial intelligence innovation. 
This document is approved for public dissemination. The document contains no business-proprietary or con ﬁdential 
information. Document contents may be reused by the government in developing the AI Action Plan and associated documents 
without attribution. 


