March 14,  2025  
Faisal D' Souza  
Technical Coordinator, National Coordination Office (NCO)  
Networking and Information Technology Research and Development (NITRD) Program  
National Science Foundation  
2415 Eisenhower Avenue 
Alexandria, VA 22314  
Submitted  by email to 
Re:  Reque st for Information on the Development of an AI Action Plan  
___________________ _____________________________  
The Gli aNet Alliance (“Alliance”), a coalition of private sector companies and other 
organizations committed to building a new trust -based Web ecosystem, is pleased to 
provide input in response to the Request for Information (“RFI”) published by the Nation al Science Foundation (“NSF”) on behalf of the White House Office of Science and 
Technology Policy (“OSTP”).
1 OSTP seeks public comment as to priorities for the Artificial 
Intelligence (AI) Action Plan (“Plan”) called for in Presidential Executive Order No. 14179, Removing Barriers to American Leadership in Artificial Intelligence , issued on January 
23, 2025. The Alliance welcomes the opportunity to convey its perspective through this filing, and to interact further with OSTP as the Plan develops.  
Introduction and Overview  
As envisio ned, the Plan will define the priority policy actions needed to sustain and 
enhance America’s global position in the AI space, and to ensure that unnecessarily burdensome requirements do not hamper private sector AI innovation. The RFI calls out,  
among other potentially relevant topics, the impact on data privacy and security, governance, innovation, and competition, and requests “concrete AI policy actions needed to address the topics raised.”  
The past  several years have seen the rise of Generative AI, creating new forms of content 
by using large language models (LLMs). But what is in store for us in 2025 and beyond? 
1 90 Fed. Reg. 9088 (February 6, 2025).  Members of the GliaNet Alliance who support this filing include 
AT Worthy, Avaris, Balnce.ai, Complex Chaos, Cryptid, Cyberus Labs, DataLucent, Data Sapien, Emortal, 
FID,  Kwaai.ai, Luxury Institute, Reliabl, Sybal, Switchchord, Personal.ai, and WOPLLI. See 
www.glianetalliance.org/members . -~ GliaNet Alliance 


The technologists and business pundits seem to agree: We are witnessing the dawn of the 
era of agentic personal AI (PAI) systems. From voice assistants on phones to automated 
shopping lists and predictive text in emails, these systems are becoming pervasive in everyday life.  
Commerc ial business applications for PAIs will also issue in a new era of communication, 
information, and marketing content tailored to individual customer preferences. The 
development and distribution of Generative AI utilizing content owned by or licensed to 
individuals and entities will require sophisticated agents to, under one use case, represent 
content owners and create compensation mechanisms. The U.S. government has the 
opportunity to endorse open standards that balance commercial applications of generative content with the common -law rights of content creators.  
The AI Ac tion Plan also could help define a market environment that promotes the 
creation of new small business entities with innovative business plans that will enhance 
competition in the broad and fast -growing AI ecosystem.  The Administration should use  
this opportunity to encourage competition to the Big Tech players in the AI space.  
Through t his submission, the GliaNet Alliance proposes that the Plan adopt a policy 
framework for AI that prioritizes human agency, trustworthy stewardship of data, and market -driven solutions to bolster competition, innovation, and consumer choice. This 
filing explores the two interrelated definitional aspects of agency: capabilities to do things 
for us, and relationships to fully represent us. Achieving a more authentic PAI agent will 
require in particular: (1) interoperability between AI systems to optim ize advanced 
capabilities, (2) trustworthy intermediation to optimize alignment of digital relationships, 
and (as one example) (3) the development of tracking and auditing systems to ensure fair 
consideration for utilizing content.  
From Platf orm Accountability to Human Agency  
To date, m ost of the public policy proposals for advanced AI systems have focused on 
what could be considered an accountability agenda. Against the backdrop of generative AI, governments around the world have sought “safe and responsible” algorithmic 
syste ms. Typically, this approach has included several components: a level of 
transparency, some “guardrails” to limit societal damage from high -risk use cases, and an 
enforcement regime. Outside these riskier algorithmic systems, lawmakers would be content to pave the way for the companies to bring their innovations to market. This 
“accountability approach” has been taken in the EU AI Act,
2 the Executive Order Issued 
2 2024  O.J.  (L 1689). -~ GliaNet Alliance 


by then -President Biden (Executive Order 14110, since rescinded),3 the G7 principles,4 
the Bletchley Park Summit accord,5 and US legislation.  
Even when b inding, imposing top -down regulation is insufficient to solve the “AI 
problem.” While such regulation may help hold Institutional AIs to account for their 
actions, the AIs themselves will be left largely under the control of the large tech compa nies. This “Platform Accountability Agenda” also fails to plant the public policy 
seeds necessary for developing alternate computational systems and business models that truly promote human agency and choice, multi -level market competition, and multi- layer  
tech innovations.  
The missin g piece is a complementary agenda that prioritizes creating value with personal 
AIs, where people and businesses can protect themselves from pernicious actions by other AI systems while also promoting their best interests.  One of the guiding principles for such a “Human Agency Agenda” is that digital technologies such as AI should be designed 
to enhance the autonomy (freedom of thought) and agency (freedom of action) rights of 
individuals and entities that interact with the digital world.  
The shi ft towards digital agents can be seen as a continuation of the evolving and 
overlapping ways people and companies are able to interact with the Web. From about 
1995 to 2010, the browser was the predominant interface provided by online companies 
to a ccess websites. Heading into the 2010s, with the introduction of the iPhone and 
Android -based mobile devices, the embedded Web application became another such 
interface. As AI apps populated our mobile and fixed devices, voice and gesture commands were mad e available to end users.  
Now, in 2 025, the digital agent is poised to become the leading interface between humans 
and the Web, encompassing all of these and other mediation points. At this juncture, we 
now have the opportunity to step back and assess where we are, and (more critic ally) 
where the larger Web/AI platforms want to take us.  
The Two D imensions of AI Agency  
By definit ion,6 there are two interrelated dimensions to being an agent: (1) making 
decisions and taking actions and (2) making and taking said actions on behalf of someone 
else. In the context of a technology, such as a PAI or other forms of a digital agent, these 
3 Exec.  Order  No. 14110, 88 Fed. Reg. 75191 (Nov. 1, 2023).  
4 Hiroshima Process International Guiding Principles for Organizations Developing Advanced AI 
system,  Oct. 30, 2023, https://perma.cc/A3AE -KKFS. 
5 Policy paper, The Bletchley Declaration by Countries Attending the AI Safety Summit, Nov. 1 , 2023, 
https://perma.cc/JAY6 -UWVP . 
6 See, e.g.,  Agent , MERRIAM -WEBSTER , https://perma.cc/DS89 -D4EE  (last visited Nov. 17, 2024); Agency , 
CORNELL LEGAL INFORMATION INSTITUTE , https://perma.cc/MZ5M- 3EQV  (last visited Nov. 17, 2024).  -~ GliaNet Alliance 


intrinsic elements can be thought of as “agenticity” (functional capability to behave like 
an agent, by performing or undertaking certain activities)7 and “agentiality” (authorized 
representation to act for another person).  
 Any searching inquiry into agenticity is incomplete without a similar exploration of 
agentiality. Indeed, without an adequate confirmed degree of agentiality, any actions taken by the AI system “on behalf of” a person should be considered unwarranted —if no t 
unethical. Figure 1 below is a schema that combines the outward -facing PAI capabilities 
with the inward -facing relationship:  
 
 
In the AI context, one can posit that the greater the capabilities for environmental or situational alignment with other systems, the greater the need for end user agency. 
Alternatively, the greater the degree of observable agentiality —the deeper the 
relat ionship —the larger the valid action space available for agenticity. This means there 
should be acknowledged proportional tradeoffs between agenticity (technical 
capabilities) and agentiality (authorized representation). Figure 2 below showcases one way to capture that crucial interrelation between the two dimensions of AI agency:  
 
 
7 Agentic, W IKTIONARY , https://perma.cc/34VU -YB9E (last visited Sept. 2, 2024).  
• II 
HUMAN Agential 
Relationship 
AGENTIAL 
RELATIONSHIP 
~ • II 
PERSONAL 
DIGITAL 
AGENT 
~ CLIPPY 
Bot Assistant -~ GliaNet Alliance 
Agentic 
Capabilities 
Avatar ■ •• OTHER 
Al SYSTEMS 
OPTIMAL 
RELATIONSHIP & 
CAPABILITIES 
X 
AGENTIC CAPABILITIES Autonomou s 
Agent 


In everyd ay terms, this means that as the agreement to AI -assisted decision -making 
becomes more consensual, the kinds of actions that AI systems can perform in the world 
become more advanced.  
Below we w ill briefly explore how both dimensions can be optimized by way of technology 
and governance implements. In brief, greater agenticity can be achieved through the 
addition of AI -to-AI interoperability, while greater agentiality can be achieved thr ough 
the addition of trustworthy intermediation. Together, they can provide tangible benefits, including greater competition, innovation, and consumer choice.  
Agentici ty: AI -to-AI AI Interop  
Agenticit y is about performing tasks for someone; the wider the possible canvas, the more 
opportunities exist for such actions. Today, a PAI is technologically limited to operating on its sponsoring platform. Without access to the computational resources r esiding on 
other platforms, a PAI is unable to carry out a host of potential functions related to those systems. The challenge then is finding ways to extend a PAI’s capabilities to other AI 
systems. The proffered solution is AI interoperability.  
Interop erability is defined as the ability of heterogeneous networks to connect and 
communicate seamlessly with one another.8 For example, to become part of the Internet, 
operators of individual networks voluntarily connect to other networks. Nearly 30 years ago, the IETF’s Request for Comment (RFC) 1958 put it plainly: the “why” of the Internet is connectivity, moving data packe ts seamlessly from Point A to Point B.
9 Such open 
connectivity requires technical cooperation between different network providers. This connective tissue, combined with open standards, modularity, and the agnostic IP protocol, is responsible for the incredible generative power of the Internet.
10 
Technol ogical interoperability long precedes the Internet, with the telephone, telegraph, 
and radio systems all relying on interoperable protocols. “The concept even predates electrical communications, and can be seen in the development of everything from railroad gauges to bullet calibers.”
11 
8 Interoperability , WIKIPEDIA , https://perma.cc/UGL4 -8RUV  (as of Nov. 17, 2024). 
9 INTERNET ENG’R TASK FORCE , Request for Comment  1958 (B. Carpenter ed., June 1996), at 2. To Kevin 
Werbach, “the defining characteristic of the Net is … a relentless commitment to interconnectivity.” Kevin 
Werbach, Only Connect , 22 BERKELEY TECH. L. J. 1233, 1273 (2007).  
10 See Richard Whitt, Hiding in the Open:  How Tech Network Policies Can Inform Openness by Design 
(and Vice Versa) , 3 G EO. L. TECH. REV. 28, 38 -45 (2018).  
11 Becky Chao  & Ross Schulman, Promoting Platform Interoperability, N EW AMERICA FOUNDATION , (May 
13, 2020) , https://www.newamerica.org/oti/reports/promoting -platform-interoperability/ .  -~ GliaNet Alliance 


In the book Interop , Palfrey and Gasser observe that “[t]he benefits and costs of 
interoperability are most apparent when technologies work together so that the data they 
exchange prove useful at the other end of the transaction.”12 Without interoperability at 
the lower layers of the Internet, interoperability at the higher human and institutional 
layers is often impossible.13 Palfrey and Gasser’s concept of “interop” is to “embrace 
certain kinds of diversity not by making systems, applications, and components the same 
but by enabling them to work together.”14 Thus, if the underlying platforms are open and 
designed with interop in mind, then all players —including end users and intermediaries —
can contribute to developing new products and services.15 
 Web platform companies have also acknowledged the importance of interop as a way for users to share access to their data. The Data Transfer Project (DTP) founded by Google, 
Apple, and Facebook —now called the Data Transfer Initiative (DTI) —has been building  
an open- source platform for moving data between various platforms.
16 As the sponsors 
put it: “DTI partners help translate principle to practice, catalyzing greater user agency and empowerment by committing dedicated policy and engineering resources to the 
promotion of data portability.”
17 
 Interop can apply in a wide variety of contexts, including in and between different digital technologies. Following these impressive legacies, the next logical step is creating 
interoperability for disparate AI systems. Connectivity that allows two or more  advanced 
computational systems to communicate directly with one another. This form would take us above the more basic data and protocols layers to the entity’s actual algorithm -based 
functions. If AI fulfills the promise of serving as the crucial platform  of the 21st century, 
we need to take a thoughtful look at the interop fabric that can bind us together — if it is 
actually adopted and utilized.  
 
The Data Transfer Project’s original version of interop —allowing users to move their data 
between existing platforms —is one example of a positive related use case. However, it 
does not address what we would need from AI systems. We don’t only seek permissi on to 
port our data from one large platform to another. We want to better enhance and promote our digital participation and agency. To accomplish this, interop is needed at the algorithmic layers, so the disparate islands and individual AI agents can connect to each 
other and/or to the underlying AI platforms.  
 
12 John Palfrey & Urs Gasser, Interop: The Promise and Perils of Highly Interconnected Systems 22 -23 
(2012).  
13 Id. at 23.  
14 Id. at 108.  
15 Id. at 121.  
16 Data Transfer Project , W IKIPEDIA , https://perma.cc/FD3R -QTC9  (as of Nov. 17, 2024).  
17 Data Transfer Initiative, https://www. dtinit.org/ . -~ GliaNet Alliance 


Even ChatGPT seems to agree: “Lack of interoperability can hinder the deployment and 
integration of AI solutions, restrict collaboration between different stakeholders, and 
limit the potential benefits of AI. Interoperability … fosters the development of a  more 
connected and collaborative AI ecosystem, leading to improved efficiency, enhanced 
decision -making, and increased innovation.”18 
 
So where is AI interop in our marketplaces, our standards bodies, or our public policy 
conversations? At this juncture only promising glimmers are evident.19 Despite 
widespread acclaim for advances with generative AI, particularly LLMs, there is little public discussion about the notion of facilitating interop between PAI agents and 
Institutional AI systems. That said, there is much yet to understand in terms of how AI -
to-AI interoperability can operate in the marketplace.  Importantly:  
 
[I]nteroperability is not– or should not be –an end in itself; it is a means to a 
broader set of goals: to address market fragmentation, to avoid market tipping 
towards monopoly; to open downstream markets for competition where the 
upstream market is monopolized; to increase follow -on innovation irrespective 
of market power; or to address a perceived societal need for general interconnectedness and communication across competing networks. In each case, before taking action, a clear and strong market failure o r public service 
rationale should be identified.
20 
 
In other words, the government’s direct involvement requires sufficient evidence that 
interoperability as a public good will not occur otherwise. The GliaNet Alliance believes that the new AI Action Plan should include AI interop as an important component bearing 
further exploration.  
 
Agentiality: Trustworthy Intermediation  
 The crucial second dimension of agency is the authority to act on behalf of another. This 
amounts to the degree to which the AI is legally / formally / ethically authorized to 
represent the principal human being or entity.  
 
Today we have no uniform or widely acknowledged way to assess the agentiality of a 
purported individual -to-agent relationship on the Web. As computer scientist Stuart 
18 Interview with ChatGPT 4.0, OpenAI, (March 4, 2025) (responding to the query “Is AI interoperability 
valuable?”).  
19 See, e.g.,  the Model Context Protocol (MCP), an open standard introduced by Anthropic as a means of 
connecting AI assistants to data repositories. https://www.anthropic.com/news/model- context-protocol . 
20 Wolfgang Kerber & Heike Schweitzer, Interoperability in the Digital Economy , J. Intell. Prop. Info. 
Tech. & Elec. Com. L. 39, 58 (2017), https://www.jipitec.eu/jipitec/article/view/190 /185 .   -~ GliaNet Alliance 


Russell notes, it “seems inevitable…that users will trust a personal assistant only if its 
primary obligation is to the user rather than to the corporation that produced it.”21 
More spec ifically, how do we ensure the user’s interests are not overridden with 
regulatory functions by the AI developer? As Bruce Schneier explains: 
Imagine  asking your chatbot to plan your next vacation. Did it choose a 
particular airline or hotel chain or restaurant because it was the best for you or 
because its maker got a kickback from the businesses? As with paid results in 
Google search, newsfeed  ads on Facebook and paid placements on Amazon 
queries, these paid influences are likely to get more surreptitious over time.  
If you’r e asking your chatbot for political information, are the results skewed by 
the politics of the corporation that owns the chatbot? Or the candidate who paid 
it the most money? Or even the views of the demographic of the people whose 
data was used in  training the model? Is your AI agent secretly a double agent? 
Right now, there is no way to know.22 
The remedy  for any agentiality  gaps is to ensure that human beings are in charge of the 
relationship with the AI assistant and its developers. The Institute of Electrical and Electronics Engineers (IEEE), the leading global standards body, first launched its Global 
Initiative on Ethics  of Autonomous and Intelligent Systems (A/IS) in 2016. That 
initiative’s inaugural paper highlights how digital agents rightfully should comport with what it calls “Ethically Aligned Design.”
23 IEEE formally adopted eight governing 
principles, including human rights, well -being, data agency, and accountability. Data 
agency signifies that people have “some form of sovereignty, agency, symmetry, or control regarding their identity and personal data,” while digital sovereignty is the ability “to own and fully control autonomous and intelligent technology.”
24 
IEEE also endorses the A/IS agent as an end user’s educator, negotiator, and broker:  
To retain a gency in the algorithmic era, we must provide every individual with a 
personal data or algorithmic agent they curate to represent their terms and 
conditions in any real, digital, or virtual environment…. A significant part of 
retaining your agen cy in this way involves identifying trusted services that can 
essentially act on your behalf when making decisions about your data…. A 
21 Stewart Russell, Human Compatible: Artificial Intelligence and the Problem of Control 71 (2019).  
22 Bruce Schneier, AI and Trust, S CHNEIER ON SECURITY , 
https://www.schneier.com/blog/archives/2023/12/ai -and- trust.html . 
23 INST. OF ELEC. AND ELEC’CS ENG’RS, Personal Data and Individual Agency , in ETHICALLY ALIGNED DESIGN 
(1st ed. 2019) , https://perma.cc/679B -5PEM. 
24 INST. OF ELEC. AND ELEC’CS ENG’RS, General Principles,  in ETHICALLY ALIGNED DESIGN (1st ed. 2019) , 
https://perma.cc/N5TY -3GEV . -~ GliaNet Alliance 


person’s A/IS agent is a proactive algorithmic tool honoring their terms and 
conditions in the digital, virtual, and physical worlds.25 
 
Obviously there are a number of ways that one’s autonomy and agency can be promoted 
via AI and other advanced digital technologies. The GliaNet project rests on the 
foundation of fiduciary principles taken from the common law.26   
 
Experts have pointed out that fiduciary law is essentially the common law of uneven 
relationships. Noted expert Tamar Frankel observes that “throughout the centuries, the 
problems that these laws were designed to solve are eternal, etched in human nature, 
derived from human needs, and built into human activities.” Not surprisingly, fiduciary principles are near -universal, applied across a vast array of human endeavors. These 
include agency, trust law, corporate law, nonprofits law, banking, pension law, emp loyment law, bankruptcy, family law, health care, and international law.  
 
The basis for a fiduciary relationship is straightforward: assigning legal and moral 
obligations to people and entities engaged in exchanges of value. The linchpin is what 
Frankel calls “entrusted power.” An individual or entity (the entrustor or beneficia ry) 
grants access to something of value to another individual or entity (the fiduciary) for the 
purpose of having the fiduciary undertake tasks that benefit the entrustor. In these 
situations, the fiduciary normally has some knowledge or expertise that the entrustor 
lacks. Moreover, sensitive information is often revealed in the context of establishing the relationship.  Because the entrustor willingly makes themselves vulnerable to the other’s 
expertise, it is a duty rooted in asymmetric power relationships between the parties.  
 
Fiduciaries abide by two basic types of duties: care and loyalty. The duty of care obligates 
the fiduciary to, at minimum, act prudently and do no harm to the entrustor. The duty of loyalty goes further in requiring the fiduciary to have no conflicts of interest, and to 
promote the best interests of the entrustor.  
 The GliaNet initiative has introduced a new type of entity: a trusted digital intermediary 
we call the Net Fiduciary. These intermediaries provide technologies, like authentic PAI agents, answerable directly to us. Net Fiduciaries are entities that would be established to 
serve the individual as an actual client, and not a mere “end user.” Importantly, these Net 
Fiduciaries voluntarily take on fiduciary law -based duties of care and loyalty to each of 
their customers or clients who would be acting as willing  “principals.”  
 The GliaNet Alliance has sketched out the “PEP Model,” shown in Figure 3 below — 
standing for Protect, Enhance, and Promote. This framework demonstrates what an ecosystem of Net Fiduciaries would entail, using common law principles as a guide.
 
 
25 IEEE , ETHICALLY ALIGNED DESIGN , at 114.  
26 See generally Richard Whitt, R EWEAVING THE WEB (2024) , at 165 -213.  -~ GliaNet Alliance 


 
 
First , the lowest level of obligation is a general duty of care. Entities could agree under 
law, or perhaps using a binding contractual agreement, to take reasonable and prudent 
steps to ensure that the PAI does not harm the individual. This could be seen as the 
Guardian  role, to denote the role of protecting the principal. Examples in the digital 
environment include: being transparent about your data policies, taking prudent steps to 
protect personal data from hackers, and refraining from selling or sharing one ’s data with 
untrusted third parties.  
 
Second , as scholars agree, the duty of care is not the core element of the fiduciary 
relationship: that obligation is the duty of loyalty. Loyalty can be defined in two different 
ways. The lower level —or “thin” duty of loyalty —entails no conflicts of interest or  duties 
vis-à-vis other players. This Mediator  role can take on a duty of fidelity . With greater 
proposed agenticity in terms of what the PAI could accomplish on behalf of the individual, end users could seek out entities who agree to take on such a duty. This would mean that 
the entity would mediate in an unbiased manner between the principal and various 
sources of news, information, commerce, and entertainment.  
 Third , at the highest level, the individual could agree to be represented by a PAI that 
embraces “thick loyalty,” which requires acting in the principal’s best interest. This 
Advocate  role encompasses a straightforward duty of loyalty , where the entity actively 
promotes what is optimal for the principal. This could include affirmatively informing them about online risks, filtering out unwanted or harmful content from their online 
feeds, arming them with technology tools to protect them selves, and presenting  them with 
advertising and marketing options tailored to their particular wants or needs —or no ads 
at all.
27 
 This PEP model is not just limited to variations on “user alignment.” The model can open 
up entirely new market opportunities, where individuals and entities can freely negotiate 
27 Id. at 135.  
-~ GliaNet Alliance 
Function Role Duty Web Example 


over the terms and conditions of digital representation.28 The authentic PAI agent would 
be a crucial bridge between the end user and the Web, taking on an increasing variety of 
agentic duties as the principal's duly authorized and trusted representative. As the capabilities of agenticity increase, so too would t he depth of relationships of agentiality.  
Importa ntly, the duties of fidelity and loyalty are not absolute. The common law of 
fiduciaries has always recognized and incorporated larger societal considerations. For 
example, physicians typically must identify highly contagious patients to health 
auth orities, as well as report negligent acts observed by fellow physicians to licensing 
authorities. Additionally, under the “crime -fraud” exception, attorneys must report 
clients to law enforcement if they know there is a high probability their clients will commit a serious crime.
29 The real work will come with fashioning and applying an appropriate 
balancing test of interests.  
The GliaN et Alliance suggests a two -tiered approach to Web governance.30 Platform 
providers and others with access to personal data, and utilizing AI systems on such data, would be bound by a general duty of care. By contrast, Net Fiduciaries would operate on 
a voluntary relational basis, pursuant to the higher duties of fidel ity and loyalty towards 
their clients.
31 The premise is that mandating a general tort -like duty of care for those who 
interact with personal data is more politically and practically viable than mandating heightened duties of fidelity and loyalty from those same entities. For them, an ethics -
informed business model becomes an unwanted compliance matter. Or, as Frankel puts 
it, forced loyalty amounts to no true loyalty at all.
32 
The Glia Net Alliance: Promoting Both Dimensions  
One way t o implement a human agency agenda is to instantiate it in the private sector. 
Although doctors, lawyers, and certain financial advisors abide by fiduciary duties of care and loyalty towards their patients, customers, and clients, the Web today lacks entities 
that voluntarily take on such obligations. The GliaNet Alliance aims to fill that gap, with 
an initial roster of some twenty for -profit companies exploring ways to willingly take on 
duties of care and loyalty as a crucial way to build authenti c trust with customers and 
clients.  
Combining enhanced capabilities and deeper relationships promotes greater personal, 
social, and economic value, as more opportunities are created to promote intentions and 
capture influences. These opportunities would be realized on both the supply side (m ore 
28 Id. at 160 -161. 
29 Id. at 253.  
30 Id. at  365–366. 
31 Id. at 121 –126.  
32 Id. at 249. -~ GliaNet Alliance 


decision engines are created) and on the demand side (as those decisions become more 
personal and consequential). Below are a few potential use cases that demonstrate the 
robustness of this approach:  
 
● Protecting personal data flows . Authentic PAI agents could manage the 
individual’s privacy contours: the flow of personal data to online and offline environments. For example, this could include utilizing real -time machine -to-
machine (M2M) connectivity to interpret a website’s particul ar privacy policy and 
recommend whether the individual should or should not engage.  
 
● Broadcasting intentions . The PAI could interpret a website or app terms of service 
(ToS) and other policies to generate tailored consent responses. One could even 
broadcast —“intentcast” —the client’s own ToS to the Web, setting up interesting 
opportunities for real negotiation, b argaining, and compromise.  
 
● Creating and exporting independent decision engines . As noted above, the PAI 
could set individual preferences and defaults for the individual’s dealings with news feeds, social networks, retail sites, and other online interfaces. The PAI also 
could ensure that Web -based recommendation engines are serving r elevant 
information, and not harmful content, such as “fakes” or addictive videos. Those 
recommendation engines could even be replaced with “middleware” that better 
matches the individual’s interests.  
 
● Circulating a consumer’s universal shopping cart.  The PAI could set up and 
manage an individual’s own online shopping cart, pseudonymously taken from site 
to site. The cart could project only necessary identity information, using zero 
knowledge proofs and other edgetech to validate its owner’s financial viability.  
 
● Mediating the terms of environmental engagement. The PAI could help the individuals dictate the terms of their immersive digital experiences with 
AR/VR/MR platforms. The PAI could even negotiate directly with environmental 
devices —smart speakers, digital cameras, biometric sensors —and authorize, limit,  
or block access from surveilling and extracting personal data.  
 
● Building communities of interest. The PAI could utilize these and other functions to enable individuals to construct their own actual and virtual communities.  
 
● Evaluating and valuing an individual’s digital content.  The PAI could function as 
a broker between an individual and commercial enterprises looking to monetize digital content (e.g. for targeted marketing) in return for consideration. Depending on the applications, the PAI could establish an unbiased value of specific user data 
and help negotiate consideration between parties based on that valuation.  
 -~ GliaNet Alliance 


●Facilitating ID tokenization and verification.  The PAI could verify an individual’s
identity to third parties looking to enter into financial or other contracts with
customers.
Import antly, in each case the primary focal point is the individual and their agential 
intentions. The human being should be considered the actual subject of their own digital destiny, armed with a full -fledged, authentic PAI agent. The trusted intermediar y would 
help ensure that individuals are the actual subjects of their own digital destiny.  
Conclu sion: Enhancing US Leadership  
At this  juncture in early 2025, an enduring policy and governance landscape for advanced 
AI systems in the United States has yet to be sketched.  The GliaNet Alliance suggests that pursuing the goals of both achieving AI interop (for the agentic dimension)  and 
trustworthy intermediation (for the agential dimension) will ensure that each is given 
appropriate weight.  
With vert ical AI interop, multistakeholder bodies such as the IEEE can pursue open 
standards and protocols. With trustworthy intermediaries, interested entities can band 
together to create professional codes of conduct and other explicit indicia of adheren ce to 
fiduciary law -based duties. Together, the two dimensions of AI agency can put the United 
States at the forefront of the AI world – with American consumers and businesses sharing 
in the vast benefits.  
*    *    *    *    *  
This d ocument is approved for public dissemination. The document contains no business -
proprietary or confidential information.  Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without attribution.  
Sincerely , 
/s/ Rich ard Whitt  
Richard Wh itt 
President  
GliaNet Alliance  -~ GliaNet Alliance 


