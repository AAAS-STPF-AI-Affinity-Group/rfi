ISACA response  re:  
Agency: National Science Foundation  
Document Citation 90 FR 9088  
Document Number 2025 -02305  
 
This document is approved for public dissemination.  The document contains no business -proprietary or 
confidential information.  Document contents may be reused by the government in developing the AI 
Action Plan and associated documents without attribution.  
 
 
Introduction  
About ISACA : 
ISACA is an independent nonprofit association  focused on the meeting the knowledge, skilling, and 
related needs of technical professionals throughout the world.  ISACA is actively engaged  in the 
creation, development, adoption , and use of globally accepted, industry -leading knowledge and 
practices for the effective and safe organizational  and personal use of technology.  ISACA’s long and 
distinguished history of meeting the needs of technical professionals in the United States began  more 
than fifty years ago, when it was founded in California.  Today, from its global headquarters  in Illinois , 
ISACA meets the needs of member  and certification holder communities  throughout the United States  
that comprise a central —and growing —constituency within ISACA’s global community of nearly 
180,000 members worldwide . 
ISACA has a long history of supporting national initiatives focused on information and cyber security, 
privacy, governance, risk management, and auditing, and stands ready to assist the US government in 
any capacity it can as the United States  continues to chart a forward -focused path across rapidly 
evolving cybersecurity, workforce, and technology landscape s. 
 
Response to the Oﬃce of Science and Technology Policy’s (OSTP’s) Networking and Information 
Technology Research and Development (NITRD) National Coordination Oﬃce ’s (NCO ’s) Request for 
Information on the Development of an AI Action Plan (“Plan”)  
ISACA is appreciative of the NITRD NCO’s request for input regarding the development of an AI Action Plan for the current Administration, and recognizes the critical need to balance sound policy with 
actions that support rather than stiﬂe innovation.  Our organization believes that , by focusing on a few 
key areas, this goal can be accomplished in a comprehensive and impactful manner.   
For the Action Plan to have measurable and lasting impact , ISACA feels that the Administration would 
greatly beneﬁt by focusing  on AI policy actions addressing:  
1) education and workforce development,  
2) regulation and governa nce, including technical and safety standards,  
3) and security, privacy, and impartiality throughout the lifecycle of AI system development  and 
deployment . 
ISACA believes that eﬀorts such as these are foundational in nature .  It is ISACA’s considered opinion 
that improvements in these three areas have the potential to create force multiplier eﬀects across 


industries and workforces, improving innovation and competition, national security and defense, 
international collaborations, and America’s overall economic landscape.   ISACA has several suggestions 
for potential policy initiative s to support the Administration’s AI Action Plan . 
Education and Workforce Development  
It is ISACA’s deeply -held belief that it is critical to the US public and private sectors that a trained 
workforce is in place that is capable of meeting the challenges AI presents today and —going forward —
has the capacity to address challenges that will arrive as AI’s maturation continues.  
“Sprints” have been in vogue for quite some time, in both the private and public sectors.  While these can be of value, ISACA believes that AI requires more of a “Marathon” approach.  Focusing on growing the workforce through a rush to create apprenticeshi p opportunities, to make commitments for 
credentialing a certain number of workers —ISACA believes these eﬀorts help to address areas like AI; 
similar eﬀorts, in fact have already beneﬁted cybersecurity.  However, ISACA also believes that such eﬀorts ad dress the symptoms of problems, rather than the core elements of the problems themselves.  
No matter how well -intentioned or well -executed a “sprint” is, however, the fact remains that it is a 
short -term solution to a problem that will be around for the long term.  AI, for all the advances we have 
seen thus far, is still a maturing technology; t he Action Plan must not merely be built for the next few 
years, but remain eﬀective far into the future.   
ISACA believes that a long -term, sustainable and sustained focus on developing educational pipelines 
that begin in primary and secondary education, progress through community colleges and universities, and are strong, yet ﬂexible enough to address evolving workforce needs  is of paramount importance.   
ISACA’s State of Cybersecurity research  has shown, in recent years,  a distinct  need for both technical 
and non- technical skills  within the professional workforce .  It will be important, in ISACA’s considered 
opinion, for the Action Plan to focus  on both types of skills through apprenticeships, career and 
technical education, career and military transitioning opportunities, and workforce development 
eﬀorts .  Such a focus  ensures that individuals entering workforces in which AI will play a central role 
embark on their careers armed with all the expertise, skills, and abilities  needed to excel  and advance.  
As was previously mentioned, for all its ongoing impact AI remains a still -maturing technology.  Because 
of this, ISACA believes that there is a concurrent need for policy solutions which can anticipate and 
support eﬀorts to address the rapidly changing educational needs that will arise as a result of AI’s 
maturation as a technology.  There are already linkages between  governmental agencies that focus, 
respectively, on education and workforce development; ISACA respectfully suggests that those 
government a gencies could be more impactful if united, rather than merely linked.  Our organization 
believes that this could create economies of scale when addressing education (including career and technical education) and workforce development needs , as well as provide a more nimble, uniﬁed 
construct within the Federal government to meet  evolving educational and workforce needs.  
Regulation and Governance, Including Technical and Safety Standards  
As AI matures, the importance of the appropriate application and strengthening  of existing laws and 
regulations, augmented by complementary new measures aimed at ensuring safety, security, and 
privacy while enhancing innovation capabilities, cannot be overstated.  For this reason, ISACA suggests 


the consideration of the creation of a n AI Coordination Committee or Working Group  
(Committee/Group) , and consisting of stakeholders from across the public, private, academic, and NGO 
sectors .  The United States government should be informed of and adopt the best practices that would 
allow   the harmonization and alignment of existing laws and regulations  at the Federal level  and 
become an even more impactful resource to unleash AI innovation consistent with national  needs .   
Regulators  across industries  should take a similar approach with technical and safety standards, aligning 
those as well.  The Committee/Group could even go further, encompassing international technical and 
safety standards  that align with US eﬀorts as well as best practices within the space.  Representatives 
from the NGO sector, such as ISACA, could be considered as non- oﬃcial members of this 
Committee/Group, ensuring that the Committee/Group beneﬁts from insights, feedback, or best 
practices from other  national AI -focused leadership endeavors.   ISACA believes that such  an alignment 
could beneﬁt from some of the concepts put forth in the “Streamlining Federal Cybersecurity 
Regulations Act”  of the 118th Congress (S. 4630) , particularly the emphasis on the creation of an 
interagency , multi -stakeholder committee .  The regulatory reviews should carefully review the 
availability of best practices and frameworks from industry that have a proven track record of 
improving performance, governance and achieving risk  management goals.   ISACA ’s CMMI 3.0 
framework  has been doing just that since its launch in 2023 . The CMMI 3.0 framework is recognized by 
many US government agencies for its rigor and ﬂexibility in meeting regulatory requirements, including by the Department of Defense and Food and Drug Administration  
Given the complexity of this task, addressing this complicated task  with innovative  AI resources would 
enable the AI Action Plan to essentially use AI to address the challenges of AI .  ISACA believes this is  a 
course of action that is not only unique internationally, but could shorten the time needed to 
harmonize and align a complicated public policy landscape from years to months.  Moreover, once created, ISACA believes these eﬀorts could serve as a baseline for further eﬀorts going forward, so that 
tomorrow's public policy eﬀorts are built on the solid foundations created by the work of this Committee /Group .  As an added beneﬁt , the work of the Committee/Group would address the 
“patchwork quilt” currently being built across the  United States as individual States author and enact AI 
legislation and regulations ; doing so would ensure that, as AI matures, there is no need to replicate 
those piecemeal eﬀorts.   Additionally, if requirements for the presence of trained and credentialed 
professionals  are contained within any ﬁnal harmonized public policy (ies), ISACA believes this will 
ensure that the workforces charged with working within this new policy environment possess the appropriate knowledge and skills needed to ensure continued progress and prosperity.  
Security, Privacy, and Impartiality Throughout the Lifecycle of AI System Development and Deployment  
Just as the development of tomorrow’s AI workforce is critically important, so too are the systems 
those individuals will be tasked with working on or with.  Therefore, it is critically important to use 
existing and widely accepted frameworks for IT and AI auditing, as well as those frameworks that 
address data and privacy security , so that there are appropriate levels of safeguards ‘baked in’ to the AI 
systems that are developed and deployed.  Leveraging existing skills, training, knowledge, and 
frameworks  from certiﬁcation bodies such as ISACA and CMMI meet the  intent of accounting for these 


crucial considerations but do so in a way that leverages leading industry  practices so as not to inhibit 
innovation and growth.  
In the past , the Federal Communications Commission (FCC)  created and deployed the U.S. Cyber Trust 
Mark, a voluntary cybersecurity labeling program for wireless consumer Internet of Things (IoT) 
products.  While this may have been well -intentioned, it is nonetheless voluntary and, as such, does not 
have to be followed.  The AI Action Plan, however, can beneﬁt from the lessons learned regarding the 
Cyber Trust Mark.   
ISACA recognizes  that a primary goal of the AI Action plan is to foster innovation, not impede it; while 
our organization sees a more stringent certiﬁcation approach similar to the “Energy Star” certiﬁcation 
process as an “added value” for an AI system, it is understandable that others might disagree.  To that 
end, ISACA would also suggest a compromise ; that such a certiﬁcation be reserved as a requirement  for 
AI systems in areas such as critical infrastructure, national security, or sectors of similar signiﬁcan ce.  
For AI systems  of smaller signiﬁcance, demonstrated adherence to or alignment with accredited 
voluntary industry standards or frameworks could prove suﬃcient.   Beyond the certiﬁcation process for 
AI systems, though, there will always remain the human factor; human oversight, human -driven 
auditing of AI systems, accomplished with skilled professionals using industry -recognized frameworks 
are core elements of ‘g etting AI right’ that cannot be overlooked or understated.  
ISACA believes that it will be of paramount importance for the characteristics of the workforce(s) 
needed to support these eﬀorts  to reﬂect the Administration 's desire to see accountability and 
responsibility embedded across the AI life cycle.  Critical to accomplishing this, ISACA believes, is the presence of trained and credentialed professionals contributing to the design of integrity controls 
during the dev elopment process, as well as the need for similarly trained and credentialed 
professionals auditing and validating the deployment, operation, and risk management of all AI 
systems.  
Conclusion  
ISACA is grateful for the opportunity to contribute the organization’s thoughts on the future of AI as 
both a technology and an economic driver .  ISACA looks  forward to assisting the Government in any 
capacity it can in the months and years to come.  


