PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-0wih-zinf
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-6956
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Nick Har
Em ail:  
General Comment
Regulating AI will PROTECT pivotal creative econom ies. The protections we have in place pertaining to copyright are crucial to prevent
Generative AI/LLMs from  ruining (and outright stealing) the creative endeavors of every m edia outlet in our country. Loosening these
regulations will open the door to m ass plagiarism  as Gen AI uses already-available creative works to train itself on, without the consent of
the creators whose work is being scraped for content. There are plenty of studies in academ ia and econom ical theory to explain why this
would drive a knife into our country's m ass m edia environm ent, but to put it concisely, unregulated Gen AI will lead to a rise in deepfaked
content, as well as m uck up any effort to prove the integrity of social m edia outlets. Additionally, unregulated Gen AI will harm  our
nation's ability to advance any sort of sem blance of AI dom inance since, without proper controls and lawful regulations in place to protect
the copyrights and ownership of the creations that the people it scrapes content from , it would dem olish all creative sectors with generic-
looking, generic-sounding, sanitized, and un-innovative content slushed out by a com puter that takes genuine creative content m ade by
actual hum ans and churns out cheap im itations of it while hum an creators are discouraged from  putting out their own authentic m aterial.
Copyright laws PROTECT our artists, m usicians, authors, and all other creators from  having their hard work copied and illegally
reproduced, which Generative AI and LLMs ultim ately threaten.


