PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-hrot-9x9t
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-2134
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Magpie Reed
Em ail:  
General Comment
The current AI action plan is fed into by m onopolies insisting that they cannot function without copyrighted data that they have not been
given consent to, as well as xenophobic and racist ideas about national security overblown by other countries having technology. These
are overshadowing the actual fact that AI is a dying industry that no one other than a niche subgroup of m oguls buys into anym ore due to
its inability to work as well as a hum an being - this has been tested in studies, and people can sim ply notice this.
AI can only perform  as well as the code and training input into it, which is flawed, as hum ans are, and has biases unconsciously input into it
with that in m ind. If you're putting training data in by people who are xenophobic towards the Chinese and claim ing that it's a m atter of
National Security to outperform  them  in technological aspects, you're going to m ake an AI that has training data that is biased against
China. This has been proven since the dawn of technology.
You're going to have plenty of people inform ing you that your plan is replacing hum an workers and increasing energy cost m assively, and
it is. This is unethical for the sake of turning a profit. I do not think you care about that. My point, however, is that your m achines aren't
even good, and the bias you're going into this with is going to m ake them  worse. The only way to m ake m achine learning viable is to go in
with a properly picked dataset, chosen by variables you actually know what you're inputting, not just scraped random ly from  all of the
internet for SECURITY, and typically from  people who can actually consent so they can give you proper inform ation for your tags. With
not enough inform ation your m achine will be biased and zero in on people who didn't get enough inform ation in on culprits of Absolutely
Nothing Other Than Being Different. This will not actually function as a m achine unless you train it ethically. I cannot tell you not to use the
m achine. I can tell you that I've actually asked people who run AI how it works and you're doing it wrong.


