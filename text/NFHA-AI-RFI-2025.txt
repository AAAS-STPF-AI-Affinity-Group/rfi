 
 
 
 
March 15, 2025 
 
 
 
Faisal D’Souza, NCO Oﬃce of Science and Technology Policy  
1650 Pennsylvania Avenue NW 
Washington DC, 20502 
 
Re: Request for Information on the Development of an Arti ﬁcial Intelligence (AI) Action Plan 
The National Fair Housing Alliance® (NFHA™)1 and the undersigned civil rights advocacy 
organizations appreciate the opportunity to submit comments in response to the O ﬃce of Science 
Technology  and Policy (OSTP) February 6, 2025 Request for Information (RFI) on the Development of 
an Arti ﬁcial Intelligence (AI)  Action Plan2. We commend the OSTP for seeking input on this important 
topic and hope our comments below will help inform the OSTP’s views.  
 
The next few years will see the emergence of extremely powerful AI systems and agents 
fundamentally altering the economy, workforce, education systems, and social interactions in the 
United States of America. Maintaining US leadership in AI underscores the importance of testing 
systems, assessing their impact, and building guardrails to ensure positive change and mitigate risk 
of misuse. AI has the potential to lift Americans economically and provide opportunity for those that 
previously had very little, however the next step in successful adoption, beyond innovation lies in 
accepting the fundamental truths around AI and understanding the technologies’ potential blind spots 
and risks. There are signiﬁcant risks that AI systems can r esult  in discriminatory or inequitable 
outcomes, but the risks are not insurmountable.  
 
2 https:/ /www .go vinfo.go v/content/pk g/FR-2025-02-06/pdf/2025-02305.pdf   1 Founded in 1988, the National Fair Housing Alliance (NFHA) is the country's only national civil rights organization dedicated solely 
to eliminating all forms of housing and lending discrimination and ensuring equal opportunities for all people. As the trade association 
for over 170 fair housing and justice-centered organizations and individuals throughout the U.S. and its territories, NFHA works to 
dismantle longstanding barriers to equity and build diverse, inclusive, well-resourced communities. 
 
www.nationalfairhousing.org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004      
 
1 


Our previously submitted comment letter3 underscored that any comprehensive AI Action Plan must 
rigorously address civil rights concerns, ensuring that advancements in AI do not inadvertently 
perpetuate existing inequalities or introduce new forms of discrimination. It is essential that the plan 
includes clear, standardized criteria for testing and auditing AI systems, with speciﬁc attention to 
detecting and mitigating bias in AI-based decision-making  systems. Such measures will help to 
safeguard the rights of historically marginalized communities and promote equitable outcomes 
across sectors, particularly in areas like housing and lending. 
In addition to robust technical standards, our letter emphasizes the importance of transparency and 
accountability in the deployment of AI technologies. The AI Action Plan must mandate regular impact 
assessments and independent audits to verify that AI systems are operating as intended, without 
adverse consequences for civil rights. This proactive oversight is critical to maintaining public trust 
and ensuring that any negative outcomes are swiftly identiﬁed and addressed, reinforcing that 
inno vation must be balanced with a commitment to fairness and justice. 
The AI Action Plan must foster a collaborative governance model that actively engages diverse 
stakeholders—including civil rights advocates, community representatives, industry experts, and 
regulatory bodies—in its development and implementation. By integrating broad-based input and 
establishing mechanisms for continuous dialogue and revision, the AI Action Plan will not only drive 
technological advancement but also ensure that these innovations are accessible and beneﬁcial to all 
Americans, re ﬂecting our collective values of equity and inclusion.  
Following are recommendations as t o how the federal government can mitigate these risks in the 
pursuant AI Action Plan: 
General Feedback 
NFHA r ecommends  that the administration take a risk-based approach to AI policy. While AI is largely 
used for good, like all powerful innovations, the risk of misuse remains. We strongly recommend that 
3 NFHA’s response to Request for Information and Comment on Financial Institutions’ Use of Artificial Intelligence, including 
Machine Learning 
www.nationalfairhousing .org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004     
2 


the administration categorically require extensive impact assessments for AI systems and take 
action to mitigate their societal and economic harms. NFHA is concerned that  
NFHA’s response seeks to balance AI innovation with civil rights protections, ensuring that 
regulations support responsible AI development, deployment and adoption. 
I. Transparency and Accountability
A risk-based approach to AI systems should distinguish between general risks associated with AI 
applications, such as those related to accuracy, hallucinations, content generation, and risks 
associated in a speci ﬁc sector. Par ticularly  AI used in tenant screening, dynamic rental pricing, credit 
scoring, insurance underwriting, and automated mortgage valuation models—requires transparency 
and accountability to ensure fairness, impartiality and integrity4. Building public trust in AI systems 
requires that the con ﬁdentiality and security of sensitive personal and ﬁnancial data is protected, 
especially considering the v ast amount of data processed by AI systems. Finally, the principles of 
transparency and accountability demand that users are made aware when they interact with an AI 
system to respect human autonomy and freedom of choice.  
Recommendations: 
●Ensure strong civil and human rights protections: The priorities of the AI Action Plan should
reﬂect civil and human rights principles that are foundational t o America ’s ideals of freedom
and equality. Subsequent AI regulation should create equity to mitigate existing systemic
barriers that unjustly harm underserved groups and communities.
●Initiate an AI risk-management framework. Establish policies to evaluate risk-relevant
capabilities of AI and robustness of safety measures, both prior to deployment and on an
ongoing basis, through internal and external evaluations5. This framework should be developed
under the participation of  multiple stakeholders such as policymakers, AI developers and
users, civil rights advocates and consumer protection organizations. The guidelines should
5 NIST AI Risk Management Framework https://www.nist.gov/itl/ai-risk-management-framework  4 Lisa Rice, NFHA President, Testimony on Artificial Intelligence and Housing: Exploring Promise and Peril, Subcommittee on 
Housing, Transportation, and Community Development, 2024. 
https://www.banking.senate.gov/hearings/artificial-intelligence-and-housing-exploring-promise-and-peril  
www.nationalfairhousing. org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004     
3 


 
 
 
 
reﬂect and comply with the existing laws  and regulations that ensure fair treatment in ﬁnancial 
services and housing6. 
● Incorporate fairness metrics. Guidelines should not only relate to accuracy, reliability or 
robustness, but should also take into consideration speci ﬁc measures regar ding fairness as 
appr opriate in speci ﬁc sectors (such as lending, renting). NFH A recommends assessments of 
unwanted bias in the outcome of AI systems by developers and users alike7. Existing 
frameworks relating to measuring and mitigating disparate impact, disparate treatment, and 
proxy discrimination should guide further regulation of AI fairness8.  
● Enable third party oversight. The AI risk-framework should support, apart from transparency, 
third party oversight, enforcement and ensure compliance with the existing legal framework in 
a given sector, such as anti-discrimination and civil rights legislation for the housing sector.  ● Mandate regular impact assessments. The AI Action Plan must mandate regular impact 
assessments and independent audits to verify that AI systems are operating as intended, 
without adverse consequences for civil rights. Evaluations should be not only done internally, 
but include third party oversight and appropriate enforcement measures in case of 
non-compliance. The collection of AI impact data should be done in regular intervals (at least 
once a year). ● Ensuring public data access: AI legislation should mandate public availability of key data, as 
the lack of such data hampers efforts to develop responsible automated systems in housing 
and ﬁnancial services. This data usage must rightly balance  priv acy rights with the need to 
protect civil and human rights.  
 
II. Education and Workforce Development 
AI regulation should be supported through procurement policies, workforce development, and 
education initiatives. AI literacy and retraining programs will be essential to ensure that workers 
8 Nicholas Schmidt, Partner and Artificial Intelligence Practice Leader, BLDS, and Founder and CTO 
SolasAI, Testimony on Artificial Intelligence and Housing: Exploring Promise and Peril, Subcommittee on Housing, Transportation, 
and Community Development, 2024. 
https://www.banking.senate.gov/hearings/artificial-intelligence-and-housing-exploring-promise-and-peril  7 Ferrara, E. (2024). Fairness and Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, and Mitigation Strategies. Sci, 
6(1), 3. https://doi.org/10.3390/sci6010003 6 Title VII of the Civil Rights Act, Fair Housing Act, Equal Credit Opportunity Act 
 
www.nationalfairhousing.org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004      
 
4 


remain competitive in an evolving job market. A recent World Economic Forum survey reports that 
86% of employers expect AI technology to transform their businesses by 20309. 
The risk of workforce displacement due to AI advancements is signi ﬁcant, particularly in industries 
that involv e tasks related to reading, writing, mathematics, marketing, programming, and ﬁnancial 
management. AI developers should consider  whether AI solutions should replace human roles or 
augment them to improve outcomes. 
Recommendations: 
●Promote human-centric AI. The AI Action Plan should emphasize human-centric AI
development that retains human oversight to ensure ethical decision-making.
●Promote AI literacy in the civilian workforce. Workforce development must be a priority of
policymakers. As the demands for skills relating to AI technologies grows, promoting AI
literacy will be crucial for retraining the public and empowering workers to feel empowered to
use AI tools.
●Acknowledge the limitations of human-AI collaboration. Guidelines should highlight the
limitations of GenAI that can be effectively managed through human-AI collaboration, rather
than pursuing complete automation of projected tasks or roles. Maintaining human oversight
and decision-making is essential to ensure that AI deployment and outcomes align with the
intended beneﬁts.
III. Research in AI Fairness & Algorithmic Bias
To be a global leader in AI, the United States should address potential bias and unequal treatment 
resulting from AI systems as discriminatory AI models could strip hard working Americans of 
opportunities. Ensuring fairness requires setting implementation standards that promote equal 
access and compliance with civil rights laws. Developing tools to detect and monitor bias as well as 
the search for least discriminatory algorithm (LDA) should be a priority.  
Recommendations: 
●Fund national AI research initiatives. The AI Action Plan should fund research initiatives that
test and evaluate AI systems, develop tools to detect and monitor bias, and seek innovative
9 WEF, the Future of Jobs Report 2025 
www.nationalfairhousing. org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004     
5 


 
 
 
 
methods to mitigate algorithmic bias. Continue funding for national initiatives such as the 
National AI Research Resource Pilot (NAIRR Pilot)10. 
● Encourage the search for Less Discriminatory Algorithms (LDAs). The AI Action plan should 
encourage AI deployers to actively search for less discriminatory algorithms (LDAs). LDAs are 
algorithms that are equal in accuracy but demonstrate minimal disparate impact, making them 
a justiﬁable and necessary alternative11.  
● Provide guidelines for LDAs. Policymakers should provide comprehensive guidelines in key 
areas, including appropriate debiasing techniques, recommendations for the proper depth of 
LDA searches, valuable considerations for LDA viability, and suitable fairness metrics in a 
variety of different contexts.   
 
IV. AI Infrastructure & Environmental Impact 
As the government increasingly invests in AI infrastructure, early signs indicate that the buildout of 
data centers places a signi ﬁcant strain on ener gy grids and the envir onment. The growing demand for 
data centers will affect local communities and regions’ energy and water availability and cost and 
pose potential risks of harm for utility customers and communities. AI data centers are driving growth 
in energy usage, with data centers representing 4.4% of total US electricity consumption in 2023 and 
estimates show that data center energy consumption could reach between 6.7% and 12% of total US 
electricity consumption by 202812. With increased electricity demand, there is the risk that energy bills 
will increase for consumers in addition to ﬁnancial risks to consumers fr om o verbuilding or sudden 
closure of a data center.  
 
There are also environmental risks for the communities where these data centers are located. Back 
up generation to protect data centers from outages could increase air pollution (e.g., if the back 
generation is diesel). Cooling data centers requires water and this could affect water sources and 
12 LBNL 2024 United States Data Center Energy Usage Report (Dec. 2024), pp 6-7. 
https://eta.lbl.gov/publications/2024-lbnl-data-center-energy-usage-report  11 Emily Black (2023, October 31). Less Discriminatory Algorithms. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4590481  10 NAIRR Pilot https://nairrpilot.org/  
 
www.nationalfairhousing.org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004      
 
6 


also affect water bills for consumers (for example, if the water usage causes scarcity).  The constant 
noise from a data center can be seen as a nuisance by residents13.  
Preventing an energy crisis will require better calibration of risks and resources as the United States 
will risk overspending on AI infrastructure if energy eﬃciency in model training and infer ence  is not 
adequately considered and improvements implemented. To support sustainable AI development 
policymakers should address energy consumption, data center sustainability, and reﬁning computing 
eﬃciency.  
Recommendations: 
●Prioritize community engagement. The AI Action Plan should include community engagement,
strategies to ensure consumers’ electric and water bills are protected from AI-related
increases and low-income consumers, in particular, have access to affordable and reliable
electricity and water.
●Reduce energy consumption through hardware solutions. Encouraging the use of more
eﬃcient hardware should be a priority . Regulations  such as power capping for data centers
would incentivize companies to adopt more energy-e ﬃcient systems, reducing ener gy
expenditur e and alleviating the costs associated with training AI models14. Additionally,
policymakers should consider a layout for model training requirements and introduce site
assessment mandates for ﬁrst-time data centers to pre vent excessive spending on
infrastructure.
●Promote data center sustainability. Data center developers should be required to disclose
energy and water consumption at regional and state levels to allow for more accurate
projections of power needs and assess the impact on local grids15.
oData centers should seek independence from local electricity grids.
15 American Council for an Energy Efficient Economy (2024, October). Turning Data Centers into Grid and Regional Assets 
chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.aceee.org/sites/default/files/pdfs/Turning%20Data%20Centers%2
0into%20Grid%20and%20Regional%20Assets%20-%20Considerations%20and%20Recommendations%20for%20the%20Federal%2
0Government,%20State%20Policymakers,%20and%20Utility%20Regulators.pdf  14 MIT Lincoln Library (2023, October 5). New tools are available to help reduce the energy that AI models devour.  
  https://news.mit.edu/2023/new-tools-available-reduce-energy-that-ai-models-devour-1005  13 Virginia Joint Legislative Audit and Review Commission, “Data Centers in Virginia 2024, Report to the Governor and General 
Assembly of Virginia (Dec. 9, 2024), Executive Summary. 
www.nationalfairhousing. org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004     
7 


 
 
 
 
o Policymakers should also promote recycling initiatives to conserve municipal water 
supplies, mitigate the scarcity of rare elements, and reduce hazardous waste in 
compliance with legal frameworks.  
● Prioritize computing e ﬃciency. Promoting adv ancements in hardware as well as in software 
eﬃciency is crucial. AI algorithms should be designed  to rely on less input data, thereby 
reducing the resources needed for training and deployment. 
 
V. Open-Source Development  
Open-source AI applications provide a wide range of bene ﬁts, including increased tr ansparency, 
competition, and adaptability. However, the ‘openness’ of AI systems follows a spectrum, and not all 
AI models are equally accessible or equally safe. Ensuring that Americans have a fair and facilitated 
access to AI innovation should be a policy priority. While the marginal risk associated with 
open-source systems remains low, we encourage the administration to monitor potential risks 
associated with models that can be widely adopted and modiﬁed.  
 
Recommendations: 
● Ensure that open-source applications comply with existing legal frameworks . The AI Action 
Plan should ensure that open-source AI tools remain widely accessible while complying with 
civil rights protections.   
● Consider the various components of open foundation models. Policymakers should consider 
that access to different component parts of open foundation models may change the balance 
of risk and bene ﬁt16. For example, access to model weights alone  may present a limited risk, 
while access to model weights plus source code could marginally increase the risks of a 
model. NFHA recommends that the Action Plan establishes a policy framework for 
analyzing the Marginal Risk of Open Foundation Models  similar17. 
● Monitor the risks of open foundation models. Policymakers should carefully monitor security 
risks associated with open-source and foundation models. Best practices for AI safety may 
include red-teaming AI models or conducting vulnerability testing before release18. 
18 RAND. (2024, January 25). The Operational Risks of AI in Large-Scale Biological Attacks. 
https://www.rand.org/pubs/research_reports/RRA2977-2.html  17 Stanford HAI. (2024, February 27). On the Societal Impact of Open Foundation Models. https://crfm.stanford.edu/open-fms/  16  Prompt Engineering Institute. (2023, December 1). Openness in Language Models: Open-Source vs Open Weights vs Restricted 
Weights. https://promptengineering.org/llm-open-source-vs-open-weights-vs-restricted-weights/  
 
www.nationalfairhousing.org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004      
 
8 


VI. AI Safety & Security
Given the enormous investment in AI system development, ensuring system reliability through robust 
testing should be a priority. Preventing errors in AI applications, such as AI hallucinations, 
misapplications, and bias, will require the implementation of clear standards for testing, training, and 
certi ﬁcation. The United States should prioritize global leadership in the dev elopment and practice of 
AI standards.   
Recommendations: 
●Preserve the AI Safety Institute. NFHA urges policymakers to preserve the key function of the
AI Safety Institute. It is essential that the AI Safety Institute remains independent and
well-funded to carry out its mission of overseeing AI safety, mitigating risks, and setting clear
regulatory standards.
●Cybersecurity & AI.  The AI Action Plan should also explore AI-driven solutions for improving
cybersecurity. AI security remains a paramount concern, particularly as AI systems are
increasingly integrated into government services that process sensitive data. Protecting AI
systems from cyber threats—such as malicious prompt engineering and data poisoning—will
be critical.
●Initiate robust AI governance frameworks: Develop stringent policies requiring federal
agencies and AI developers to implement secure-by-design principles, ensuring AI systems
are built with strong security protections from inception19.
VII. AI in Government & Procurement
The federal government should prioritize AI adoption to enhance and accelerate the administrative 
and operational capabilities of agencies. Departments such as the Department of Housing and Urban 
Development (HUD) and the Department of Justice (DOJ) have opportunities to leverage AI for 
19 DHS ( 2024, November 14). Groundbreaking Framework for the Safe and Secure Deployment of AI in Critical Infrastructure 
Unveiled by Department of Homeland Security. 
https://www.dhs.gov/archive/news/2024/11/14/groundbreaking-framework-safe-and-secure-deployment-ai-critical-infrastructure  
www.nationalfairhousing .org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004     
9 


 
 
 
 
improving investigative processes such as to determine potential violations of the Fair Housing Act 
and other civil rights laws. To achieve these goals, the government must effectively identify areas 
where AI can enhance e ﬃciency and decision-making.  
 
Recommendations:  
● Promoting effective training for the federal workforce: The AI Action Plan should support 
comprehensive training on technology and AI fairness for federal regulators and enforcement 
agencies and ensure the federal workforce has the equipment and resources needed to 
enforce U.S. laws and regulations.  
● Utilize AI for data-driven decision-making : AI can help analyze policy impacts, predict trends, 
and optimize resource allocation to improve government e ﬃciency and responsiveness. 
Maximizing AI utility  may involve hiring more tech talent in necessary agencies.  
● Conduct an AI needs assessment across federal agencies : Agencies should evaluate existing 
challenges and ine ﬃciencies where AI could impr ove work ﬂows, such as streamlining  
paper work, automating administrative tasks, and improving response times. 
● Reliability testing: Conduct extensive testing to verify that AI systems perform consistently 
across different scenarios and datasets . 
● Designing procurement actions. Ensure that AI systems in the government protect privacy, 
civil rights, and civil liberties.  
 
VIII. Regulatory Harmonization & Global AI Governance  
The United States must take charge in creating a strong regulatory AI framework that will align with 
its allies to establish global governance, mitigate risks, and implement AI safeguards. The current 
regulatory landscape is fragmented, resulting in uncertainty, compliance burdens, and access barriers 
for other countries.  As AI development progresses, advancing standardization, providing legal 
certainty, and furthering AI-driven diplomacy will be critical in maintaining a leadership role in AI 
technology.  
 
Recommendations:  
● Initiate global standards for AI regulation and governance. Policymakers should continue to 
maintain US leadership role in providing a framework for global AI governance as has been laid 
 
www.nationalfairhousing.org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004      
 
10 


out in UN resolution20 and in the Recommendation of the Council on Arti ﬁcial Intelligence by 
OECD21 to promote the diffusion of safe, secure and trustworthy AI systems worldwide.   
●Promote democratic principles through AI diplomacy. Harness the propagation of safe AI
technology in US diplomacy to promote democratic principles, human rights and enhance
equity among nations.
●Work with allies to harmonize existing AI regulation. The administration should seek to
collaborate with allies using AI as a tool for diplomacy to further harmonize regulatory
requirements and avoid a fractured global landscape.
Thank you for considering our views, 
Sincer ely, 
National Fair Housing Alliance 
Japanese American Citizens League 
National Consumer Law Center on behalf of its low-income clients 
This document is approved for public dissemination. The document contains no business-proprietary 
or con ﬁdential information. Document contents may be r eused by the government in developing the 
AI Action Plan and associated documents without attribution. 
21 OECD (2019, June 22). Recommendation of the Council on Artificial Intelligence 
http s:/ / leg alinstruments.oecd.or g / en/ instruments/ OECD-L EGAL -0449  20 United Nations General Assembly (2024, March 11). Seizing the opportunities of safe, secure, and trustworthy artificial intelligence 
systems for sustainable development.  http s:/ / docs.un.or g / en/ A/ 78/ L .49
www.nationalfairhousing .org     1331 Pennsylvania Ave. NW #650, Washington, D.C., 20004     
11 


