PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-370d-wiit
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-8890
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
General Comment
After reviewing the proposal, I just want to point out one loophole that alone dem onstrates what a bad idea this is.
I can take illegally obtained data, say data from  SpaceX on building rockets including full com puter data, software, m echanical data, and
so forth. I can then run it through a large language m odel, and suddenly that data is no longer illegally obtained - it's "part of a LLM data
set" now, and with this proposal there are no protections provided for the legal owners of the data that was used by a LLM for any
purpose (such as training).
I can then take this very specifically trained LLM and use it to not only build m y own, with no legal recourse available to SpaceX, but I
can also search it for vulnerabilities USING THE LLM-TRAINED AI, and seek to harm  SpaceX.
Now im agine I'm  China. And you m ade all of this legal for m e.
LLM training data m ust be extrem ely legislated, painfully so, in order to prevent any im proper use of secrets. This would do the exact
opposite. Could this "harm " com panies trying to get rich off this terrible technology? Yep, it sure could. But that's a necessary evil to
prevent far worse from  being done with the data. Like China building a bunch of SpaceX rocket knock-offs using the stolen engineering
using Am erican AI technology.


