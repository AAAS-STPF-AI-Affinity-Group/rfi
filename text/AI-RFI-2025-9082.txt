PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-31j6-1bwn
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-9082
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
General Comment
See attached file(s)
Attachments
AI Action Plan Com m ent


I write to express some serious reservations about the state of generative AI in the United 
States at the moment, and to recommend several principles that should be applied to the 
development and implementation of the Action Plan. I am a library paraprofessional and work 
with technology every day, and have become quite familiar with AI tools as a result; I am also a 
writer who doesn't want her words to be used to enrich the largest companies in America.
At present, there is a profound lack of clarity in the law regarding the use of publicly-available 
but non-public-domain material in the training of generative AI models, especially large 
language models (LLMs) and image generators. Some tech companies have argued that 
principles of fair use permit them to use anything that exists on the public Internet to train their 
models; this is a profound abuse of the principle of fair use, which is intended to allow the 
limited  use of portions  of copyrighted material for specific (principally educational or other 
nonprofit) purposes (17 U.S.C. § 107). If accepted, this argument would pervert the fair-use 
doctrine by using it to legitimize massive use of the entirety of a copyrighted work for 
commercial purposes, without the permission of, or compensation for, rights-holders. The Action 
Plan needs to specifically address and rebut this contention.
Turning from copyright to patent law, tech companies like Google and Meta have argued 
publicly that American innovation in AI will be impossible if they are not permitted to train their 
models on anything they happen to find on the Internet, without compensation to, permission 
from, or even awareness of the creator of that thing. This is not only nonsensical (the tech 
companies have somehow managed to survive this long without being allowed to steal other 
people’s work for their own profit) but entirely backwards: innovation in every  field will be stifled 
if the tech companies are allowed to leach whatever they want from anything and everything 
without restriction, permission, or compensation. Art, music, literature, code – what incentive is 
there to create if one knows that Google or Meta or Open AI will just vacuum it up, repurpose it, 
and use it to make even more money? The Action Plan must reject this argument entirely, and 
prioritize the interests of individual human creators over those of artificial content aggregators.
Animating these objections are three key principles that should be foregrounded as the Action 
Plan is developed and put into practice. Firstly, consent : the government should ensure that the 
works and words of artists, other creators, and all Americans are not used to train generative AI 
models without their express consent -- on an opt-in basis, with fair compensation for this use. 
Secondly, authenticity : if a technology company uses AI tools to create a piece of content, it 
should be labeled as such so that consumers are not misled – and the training data used to 
create it should be disclosed. There is a clear need for a consumer to know whether something 
that they are using, reading, or watching was created by an actual human or by an LLM. And 
thirdly, innovation : the vital importance to the American economy, and the American spirit, of 
individual artists, writers, musicians, coders, and creators of all kinds. These people and their 
art, their individual creations, are what makes generative AI work at all; if their work is to be 
used to train an AI model, it must be on their terms, and not on the terms of the largest 
companies in the world.


Personally, I am skeptical about the use of generative AI in general -- not all AI, for other types 
(such as those capable of machine learning) can be extremely beneficial without generative AI's 
inherent flaws. But everyone, regardless of their opinion of AI of any type, should be able to 
agree that giant technology companies should not have the right to use the fruits of other 
people's labor for free and without their consent.
Thank you for your time.


