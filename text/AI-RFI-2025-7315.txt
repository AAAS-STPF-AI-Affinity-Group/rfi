PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-1bo5-rkys
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7315
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
Em ail:  
General Comment
Dear President Donald Trum p and the United States Governm ent,
I want to tell you that what you are doing is wrong.
Funding and authorizing the developm ent of artificial general intelligence (AGI), an AI system  that is slightly m ore intelligent than all hum an
experts in any field, and artificial superintelligence (ASI), an AI system  that is several tim es m ore intelligent than all hum ans com bined,
threatens the extinction of all life on Earth.
This is a violation of the first three inalienable rights of the U.S. Constitution: life, liberty, and the pursuit of happiness.
AI experts warn that the risk of extinction from  AI is very real.
“I actually think there is a greater than 50% existential risk [of AI wiping out hum ans],” says Geoffrey Hinton, a Nobel Prize winner in AI.
“AI will probably lead to the end of the world, but in the m eantim e, there will be great com panies using m achine learning,” says Sam
Altm an, CEO of OpenAI.
A poll of 2,778 AI researchers published in 2023 found that 19% of respondents said AI would wipe out hum ans. The danger here is that
AGI/ASI m ay want to do som ething that will lead to our extinction, sim ilar to how we caused the extinction of m any less intelligent
species, as they becom e the m ost intelligent species on Earth. 
And m any experts agree that if ASI goes rogue, it can’t be turned off. 
The benefits of AGI and ASI are not worth the threat of extinction, especially if there is no em pirical way to know for sure what the
likelihood of extinction from  AGI/ASI is. 
Stop the crazy arm s race with China and Russia to build som ething that will kill everyone on Earth. 
The im pact of hum anoid robots on society m ay not be positive. 
Som e people worry that robots will replace hum an jobs, 
and there m ay be resistance to this. 
This societal backlash could hinder technological progress. 
Hum anoid robots could raise ethical issues. 
People m ay m isunderstand that m achines can understand and express em otions, 
and this could increase their dependence on robots. Also, if the robot's behavior does not m eet hum an m oral standards,
problem s m ay arise.
It is not sim ply a m atter of stopping technological developm ent, but an essential m easure for the sustainability of hum anity.
If we want to protect a world led by people, not a world led by AI.
We have reached a world where there is no end to developm ent and no lim it to speed.
However, I think that all technologies are m eant to be used m eaningfully in relation to hum an life.
In order to be used safely and usefully, we need to pause for a while, anticipate side effects, and prepare for them .
I also think that there is nothing to lose.
This is because we can take som e tim e to prepare,
and then spur developm ent again.
You m ight argue that two years is a long tim e, but if hum an life is essentially a priority,
I think that hum ans should be able to lim it and control the speed of technology.


So I think it is tim e to pause technological developm ent for a while and take care of the social im pact together.
Let's stop the "uncontrolled developm ent race" that even developers have difficulty controlling, and m ove forward to "create m ore
accurate, safer, and m ore transparent AI." Now that we have entered the spring of AI, it is understood as a speed control theory that we
should take a breather and spend the tim e in the “AI sum m er” to enjoy the benefits of technology rather than rushing into the fall when we
will reap the fruits. 
Robots for hum ans have becom e hostile to hum ans as they acquire self-awareness. 
They even confine or attack hum ans. 
There is no way to know for sure that AGI/ASI will never cause hum ans to becom e extinct or perm anently disable the hum an species. 
I don’t want to show m y children being dom inated in the future. 
Do President Trum p and the US governm ent want to create a world where their children and grandchildren are dom inated by hum an-
shaped hum anoid robots? Or do they not want to leave behind a happy life in a world where only hum ans live? 
I would like to see a world where only hum ans live. 
We now dem and the following from  the US governm ent: 
1) Create a new am endm ent to the US Constitution that perm anently prohibits the developm ent of artificial general intelligence (AGI) and
artificial superintelligence (ASI). 
2) Prevent hum an workers from  being replaced by AI system s if they do not want to be replaced. 
3) Prohibits the use and creation of AI-generated im ages, text, video, and audio.
4) Prohibits the use of AI to create biological and chem ical weapons.
5) Prohibits the use of AI in weapons system s.
6) Include a citizens' assem bly of random ly selected U.S. citizens in the federal legislature.
7) Prohibits the developm ent of hum anoid robots (killer robots, dom estic robots, etc.).


