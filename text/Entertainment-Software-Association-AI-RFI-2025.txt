March 15 , 2025 
Filed t hrough email at 
Suzanne H. Plimpton 
Reports Clearance Officer  
National Science Foundation 
2415 Eisenhower Avenue Alexandria, VA 22314 
Re:  R
equest for Information  on the Development of an Artificial Intelligence 
Action Plan, 90 Fed. Reg. 9088, pp. 9088-89 ( March 15 , 2025)  
Dear Ms. P limpton : 
The Entertainment Software Association1 (“ESA”) welcomes the  
opportunity to respond to the Office of Science and Technology Policy’s  (“OSTP”)  and 
the National Science Foundation’s (“NSF”) request for information (“ RFI”) from 
stakeholders on what should be the administration’s priority policies that will help the 
United States to maintain its leadership on innovation in artificial intelligence (“AI”) 
technologies.2  
ESA members welcome the administration’s objective of promoting 
innovation and creativity  in the development of AI technologies through the elimination  
of restrictive policies  that hamper the ability of U.S. companies to innovate. While ethical 
considerations remain important, a lighter regulatory touch ensures that AI development 
is driven by market demands rather than government constraints. To assist in 
accomplishing the administration’s vision  of restoring the American entrepreneurial 
spirit, ESA members encourage the U.S. government to adopt a risk- based regulatory 
approach that avoids disincentivizing minimal-risk uses of AI technology, such as video 
1 ESA is the U.S. trade association for companies that publish interactive entertainment software for video 
game consoles, handheld devices, personal computers, and the internet.  Our members not only create some 
of the world’s most engaging interactive experiences  for consumers, but they also develop novel technologies 
that are at the cutting edge, such as virtual, augmented, and mixed reality hardware and software as well as 
the latest consoles and handheld video game devices.  
2 The White House’s Executive Order on Removing Barriers to American Leadership in Artificial  
Intelligence , directs certain federal agencies to develop and submit to the president an action plan on AI  
that propels U.S. businesses forward with respect to AI.  Exec. Order No. 14179, “ Removing Barriers to 
American Leadership in Artificial Intelligence ,” 90 Fed. Reg. 8741 (2025) available at   
https://www.whitehouse.gov/presidential- actions/2025/01/removing -barriers-to-american-leadership -in-
artificial-intelligence/.  ent'· 
association 


games and other entertainment media, and long-standing practices of self -regulation. For 
that reason, w e ask that OSTP and NSF : 
•Realize that regulations should not adopt a “one- size-fits-all” approach, but
instead consider the sector and the use or application in which AI technology is
deployed to determine whether such use is a high-risk or low- risk;
•Recognize that the video game industry has a long and successful history of using
artificial intelligence in game development and that those uses are low - to no-risk;
•Be aware that concerns over fraud, misinformation and other harms are generally
not present in expressive works for entertainment, such as video games, where
consumers expect to be interacting with fictional and/or creative worlds and
characters.
•Understand that general transparency and labeling obligations should focus on
high-risk AI systems but also be thoughtful about context and nuance, and not be
overbroad in scope. Different creative industries must be permitted to take an
approach to labeling or watermarking that works best for their stakeholders;
•Encourage a self -regulatory approach for low- to minimal-risk uses of AI
including the promotion of trust and safety of players online;
•Understand the importance of intellectual property protection for innovation and
creativity with respect to AI  inventions and content ; and
•Partner with the private sector on policies to create a digitally advanced workforce
and educate the next generation of students and workers.
The Video Game Industry  Has a Longstanding History of Innovation 
Including in Artificial Intelligence  
Every day, millions of Americans play video games. Research has shown 
that more than 190 million players in the United States drove industry growth to the tune 
of $58.7 billion in 2024 with $50.6 billion spent on content, $4.9 billion on hardware and 
an additional $3.2 billion on accessories.3 The industry is fast-growing and leaves a deep 
economic footprint. In 2023, it generated direct economic output of more than $101 
billion, added more than $66 billion in GDP to the U.S. economy and created over 
3 ENTERTAINMENT SOFTWARE ASSOCIATION , “U.S. Consumer Spending on Video Games Totaled $5 8.7  
Billion in 202 4,” Jan. 23, 2025 at https://www.theesa.com/u -s-consumer -spending-on-video-games-totaled-
58-7-billion-in-2024.nt'· 
association 


350,000 jobs.4 Video game companies distribute their games, hardware, and services 
globally. Through innovative subscription business models, some companies have been 
able to achieve monthly totals of tens of millions of active users in ongoing engagement 
with new and extra content , as well as  live services. In tandem with the evolution of 
games, the industry’s self-regulatory body, the Entertainment Software Rating Board 
(“ESRB”)  provides information to parents to help them decide what types of games are 
appropriate for their families.5   
While video game companies routinely adopt and develop new technologies to 
improve game development processes, the use of artificial intelligence in video games is 
long-established and should be considered minimal-risk. ESA members consider 
generative AI t o be another emerging technology that will be useful in designing and 
operating the next generation of video games in areas such as content creation, art 
generation, animation, sound, natural language processing (for example, natural speech 
and responses from non- player characters within the game), and localization.  
The video game industry has a long and successful history of utilizing artificial 
intelligence (“AI”) in game development.  Various forms and iterations of AI technology, 
including machine learning, have been deployed in games for over two decades as useful 
tools for a variety of purposes, such as background and terrain generation, processing or 
analysis of data within the game, and quality control.   
The Ideal Regulatory Framework: Why a Risk- based Approach Works  
Regulations should not adopt a “one- size-fits-all” approach but should instead 
consider the sector and the use or application in which AI technology is deployed to 
determine whether such use is a high -risk or low-risk. High-risk applications, in which 
the unmitigated use of AI could result in significant risks to safety, privacy or access to fundamental resources, are best suited for regulation. Entertainment software, such as video games and related interactive experiences, such as virtual reality, should be considered low-risk. Less prescriptive regulation for low-risk appli cations incentivizes 
investment and innovation while decreasing administrative burdens. In addition, industry- or sector-specific best practices or voluntary frameworks are most appropriate for 
regulating low-risk applications because they promote creativity  and innovation, like in 
video games. 
Because A
I models used in low- risk situations , such as video game development, 
do not impact  a person’s rights or access to basic necessities , certain aspects of AI 
regulation would impose high administrative costs  and hamper growth and innovation 
4 Martin Grueber  and Dylan Yetter, Video Games in the 21st Century: The 2024 Economic Impact Report 
available at  https://www.theesa.com/wp -content/uploads/2024/02/EIR_ESA_2024.pdf .  
5 ENTERTAINMENT SOFTWARE RATING BOARD, “About ESRB: What We Do and Why,” available 
at https://www.esrb.org/about/ . ent'· 
association 


without yielding any benefit to the end user or the product/system. This includes 
requirements for video game developers to conduct red -teaming,6 implement human 
oversight, offer opt-outs of automated decision-making technologies7, schedule mandated 
pre-deployment impact assessments, and make consumer -facing disclosures about new 
training data. In contrast, the use of AI in video games does not present a high risk to consumers or society.   
 Transparency and Labeling of Content Should Align with the Level of Risk Posed 
ESA 
member companies  believe that the regulation of generative AI and AI-
generated content should also take a risk -based approach, recognizing that the sort of uses 
of AI in video games, which are not designed to deceive or harm, are low- or no-risk. As 
evidently artistic, creative, or fictional works, video games should not be subject to burdensome AI transparency, disclosure, and labeling requirements. This is a crucial issue for the video game industry because players look to games for entertainment and are accustomed to in teracting with advanced technology, which may include AI and/or 
generative AI. Unlike contexts in which an important life decision is made about an 
individual or in which AI-generated content may be used to deceive consumers, or there is a need to protect consumers from misinformation , the use of AI-powered creator tools 
by video game developers and publishers poses little to no risk and is an integral piece of 
the creative and interactive content that improves the player’s experience.  In addition, i t 
would be unnecessary and impractical to require video games to contain disclosures, notices or labeling of the types of technologies used in video game development when companies have been using the technology responsibly in an entertainment, fictional context and where player confusion is not an issue. 
Transparency and labeling obligations need to be proportional to the risk level and 
a
lign with consumer expectations. They  should not be required in situations where it is 
clear to a reasonable player that they are interacting with AI -generated content.8 Instead, 
6 Video game development, quality assurance, or internal analytics should be exempt from red- teaming 
requirements.  AI systems used in video game development are generally considered less likely to pose the 
same risks as AI systems that are publicly availab le and directly accessed by many individuals and 
companies.  
7 Automated decision -making technologies are a foundational component of all online services, including 
the computational processes that power video games and there are already existing opt -out and choice 
options for consumers.  Video game publishers have been at the forefront of using automated decision-making technologies to make games more fun to play, to protect their users and to promote a positive gameplay environment, player safety, and online safety.  Allowing players to opt -out of use of or 
interactions with AI tools would undermine safety objectives and the quality of gameplay.  For example, 
members use these technologies to detect and prevent security incidents, cheating, fraud, harassment, bullying, and other unlawful or malicious activity.  Overly broad regulations in this space, such as broad opt-out rules, could impede the basic functionality and business operations of online services.  
8 Further, to the extent that any labeling or watermarking is required, purpose and proportionality with  
respect to expressive content is crucial. What may work for an image- generation or image licensing  
platform may not work for a computer program like a video game. Not only is such a requirement cost - 
prohibitive for video game companies, especially small - to medium -sized companies, overuse of  ent'· 
association 


we recommend a self -regulatory approach with different creative industries deciding if 
and what works best for their stakeholders. 
 
Fortunately, private sector coalitions are already working on the development of 
open standards for provenance and authentication and understand the importance of collaboration but also that any standards that are developed in this space will depend on the type of industry and type of media.  The administration should encourage these efforts and resist calls to impose mandates or broad rules for content standards adoption, tracking or labeling. Context matters. What may be best practices for images, video or audio may not work for video games. A one- size-fits-all approach that requires mandates, 
as is being considered in other countries and here at home, will only chill both creativity and innovation. The path to maintaining U.S. technological competitiveness, both domestically and globally, will be through an understanding of context and that all content is not the same nor should it all be treated the same.  
 
The U.S. government already recognizes , through long-standing practice, that a 
multistakeholder approach to standards development is crucial. Nowhere is this approach more important than when it comes to content, especially in an ecosystem with many and varied parties such as platforms hosting user-generated content, video gam es, 
foundational AI models, news media, or film studios.  
 
Self-Regulation Empowers Video Game Companies to Promote and Foster 
Online Safety  
 
A self-regulatory approach allows the industry to ma ke the gameplay experience a 
safe and positive one for all players by creating and using cutting-edge technologies, including AI. For over thirty years, the industry has worked to ensure that consumers—
especially parents and caregivers —have the most comprehensive information and tools 
needed to make informed decisions about video games. Since 1994, ESRB has provided parents with age and content ratings for video games and apps to help them make informed decisions about which products are appropriate for their family.
9  
 
Video game communities benefit from environments that encourage 
sportsmanship, camaraderie and mutual respect. AI safety  technologies are often enabled 
in the background of gaming environments, working to prevent harm before it happens and allowing the industry to proactively address inappropriate content and conduct without having to rely on players to report incidents. These technologies, which include communication -filtering, image -hashing, and anti-grooming technologies, can work 
hand-in-hand with skilled human moderators who help monitor many gaming 
environments. ESA member companies may also customize their approach to human 
disclosure and labeling can also desensitize and create user fatigue (for example, if every non -player 
character, scene—including background—or level in a game is labeled) and may become meaningless as  an 
indicator of deception, especially as more and more content will either be created or modified with a 
generative AI tool in the near future.  
 
9 ENTERTAINMENT SOFTWARE ASSOCIATION , “Trust and Safety,” available at    
https://www.theesa.com/trust- safety/. Accessed Feb . 27, 2025. ent'· 
association 


moderation and advanced technologies depending on what is most appropriate for their 
games, services and player community that  empower players to manage their gameplay 
experience and increase trust . 
AI tools can  also increase efficiency  for companies  in identifying fraudulent, 
harassing, malicious or deceptive, or other harmful activity, such as cheating in video games.  Cheat software, such as  bots and hacks, enable the modification of a game to 
create an unfair  advantage for a player. The rise and sale of such software negatively 
affects video game companies and consumers by diverting significant revenue away from game developers and publishers. It also increases the threat of consumer fraud, including through account takeovers via phishing or theft of payment information connected to in-app purchases. Therefore, we advise the U.S. government that  AI regulation should 
always explicitly exempt activities that support the detecti on or addressing of fraud, 
platform integrity, or abusive practices, an approach that is consistent with those taken in 
other contexts, such as comprehensive privacy laws. We think that concerns on content moderation should be addressed through existing laws and regulations but if any change to existing law is desired, it should not impact the ability of video game companies to detect and prevent malicious activity that could compromise player safety or the inte grity 
of the platform. 
Self-
regulatory approaches to the promotion of fair and positive play through 
moderation should be encouraged. Video game publishers should retain the right and ability to employ moderation tools that work best for each game and its associated player 
communities.  In creating guidelines and best practices, the U. S. government should 
consider that intervention may be needed only under certain limited circumstances, such 
as for example, in high-risk contexts where a market failure can be identified and even 
then, it should be thoughtful and restrained. 
Existing Intellectual Property Laws are A
dequate to Protect Artificial 
Intelligence Technology in Video Games  
Intellectual property rights are vital to the innovative AI technologies 
incorporated into video games. Robust rules on intellectual property rights preserve incentives for companies in the U.S. video game industry to continue producing the engaging content and interactive experiences that consumers want. It also provides a certain assurance for companies as they invent new technologies that allow them to offer players new ways to interact with content. Because t he video game industry has been 
using AI technology responsibly for decad es, and consistent with a risk-based regulatory 
perspective,  we think that current intellectual property  law remains an adequate 
framework to analyze those uses and are recommending no changes to either law, policy, or practice, at this time . The agencies expert in intellectual property , the U.S. Patent and 
Trademark Office (“USPTO”) and the U.S. Copyright Office, have already largely 
adopted this point of view and we encourage them to maintain it.  ent'· 
association 


Maintain Innovation Through Robust Patent Policy  
As an industry at the forefront of innovation, ESA members rely on the strong 
protection and enforcement of patents.  They  own global portfolios containing thousands 
of patents that advance the state of the art in entertainment software and hardware, 
including animation, image generation and processing, machine learning and AI.  T he 
industry does not consider changes to U.S. patent law , at this time,  to be necessary  and 
does not believe that the use of AI  software should impact patentability determinations 
made by the USPTO.  Existing law and USPTO practice are sufficient to account for AI 
in such determinations. 
Continue to Uphold Copyright Principles  
Copyright protection is vital to the innovative AI technologies incorporated into 
video games. Because U.S. copyright law and regulations are already drafted to tackle the 
advent of new technologies and have adequately addressed other technological innovations over the last century, we should not assume a different result is called for here. Although certain uses of generative AI have launched questions of copyrightability 
and authorship, it is important to remember that AI technology is and should be treat ed as 
any other software tool with respect to copyright protection. 
Carefully Assess C
opyright Transparency Requirements 
Consistent with our position that the U.S. government should encourage a robust 
marketplace for emerging technologies by taking a risk- based perspect ive, we believe 
that the mandated disclosure of the use of copyrighted works in machine learning needs careful consideration and balancing of priorities, especially when the AI developer owns or licenses the works at issue or the resulting output, or when mandated disclosure could jeopardize confidential information, trade secrets or other protected data.
 If the purpose of 
such disclosure is to enable copyright owners to enforce their exclusive rights, then there would appear to be little justification for the imposition of a transparency and disclosure requirement on a developer of a non-public-facing AI system that is trained on the developer’s own works, internal, licensed or legally accessed data, or on an implementer of a foundation model that fine tunes the model on its own or licensed works. To the 
extent that a video game developer or publisher is also a user of other third-party 
software, such as an AI  model or a tool, an attenuated chain of responsibility becomes 
burdensome and does not substantially advance the goals that spurred the demand for such mandates in the first place.
 
Avoid the Over-regulation of D igital Replicas 
Digital replicas are realistic computer -generated representations of an individual’s 
image, likeness, or voice that typically appear in expressive works, such as video games 
or movies. They  should be distinguished from deepfakes, which are realistic, materially 
deceptive content , created using software, that  is intended to deceive, mislead or defraud ent'· 
association 


the public. ESA supports efforts to regulate intentionally deceptive use of a person’s 
likeness. However, regulation of deepfakes must be consistent with constitutional protections such as including clear exceptions for First Amendment- protected expressive 
works, espe cially fictionalized uses for entertainment like video games.  
Because video games are important artistic works of storytelling, legislation on 
digital replicas, whether state or federal, must include the same crucial constitutional speech protections found in state right of publicity laws and avoid imposing obligations 
that would hinder the ability of video game companies to bring to players the immersive and engaging experiences they want while also productively collaborating with artists and performers who bring those experiences to life. 
 
   Global Engagement is Essential for  U.S. Leadership on Artificial Intelligence   
  As artificial intelligence continues to shape the global economy, the U.S. must 
actively engage with international partners to sustain its technological leadership and 
drive innovation forward. As developers of AI technology and creators of AI- enabled 
content, the video game industry increasingly depends on strong digital trade principles to foster creativity and innovation, ensure market access, and support the growth of this vital export secto r. 
 Digital trade has grown significantly for the video game industry, which  
has seen in the past few years marked shifts (from physical to digital formats) in the 
derivation of its revenue from the sale of video games and related services. ESA members are an integral part of the digital economy and rely on rules and policies that promote principles of fairness and flexibility in order to succeed commercially on the modern internet. As such, the industry supports norms that promote digital trade in content, goods and services, the results of which are beneficial for both industry and consumers, including: 
• strong protection and enforcement of intellectual property rights; 
• enabling the free flow of data across borders, avoiding data localization  
requirements ; 
• preventing forced transfers of source code and other technology as a condition of 
doing business; and  
• upholding and promoting global agreements against  the imposition of customs 
duties on electronically -transmitted content.  
 
These principles are equally important where artificial intelligence and other  
emerging technologies are concerned. 
 
    
    ent'· 
association 


Workforce Training and Education Are Key to a Strong National  
Artificial Intelligence Policy  
Vice President J .D.  Vance noted in his speech  at the February 2025 AI Action 
Summit in Paris  that the administration will place American workers at the center of its 
policies on AI and is committed to pursuing actions that will encourage the use of AI to 
supplement work rather than replace workers . Video games provide a pathway through 
which the administration’s goals can be achieved.   
Th e integration of AI into the video game experience has the potential to unlock 
new workforce opportunities by enhancing rather than supplanting human creativity and 
innovation. Generative AI technology provides video game companies the opportunity to 
elevate the game experience for players and be responsive to their expectations while supporting the programmers, artists, writers, musicians, and others that are essential  to 
game development . Generative AI allows these creative and technical roles  to focus less 
on tedious tasks and more on meaningful projects that will ultimately enrich the gameplay experience. The industry relies on artistic and inventive talent to drive creativity and innovation, which requires a robust pipeline of highly-skilled workers to produce the next generation of video games and services for the U.S. and global markets. Toward that end, the industry supports the education of American students for STEAM
10 
careers and  preparation of the American workforce for an AI -powered economy. 
For example, t he ESA Foundation provides grants and “scholarships to the next 
generation of video game innovators and support schools and charitable organizations 
that leverage entertainment software and technology to create meaningful opportunities for America’s youth.”
11 We recommend the U.S. government partner with businesses and 
universities, such as through innovation hubs, to assist with such a pivot and transition. 
Conclusion  
In sum, we would like to express our appreciation to OSTP and N SF for seeking 
input from stakeholders as it creates an action plan according to the president’s executive 
order. In his speech in  Paris, Vice President Vance emphasized themes of optimism and 
opportunity with respect to AI . To unleash the innovation and creativity the 
administration has called for , the U.S. government should adopt approaches that refrain 
from imposing mandates on low-risk uses of AI and instead support self -regulation for 
those types of uses, driven by the private sector. We recommend  that OSTP and NSF  
continue to work together with industry stakeholders in these and other matters involving 
10 Science, technology, engineering, art, and mathematics.  
11 See ENTERTAINMENT SOFTWARE ASSOCIATION FOUNDATION , “Creating Social Impact,” available at 
https://esafoundation.org/ .  ent'· 
association 


emerging technologies, and we remain  available to answer any additional questions you 
may have.  
 
Respectfully submitted,  
 
______________________ 
Bijou Mgbojikwe 
Senior Policy Counsel 
   
 This document is approved for public dissemination. The document contains no business-proprietary or confidential information. Document contents may be reused by the government in developing the AI Action Plan and associated documents without attribution. ent'· 
association 


