1 
Rich Campanella, an individual 
March 15, 2025 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by 
the government in developing the AI Action Plan and associated documents without 
attribution. 
Since I first saw DeepMind’s AlphaZero chess AI back in 2017, I have believed that this 
wave of AI innovation would help humanity make great scientific discoveries and cure 
many, if not all, diseases.  While I still hold that same optimism for advancements in 
science and medicine, there is a dark side to AI in that it will have many devastating, 
anti-human effects if left unchecked.  One example would be what results from allowing 
AI companies (as well as individuals training AI systems on their local machines) to 
exploit the work of creators for training AI models without compensation and recognition 
for the rights holders. 
The ability to learn is at the foundation of all human talent and skills. It is the primary 
feature of our nervous system that is universally responsible for our ability to acquire 
and use any and all skills.  There has never been a technological advancement as 
significant as the ability for machines to ‘learn’ in a simulated way to how humans learn 
(though not actually how we learn).  As such, existing law was not drafted with this 
pivotal technological advancement in mind.  Multiple concepts, such as plagiarism 
and theft, need to be re-evaluated and updated to accurately reflect what is 
possible in the age of AI. 
This comment will address the effects that freely allowing training on copyrighted 
material will have on creators as well as America’s broader creative and entertainment 
industries, review a real-world example that demonstrates the economic harm and 
harassment possible by individuals using AI to train on copyrighted works, why we have 
to update our definitions of terms and concepts such as theft and plagiarism to reflect 
what is possible in the age of AI, why AI training without consent, compensation, and 
recognition is effectively plagiarism with a few obfuscated  extra steps, “natural 
protections” that existed for rights holders before AI that no longer are present, all of 


2 
which is context to then conclude with my view on why AI training clearly violates the 
fourth factor of fair use.
Effect on Creators and the USA’s Creative Industries: 
There is a very commonly thrown around idea that creatives are overreacting about AI 
because of how artists were freaking out when the camera was invented but the camera 
didn’t end up killing artists.  Or that musicians were freaking out when the synthesizer or 
auto-tune were invented but they didn’t end up killing musicians.  These comparisons 
are meaningless because no prior technological advancement granted machines the 
ability to ‘learn.’ 
The camera did do a lot of damage to artists but, luckily for artists, the camera could 
only do one thing; capture objective reality.  This meant that artists were able to lean 
into what the camera couldn’t do such as stylization, various techniques, textures, and 
imaginative subject matter.  Even artists that do portraits and landscapes weren’t 
entirely destroyed because a camera can’t produce the aesthetic of something that has 
been painted or drawn.  However, since AI is defined by the ability to ‘learn,’ this means 
that human artists have nowhere to go in terms of filling the void of what AI cannot do.  
Anything new that artists develop to differentiate from AI will just be trained into and 
thus ‘learned’ by AI very quickly. At this point, so many well-known, highly successful creatives have spoken out about 
the dangers of AI for human creativity in general.  It seems that the vast majority of 
people in this class are not in favor of AI in creative fields, or at least believe that it 
needs to be regulated to protect human creatives. Recently Brian May (guitarist of 
Queen) said the following in regards to a campaign against the UK’s attempt to move 
forward with an opt-out strategy for AI training: “But I applaud this campaign to make the 
public aware of what is being lost. I hope it succeeds in putting a brake on, because if 
not, nobody will be able to afford to make music from here on in.” (Daily Mail and 
Jehring).  (Opt-out systems would be extremely damaging to creatives because it would be a 
full-time job in-and-of itself, and realistically wouldn’t even be possible, to keep up with 
all of the new AI startups or even individuals employing open-source AI to train custom 
models on their local machines at home.) 
When you look at which creatives are against AI and those that are for it, one will notice 
that it’s mostly the established, household name creatives that have given timeless 


3 
classics to the world who are speaking out about the dangers of this technology for 
human creativity overall. The majority of these established, household name creatives 
have no reason to fear for their jobs, so it should be noted that they aren’t motivated 
to speak out for that reason.  They have also proven that they truly understand human 
creativity through their success, so their insight should be valued.  On the other hand, 
most of the pro-AI support related to creative fields comes from creatives who don’t 
have much to show for their skills and want to use it to compensate for skills that they 
lack, AI companies that want to sell their products, or companies that want to save 
money by laying off creatives. The best creative content (music, art, books, movies, games, etc.) has always been 
made by people who have the most talent and passion for their work. Content like this 
exudes a “made-with-love” quality representative of that level of talent and passion. It is 
this quality that has resulted in the rest of the world trying to catch up to us creatively.  If 
people such as this are disincentivized from making content due to lack of protection 
from AI training, this will result in a decline in content of the highest quality.  I believe 
that disincentivizing true artistic talent (not people that use AI and don’t have an 
understanding of the fundamentals of their craft), and passion from these industries 
runs counter to what America has always represented and will ultimately result in a 
decline of America as a leader of creative and entertainment-oriented industries in the 
world. (It is also important to note that AI requires novel, high-quality data in order to evolve, 
and pushing out the most talented and passionate creatives from the industry will 
eventually result in AI being starved for the data it needs to evolve.) 
I believe that even the act of forcing the use of AI into these fields will eventually drive 
out the top-talent because AI runs counter to the personality traits of people that are 
driven by their passion for doing a particular creative activity to develop the highest level 
of skills in that medium.  This is because, as creative work is outsourced to AI, humans 
are effectively sidelined from parts or sometimes even all of the creative process. 
To use an analogy, professional athletes are driven to reach the top level of their sport 
because they love using their bodies and minds to engage in the sport itself as well as 
training and experiencing their growth over time.  Why would someone with this type of 
personality want to send in a robot to play for them instead of playing themselves? The 
idea of a professional athlete sending in a robot to substitute for them is in fundamental 
opposition to the personality traits that result in top-level athletes in the first place.  
Allowing robots in the NFL would result in top-talent humans eventually choosing to do 
other things rather than pursue greatness in football; and would anyone actually want to 


4 
watch robots play football against each other more than once or twice after the novelty 
quickly wears off? I don’t think so and I believe the same to be true about AI-created art. 
AI companies such as OpenAI have suggested in their comments for this ROI that they 
need the ability to train freely on copyrighted data to avoid losing the AI race to China.  I 
don’t believe AI companies need to be able to access all forms of copyrighted data, 
including music, visual art, movies, YouTube videos, etc., in order to continue winning 
the AI race.  We have what China wishes they had, the world’s strongest creative 
industries, and the only thing that will tip that in China’s favor is disincentivizing our best 
creative talent from pursuing their passions by allowing their work to be trained by AI 
companies to create AI products that produce competing works with the original training 
material (a clear-cut violation of the fourth factor of fair use). If it is true that AI companies need copyrighted data to compete with China, we have 
more than enough resources in our country to make sure rights holders are 
compensated for our work, rather than crippling our creative economy. 
Economic and Personal Harassment - SamDoesArts:
There are societal dangers in allowing AI models to be trained on an artist’s work 
without consent.  One of these dangers is a new form of personal and economic 
harassment now available to anyone with a computer.  This new form of harassment 
can be significantly amplified by social media communities where users can band 
together to direct collective harassment in this form toward one or more people. 
Everyone involved in making decisions regarding AI regulation should be made aware 
of an example of this form of harassment, which involves visual artist Sam Yang and the 
Stable Diffusion AI art community.  This is just a small example of what is possible if 
rights holders are not protected by AI training. 
For those who may not know, Stable Diffusion is one of the prominent AI art generators 
and is unique because it is open-source, meaning users can download and modify the 
source code for the program to fit their use cases.  As of today, the Stable Diffusion 
community on the social media platform Reddit has 630,000 members, ranking it within 
the top 1% of communities based on size on the entire website.  Since Stable Diffusion 
is open-source, the ability for any user to train their own AI models on any work of their 
choosing has become available for free. 


5 
In the video titled “Why Artists are Fed Up with AI Art”1 on Yang’s YouTube channel 
SamDoesArts, at timestamp 8:32, he details his highly disturbing experience of 
harassment from this community.  He shows numerous screenshots of particular 
interactions, comments, and even a screenshot of an email he received from the 
popular AI art website Civitai showing their support for this harassment of Yang and 
their plan to further encourage it in the Stable Diffusion online community by sponsoring 
a competition. 
 
A brief explanation of the story is as follows: A user of the open-source Stable Diffusion 
AI system trained an AI model on 300 of Sam Yang’s works without notifying him or 
getting his consent. This user shared this Sam Yang AI model with the Stable Diffusion 
community on Reddit, making it available for download by anyone who wanted to use it.  
Someone brought this to Yang’s attention, and he took to his social media accounts to 
raise awareness and voice his discontent.  In response to Yang, members of the Stable 
Diffusion community doubled down against his wishes and actually started a 
competition on Reddit to see who could train the best AI model using even more of 
Yang’s works without his consent.  They also started harassing him on various social 
media platforms. 
 
At this point, they explicitly knew that Yang did not want his works to be used for this 
purpose, and they disregarded his wishes entirely in order to harass him.  This led to 
the popular AI art website Civitai emailing Yang.  In the email, this representative for 
Civitai expressed no sympathy for Yang’s situation, used taunting language, and told 
Yang that Civitai would be sponsoring a formal competition in the Stable Diffusion 
community to train the best model on his works called “Battle of the Sams!”. 
 
Here are some notable comments that Yang shows screenshots of in his video: 
 
The first one, which is from the email sent by someone who works at the popular AI 
art-sharing website Civitai, reads: “To celebrate the work of these fine creators, we’re 
hosting a “Battle of the Sams!” where users of r/stablediffusion can vote on which of 
your models did it best.”  They go on to say that the first prize winner of the competition 
will receive an 8x10 print of one of Yang’s works, stating that they “actually believe in 
supporting artists.”  However, it should be obvious that their supposed willingness to 
purchase a single 8x10 print does not come anywhere close to outweighing the 
economic damage done to Yang by formally sponsoring a competition to have hundreds 
or thousands of people use his work against his wishes; not to mention their blatant lack 
of empathy or concern for Yang in this situation. 1 Yang, Sam. “Why Artists Are Fed Up with AI Art.” YouTube, 24 Dec. 2022, 
https://www.youtube.com/watch?v=5Viy3Cu3DLk&amp;t=636s. Accessed 30 Nov. 2023. 
 


6 
Two other notable comments from random harassers are: “Sam failed to understand 
that we hold all the cards, and we can do whatever we want.  An artist has no right to 
speak to gods.” “You can expect even more Samdoesarts [AI] models.  This is just the 
start.  Probably a lesson to show that you can’t stop this even if you want, adapt and 
accept or keep crying.” 
This issue represents more significant risks than simply some online harassment or 
cyberbullying. This can be viewed as economic harassment because people can band 
together to coordinate a market flood of work in another person’s style with the sole 
intent of devaluing their work and damaging their career.  AI art models can generate 
images in seconds right now, and things will only get faster.  This means people could 
flood the market with thousands or hundreds of thousands of works in another artist’s 
style if they decide they want to harass a particular artist for whatever reason.  Other AI 
systems already exist for automating inputs to AI models, so this could be a situation 
where people press a button and let the computer entirely automate the generation of 
hundreds of thousands of images that they then use against the artist they have chosen 
to target. I imagine that many people involved in these online AI art communities are from a 
relatively wide range of ages (up to a point), but I am sure a decent amount of them are 
relatively young.  A technology that allows anyone, including kids, to be able to 
personally and economically harass professional adult artists in this way is very 
dangerous.   
The ability for anyone, including kids, to train AI models on anyone’s work puts 
far too much power over professional creators into the hands of anyone who 
owns a computer. 
Plagiarism: 
Again, I believe AI technology is incredible for doing things that are simply beyond 
human capability - like parsing terabytes worth of data to find obscure correlatory 
patterns that no human would be able to find - but when it’s used to produce content 
that humans already produce I fail to see how it is anything other than a giant plagiarism 
machine with some extra, obfuscated steps. 
We all have an intuitive sense of fairness and I believe that anyone being honest in their 
analysis of AI should recognize egregious violations of this sense of fairness.  We have 


7 
to update our current definitions of terms and concepts such as plagiarism and theft to 
reflect what is possible with AI.  People with stakes in AI are currently hoping that policy 
makers and the general public do not update these terms and concepts so that they can 
slip through the fuzzy gray areas that have opened up with the advent of this tech. 
In order to update these concepts to the age of AI, it’s important to break them down to 
view what they represent at their core; their essence.  The word and concept of 
plagiarism is something related to our intuitive sense of fairness.  It reflects the fact that 
we don’t think it’s fair for someone to use work done by another person to profit without 
compensation or recognition to the person who did the work, but also, even simpler than 
that, it reflects that we don’t think it’s fair for people to profit off of work they haven’t 
done.  Apply those basic elements of the concept to the current age of AI. To illustrate one of these gray areas with an hypothetical example, imagine you have 
worked for years as an artist and have developed your own unique style, your own 
‘secret sauce,’ that has garnered you much success.  Copyright law protects you from 
people using your pieces of  artwork to make various products that they could produce 
and sell.  But now, what if those people had a machine that they could feed in your life’s 
work then have that machine produce thousands of works that use your own personal 
‘secret sauce’ for their own use to produce products that compete with yours? Does that 
feel fair? Your work has effectively been used against you.  The people doing this don’t 
possess your level of talent, skill, or passion for the medium of your work and they 
haven’t put in the time or energy to respectfully learn from what you have done and 
incorporate it into their own work in their own unique and original way. This gets especially murky when you consider that AI companies are training AI models 
on millions of pieces of content from thousands or more creators, making it a little more 
difficult to pin down specific violations of copyright from individual creators.  At the end 
of day, does this really feel fair? Do these companies deserve to profit immensely off of 
the talent and life’s works of so many talented, passionate artists who have pursued 
their craft in spite of the economic risks they have taken to do so? While people try to 
slip through legal loopholes that exist because law wasn’t written with protections for 
machines that can learn in mind, I think anyone being honest when they look at this 
should recognize that this just isn’t fair. Another gray area: despite how often AI companies love to throw around the word “tool” 
to describe their technology, AI models are much more than tools.  In fact, it’s in the 
name: “Artificial Intelligence.” Using an AI art model as an example, for all intents and 
purposes an AI art model is essentially a non-sentient artist.  Just like a human artist, 


8 
you can commission work from it using human written language and it will respond by 
producing master-level artwork for you.  This is not a “tool” like a paintbrush or piano. 
 
If someone commissions work from an AI art model, which is what is being done when 
people use AI “tools,” and then that person uses that work for their own personal gain, 
they have effectively plagiarised work from a non-sentient artist, or an non-sentient 
intelligence.  The difference between that and a human artist is that a non-sentient 
artistic intelligence is not going to defend its work. 
 
Does a person really deserve to profit off of work produced by another intelligence, 
regardless of whether or not that intelligence is sentient? Again, I think this super easy 
trips the intuitive sense of fairness alarm since people are attempting to profit off of work 
they haven’t done. 
 
Coming back to the gray area that relates to AI training, the specific, individual talent 
and skill that underpins, allows for, and gives rise to the works created by a particular 
person should now be considered something able to be plagiarized if it is ‘downloaded’ 
or extracted from the work of an artist by a machine without their consent. 
 
In my mind, training represents a new way to plagiarize the work of others through a 
loophole.  We must reconceptualize work to refer to the work one does to develop their 
talent.  Since one cannot copy a particular work done by a person without it being 
considered plagiarism, one can now ‘download’ or extract the talent that underpins, 
or gave rise to, the work of another so that one can access the internal qualities that 
allow a person to generate work of high quality.  If someone doesn’t have the talent to 
paint at a master level, rather than using particular works made by another, they can 
now just download someone else's talent to do so and use it for their own purposes.  
This circumvents the current idea of plagiarism since they aren’t copying specific works 
but still violates what I believe is the essence of plagiarism, which is benefiting from the 
work of another without one’s own contribution. 
 
To me, this just represents a loophole for plagiarism.  “If I can’t use their individual 
works, I’ll just use a machine to download or extract what makes them able to produce 
works of that style and quality; their talent.”  The talent and skill that underpins, 
allows for, and gives rise to the works created by a person should now be 
considered something able to be plagiarized if it is ‘downloaded’ or extracted 
from the work of an artist by a machine without their consent. 
 
  


9 
“Natural Protections”: 
Laws generally reflect the state of the world (of which technology is highly relevant) at 
the time they were created. As far as I understand, the laws related to copyright were 
not drafted with a technology that can learn as humans do and completely overlaps the 
full spectrum of human creativity in mind. 
While it's true that you can't currently copyright style, there were some incredibly strong 
"protections" already "in place" that weren't even regarded as protections because they 
were just worldly realities.  These “natural protections” were: talent, number of artists, 
time, social stigma, and the desire to be unique.  
There aren't that many people who pursue careers as artists relative to the overall 
population and there simply are not that many people talented and dedicated enough to 
develop the skill to rip off some other highly talented artist's style to begin with. There 
was also a buffer of time before other people started to replicate an artist's style or 
integrate elements of it well enough to be significant because they would have to 
actually learn how to replicate the style first. Then there is the societal protection of 
being labeled a "rip-off," which encourages artists to differentiate themselves. With all of 
these natural "protections" in place, the law was written to address needed protections 
to the degree in which they were required while maintaining a healthy balance in order 
to not stifle artists and competition in the realm of artistic IP. 
The entrance of AI removes all of those natural "protections" that were in place. Now, 
people with no artistic talent or experience can access the style of any master artist for 
whatever purpose they want, including to make money. Since the talent requirement is 
now non-existent, the number of people in a position to be able to access another 
artist's style is theoretically the entire population that has internet access. It no longer 
requires time for anyone to learn how to replicate an artist's style and integrate elements 
of it into their own style because AI can learn the style in no time, and then anyone can 
use it. Due to these natural protections being eliminated, protections now need to be 
reconsidered. 
The ability to copyright style would be severely damaging to actual creators. However, 
allowing AI to replicate style is also severely damaging to creators.  People who use AI 
to access another artist’s style are not putting in any significant amount of work 
themselves; they are utilizing a loophole to access an artist’s hard work.  Therefore they 


10 
should have no avenue to benefit from an actual artist’s hard work.  However, humans 
who learn from the styles of others absorb concepts or aspects of style and filter them 
into their own personal style (Context: Reply: “Every mathematical combination has 
already occurred”).  This organic process has been happening for a long time and 
doesn’t result in unfair competition due to the factors of human limitation and “natural 
protections.” 
The only fair solution, in my view, is to heavily restrict copyright on AI-generated work to 
disincentivize it.  This would still allow artists to naturally absorb elements of style while 
still making them their own, but prevent people who don’t have artistic talent from using 
AI to access the styles of others without putting in any work (plagiarism). 
Violation of Fair Use: 
Before providing my explanation, I would like to quote former executive at Stability.ai and 
professional composer Ed Newton-Rex.  He resigned from his role at Stability.ai specifically 
because he disagreed with the company’s and the entire AI industry’s stance on fair use. 
I disagree because one of the factors affecting whether the act of copying is fair use, 
according to Congress, is “the effect of the use upon the potential market for or value of 
the copyrighted work”. Today’s generative AI models can clearly be used to create works 
that compete with the copyrighted works they are trained on. So I don’t see how using 
copyrighted works to train generative AI models of this nature can be considered fair 
use. 
But setting aside the fair use argument for a moment — since ‘fair use’ wasn’t designed 
with generative AI in mind — training generative AI models in this way is, to me, wrong. 
Companies worth billions of dollars are, without permission, training generative AI 
models on creators’ works, which are then being used to create new content that in 
many cases can compete with the original works. I don’t see how this can be acceptable 
in a society that has set up the economics of the creative arts such that creators rely on 
copyright.2 
Though I am not a legal expert, I believe training AI models on copyrighted art clearly violates 
the fourth factor of fair use.  Consider the combination of the following three factors: 
●AI models can generate master-quality content orders of magnitude faster than humans
and will only become faster and more capable over time.
●Access to these AI systems is already widely available to the general public, does not
require any artistic talent, skill, or experience to use, and will only become more
2 @ednewtonrex. Twitter, Nov 15, 2023, 4:28 PM, twitter.com/ednewtonrex/status/1724902327151452486  


11 
accessible to the overall population over time.  This includes the ability for anyone to 
train their own AI models, currently available with open-sourced AI systems but likely 
available commercially in the future. 
●Separate AI systems and other methods to automate inputs and the operation of
generative AI systems already exist, allowing them to run and generate content without
human interaction.3 4  These types of technologies will also grow over time. (Context:
Automated Inputs)
Due to the combination of these three factors, the ability to flood the market with competing 
works that vastly outnumber the originals used to train AI models should be apparent.  This 
ability to flood the market already exists today but will become exponentially more possible as 
development results in even faster and more powerful AI systems that are more widely 
accessible to the overall population.  It certainly will not be long before AI has generated more 
high-quality art than that produced by all humans throughout history combined. 
Consider the following potential scenario: I release an album containing a new significant 
stylistic innovation in guitar playing.  Within the same day of release, numerous people hear the 
album, recognize the value of my stylistic innovation, and decide to train AI models on my work. 
Those who trained these AI models on my work share these trained models in various online AI 
communities, allowing anyone to download and use them.  Within days or even hours of 
release, there could theoretically be hundreds or hundreds of thousands of people using AI to 
generate millions of competing tracks from the AI model trained on my work.  This hypothetical 
situation needs to be avoided at all costs if creators are going to have any incentive to create.  
This is one example of why generative AI is fundamentally anti-competitive, which I address in 
more detail in a later section (Context: AI is Fundamentally anti-competitive). 
Using somewhat loose numbers for a hypothetical, let’s say the average digital painting takes 5 
hours to complete.  AI can produce competing images in seconds, but let’s say an average time 
is 30 seconds.  In the time it takes one person to finish a digital painting, a single AI model could 
produce 600 competing works.  If 100 AI models were running simultaneously, they could 
produce 60,000 competing works in the time it takes a human to produce 1 digital painting.  
Now consider the fact that millions of generative AI models will be able to generate content at 
any given time since millions of people will have these AI systems installed on their personal 
devices. 
It is relevant here to address a common talking point regarding AI training: the idea that training 
is like reading and, therefore, does not violate copyright.  Here is one quote from an article on 
Wired.com: 
There are other objections too. The US Copyright Office is currently accepting comments 
for its study on AI, and many of those submitted reveal starkly different schools of 
4 “Automate THOUSANDS of Midjourney Graphics for Your POD & Digital Products Business!” YouTube, 
YouTube, 25 Apr. 2023, https://www.youtube.com/watch?v=d0EHn7ZsUZM. Accessed 13 Dec. 2023. 3 “Midjourney Automator.” Titan XT, www.titanxt.io/midjourneyautomator. Accessed 13 Dec. 2023. 


12 
thought on whether AI training violates copyright. The Copia Institute, a think tank 
founded by Techdirt founder Mike Masnick, argues bluntly that artists have no right to 
exclude their work from AI training, because it views said training as more akin to 
reading than copying. “Ultimately when we speak of training AI we are speaking about 
letting software ‘read’ or otherwise consume works on behalf of the people developing it. 
Copyright law does not prevent reading,” its comment states. If the courts adopt this line 
of thinking—the training-as-consuming metaphor—it will be difficult to sway them with 
arguments founded on the idea of training as theft.5 
Again, the fact that we are dealing with an entirely unprecedented technological advancement, 
one that has granted machines with no human limitation a simulated ability to learn as we do, 
should render comparisons to anything before AI, including the capacity to which we humans 
can interact with copyrighted material, to be nearly useless.  There is a vast difference in the 
potential for unfair competition between a human consuming copyrighted works and a 
super-machine that can both consume and generate competing works orders of magnitude 
faster than any human or group of humans ever could. 
If it were common in the past for people to amass slave armies the size of 1 million or more 
humans with the sole purpose of having them consume specific best-selling copyrighted works 
and then focusing them on the task of producing thousands of competing works heavily inspired 
by the works they consumed, copyright law would likely be different today.  The point is that 
human limitations in the past offered some form of “natural protections” that no longer exist in 
the age of AI.  Humans’ ability to read copyrighted works did not pose anywhere near as much 
of a threat in terms of unfair competition, whereas AI that can ‘read’ in a simulated way to 
humans does. 
Though AI models are capable of producing works that may not closely resemble specific works 
they were trained on, I believe that the ability to train AI on copyrighted work without authors’ 
consent has introduced new concepts of theft that should now be defined: instead of theft of 
individual works, the ability to train on an artist’s life’s work is like a theft of overall talent 
or theft of individuality, which can be considered a new type of identity theft.  I do not 
know exactly what to call them, but this new technology has introduced a new feeling or intuition 
that creators worldwide are dealing with, trying to make sense of, and trying to find ways to 
articulate right now.  There is some profound and disturbing violation, some form of theft. 
This technology effectively allows people with no talent, skill, or experience in a specific creative 
medium to ‘download’ the talent or style of other humans who have produced high-quality work 
in that medium and then generate innumerable competing works orders of magnitude faster.  I 
believe we all have an intuitive sense of fairness and, for any honest and decent person, this 
should set off alarm bells as being wrong on numerous levels. The ability to take someone’s 
work or talent is an oppressive form of power that feels like it violates aspects of freedom 
itself.  Talent is a quality that is valued as part of our identity.  The ability to take talent from 
5 Knibbs, Kate. “Meet the Lawyer Leading the Human Resistance against AI.” Wired, Conde Nast, 22 Nov. 2023, 
www.wired.com/story/matthew-butterick-ai-copyright-lawsuits-openai-meta/.  


13 
other people is a step toward our loss of individuality. (Context: “Copyright isnt’ a jobs program” - 
Societal Concerns) 
If one were to train AI solely on the work of one human artist, this would likely resonate with 
most people as unfair and unethical, like some form of theft.  If, for some reason, AI models 
could only be trained on the work of a single artist, I do not think policy decisions would end up 
in favor of the AI companies.  However, things get a bit more murky when AI is trained on the 
works of countless artists instead of one.  This introduces a potential loophole for mass talent 
theft that AI companies seek to exploit.  The talent of an entire class of humans that pursue 
particular career paths purely out of passion is being taken and used to create products 
that will devalue all of our work in the market while also being able to compete with each 
of us specifically by replicating our individual styles.  Just because things are murky due to 
training on the work of many artists doesn’t mean there isn’t something profoundly wrong going 
on here; it just means that the protections against it arent’ yet codified (Context: A new type of 
plagiarism?). 
When humans consume content, we can understand and contextualize that content due to our 
experiences of the world through our senses.  My understanding is that AI does not possess the 
ability to understand the content it consumes; it only creates statistical correlations that allow it 
to guess what decisions a human is likely to make.  This lack of understanding on behalf of AI is 
evident in the fact that AI image generators notoriously have a problem with things like hands, 
fingers, and various aspects of the human body overall.  They do not get these elements wrong 
all of the time, and AI developers are improving on this particular weakness regularly. However, 
the point is that a human artist would never make a mistake where they accidentally paint a 
human with four arms and six or seven fingers on each hand.  
According to professor of AI Amelia Winger-Bearskin, “Generative artificial intelligence that’s 
trained on billions of images scraped from the internet does not really understand what a “hand” 
is, at least not in the way it connects anatomically to a human body.” Another quote of 
Winger-Bearskin from the same article reads: “In images, hands are rarely like this,” 
Winger-Bearskin said, holding up her hands with fingers spread apart. “If they were like this in 
all images, the AI would be able to reproduce them perfectly.” AI, she said, needs to understand 
what it is to have a human body, how exactly hands are connected to it, and what their 
constraints are.”6 
Though still functionally equivalent in ability to produce master-level artistic output, the potential 
for these mistakes demonstrates that AI does not possess a true ability to learn, which is 
defined by the ability to understand and contextualize information.  This may be relevant for the 
legal interpretation that AI is ‘learning’ or ‘reading’ from copyrighted content as humans do. 
Another quote from the same Wired.com article referenced earlier: 
6 Dixit, Pranav. “AI Image Generators Keep Messing up Hands. Here’s Why.” BuzzFeed News, BuzzFeed News, 31 
Jan. 2023, www.buzzfeednews.com/article/pranavdixit/ai-generated-art-hands-fingers-messed-up.  


14 
Many copyright experts are skeptical too. Berkeley’s Samuelson, for example, says it’s 
“ridiculous” to claim everything an AI outputs is infringing by default because of how it is 
trained.7 
If we recognize that the ability to train on the life’s work of artists is a form of overall talent theft 
or some form of identity theft, then an AI model trained on copyrighted material without authors' 
consent would represent an infringing work.  Even if the outputs of this system do not qualify as 
infringement themselves, they should be treated as such due to the process in which they were 
created. 
7 Knibbs, Kate. “Meet the Lawyer Leading the Human Resistance against AI.” Wired, Conde Nast, 22 Nov. 2023, 
www.wired.com/story/matthew-butterick-ai-copyright-lawsuits-openai-meta/.  


15 
Work Cited 
Daily Mail, and Andy Jehring. “Copyright 'sell-out' will silence British musicians, says 
BRIAN MAY.” Daily Mail, 23 02 2025, 
https://www.dailymail.co.uk/news/article-14427469/Copyright-sell-silence-British-
musicians-says-BRIAN-MAY.html. Accessed 15 03 2025. 


1 
Rich Campanella, an individual 
March 15, 2025 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by 
the government in developing the AI Action Plan and associated documents without 
attribution. 
Since I first saw DeepMind’s AlphaZero chess AI back in 2017, I have believed that this 
wave of AI innovation would help humanity make great scientific discoveries and cure 
many, if not all, diseases.  While I still hold that same optimism for advancements in 
science and medicine, there is a dark side to AI in that it will have many devastating, 
anti-human effects if left unchecked.  One example would be what results from allowing 
AI companies (as well as individuals training AI systems on their local machines) to 
exploit the work of creators for training AI models without compensation and recognition 
for the rights holders. 
The ability to learn is at the foundation of all human talent and skills. It is the primary 
feature of our nervous system that is universally responsible for our ability to acquire 
and use any and all skills.  There has never been a technological advancement as 
significant as the ability for machines to ‘learn’ in a simulated way to how humans learn 
(though not actually how we learn).  As such, existing law was not drafted with this 
pivotal technological advancement in mind.  Multiple concepts, such as plagiarism 
and theft, need to be re-evaluated and updated to accurately reflect what is 
possible in the age of AI. 
This comment will address the effects that freely allowing training on copyrighted 
material will have on creators as well as America’s broader creative and entertainment 
industries, review a real-world example that demonstrates the economic harm and 
harassment possible by individuals using AI to train on copyrighted works, why we have 
to update our definitions of terms and concepts such as theft and plagiarism to reflect 
what is possible in the age of AI, why AI training without consent, compensation, and 
recognition is effectively plagiarism with a few obfuscated  extra steps, “natural 
protections” that existed for rights holders before AI that no longer are present, all of 


2 
which is context to then conclude with my view on why AI training clearly violates the 
fourth factor of fair use.
Effect on Creators and the USA’s Creative Industries: 
At this point, so many well-known, successful creatives have spoken out about the 
dangers of AI for human creativity in general.  It seems that the vast majority of people 
in this class are not in favor of AI in creative fields, or at least believe that it needs to be 
regulated to protect human creatives. Recently Brian May (guitarist of Queen) said the 
following in regards to a campaign against the UK’s attempt to move forward with an 
opt-out strategy for AI training: “But I applaud this campaign to make the public aware of 
what is being lost. I hope it succeeds in putting a brake on, because if not, nobody will 
be able to afford to make music from here on in.” (Daily Mail and Jehring).  (Opt-out systems would be extremely damaging to creatives because it would be a 
full-time job in-and-of itself, and realistically wouldn’t even be possible, to keep up with 
all of the new AI startups or even individuals employing open-source AI to train custom 
models on their local machines at home.) 
When you look at which creatives are against AI and those that are for it, one will notice 
that it’s mostly the established, household name creatives that have given timeless 
classics to the world who are speaking out about the dangers of this technology for 
human creativity overall. The majority of these established, household name creatives 
have no reason to fear for their jobs, so it should be noted that they aren’t motivated 
to speak out for that reason.  On the other hand, most of the pro-AI support related to 
creative fields comes from mostly creatives who want to use it to compensate for skills 
that they lack or AI companies that want to sell their products. The best creative content (music, art, books, movies, games, etc.) has always been 
made by people who have the most talent and passion for their work. Content like this 
exudes a “made-with-love” quality representative of that level of talent and passion. It is 
this quality that has resulted in the rest of the world trying to catch up to us creatively.  If 
people such as this are disincentivized from making content due to lack of protection 
from AI training, this will result in a decline in content of the highest quality.  I believe 
that disincentivizing true artistic talent (not people that use AI and don’t have an 
understanding of the fundamentals of their craft), and passion from these industries 
runs counter to what America has always represented and will ultimately result in a 
decline of America as a leader of creative and entertainment-oriented industries in the 
world. 


3 
(It is also important to note that AI requires novel, high-quality data in order to evolve, 
and pushing out the most talented and passionate creatives from the industry will 
eventually result in AI being starved for the data it needs to evolve.) 
I believe that even the act of forcing the use of AI into these fields will eventually drive 
out the top-talent because AI runs counter to the personality traits of people that are 
driven by their passion for doing a particular creative activity to develop the highest level 
of skills in that medium.  This is because, as creative work is outsourced to AI, humans 
are effectively sidelined from parts or sometimes even all of the creative process. 
To use an analogy, professional athletes are driven to reach the top level of their sport 
because they love using their bodies and minds to engage in the sport itself as well as 
training and experiencing their growth over time.  Why would someone with this type of 
personality want to send in a robot to play for them instead of playing themselves? The 
idea of a professional athlete sending in a robot to substitute for them is in fundamental 
opposition to the personality traits that result in top-level athletes in the first place.  
Allowing robots in the NFL would result in top-talent humans eventually choosing to do 
other things rather than pursue greatness in football; and would anyone actually want to 
watch robots play football against each other more than once or twice after the novelty 
quickly wears off? I don’t think so and I believe the same to be true about AI-created art. AI companies such as OpenAI have suggested in their comments for this ROI that they 
need the ability to train freely on copyrighted data to avoid losing the AI race to China.  I 
don’t believe AI companies need to be able to access all forms of copyrighted data, 
including music, visual art, movies, YouTube videos, etc., in order to continue winning 
the AI race.  We have what China wishes they had, the world’s strongest creative 
industries, and the only thing that will tip that in China’s favor is disincentivizing our best 
creative talent from pursuing their passions by allowing their work to be trained by AI 
companies to create AI products that produce competing works with the original training 
material (a clear-cut violation of the fourth factor of fair use). If it is true that AI companies need copyrighted data to compete with China, we have 
more than enough resources in our country to make sure rights holders are 
compensated for our work, rather than crippling our creative economy. 
Economic and Personal Harassment - SamDoesArts:


4 
There are societal dangers in allowing AI models to be trained on an artist’s work 
without consent.  One of these dangers is a new form of personal and economic 
harassment now available to anyone with a computer.  This new form of harassment 
can be significantly amplified by social media communities where users can band 
together to direct collective harassment in this form toward one or more people. 
 
Everyone involved in making decisions regarding AI regulation should be made aware 
of an example of this form of harassment, which involves visual artist Sam Yang and the 
Stable Diffusion AI art community.  This is just a small example of what is possible if 
rights holders are not protected by AI training. 
 
For those who may not know, Stable Diffusion is one of the prominent AI art generators 
and is unique because it is open-source, meaning users can download and modify the 
source code for the program to fit their use cases.  As of today, the Stable Diffusion 
community on the social media platform Reddit has 630,000 members, ranking it within 
the top 1% of communities based on size on the entire website.  Since Stable Diffusion 
is open-source, the ability for any user to train their own AI models on any work of their 
choosing has become available for free. 
 
In the video titled “Why Artists are Fed Up with AI Art”1 on Yang’s YouTube channel 
SamDoesArts, at timestamp 8:32, he details his highly disturbing experience of 
harassment from this community.  He shows numerous screenshots of particular 
interactions, comments, and even a screenshot of an email he received from the 
popular AI art website Civitai showing their support for this harassment of Yang and 
their plan to further encourage it in the Stable Diffusion online community by sponsoring 
a competition. 
 
A brief explanation of the story is as follows: A user of the open-source Stable Diffusion 
AI system trained an AI model on 300 of Sam Yang’s works without notifying him or 
getting his consent. This user shared this Sam Yang AI model with the Stable Diffusion 
community on Reddit, making it available for download by anyone who wanted to use it.  
Someone brought this to Yang’s attention, and he took to his social media accounts to 
raise awareness and voice his discontent.  In response to Yang, members of the Stable 
Diffusion community doubled down against his wishes and actually started a 
competition on Reddit to see who could train the best AI model using even more of 
Yang’s works without his consent.  They also started harassing him on various social 
media platforms. 
 1 Yang, Sam. “Why Artists Are Fed Up with AI Art.” YouTube, 24 Dec. 2022, 
https://www.youtube.com/watch?v=5Viy3Cu3DLk&amp;t=636s. Accessed 30 Nov. 2023. 
 


5 
At this point, they explicitly knew that Yang did not want his works to be used for this 
purpose, and they disregarded his wishes entirely in order to harass him.  This led to 
the popular AI art website Civitai emailing Yang.  In the email, this representative for 
Civitai expressed no sympathy for Yang’s situation, used taunting language, and told 
Yang that Civitai would be sponsoring a formal competition in the Stable Diffusion 
community to train the best model on his works called “Battle of the Sams!”. 
Here are some notable comments that Yang shows screenshots of in his video: 
The first one, which is from the email sent by someone who works at the popular AI 
art-sharing website Civitai, reads: “To celebrate the work of these fine creators, we’re 
hosting a “Battle of the Sams!” where users of r/stablediffusion can vote on which of 
your models did it best.”  They go on to say that the first prize winner of the competition 
will receive an 8x10 print of one of Yang’s works, stating that they “actually believe in 
supporting artists.”  However, it should be obvious that their supposed willingness to 
purchase a single 8x10 print does not come anywhere close to outweighing the 
economic damage done to Yang by formally sponsoring a competition to have hundreds 
or thousands of people use his work against his wishes; not to mention their blatant lack 
of empathy or concern for Yang in this situation. Two other notable comments from random harassers are: “Sam failed to understand 
that we hold all the cards, and we can do whatever we want.  An artist has no right to 
speak to gods.” “You can expect even more Samdoesarts [AI] models.  This is just the 
start.  Probably a lesson to show that you can’t stop this even if you want, adapt and 
accept or keep crying.” 
This issue represents more significant risks than simply some online harassment or 
cyberbullying. This can be viewed as economic harassment because people can band 
together to coordinate a market flood of work in another person’s style with the sole 
intent of devaluing their work and damaging their career.  AI art models can generate 
images in seconds right now, and things will only get faster.  This means people could 
flood the market with thousands or hundreds of thousands of works in another artist’s 
style if they decide they want to harass a particular artist for whatever reason.  Other AI 
systems already exist for automating inputs to AI models, so this could be a situation 
where people press a button and let the computer entirely automate the generation of 
hundreds of thousands of images that they then use against the artist they have chosen 
to target. I imagine that many people involved in these online AI art communities are from a 
relatively wide range of ages (up to a point), but I am sure a decent amount of them are 


6 
relatively young.  A technology that allows anyone, including kids, to be able to 
personally and economically harass professional adult artists in this way is very 
dangerous.   
The ability for anyone, including kids, to train AI models on anyone’s work puts 
far too much power over professional creators into the hands of anyone who 
owns a computer. 
Plagiarism: 
Again, I believe AI technology is incredible for doing things that are simply beyond 
human capability - like parsing terabytes worth of data to find obscure correlatory 
patterns that no human would be able to find - but when it’s used to produce content 
that humans already produce I fail to see how it is anything other than a giant plagiarism 
machine with some extra, obfuscated steps. 
We all have an intuitive sense of fairness and I believe that anyone being honest in their 
analysis of AI should recognize egregious violations of this sense of fairness.  We have 
to update our current definitions of terms and concepts such as plagiarism and theft to 
reflect what is possible with AI.  People with stakes in AI are currently hoping that policy 
makers and the general public do not update these terms and concepts so that they can 
slip through the fuzzy gray areas that have opened up with the advent of this tech. In order to update these concepts to the age of AI, it’s important to break them down to 
view what they represent at their core; their essence.  The word and concept of 
plagiarism is something related to our intuitive sense of fairness.  It reflects the fact that 
we don’t think it’s fair for someone to use work done by another person to profit without 
compensation or recognition to the person who did the work, but also, even simpler than 
that, it reflects that we don’t think it’s fair for people to profit off of work they haven’t 
done.  Apply those basic elements of the concept to the current age of AI. To illustrate one of these gray areas with an hypothetical example, imagine you have 
worked for years as an artist and have developed your own unique style, your own 
‘secret sauce,’ that has garnered you much success.  Copyright law protects you from 
people using your pieces of  artwork to make various products that they could produce 
and sell.  But now, what if those people had a machine that they could feed in your life’s 
work then have that machine produce thousands of works that use your own personal 
‘secret sauce’ for their own use to produce products that compete with yours? Does that 
feel fair? Your work has effectively been used against you.  The people doing this don’t 


7 
possess your level of talent, skill, or passion for the medium of your work and they 
haven’t put in the time or energy to respectfully learn from what you have done and 
incorporate it into their own work in their own unique and original way. 
 
This gets especially murky when you consider that AI companies are training AI models 
on millions of pieces of content from thousands or more creators, making it a little more 
difficult to pin down specific violations of copyright from individual creators.  At the end 
of day, does this really feel fair? Do these companies deserve to profit immensely off of 
the talent and life’s works of so many talented, passionate artists who have pursued 
their craft in spite of the economic risks they have taken to do so? While people try to 
slip through legal loopholes that exist because law wasn’t written with protections for 
machines that can learn in mind, I think anyone being honest when they look at this 
should recognize that this just isn’t fair. 
 
Another gray area: despite how often AI companies love to throw around the word “tool” 
to describe their technology, AI models are much more than tools.  In fact, it’s in the 
name: “Artificial Intelligence.” Using an AI art model as an example, for all intents and 
purposes an AI art model is essentially a non-sentient artist.  Just like a human artist, 
you can commission work from it using human written language and it will respond by 
producing master-level artwork for you.  This is not a “tool” like a paintbrush or piano. 
 
If someone commissions work from an AI art model, which is what is being done when 
people use AI “tools,” and then that person uses that work for their own personal gain, 
they have effectively plagiarised work from a non-sentient artist, or an non-sentient 
intelligence.  The difference between that and a human artist is that a non-sentient 
artistic intelligence is not going to defend its work. 
 
Does a person really deserve to profit off of work produced by another intelligence, 
regardless of whether or not that intelligence is sentient? Again, I think this super easy 
trips the intuitive sense of fairness alarm since people are attempting to profit off of work 
they haven’t done. 
 
Coming back to the gray area that relates to AI training, the specific, individual talent 
and skill that underpins, allows for, and gives rise to the works created by a particular 
person should now be considered something able to be plagiarized if it is ‘downloaded’ 
or extracted from the work of an artist by a machine without their consent. 
 
In my mind, training represents a new way to plagiarize the work of others through a 
loophole.  We must reconceptualize work to refer to the work one does to develop their 
talent.  Since one cannot copy a particular work done by a person without it being  


8 
considered plagiarism, one can now ‘download’ or extract the talent that underpins, 
or gave rise to, the work of another so that one can access the internal qualities that 
allow a person to generate work of high quality.  If someone doesn’t have the talent to 
paint at a master level, rather than using particular works made by another, they can 
now just download someone else's talent to do so and use it for their own purposes.  
This circumvents the current idea of plagiarism since they aren’t copying specific works 
but still violates what I believe is the essence of plagiarism, which is benefiting from the 
work of another without one’s own contribution. To me, this just represents a loophole for plagiarism.  “If I can’t use their individual 
works, I’ll just use a machine to download or extract what makes them able to produce 
works of that style and quality; their talent.”  The talent and skill that underpins, 
allows for, and gives rise to the works created by a person should now be 
considered something able to be plagiarized if it is ‘downloaded’ or extracted 
from the work of an artist by a machine without their consent. 
“Natural Protections”: 
Laws generally reflect the state of the world (of which technology is highly relevant) at 
the time they were created. As far as I understand, the laws related to copyright were 
not drafted with a technology that can learn as humans do and completely overlaps the 
full spectrum of human creativity in mind. 
While it's true that you can't currently copyright style, there were some incredibly strong 
"protections" already "in place" that weren't even regarded as protections because they 
were just worldly realities.  These “natural protections” were: talent, number of artists, 
time, social stigma, and the desire to be unique.  
There aren't that many people who pursue careers as artists relative to the overall 
population and there simply are not that many people talented and dedicated enough to 
develop the skill to rip off some other highly talented artist's style to begin with. There 
was also a buffer of time before other people started to replicate an artist's style or 
integrate elements of it well enough to be significant because they would have to 
actually learn how to replicate the style first. Then there is the societal protection of 
being labeled a "rip-off," which encourages artists to differentiate themselves. With all of 


2 
which is context to then conclude with my view on why AI training clearly violates the 
fourth factor of fair use.
Effect on Creators and the USA’s Creative Industries: 
At this point, so many well-known, successful creatives have spoken out about the 
dangers of AI for human creativity in general.  It seems that the vast majority of people 
in this class are not in favor of AI in creative fields, or at least believe that it needs to be 
regulated to protect human creatives. Recently Brian May (guitarist of Queen) said the 
following in regards to a campaign against the UK’s attempt to move forward with an 
opt-out strategy for AI training: “But I applaud this campaign to make the public aware of 
what is being lost. I hope it succeeds in putting a brake on, because if not, nobody will 
be able to afford to make music from here on in.” (Daily Mail and Jehring).  (Opt-out systems would be extremely damaging to creatives because it would be a 
full-time job in-and-of itself, and realistically wouldn’t even be possible, to keep up with 
all of the new AI startups or even individuals employing open-source AI to train custom 
models on their local machines at home.) 
When you look at which creatives are against AI and those that are for it, one will notice 
that it’s mostly the established, household name creatives that have given timeless 
classics to the world who are speaking out about the dangers of this technology for 
human creativity overall. The majority of these established, household name creatives 
have no reason to fear for their jobs, so it should be noted that they aren’t motivated 
to speak out for that reason.  On the other hand, most of the pro-AI support related to 
creative fields comes from mostly creatives who want to use it to compensate for skills 
that they lack or AI companies that want to sell their products. The best creative content (music, art, books, movies, games, etc.) has always been 
made by people who have the most talent and passion for their work. Content like this 
exudes a “made-with-love” quality representative of that level of talent and passion. It is 
this quality that has resulted in the rest of the world trying to catch up to us creatively.  If 
people such as this are disincentivized from making content due to lack of protection 
from AI training, this will result in a decline in content of the highest quality.  I believe 
that disincentivizing true artistic talent (not people that use AI and don’t have an 
understanding of the fundamentals of their craft), and passion from these industries 
runs counter to what America has always represented and will ultimately result in a 
decline of America as a leader of creative and entertainment-oriented industries in the 
world. 


