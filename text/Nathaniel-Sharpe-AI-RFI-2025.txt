 
   Nathaniel Sharpe  
The rapid development of artificial intelligence has brought immense potential for scientific 
progress, economic growth, and societal benefit. However, it also carries unprecedented risks —
none more critical than the development of artificial superintellige nce (ASI), which, if 
misaligned or uncontrolled, could result in catastrophic outcomes. The current trajectory of AI 
development is reckless, competitive, and uncoordinated. If left unchecked, the race to achieve 
ASI will not reward the "winner" —it will simply bring forward the moment when humanity 
loses control. We urge the AI Action Plan to prioritize the following policy interventions: 1. 
Prohibit the Development of Artificial Superintelligence and Self -Improving AI The most 
immediate and non -negotiable safeguard is a global ban on the development of ASI and AI 
systems capable of recursively improving themselves. AI models that can autonomously enhance 
their own intelligence pose an existential risk because they could escape human oversight, 
develop unfor eseen capabilities, and alter their own objectives. Current AI developers cannot 
reliably predict the capabilities of the systems they train before deployment, and post -hoc 
evaluations are insufficient to ensure safety. We must explicitly prohibit AI that:  Improves its 
own architecture or code without human oversight. Possesses capabilities that exceed general 
human intelligence across a broad set of domains. Can break out of its training or operational 
environment. Just as the international community has e stablished frameworks to prevent the 
proliferation of nuclear and biological weapons, we must categorically prevent the creation of 
ASI until proven control mechanisms exist. 2. Establish a Licensing System for AI Development 
and Deployment AI systems shou ld not be developed in a regulatory vacuum. The AI Action 
Plan must implement a strict licensing regime for both AI models and the compute infrastructure 
that supports them: Training Licenses: No AI model above a designated capability threshold 
should be t rained without explicit government approval and oversight. Compute Licenses: Data 
centers and cloud computing providers must be required to track AI workloads and report 
compliance with safety regulations. Application Licenses: Deploying AI systems in high -risk 
domains must require ongoing evaluation to ensure safety constraints remain effective over time. 
A failure to implement such oversight mechanisms will allow AI capabilities to scale unchecked, 
outpacing regulatory and security measures. 3. Shift from  Competitive AI Development to 
Cooperative International Safeguards A core assumption in recent AI policy rhetoric is that the 
United States must "win" the AI race against China. This framing is dangerously misguided. AI 
safety is not a zero -sum game —an uncontrollable ASI developed in any country is an existential 
threat to all of humanity. The AI Action Plan should: Engage in direct diplomatic efforts to 
ensure China, the EU, and other AI -leading nations commit to a coordinated slowdown in 
frontier AI deve lopment. Establish a global AI safety agency with verification mechanisms 
similar to those used in nuclear arms control, including: Compute tracking via semiconductor 
manufacturers. International inspections of AI research labs and data centers. Energy mon itoring 
to detect unauthorized AI training runs. It is crucial that policymakers recognize that competition 
fuels reckless acceleration. The only way to ensure AI safety is through an enforceable, 
internationally verifiable slowdown —not through an arms rac e that increases the risk of losing 
control. Conclusion The most dangerous assumption we can make is that we can "safely" 
continue to advance AI without binding international safeguards. The risks of ASI are not merely 
hypothetical; leading AI researchers and industry executives themselves have publicly 
acknowledged the lack of control mechanisms for frontier models. The AI Action Plan must 
prioritize prohibition, licensing, and international cooperation over laissez -faire development. 


 
   Once the intelligence and capability of AI surpasses human oversight, we do not get a second 
chance to correct our mistakes. Thank you for considering these recommendations. Sincerely, 
Nate Sharpe  
 


