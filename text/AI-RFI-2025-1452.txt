PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-9isn-ujbn
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1452
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
General Comment
Suggestions for AI security research (from  a professional security researcher, wannabe m athem atician and ai security reseracher)
I love that you're doing this.
And it would be am azing if us firm s weren't so ham strung by copyright law. Like why is som e legacy m agazine able to sue a leading
industry over accidentally consum ing their news articles or not paywalling their news articles effectively and losing 'valuable content' which
is worth nothing.
Although civil law has long been a regulating factor it has also notably been weaponized by banks and other industries to stym ie
innovation, oppress and censor individuals and prevent non-com petitive research and ideas.
However that's not m y specific dom ain and not what I'd like to discuss.
Security research since I got into it has been the m ost im portant field. In 2006 when I was young I knew it was im portant because all the
m oney in the world was regulated by the SWIFT system  which was protected by cryptographic protocols. I knew this because I was
fortunate, for I had fam ily who worked in finance.
I thought, what could be a m ore com petitive and interesting industry than that which m anaged all the value in the world.
I was not wrong... and the industry has grown and it has grown. With it there has been inovation and now with XBOW and other
com panies doing wonderful things juxtaposed with AI the darpa grand cyber challenge being solved, in an innovativeless way. It is clear
that we are entering the era of ICE not softice the kernel debugger but BLACK ICE like from  sprawl series.
We are looking at fully autom ated attack (and defense) pipelines.
We as the USA should be on the forefront of this. As a patriot and an am erican I know that it can be hard to push for the right thing in
politics but I also know that this is essential to m aintaining inform ation and technological advantages. 
Given all this I suggest the following two key points:
1) Increase penalties for selling weaponized ai security technology to foreign assets ( I know this is a strange suggestion from  a hacker
from  the bay area but even when I was very young.. I knew we had crypto em bargos and for good reason. It is sane to realize that this
has the potential to be m ore valuable in som e ways to m ilitary com m unication security than m any cryptographic advances and it needs to
be protected very closely to if not at the sam e tier.
2) Rem ove penalties and risks for US security researchers
If I want to say learn m ore about AI security I currently need to use platform s like crucible. But really I should be able to try and extract
m odels from  our m ajor com m erical providers. This is because if they cannot secure their m odel (i.e. deepseek) this creates a security risk
for the USA. We should encourage innovation in this m anner if Y com pkany can't do it som eone else can.... SMALL CAVEAT: I do not
think researchers should be able to profit from  this. Us few intellectuals who do this sm ashing for fun and not profit should not be hounded
civilally, crim inally or nationally. We should be encouraged to help m ove things forward. We don't want another deepseek fiasco do we?
I will elaborate further in addition to extracting m odels from  blackboxes we should perm it: doing CoT analysis, m asking and m anipulation


of m odels(obviously jailbreaking), developing novel offensive cyber weapons using ML (god I don't like the term  cyber and never will)
and anything across the rainbow unicorn sky of AI weaponry. My list is replete and I know it and you should too, carve out buffers for the
future encouragem ent of us pushing the envelope.
I would suggest the following radical m antra:
SECURITY FIRST, ECONOMIC DOLLARS second. Or do I need to reiterate how SWIFT works?
We should allow security researchers and private entities to hack and hack and hack an AI security project they want that doesn't cause
loss of life or ecnom ic resources intentionally even though m istakes will happen
We should to the m axim um  ability of the US governm ent encourage researchers to do thusly, protect them  from  civil and crim inal
persecution and provide resources and education to indivduals, program s sponsoship whatever it takes to get us ahead of the curve
As a student of the world having living in china for a while when I was young I know that china has been heavily focused for the past
couple decades on AI and m ath training and I know that from  a hum an resource perspective we are behind(anyone else read arxiv?).
When I was younger in 2012 m y ML book for an actual course was the m andarin international edition, which was very cheap and printed
m any tim es.
We need to get ahead, we need to innovate, if we choose to stym ie research for epherm eral m om entary corporate dollars we will have
deepseek after deepseek after deepseek until we are on the other end. Please do not go the route of DMCA with DRM researchers for
AI security because then I will have to m ove and the USA will be absolutely ruined.


