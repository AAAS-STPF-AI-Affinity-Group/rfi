PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 10, 2025
Status: 
Tracking No. m 83-dehq-y566
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1123
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: A. King
Em ail:  
General Comment
Dear Office of Science and Technology Policy (OSTP) and NITRD NCO,
I appreciate the opportunity to provide input on the developm ent of the AI Action Plan, as directed by Executive Order 14179. As a
student of AI Policy and Managem ent at Purdue University, I recognize the im portance of m aintaining U.S. leadership in AI innovation.
However, I urge policym akers to prioritize consum er protection, transparency, and ethical governance rather than sim ply reducing
regulatory oversight. 
While deregulation can foster rapid AI advancem ent, a lack of safeguards exposes consum ers to risks such as discrim ination,
m isinform ation, fraud, and privacy violations. The revocation of the Biden-Harris AI Executive Order 14110 rem oves critical consum er
protections, particularly in ensuring AI m odels are explainable, accountable, and safe for deploym ent. It is essential to establish clear
liability and accountability structures for AI developers and deployers, ensuring consum ers have recourse in cases of AI-induced harm .
Additionally, m andatory risk assessm ents should be required for high-im pact AI applications, such as financial services, hiring, healthcare,
and law enforcem ent.
AI system s inherently reflect the biases present in their training data. Without proper governance, oversight, and transparency, we risk
em bedding structural discrim ination and reinforcing societal inequalities. Moreover, the push for exponential AI developm ent without
corresponding safeguards increases the likelihood of biased decision-m aking in areas like hiring, lending, crim inal justice, and access to
governm ent services. To m itigate these risks, AI decision-m aking m ust be auditable, with m echanism s in place to detect and correct
biases. Diverse and representative training datasets should be m andated to m inim ize system ic discrim ination, and third-party AI audits
should be encouraged to ensure transparency and com pliance with fairness standards.
Additionally, AI’s ability to process and analyze m assive datasets poses significant privacy risks. The elim ination of so-called
“burdensom e” regulations m ust not com e at the cost of weakened privacy rights. AI’s rapid expansion into surveillance, deepfake
technology, and autonom ous decision-m aking raises serious ethical concerns that cannot be ignored. To address this, stronger data
privacy protections m ust be im plem ented to prevent AI system s from  exploiting personal data without inform ed consent. Ethical AI im pact
assessm ents should be required before deploying AI in public sector or critical infrastructure applications, and a governm ent advisory
board on AI ethics should be established to guide responsible deploym ent.
AI is evolving at an exponential pace, and the governm ent traditionally m oves m uch slower in policym aking. While accelerating AI
leadership is essential, hasty deregulation can lead to long-term  unintended consequences. The U.S. should pursue sm art, adaptive AI
policies that allow for agility without sacrificing oversight. A federal AI oversight task force should be created with the authority to adapt
regulations in real tim e as the technology evolves. Public-private collaboration should be prom oted to ensure responsible AI developm ent
while m aintaining global com petitiveness, and AI policy should align with international best practices to avoid regulatory fragm entation.
AI’s potential to drive innovation, econom ic growth, and societal progress is undeniable. However, reducing regulatory oversight without
ensuring strong governance, transparency, and ethical safeguards could lead to harm ful, biased, and privacy-invading AI deploym ents.
The AI Action Plan should reflect a balanced approach, ensuring the U.S. leads in AI responsibly, ethically, and with the public’s best
interests in m ind. Thank you for considering this input. I look forward to seeing how the AI Action Plan develops to protect consum ers,
enhance AI accountability, and prom ote responsible innovation.


Sincerely,
A. King
Student, Masters of Science in AI Managem ent & Policy
Purdue University 


