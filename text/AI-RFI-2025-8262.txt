PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-2f0y-n1e8
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-8262
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Rich Price
Address: Email: 
General Comment
AI m ay be an im portant tool for som e applications, but it m ust be used responsibly and only once it has been refined and verified that it
will not do harm . 
There have been num erous instances of "AI" and Large Language Models being loaded with am ounts and types of data they weren't
ready for or m eant to process, leading to unforeseen and inappropriate circum stances. Exam ples include chatbots showing approval for
Nazi ideology and tactics, aggressive bully-like tendencies, and providing outright false inform ation about topics through "AI sum m ary".
We can't rem ove guardrails and allow "AI" com panies to consum e personal and copyrighted m aterial for their work. These content pools
should consist of either openly available inform ation (such as public records, open source m aterial, and public dom ain works) or content
authors have opted into use for these purposes.
In addition, AI m odels should not be allowed to be used in critical industries without proof that they are properly functional and will not
endanger hum an lives, and that there are hum an safeguards in place in the event that som ething goes wrong. Incidents like Tesla autopilot
failures and other failures related to autom ated processes are proof that m achines and AI can not be left unattended and unchecked.


