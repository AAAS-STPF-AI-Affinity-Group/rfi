PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-lm pt-qyli
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1672
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Proof.com
General Comment
To Whom  It May Concern,
Please see attached for Proof's com m ents in response to the adm inistration's request for inform ation regarding the developm ent of an AI
Action Plan.
Thank You
Attachments
3.14.25_Proof_RFI_Developm ent of an Artificial Intelligence Action Plan


Notarize, Inc. (dba Proof.com) 
National Science Foundation 
Attn: Faisal D’Souza 
2415 Eisenhower Avenue, 
Alexandria, VA 22314 
March 14, 2025 
RE: Proof Comments on the Development of an Artiﬁcial Intelligence (AI) Action Plan 
To Whom It May Concern: 
Proof appreciates the opportunity to respond to the administration’s request for information 
regarding the development of an AI Action Plan. Proof supports the administration's efforts to 
develop an AI Action Plan and deﬁne the priority policy actions that are needed to sustain 
America’s global leadership in AI and ensure that the government’s actions support future 
private sector innovation. 
ABOUT PROOF: 
Proof is the trusted platform for securing the digital economy. From pioneering online 
notarization to launching a comprehensive identity authorization network, Proof secures 
everything from signing simple contracts to notarizing deeds and trusts. Proof powers 
Notarize, the largest network of online notaries available remotely in real-time, 24/7. Trusted by 
thousands of businesses and organizations, Proof is deﬁning trust in digital transactions. Proof 
partners with all levels of government to advance policies that prioritize consumer safety, 
accessibility, and the future of digital commerce. For more information, visit www.proof.com .  
EMBRACING ADVANCED TECHNOLOGIES: 
While recent advancements in AI have delivered signiﬁcant beneﬁts to both the public and 
private sectors, from increased eﬃciencies to the discovery of new medicines to ﬁght disease, 
certain advancements in generative AI (GenAI) applications have supercharged fraudster's 
abilities to impersonate Americans, leading to an increase in fraudulent activity and direct harm 
to consumers. 
In November 2024, the Financial Crimes Enforcement Network (FinCEN) issued a fraud alert1 to 
ﬁnancial institutions, acknowledging the risks that deepfake media generated by AI poses to 
both institutions and consumers. FinCEN stated that it had identiﬁed an increase in suspicious 
activity reporting involving the use of deepfake media to target institutions and consumers, 
including “altering or creating fraudulent identity documents to circumvent identity veriﬁcation 
and authentication methods.” In its alert, FinCEN acknowledged that its most recent data 
1 FinCEN, FIN-2024-Alert004, “ FinCEN Alert on Fraud Schemes Involving Deepfake Media Targeting Financial Institutions,” November 13, 2024 
© 2025 Proof.com 
1/4 


indicated that fraudsters have “successfully opened accounts using fraudulent identities 
suspected to have been produced with GenAI” and noted that those fraud schemes included 
“check fraud, credit card fraud, authorized push payment fraud, loan fraud, or unemployment 
fraud.” 
While the widespread availability of these technologies is still fairly new, the early warning signs 
of GenAI-enabled fraud risks are becoming increasingly evident. According to a study examining 
17 deepfake-creation tools by the cybersecurity ﬁrm McAfee2, “for just $5 and 10 minutes of 
setup time, scammers can create powerful, realistic-looking deepfake video and audio scams.” 
Moreover, analysis from Deloitte's Center for Financial Services predicts that GenAI could 
increase fraud-related losses for ﬁnancial services ﬁrms by up to $40 billion annually by 2027.3 
Our collective defense against these increasingly sophisticated fraud attacks requires that the 
public and private sectors be permitted to deploy equally advanced countermeasures. As such, 
we encourage the administration to establish, where necessary, permissive regulations or 
regulatory sandboxes that allow critical industries to embrace new technologies speciﬁcally 
designed to respond. 
We encourage the administration to review all existing policies and rescind any regulation that 
limits the private sector's deployment of technologies that assist in identifying and responding 
to suspected fraudulent activity. Such technologies include advanced identity veriﬁcation and 
active fraud monitoring tools that leverage advanced algorithms to analyze data, identify 
patterns, and assist in decision-making. 
Proof offers a range of solutions to assist industries in auto, ﬁnancial services, healthcare, and 
real estate in preventing identity fraud across business practices. Active fraud monitoring and 
advanced identity veriﬁcation tools, such as Proof’s Defend and Identify solutions, are central to 
our role in preventing fraud and represent two areas in which the administration should 
encourage further adoption by the private sector. 
Proof's Defend detects and reports fraudulent activity at every stage of a transaction by 
performing an automated analysis of various signals (including behavioral cues, telemetrics, 
and account ages). For example, evaluating the IP locations across devices participating in a 
session and comparing that information against a customer’s claims may suggest that the 
customer is in an entirely different country despite stating they are in Boston, Massachusetts. 
Defend aggregates the identiﬁed risk signals seen across a transaction into a risk score, which 
provides a receiving party with greater insight into a transaction and empowers that party to 
investigate and take further action if necessary. Defend is purpose-built to detect traditional 
forms of identity fraud as well as emerging threats like synthetic identities and deepfake videos. 
Proof's Identify is a customer identi ﬁcation tool designed to mitigate falsi ﬁed records, forged 
signatures, and identity theft. Two notable technologies central to Identify include credential 
analysis and biometric selﬁe comparison. Credential analysis involves an automated review of 
the photo and information on a government-issued ID, which is analyzed for signs of alteration 
or forgery and authenticated. In addition to checking an identiﬁcation document for its forensic 
features and looking for other signs of alteration or forgery, further analysis can be completed 
3 Deloitte Center for Financial Services, “ GenerativeAI is expected to magnify the risk of deepfakes and other fraud in banking ,” May 29, 2024 2 McAfee, “ The State of the Scamiverse,” January 2025 
© 2025 Proof.com  2/6 


by checking the information against trusted data records (e.g., comparing a driver’s license 
number against data from the issuing motor vehicle agency). Biometric comparison evaluates 
the biometric information on the evidence provided by the customer (such as a 
government-issued ID) against a live selﬁe image captured by the customer, verifying the 
individual’s ownership of the claimed identity. 
Given the range of threats facing the public and private sectors and the American people, the 
administration should encourage the continued availability of these solutions and others like 
them and take steps to encourage their use across critical industries. 
IMPROVING THE CITIZEN EXPERIENCE IN THE AGE OF AI: 
The risks of GenAI fraud are not limited to the private sector. The same issues of impersonation, 
forgery, and fabrication facing institutions and consumers have likely already exacerbated the 
issues of identity and application fraud that impact government assistance and beneﬁt 
programs. 
According to the Government Accountability O ﬃce (GAO)4, the federal government is expected 
to lose between $233 billion and $521 billion annually to fraud. In more urgent times, such as 
during the COVID-19 pandemic, it is estimated that the government lost as much as $1 trillion5 
to fraud in delivering pandemic assistance. One of the more alarming instances stemmed from 
the Small Business Administration’s (SBA)6 two pandemic assistance loan programs, which 
have been estimated to have lost over $200 billion to fraud. At least $70 billion of this came 
from applicants with foreign IP addresses, including individuals with expected involvement in 
international criminal organizations, despite the program’s availability to businesses located 
only in the U.S. or its territories. Unfortunately, the threat of identity theft and fraud continues to impact government programs. 
In January, following the devastating Palisades wildﬁres, the Federal Emergency Management 
Agency (FEMA) issued a warning to wild ﬁre victims of fraudsters ﬁling unauthorized relief 
claims using personal information.7 In recent testimony, the Managing Director of Financial 
Management and Assurance at GAO stated that “reducing improper payments and fraud is 
critical to better managing the cost of government,” and the “amount of estimated fraud loss 
underscores the importance of prevention and need for federal agencies to manage fraud risks 
strategically.”8 
To respond, we encourage the administration to adopt identity-centric policies across federal 
government assistance and beneﬁt programs to increase program integrity. Identity-centric 
policies are grounded in the commonsense principle that the individual who completes, signs, 
and submits something to the government has proven that they are who they say they are. For 
example, when a document is executed or submitted electronically, such as a SBA loan 
application, it should be digitally signed with a tamper-evident digital certiﬁcate tied to a veri ﬁed 
identity. 
8 GAO, GAO-25-108172, Testimony Before the Subcommittee on Government Operations, Committee on Oversight and Government Reform, House of 
Representatives, “ Agencies and Congress Can Take Actions to Better Manage Improper Payments and Fraud Risks,” March 11, 2025 7 FEMA, DR-4856-CA NR 005, “ Wild ﬁre Survivors: Beware of Stolen Identity Fraud and Other Disaster Recovery Scams and Deceptions,” January 18, 
2025 6 SBA, O ﬃce of Inspector General, “ COVID-19 Pandemic EIDL and PPP Loan Fraud Landscape,” June 27, 2023 5 Rolling Stone, “ The Trillion-Dollar Grift: Inside the Greatest Scam of All Time,” July 9, 2023 4 GAO, GAO-24-105833, “ Fraud Risk Management: 2018-2022 Data Show Federal Government Loses an Estimated $233 Billion to $521 Billion Annually 
to Fraud, Based on Various Risk Environments,” April 16, 2024 
© 2025 Proof.com  3/6 


Digital certi ﬁcates are based on Public Key Infrastructure (PKI) technology which underpins 
much of the security on today’s internet. In document execution, digital certi ﬁcates can be 
issued to signers only after they have successfully validated the existence of their identity and 
veriﬁed ownership of that identity. Existing federal policies and open standards are already in 
place to govern identity veri ﬁcation (e.g., NIST IAL29), digital certi ﬁcate use (e.g., AATL10), and 
authentication (e.g., NIST AAL211), and the private sector stands ready to provide the 
government with the tools required to deploy them. In considering this approach, the 
administration must establish clear policies that enable humans to intervene to assist 
applicants when necessary. Various factors, such as limited familiarity with digital tools, user 
error, or system error, can make it diﬃcult for some individuals to complete automated 
identity-proo ﬁng processes. NIST’s latest IAL2 guidance12 addresses these challenges and sets 
clear policies for the role humans serve as trusted agents that can assist applicants that 
failover, ensuring broad availability.  
Additionally, digital certi ﬁcates create a privacy-preserving approach to identity veri ﬁcation that 
supports ongoing data minimization efforts. Available solutions are designed to the latest data 
and cybersecurity standards and can be future-proofed with quantum-resistant cryptography to 
defend against developing risks. Furthermore, agencies can leverage existing commercially 
available solutions to set up automated submission gateways to enable seamless web-based 
execution to improve eﬃciencies and reduce errors. These solutions automate verifying 
document accuracy, con ﬁrming document integrity, validating digital signatures and certi ﬁcates, 
and routing documents for manual review and approval when necessary. 
Equally concerning is the vulnerability of o ﬃcial government documentation and 
communication to sophisticated impersonation from certain GenAI applications. Today, 
Americans lose millions of dollars to fraudsters impersonating the government.13 With 
fraud-as-a-service solutions now available on the dark web,14 bad actors can easily generate 
convincing government credentials, spoof oﬃcial emails, and create deepfake audio clips. AI 
applications can not only streamline fabrication but also expedite data collection, allowing 
fraudsters to eﬃciently harvest personally identifying information, contact details, and 
addresses from across the internet to create near-perfect impersonations of government 
oﬃcials and precisely targeted lists of victims. 
These scams, which already pose a signi ﬁcant threat to the American people, especially 
vulnerable communities, such as the elderly, are being ampli ﬁed by advanced AI capabilities. 
A recent case in Maryland demonstrates the severity of this threat. One victim lost her life 
savings of $595,000 to a sophisticated scam in which the perpetrator successfully 
impersonated an FBI agent. The fraudster employed a comprehensive approach: using a real 
agent's name, spoofed email addresses, fake case numbers, oﬃcial agency insignia, and 
manipulated phone numbers to appear as legitimate FBI o ﬃce communications.15 
15 The Washington Post,  “ She believed she was an FBI ‘asset.’ The scam drained her life’s savings.,” December 2, 2024 14 Thomson Reuters, “ Fraud-as-a-Service: Creating a new breed of fraudsters,” February 21, 202513 Federal Bureau of Investigation, “ Elder Fraud Report,” April 30, 2024 12 NIST, “ NIST Special Publication NIST SP 800-63A-4 2pd,” August 2024 11 NIST, “ NIST Special Publication 800-63B,” June 2017 10 Adobe, Adobe Approved Trust List, last updated on May 24, 2023; ITU-T X.509: Public-Key and Attribute Certi ﬁcate Framework; ISO/IEC 9594 Open 
Systems Interconnections; IETF RFC 5280: Internet X.509 Public Key Infrastructure Certi ﬁcate and Certi ﬁcate Revocation List (CRL); RSA Public Key 
Cryptography Standards (PKCS); NIST FIPS 186 Digital Signature Standard 9 National Institute of Standards and Technology, “ NIST Special Publication 800-63A,” June 2017 
© 2025 Proof.com  4/6 


As recently as December 2024, the Treasury Department's Inspector General issued a consumer 
warning regarding fraudulent letters purportedly from the Bureau of the Fiscal Service. These 
letters falsely notiﬁed consumers about unclaimed funds and solicited consumers to authorize 
the release of funds.16 This example highlights how easily fraudsters can replicate o ﬃcial 
government documents with convincing authenticity. Similar fraudulent communications 
exploiting agency letterhead or email domains have been identiﬁed across multiple federal 
entities, including Health and Human Services17, the Environmental Protection Agency18, and the 
Internal Revenue Service.19 
The proliferation of fraudulent government communications undermines public trust in our 
institutions while placing American consumers at signiﬁcant risk. To address this growing 
threat, we urge the administration to require all government agencies to adopt industry-leading 
content authenticity standards and digital watermarking technologies. These measures would 
ensure that all oﬃcial communications include veri ﬁable metadata indicating their legitimate 
source and provenance. 
Existing open standards and commercially available solutions can guide the administration’s 
actions, such as the Coalition for Content Provenance and Authenticity (C2PA)20, which has 
been embraced by Adobe, Amazon, Microsoft, and others as the solution to GenAI-enabled 
fraud, forgery, and deepfakes. Any content produced in accordance with C2PA standards will be 
cryptographically signed and veriﬁable across the majority of internet services and business 
applications. 
Whether it be an email to taxpayers or an agency alert in a national emergency, Americans need 
certainty in the content they receive from the government. Promoting these standards will give 
relevant parties and the public trust, prevent manipulation, and restore the public’s conﬁdence in 
our government. 
IMPORTANCE OF STANDARDIZED DEFINITIONS: 
Since the widespread availability of AI applications, hundreds of regulations and laws have been 
introduced at both the state and federal levels. While the scope of each proposal may be unique, 
the lack of consistency in how AI is deﬁned is clear and has created a challenging regulatory 
environment for companies of all sizes, especially those in America’s startup economy. 
As such, we urge the administration to prioritize establishing a consistent de ﬁnition of AI across 
the federal government, using the de ﬁnition provided in the National Institute of Standards and 
Technology’s (NIST) Arti ﬁcial Intelligence Risk Management Framework (AI RMF 1.0).21 
When considering AI regulation, precise de ﬁnitions become critical, so it is important to 
acknowledge the nuanced differences within AI technologies. Systems relying on traditional 
machine learning algorithms function distinctly from newer generative models. The 
21 NIST, “ Artiﬁcial Intelligence Risk Management Framework (AI RMF 1.0),” See Page 1, Executive Summary, January 2023 20 Coalition for Content Provenance and Authenticity 19 Internal Revenue Service, IRS Tax Tip 2024-63, “ Beware of scammers posing as the IRS ,” July 29, 2024 18 Environmental Protection Agency, O ﬃce of Inspector General, “ Fraud Alert: Notice of Violation Letter Phishing Scam ,” July 2024 17 Department of Health and Human Services, O ﬃce of Inspector General, “ Consumer Alerts” 16 Department of the Treasury, O ﬃce of Inspector General, Fraud Alerts, “ Unsolicited Phone Calls, Text Messages, or Emails Purporting to be from the 
Treasury O ﬃce of Inspector General, O ﬃce of Investigations, FinCEN, OFAC, the Treasury “O ﬃce of Legal Affairs”, or even from the Secretary of the 
Treasury, are frauds,” December 30, 2024 
© 2025 Proof.com  5/6 


administration should carefully avoid applying overly broad terminology that inadvertently 
groups decades-old established technologies with recently developed innovations, as this could 
subject industry to unintended regulatory burdens. 
Furthermore, the administration can strengthen its support for innovative private-sector 
solutions by revisiting existing agency deﬁnitions of AI. Current de ﬁnitions may unintentionally 
restrict the use of bene ﬁcial commercial technologies, such as advanced identity veri ﬁcation 
and active fraud monitoring tools. These solutions employ sophisticated algorithms to analyze 
data, identify patterns, and support decision-making processes that ultimately protect 
consumers and government programs alike. 
CONCLUSION : 
We thank the administration for the opportunity and consideration of the perspectives raised in 
our response. Should you require more information, please contact James Fulgenzi, Director of 
Government Affairs & Advocacy, at 
Sincerely, 
James Fulgenzi 
Director of Government Affairs & Advocacy 
Proof 
© 2025 Proof.com  6/6 


