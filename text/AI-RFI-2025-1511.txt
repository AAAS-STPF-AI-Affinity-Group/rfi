PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-cgel-cnhz
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1511
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Authors Guild
General Comment
See attached file(s)
Attachments
RFI on AI Action Plan -- Authors Guild Com m ents


 
 
Before the Networking and Information Technology Research and Development (NITRD) 
National Coordination Office (NCO), National Science Foundation 
Request for Information on the Development of an Artificial Intelligence (AI) Action Plan  
 
Comments of the Authors Guild  
March 14, 2025 
The Authors Guild thanks the Office of Science and Technology Policy and the Networking and 
Information  Technology Research and Development (NITRD) National Coordination Office 
(NCO)  of the National Science Foundation for the opportunity to provide comments on the 
development of an Artificial Intelligence (AI) Action Plan.1  The Guild is a national nonprofit 
association of over 15,000 professional writers of all genres.  Its members include leading 
historians, biographers, academicians, journalists, and other writers of nonfiction and fiction whose works have appeared in the m ost influential and well-respected publications in every 
field.  The Guild has a fundamental interest in ensuring that works of authorship and the rights of 
authors are protected, and that the hard work and talents of American authors are rewarded so 
that they can keep writing, as intended by the framers of the United States Constitution.  The 
Guild believes that it is crucial for our culture and the future of democracy to ensure that our literature and arts remain vibrant and diverse.  
The Guild urges the Administration to ens ure that an y policies established or recommended by 
the AI Action Plan respect the central role of copyright law as a driver of the nation’s economy 
and culture.  To be sure, AI offers  valuable benefits in many areas of life, including as a tool that  
authors and other creators can use to enhance their creative works, just as they have done with 
technological developments throughout history.  But the process by which AI companies trained 
their large language models (LLMs) —copying massive numbers of copyrighted works without 
their creators ’ consent, control, or compensation—is not only grossly unfair; it also will, if 
allowed to continue unabated, decimate the creative industries that contribute trillions of dollars 
to U.S. GDP and employ millions of Americans .  These industries should not be forced to 
subsidize the tech sector by surrendering their valuable intellectual property for the development of produc ts from which they reap no economic benefit—and that, in fact, are used to mass -
produce machine- generated works to compete with human authors. 
Future development of generative AI systems can and must be based on mutually beneficial partnerships between technology companies and the creative professions.  This can be realized  
1 This document is approved for public dissemination.  The document contains no business -proprietary or 
confidential information.  Document contents may be reused by the government in developing the AI 
Action Plan and associated  documents without attribution. 


by promoti ng voluntary licensing arrangements like those that are already rapidly proliferating 
throughout the marketplace. 
1. Use of copyrighted works without permission to train AI systems is a major threat 
to the U.S. creative industries  
To date, the rapid development of generative AI systems has depended on mass- scale copyright 
infringement.  T he overwhelming majority of the materials used to “train” generative AI systems 
are copyright-protected works that were scraped from the internet without authorization from, or 
compensation to, the ir owners .  AI training requires ingestion of massive quantities of 
preexisting works.  The major text -generating LLMs , such as Open AI’s GPT, Google’s 
LAMDA, and Meta’s LLaMA, and Anthropic’s Claude, a ll were  trained on hundreds of 
thousands of books, plus datasets that include millions of news articles and books scraped from the internet.  All the book datasets that we are aware of were knowingly copied from well -known 
pirate ebook sites.  Other books used for training were swept in from web crawls that included 
other pirate sites. (e.g., Common Crawl, which has 60 billion domains scraped over 12 years). 
Equally important, the value of any LLM depends directly on the quality of the materials  used to 
train it.  The ability of LLMs to generate text that is grammatically and stylistically well written, 
and acceptable to todays’ readers (linguistically and also in terms of modern concepts  and 
understandings) is dependent having ingested relatively recent high- quality texts —meaning 
books, stories, articles, and blogs, often those with the highest value in the marketplace.  The 
phrase “garbage in, garbage out” refers to this phenomenon.  Put simply, if AI developers want their LLMs to produce high- quality  outputs, they  need high- quality  inputs, and they have sought 
out published, commercially valuable books precisely for that reason.  Indeed, just this  week 
OpenAI CEO Sam Altman announced a new AI model that that is “good at creative writing .”
2  
From everything we know about how AI models are trained and work, it is certain that this new AI model can write well because it was trained specifically on professionally written, copyrighted material.  
Books are valuable—a single book often takes years to write and edit, and the authors, publishers 
and others in the chain need to be paid for the work or the books would not be produced and 
published.  That makes them good training material for LLMs and it is also why copyright-protected books are rarely legally made available on the open internet.  Yes, ebooks are available 
for purchase, but only on sophisticated e-commerce platforms like Amazon, Apple, and Bookshop that have security and do not allow the books to be scraped.  So, when the large LLM companies decided that they needed books for training to improve their LLMs and that they would not bother to ask permission, they had to resort to scraping major pirate ebooks sites, such as LibGen and Z-Library and their mirror sites —all of which are foreign-based and out of reach 
of U.S. law.  These are notorious pirate sites that publishers, the Authors Guild and U.S. law 
2 Dan Milmo, ChatGPT firm reveals AI model that is ‘good at creative writing,’ The Guardian (Mar. 12, 
2025), https://www.theguardian.com/technology/2025/mar/12/chatgpt- firm-reveals- ai-model- that-is-
good- at-creative -writing -sam-altman   


enforc ement have been trying to take down for years.  For instance, in 2017 in Elsevier v. Sci -
Hub, the U.S. District Court for the Southern District of New York ruled that Sci- Hub was 
infringing and enjoined the use of sci-hub.org, libgen.org, and related domains, but the operators, 
who are based in Russia,  just moved on to other domains.3  Last  year , in Cengage Learning v. 
Does 1 -50, a group of academic publishers succeeded in a civil suit against Libgen, but again 
with no practical relief, as the book dataset was simply moved to other sites.4   
Thus, AI companies’ insistence that their training materials consist only of works that are publicly available on the open internet is disingenuous at best.  They knowingly ingested illegal copies of copyrighted books that authors never uploaded to the internet and that they have no ability to have taken down.  These companies  built their businesses by taking and exploiting the 
valuable content of authors’ works without permission , without giving them any control over 
how their works appear (or not) in outputs, or a penny of compensation.  This represents a vast 
transfer of wealth whereby creative industries are effectively forced to subsidize the tech sector.   
It is no different than if an AI company appropriated and refused to pay for the energy resources 
and infrastructure necessary to operate its data centers.  Not only is this  self-evidently unfair, but 
it incentivizes the continued widespread piracy of books and other copyrighted works, directly 
threaten ing jobs across  the creative industries that are so  vital to  the U.S. economy.
5 
The harm is compounded on the output side.  The use of AI systems to flood the market with 
machine- generated works will  devastate creators’ livelihoods, perversely forcing them  to 
compete against knockoffs that their own works were used to generate.  In the book market, 
generative AI systems are already being used to produce low- quality ebooks that attempt to 
compete with authors’ works.  We have seen examples of AI -generated books dominating 
Amazon’s best -seller lists in certain categories, resulting in fewer copies sold by human authors 
who write in those categories.  We are also seeing so -called publishers using AI to generate 
books on closely related or very similar topics that pop up for sale almost imm ediately after the 
human author listed their book for pre-order, thus preempting the sale of the human-authored works.  Generative AI is also being used to create unauthorized derivative works, such as a 
developer using ChatGPT to write the concluding books in George R.R. Martin’s A Song of Ice 
and Fire  series .
6  All these uses take money directly out of authors’ and publishers’ hands. 
3 Quirin Schiermeier, US court grants Elsevier millions in damages from Sci-Hub, Nature (June 22, 
2017), https://www.nature.com/articles/nature.2017.22196; Judgment, Elsevier Inc. v. Sci -Hub, 15-cv-
4282. doc. no. 87 (S.D.N.Y . June 21, 2017). 
4 Ashley Belanger, Pirate library must pay publishers $30M, but no one knows who runs it, Ars Technica 
(Sept. 26, 2024), https://arstechnica.com/tech -policy/2024/09/pirate -library -must-pay-publishers- 30m-
but-no-one-knows- who-runs-it/  
5 Robert Stoner & Jéssica Dutra, Copyright Industries in the U.S. Economy: The 2024 Report , INT’L 
INTELL. PROP. ALL. (Feb. 2025)  (finding that in 2023, the core copyright industries contributed more 
than $2 trillion to U.S. GDP  and employed 11.6 million workers ), 
https://www.iipa.org/files/uploads/2025/02/IIPA-Copyright-Industries- in-the-U.S.-Economy- Report -
2024_ONLINE_FINAL.pdf .  
6 Rebekah Valentine, Someone Used ChatGPT to Finish the Game of Thrones Book Series, IGN, 
https://www.ign.com/articles/someone -used-chatgpt -to-finish -the-game -of-thrones-book- series  


Freelance journalists and professional writers of web and marketing content are also reporting 
losing work at an alarming rate as a result of clients switching to AI.  An Authors Guild member 
who writes marketing and web content reported losing  75% of their work, and a content writer 
featured in a Washington Post  story about ChatGPT’s impact on writers stated that he had lost 
half of his annual income.7  These losses have ripple effects through out the entire professional 
writing ecosystem, as most book authors sustain their profession with other writing- related work, 
including freelance journalism and writing web and marketing content.  Loss of freelance work that supplements book income will hamper writers from focusing on their book projects.  As a 
result,  we will have fewer talented writers who can devote much of their professional lives to 
writing —meaning fewer great books and less diversity in what gets published. 
All this comes at a time when writers are already facing unprecedented hurdles in earning a 
living.  Between 2009 and 2018, authors’ median incomes dropped 42%.
8  Our most recent 
authors’ earnings survey found that the median writing- related income for full-time authors  in 
2022 was just over $20,000, with only half of that from books.9  The median income for 
commercial (non -academic) traditionally published full- time authors from all writing related 
activities —which includes speaking, journalism, teaching, editing, and coaching—was  $25,000 
and only $12,000 from books.  Looking at all authors, including those who reported writing part-
time, the median book income was $2000 in 2022, and the median income from books plus other 
writing related work was $5000.  When we factor in the additional income losses that generative AI will add to the mix of technological and economic disruptions in the markets from which writers deri ve income, the ability of most authors to stay in the profession becomes all the more 
doubtful. 
2. The Administration should support voluntary licensing efforts rather than new 
copyright exceptions or compulsory licenses  
AI companies have attempted to defend their unauthorized copying by arguing that it is 
permitted under the “fair use” exception to copyright law.10  That proposition—which we believe 
to be wholly without merit—is currently being tested in court: to date, nearly forty copyright 
infringement lawsuits have been brought against AI companies (including a class action led by 
the Authors Guild).  If, as we fully expect, the courts hold that unauthorized training of professionally-created copyrighted works is not fair use, AI companies have indicated that they 
will seek legislation to create a statutory exception or a compulsory license allowing them to use 
7 Pranshu Verma and Gerritt de Vynck, ChatGPT took their jobs. Now they walk dogs and fix air 
conditioners, Washington Post (June 2, 2023), 
https://www.washingtonpost.com/technology/2023/06/02/ai- taking -jobs/  
8 Authors Guild Survey Shows Drastic 42 Percent Decline in Authors Earnings in Last Decade, 
https://authorsguild.org/news/authors- guild -survey -shows -drastic -42-percent -decline -in-authors-earnings-
in-last-decade/   
9 Key Takeaways from the Authors Guild’s 2023 Author Income Survey, 
https://authorsguild.org/news/key- takeaways- from -2023-author- income -survey/   
10 Codified at 17 U.S.C. § 107.  


copyright ed works for AI training .  The Administration should oppose any such efforts.11  
Instead, it should work to support voluntary, freely negotiated licensing arrangements between 
copyright owners and AI companies —a market that already exists and is growing by the day. 
In the publishing sector alone, there have been numerous reported agreements  through which 
publishers have licensed  works to AI companies for training.  Licensors include several major 
trade and academic publishers, including Wiley, Taylor & Francis, Oxford University Press, 
Cambridge University Press, Sage, DeGruyter Brill, and Harper Collins.12  News organizations 
are doing so as well.  R ecent deals include licenses from the Associated Press ,13 NewsCorp,14 
Reuters,15 Le Monde,16 The Financial Times,17 V ox Media,18 The Atlantic,19 and Dotdash 
Meredith20 (which owns popular magazine brands such as  People and  Entertainment Weekly ).  
Third -party  licensing platforms are also rapidly emerging, such as Created by Humans, which 
has partnered with the Authors Guild to provide a way for authors to license their works for AI 
uses on terms that they themselves choose.21  Other companies like Calliope,22 Human Native,23 
11 The Constitution places authority over copyright with Congress, and therefore any changes to the scope 
of copyright protection would require legislation.  See U.S. Const. art. I, § 8, cl. 8 (“The Congress shall 
have Power . . . To promote the Progress of Science and useful Arts, by securing for limited Times to 
Authors and Inventors the exclusive Right to their respective Writings and Discoveries .”). 
12 See, e.g., Jim Milliot, Wiley Creates AI Partnership Program, Publishers Weekly (Oct. 17, 2024), 
https://www.publishersweekly.com/pw/by-topic/industry- news/industry -deals/article/96248- wiley -
creates -ai-partnership-program.html ; Matilda Battersby, Taylor & Francis set to make £58m from AI in 
2024 as it reveals second partnership, The Bookseller (July 25, 2024), https://www.thebookseller.com/news/taylor -francis- set-to-make -58m-from -ai-in-2024- as-it-reveals-
second -partnership; Heloise Wood, Wiley and Oxford University Press confirm AI partnerships as 
Cambridge University Press offers ‘opt-in,’ The Bookseller (Aug. 1, 2024), 
https://www.thebookseller.com/news/wiley -cambridge-university- press -and-oxford-university- press -
confirm -ai-partnerships ; Authors Guild, Harper Collins AI Licensing Deal, 
https://authorsguild.org/news/harpercollins- ai-licensing -deal/ .  For a continually updated list of current 
agreements, see https://sr.ithaka.org/our-work/generative- ai-licensing- agreement -tracker/ .  
13 Nitasha Tiku, Newspapers want payment for articles used to power ChatGPT, Wash. Post (Oct. 20, 
2023), https://www.washingtonpost.com/technology/2023/10/20/artificial- intelligence -battle -online- data/ .  
14 https://investors.newscorp.com/news- releases/news- release -details/news -corp-and-openai- sign-
landmark -multi- year-global-partnership  
15 https://www.axios.com/2024/10/25/meta -reuters -ai-news -facebook- instagram   
16 https://www.lemonde.fr/en/about- us/article/2024/03/13/le -monde-signs- artificial -intelligence -
partnership- agreement -with-open-ai_6615418_115.html   
17 https://www.ft.com/content/33328743- ba3b -470f- a2e3 -f41c3a366613  
18 https://www.voxmedia.com/2024/5/29/24166483/vox- media -openai- strategic -content-and-product-
partnership  
19 https://www.theatlantic.com/press -releases/archive/2024/05/atlantic -product-content-partnership-
openai/678529/   
20 https://dotdashmeredith.mediaroom.com/2024-05-07-Dotdash- Meredith -Announces- Strategic -
Partnership -with-OpenAI, -Bringing- Iconic -Brands- and-Trusted -Content -to-ChatGPT   
21 Authors Guild Partners with Created by Humans to Empower Authors in the AI Era (Oct. 9, 2024), 
https://authorsguild.org/news/ag- partners -with-created -by-humans- to-empower -authors- in-ai-era/.  
22 https://calliopenetworks.ai/   
23 https://www.humannative.ai/  


and P ersonal Digital Spaces24 are also building and deploying licensing platforms.  All these 
efforts demonstrate that voluntary collective licensing solutions for AI training are 
technologically and economically feasible for developers and are becoming more widely available every day.  
Any new copyright exceptions or compulsory licenses —the latter of which would force 
copyright owners to license their works at government- established rates —would severely disrupt 
these markets.  Indeed, as the Copyright Office has long recognized, compulsory licenses 
“conflict with the fundamental principle that authors should enjoy exclusive rights to their creative works, including for the purpose of controlling the terms of public dissemination.”
25 
Therefore, such licenses are appropriate “only in circumstances of genuine market failure and only for as long as necessary to achieve a specific goal.”
26  Far from failing, AI licensing markets 
are flourishing.  The Administration should oppose any efforts to interfere with the se voluntary 
transactions.  
Instead, any legislation in this space should facilitate  voluntary licensing by promoting a stable, 
well-functioning marketplace.  Specifically, we support legislation in the following areas: 
 Transparency  
Companies that make generative AI models commercially available should be required to 
publicly disclose or to notify copyright owners of any unlicensed copyrighted works that were used in the training datasets, including the URL of any online location from which the data was obtained.  This will ensure safety of the models and prevent use of sensitive, harmful, or illegally harvested data in the training.  It  also will further encourage AI developers to work with 
copyright owners on licensing solutions. 
Several legislative  approaches to accomplish this have been suggested.  The EU has adopted 
legislation requiring developers of general-purpose AI models to make publicly available a 
“sufficiently detailed summary” of the content used for training.
27  Similarly, California requires 
developers to post a “high -level summary of the datasets ,” including the sources or owners of the 
datasets and whether they contain data protected by copyright, trademark, or patent.28  Another 
24 https://www.personaldigitalspaces.com/   
25 U.S. Copyright Office, Legal Issues in Mass Digitization: A Preliminary Analysis and Discussion 
Document , at 38 (2011), https://copyright.gov/docs/massdigitization/USCOMassDigitization_ 
October2011.pdf    
26 Id. 
27 EU AI Act, Regulation (EU) 2024/1689, art. 53(1)(d), https://eur -lex.europa.eu/legal-
content/EN/TXT/HTML/?uri=OJ:L_202401689; see also  Generative AI Copyright Disclosure Act of 
2024, H.R. 7913, 118th Cong., 2d Sess. (2024) (bill requiring developers to submit a notice to the 
Copyright Office containing a sufficiently detailed summary of any copyrighted works used in the dataset, 
as well as the URL for any publicly available dataset ). 
28 A.B. 2013, https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240AB2013  


proposed a pproach would create an administrative subpoena process al lowing copyright owners 
to obtain information from a developer about whether their works were used in training.29 
While any  of these approaches would be preferable to the status quo, the Guild believes that AI 
developers should be required to disclose more than merely a summary of their training datasets.  
To fully achieve the goals of transparency and accountability, they should be required to make 
publicly available the sources of the copyrighted works used to train their models .  This 
obligation should not be unduly burdensome.  If the datasets were compiled in -house, then the 
developers already know what data is included and where it is located .  If the datasets are 
obtained from third parties, the developers can require that  the information be provided to them. 
 Labeling of AI Outputs  
Content that is  AI-generated or significantly AI-manipulated should be labeled as such .  It 
appears —based on comments authors have reported receiving from readers, as well as comments 
made on various platforms—that most readers prefer to read human authored books (reading is in part about connecting with the author) and feel deceived if they find out that a work they have purchased was AI -generated.  They need a way to determine whether something was human 
written before purchasing it.
30  Labeling AI -generated content is also essential for ensuring that 
markets for copyrighted works are not inundated with AI- generated content that consumers will 
purchase unwittingly, diluting the copyright industry ecosystems and incentives to create and invest in new works and eventually displacing human creators.   
We agree with the labeling requirements under the recently adopted EU AI Act, which require all general -purpose AI system providers “to ensure the outputs of the AI system are marked in a 
machine- readable format and detectable as artificially generated or manipulated.”
31 
 Antitrust Exemption  
As discussed, AI companies have en tered into licensing agreements with multiple  publishers to 
acquire catalogs for training .  In many cases, however, publishers do not possess the rights to 
license out works for AI training, or the ir contract with the author is unclear.  Moreover, rights to 
many out-of-print books (which is most books that are more than several years old) have 
reverted to the authors, and the majority of books published today are self-published, meaning 
that the author retains the rights.  To license these books, as well as many freelance literary texts 
for which the writer retains rights, AI companies need a means of licensing directly from the authors.  And because it is highly inefficient for them to do so on a case -by-case basis,  authors 
29 Transparency and Responsibility for Artificial Intelligence Networks (TRAIN) Act, S. 5379, 118th 
Cong., 2d Sess. (2024). 
30 That is why the Authors Guild has created a certification mark, “Human Authored,” to protect authors 
and readers until such time as we can ensure that AI -generated material is labeled as such.  See 
https://authorsguild.org/human-authored/  
31 EU AI Act  art. 50(2). 


need to be able to form collective management organizations (CMOs)  to offer blanket licenses , 
similar to those that have existed in the music industry for decades.  
What stands in the way of such  licensing is that antitrust laws may impose risks to forming 
CMOs that set rates on behalf of their members.  We therefore are seeking legislation clarifying 
that these specific AI -use collective licenses will not violate U.S. antitrust laws.  This could take 
the form of legislation that woul d allow certain creators (for instance, in the text and image 
sectors) to collectively bargain with AI companies for a specified period for purposes of negotiating licensing fees. 
3. Copyright protection should not be extended to AI -generated works  
It is well settled that materials generated by machines or other non-humans are ineligible for 
copyright protection.
32  The Administration should oppose any legislation to extend copyright or 
sui generis  rights to AI -generated works.   Granting such  protection would undermine the market 
for human-created works without providing any countervailing benefit to  society.  
If AI-generated works were entitled to the same protection as human -created works, or even a 
lesser sui generis  from of protection, it would give their producers (who in the book field for 
now are mostly scam -like operations that appear to have no writing or publishing background) 
unfair leverage in the marketplace and would further incentivize the distribution of AI- generated 
content to the public, crowding and diluting the marketplace to the point that copyright incentives no longer function as intended.  Few human creators will be able to earn enough to sustain a profession and the human quality of work produced by professionals—those who have talent and have trained in their careers for many years —will disappear.  Since all human 
creativity starts with the human creators, our literary works and arts—and other media that rely heavily on human written work, such as film, will suffer tremendously as a result. 
These costs cannot be justified by any purported need to incentivize AI development.  Tech 
companies do not need additional incentives beyond those they already have in the form of 
patent, copyright, and trade secret protection for their technologies.  Generative AI technology development until now has occurred without copyright incentives on outputs, and we see no 
rationale for providing such  protection to encourage further innovation in that area.  Nor do the 
users of generative AI systems need additional legal incentives to generate content, which can be 
produced quickly and cheaply using these systems.  Indeed, as the U.K. Intellectual Property 
Office  recently noted, there is no evidence that laws protecting computer- generated works 
(which exist in a few countries) have led to any increase in AI outputs or investment in AI technology as compared to countries without such laws.
33 
32 See Copyright Registration Guidance:  Works Containing Material Generated  by Artificial Intelligence , 
88 Fed. Reg. 16190, 16191-92 (Mar. 16, 2023) ( discussing case law).  
33 U.K. Intellectual Property Office, Copyright and AI: Consultation at 27, ¶¶ 152-53 (Dec. 2024), 
https://assets.publishing.service.gov.uk/media/6762c95e3229e84d9bbde7a3/241212_AI_and_Copyright_
Consultation_print.pdf  


