 
 
 


2 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without attribution.  
Executive Summary 
This policy brief explores the evolving landscape of AI development, by highlighting the ethical 
concerns and risks posed by AI misuse in the weaponization of information. Additionally, this 
brief explores ethical  lapses in data and resource utilization, and the persuasive spread of 
misinformation on unregulated social media. Finally, this brief covers how these challenges can 
be addressed while positioning the United States as a global leader in AI innovation. 
While the U.S. must remain at the forefront of AI technologies, the pace of development 
outstrips current regulatory frameworks. To manage both the opportunities and dangers posed by 
AI, the creation  of a White House AI Commission or Council is recommended to provide a clear 
path for policy, regulation, and national collaboration. This body would oversee AI development 
to ensure that innovation continues in a manner that maximizes benefits for the economy and 
society, while also mitigating risks such as misinformation, exploitation of vulnerable 
populations, and environmental degradation.  
Key Findings Include: 
AI Exploitation of Child Vulnerability: Unregulated social media platforms enable the rapid 
spread of misinformation targeting children. Malicious figures have exploited these spaces to 
manipulate  young minds, distort perceptions, and influence behavior particularly on climate 
change and public health. With AI evolving faster than regulations, children face growing risks. 
These risks include AI-driven disinformation, deepfakes, and manipulative content designed to 
exploit their vulnerabilities.  
Ethical and Environmental Impacts: Large-Scale AI models – such as ChatGPT – demand 
substantial water and energy resources. The computational power required for training and 
running these models places a significant  strain on environmental sustainability. These systems 
require high energy consumption which contributes to carbon emissions, and use a vast amount 
of water for cooling AI data centers. This further exacerbates resource scarcity in already 
water-stressed regions.  
Key Alternatives and Recommendation:  
Alternative One: Sustainable AI Development and Resource Accountability 
To off put the environmental strain of AI, policy makers mandate sustainability standards for AI 
development.  This could include the prioritization of renewable energy sources, designing more 
resource suf ficient AI models, and requiring tech firms to disclose their energy and water 
consumption. 


 
3 
 
Alternative Two: Child Centric AI safeguards 
Implement targeted regulatory measures to prevent the weaponization of AI against children. 
This includes enforcing specific content filters on digital platforms, and establishing the rapid 
response protocols to remove harmful AI generative content such as defects that target children. 
Additionally, integrating digital literacy programs into school curricula can empower younger 
users to recognize and counteract manipulative content. 
 
Alternative Three: Enforceable AI regulations With Public Environmental Protections  
Rather than merely reacting to AI-related harms, policymakers should take a proactive approach. 
Governments should implement legally binding accountability measures to ensure AI 
development aligns with ethical and public safety standards. This includes creating enforceable 
liability frameworks that hold companies responsible for AI-generated harm, from 
misinformation to environmental damage. 
 
Final + Main recommendation: Establishment of a White House AI Commission or Council 
Establish a White House AI Commission or Council that would focus on ensuring U.S. 
leadership in AI while balancing ethical and environmental concerns. This commission would 
work to ensure enforceable regulations that hold AI developers accountable for harmful 
outcomes such as misinformation, and  environmental harm. 
 
Summary 
As AI continues to shape society, its governance must evolve to protect public interest while 
encouraging innovation. Without enforceable regulations, AI’s unchecked expansion risks 
seeping social and environmental inequalities. By implementing robust accountability 
frameworks, sustainability mandates, and child centric protections, policymakers can ensure AI 
serves as a tool for progress rather than exploitation. The development of the AI Action Plan 
presents a pivotal opportunity to establish lasting safeguards that prioritize ethical responsibility, 
public trust, and environmental sustainability.  
 
 
 
 
 
 
 


4 
Background 
Artificial intelligence has emerged as a transformative technology across multiple sectors — 
from healthcare and education to defense and environmental management. Historically, 
advancements in AI have been lauded for their potential to revolutionize industries; however, 
this progress has also raised ethical and environmental concerns. For instance, training large 
language models (LLM) like ChatGPT requires substantial energy and water resources. A factor 
often overlooked in broad discussions of digital transformation. Furthermore, social media 
platforms – which are largely unregulated – have become hot beds for climate misinformation, 
undermining efforts to communicate critical data about the environment. 
This brief is situated within a complex policy landscape that includes multiple stakeholders, such 
as national federal agencies like the EPA and NIST. The imperative is clear: develop an AI 
framework that not only encourages innovation, but also mitigates adverse impacts on youth and 
the environment.  
Child Safety Concerns Regarding AI 
AI Exploitation of Child Vulnerability 
The rapid evolution of artificial intelligence presents a complex landscape of opportunities  and 
risks. Two interrelated issues stand out: the exploitation of child vulnerability via unregulated 
social media platforms, and the considerable ethical and environmental impact of large-scale AI 
systems. Unregulated social media platforms have become conduits for rapidly disseminating 
false and misleading information aimed directly at children. Malicious figures are within these 
unprotected digital spaces to manipulate young minds, skew, public perceptions, and influence 
behavior, particularly in critical areas, such as climate change awareness in public health. 
Meanwhile, the rapid pace of AI development has outpaced current regulatory frameworks, 
leaving children increasingly vulnerable to harmful practices. These vulnerabilities include the 
weaponization of AI to deliver manipulative content, orchestrate online scams, and launch 
tailored disinformation campaigns that specifically exploit their development weaknesses.  
Echo Chambers and Algorithmic Bias   
Social media platforms have become epicenters for the rapid dissemination of misinformation, 
deepfake content, and polarizing narratives. Driven by algorithms optimized for engagement 
rather than accuracy , these platforms create  echo chambers that expose young users to 
disoriented narratives on topics such as climate change, public health, and political events. Pupils 
are not only sharing conspiracy theories but are also increasingly influenced by highly 
manipulated content, which highlights the urgent need for both regulatory intervention and 
robust digital literacy programs. These systems repeatedly curate feeds with sensational and 
polarizing material. This phenomenon, well-documented in academic literature, results in echo 
chambers where young users, who’s critical thinking skills are still developing, are repeatedly 
exposed to the same disordered narratives. 


5 
Deepfakes and AI Generated Misinformation 
The rise of deepfake technology has added a dangerous dimension to digital misinformation. A 
deepfake is a synthetic media — such as an image, video, or audio recording — created using 
artificial intelligence to realistically replace someone’s likeness or voice with another. Advanced 
AI methods now allow for the creation of hyper-realistic videos and images that are virtually 
indistinguishable from authentic media. Malicious actors can easily exploit these tools to 
generate fake news, non-consensual explicit material , and politically manipulate context. 
AI-generated revenge porn – an early form of deepfake misuse – signals a broader risk to 
political discourse, personal privacy, and safety. As deepfakes become more accessible, the 
ability to differentiate genuine content from manipulated media becomes increasingly 
challenging, thereby eroding public trust in legitimate information sources. 
Regulatory Gaps and Economic Incentives  
One of the core challenges lies in the regulatory gap: as AI technologies and deepfake 
capabilities evolve rapidly, legislative frameworks have lagged behind. As of now, there are no 
comprehensive  federal laws in the U.S. specifically prohibiting the creation or distribution of 
deepfake, leaving a legal void that allows for the potential misuse of AI technology. Social media 
companies, divine by profit and high engagement metrics, have little incentive to overhaul 
algorithms that promote sensational content – even if that content is misleading or harmful. The 
current profit-driven model of these platforms further incentivizes the spread of false narratives. 
Without robust oversight, these companies continue to operate in a way that prioritizes revenue 
over public safety, leaving young and impressionable users exposed to persistent misinformation.  
Impact of Weaponization of AI and Social Media 
A particularly alarming trend is the weaponization of AI combined with social media’s vast 
reach. Malicious actors are now leveraging AI technologies – such as deepfake generation to 
intentionally  craft disinformation campaigns that are tailored to manipulate public opinion and 
polarize communities. Coordinated deepfake videos can be designed to discredit political figures 
or fabricate evidence that incites social unrest. This weaponization of AI is not merely a 
byproduct of technological advancement; it is a strategic effort to undermine democratic 
processes and destabilize societal trust. The rapid proliferation of such manipulated content 
creates a pervasive climate of uncertainty, making it difficult for citizens, especially young users, 
to trust any digital media. The economic structure of social media platforms further exacerbates 
this threat, as sensational content designed to provoke strong emotional reactions is more likely 
to go viral and generate profit. The combined effects of advanced AI weaponization and 
algorithmic bias thus pose a dual threat; not only is the truth directed, but the very foundations of 
a reliable public discourse are at risk.  
In summary, the convergence of unregulated social media practices, algorithmic bias, and the 
rapid advancement of deepfake technology creates a dangerous environment for young users. 


 
6 
Evidence from multiple studies shows that these platforms are fostering echo chambers that limit 
diverse perspectives, while deepfakes further blur the line between reality and manipulation. 
Coupled with legal gaps and economic incentives that favor sensational content the result is an 
alarming increase in misinformation and a weaponized information environment. Addressing 
these issues requires immediate policy interventions — ranging from stricter regulatory oversight 
to the integration of digital literacy programs in education — to safeguard the next generation 
and preserve the integrity of public discourse.  
 
Environmental Concerns of AI 
The rapid advancement of artificial intelligence has introduced significant ethical and 
environmental challenges that necessitate comprehensive analysis and action. A critical concern 
is the substantial environmental footprint of large-scale AI systems, particularly regarding their 
energy of water consumption. 
 
Training and deploying AI models demand considerable computational resources, leading to 
high energy consumption and carbon emissions. Data centers, which form the backbone of AI 
operations, currently consume about 2% of global electricity . This energy demand is projected to 
rise as AI technologies become more prevalent. Moreover these facilities require vast amounts of 
water for cooling purposes, exacerbating water scarcity issues in various regions. The United 
Nations Environment Programme highlights that data centers are significant consumers of water 
and electricity, contributing to environmental degradation. 
 
Recent developments underscore the urgency of addressing AI’s environmental impact. Utilities 
in the United States are planning to construct new natural gas-fired power plants to meet the 
escalating energy demands of AI data centers. For instance, projects by tech giants like 
Microsoft, Meta, and Amazon involve significant investments in natural gas infrastructure, 
raising concerns about increased carbon emissions and reliance on fossil fuels. 
 
However, some experts argue that the perceived energy crisis associated with AI may be 
overstated. While AI companies express concerns about energy shortages, data center energy 
demand is growing but is not likely to push electrify demands to a critical point. The U.S has 
consistently produced more energy than it consumes, and a significant portion of new electricity 
capacity is expected to come from renewable sources. Therefore, the narrative that AI 
development necessitates increased fossil fuel production may be driven more by political and 
economic interests than by actual energy requirements. 
 
Sustainable AI Practices: 
To mitigate these environmental challenges, several strategies are being explored: 
 


 
7 
● Energy-Efficient Hardware: Developing and developing hardware optimized for energy 
efficiency can significantly reduce the power requirements of AI systems. Innovation in 
chip design and cooling technologies are pivotal in this endeavor. For example, NVDIA  
has introduced liquid-cooled GPUs that allow data centers to cool systems more 
effectively than traditional air conditioning, consuming less power and water.  
 
● Renewable Energy Integration: Powering data centers with renewable energy sources, 
such as wind and solar, can offset carbon emissions associated with AI operation. 
Companies are increasingly investing in renewable energy projects to support their data 
centers. Brookfield Asset Management, for instance, has committed up to €20 billion  to 
develop AI infrastructure in France, focusing on digitalization and clean power.  
 
Regulatory and Economic Implications  
The environmental ramifications of AI have prompted calls for stricter regulations and 
sustainable practices. The United States, the Environmental Protection Agency emphasizes the 
importance of sustainability across industries, advocating for practices that minimize 
environmental impact. Economically, while AI offers substantial benefits, the long-term costs 
associated with environmental degradation could outweigh immediate gains. Therefore, 
integrating sustainability into AI development is not only an ethical imperative but also an 
economic necessity. 
 
Addressing the environmental impact of AI requires a multifaceted approach that combines 
technological innovation, regulatory oversight, and a commitment to sustainability. By adopting 
energy-efficient practices, investing in renewable energy, and designing optimized data centers, 
the AI industry can mitigate its environmental footprint, ensuring that technological progress 
does not come at the expense of our planet’s health. 
Policy Recommendations 
Recommendation One: Sustainable AI Development and resource accountability  
The environmental impact of AI is profound, with large-scale models requiring immense 
computational power and significant resources for cooling data centers. Operations of these 
centers already consume vast amounts of energy, with some data centers using as much 
electricity as small cities . Google reported a 20% increase  in water consumption since 2022. As 
AI continues to advance, this strain on global energy supplies will only intensify. To counteract 
these effects, sustainability standards that ensure AI development is conducted responsibly must 
be implemented. A key component of this strategy is prioritizing renewable energy sources. On 
February 10, 2025, Brookfield Asset Management  announced a €20 billion investment program 
in AI infrastructure powered by clean energy, proving that a sustainable transition is both 
possible and economically viable.  
 


8 
In addition to energy concerns, AI models demand vast amounts of water cooling, exacerbating 
water scarcity in already vulnerable regions.The substantial water consumption of AI data 
centers poses significant challenges, particularly for low-income communities in water scarce 
regions. These facilities often require millions of gallons of water daily for cooling purposes. For 
instance, a single data center can consume up to 5 million gallons of potable water per day, 
sufficient to supply thousands of households or farms. The environmental impact extends beyond 
water usage.  
Research has shown that data centers contribute to air pollution , which disproportionately affects 
low-income communities because of how close they can be to data centers. This pollution can 
lead to adverse health  effects, exacerbating existing social inequalities. There's an urgent need for 
resource-efficient AI models. The development of algorithms that optimize computations while 
minimizing e-usage must be enforced. Currently, few companies disclose their energy and water 
consumption making it difficult to assess AI’s true environmental impact. Policies that mandate 
data center efficiency and require public reporting of energy usage, allow policymakers to make 
informed regulatory decisions. Without such measures, AI’s rapid expansion could become a 
major driver of global  resource depletion and environmental degradation. 
Recommendation Two: Child Centric AI Safeguards 
Children are particularly vulnerable to the negative effects of AI-driven misinformation and 
exploration. Digital platforms, powered by engagement-driven algorithms, often expose young 
users to harmful or manipulative  content. The children’s internet protection act has attempted to 
address this issue by requiring schools and libraries to implement content filters, yet manages go 
unprotected. A critical component of safeguarding children involves the establishment of rapid 
resounds protocols to remove harmful AI-generated content.  
Recently, companies like Roblox, Discord, OpenAi, and Google have collaborated to develop 
robust open online safety tools or ROOST. ROOST is an initiative aimed at providing 
AI-powered content moderation solutions. Voluntary corporate initiatives are not sufficient. The 
establishment  of legally binding protocols that require digital platforms to detect and remove 
harmful content targeted at children in real-time is needed.  
Furthermore, integrating digital literacy programs into schools curricula is essential for 
equipping children  with the skills necessary to identify and counteract manipulative 
AI-generated  content. Without proactive intervention, AI-powered misinformation will continue 
to exploit the developmental vulnerabilities of children, shaping their perception and influencing 
their behavior in ways that could have long-term societal consequences. 


 
9 
Recommendation Three: Enforceable AI Regulations with Public Environmental 
Protections  
Rather than adopting a reactive stance toward AI-related harms, policymakers must shift from a 
reactive to a proactive approach by implementing a comprehensive regulatory framework that 
ensures AI development aligns with ethical, environmental, and public safety standards. This 
framework would consist of federal policies that mandate transparency, fairness, and 
accountability in AI systems. For example, AI companies could be required to disclose their 
algorithms, resource usage, and environmental impact, ensuring that their technologies comply 
with established ethical guidelines. A legally binding system of accountability would establish 
clear consequences for companies that violate these standards. If a company’s AI system causes 
harm – whether through misinformation, privacy violations, or environmental damage – it could 
face penalties such as fines, suspension of operations, or legal action. These penalties would 
encourage responsible development and deploy,en, ensuring that AI systems serve the public 
interests while minimizing harm. 
 
A crucial aspect of AI regulation is establishing liability frameworks that hold tech firms 
accountable for AI-related damages, such as misinformation, privacy violations, and 
environmental costs. Federal agencies like the FTC and DOJ could enforce regulations, while an 
independent AI oversight body could monitor compliance and impose penalties. AI-related 
damages should be added based on the harm caused, such as economic losses from biased 
algorithms or environmental impact from excessive resource use. For example, companies 
responsible for deepfakes or discriminatory AI systems should be held liable. Clear legal 
responsibility ensures companies prioritize ethical development, balancing innovation with 
public welfare. 
 
The long term costs of environmental degradation and societal harm far outweigh the short term 
economic benefits of unchecked AI growth. By integrating sustainable practices into AI policies, 
governments can encourage responsible innovation while mitigating the broader environmental 
risks associated with unsustainable AI practices.  
 
Ultimately, enforceable AI regulation must be designed to balance technological progress with 
ethical responsibility. Without comprehensive legal frameworks and strict accountability 
measures, AI’s rapid evolution will continue to pose risks to public safety, democratic integrity, 
and environmental sustainability. The U.S. government must take action to implement legally 
binding safeguards that ensure AI serves the national interest, addressing societal and 
environmental challenges within the country. 


 
10 
 
Final + Main Recommendation: Establishment of a White House AI Commission or 
Council 
The rapid evolution of artificial intelligence (AI) presents unprecedented opportunities for U.S. 
economic growth, national security, and societal advancement. However, the development and 
deployment of AI technologies also bring significant challenges– ranging from the spread of 
misinformation and algorithmic bias to environmental concerns due to immense energy 
demands. To maintain leadership in this emerging field, the United States must adopt a national 
framework that balances innovation  with ethical and environmental safeguards. A dedicated 
White House AI Commission or Council, overseeing and guiding AI policy across federal 
agencies, is essential to achieve this balance.  
Why a National AI Commision is Essential  1. Ensuring U.S. Technological Leadership 
The United States has long led technological innovation,  and AI is now one of the most 
transformative fields shaping our future. Maintaining a competitive edge in AI is critical 
for both economic prosperity and national security. Although recent federal actions 
emphasize the need to expand domestic AI infrastructure , existing regulatory frameworks 
are struggling to keep pace with rapid advancements. A dedicated national AI 
Commission would consolidate policy efforts, streamline oversight, and establish a 
coherent strategy for AI development – ensuring that regulations evolve alongside 
innovation.  
 2. Mitigating Ethical and Societal Risks  
While AI systems can drive progress, they also pose serious ethical and societal risks. 
AI-generated misinformation – such as deepfakes – threatens democratic processes and 
can manipulate  public opinion. Additionally, algorithmic biases can result in 
discrimination against marginalized communities, exacerbating social inequalities. A 
national AI Commission would be responsible for formulating clear ethical guidelines 
and establishing transparency requirements to ensure that AI technologies are developed 
and deployed in ways that protect civil rights, promote fairness, and prevent harm.  
 3. Addressing Environmental Challenges  
The environmental impact of AI is another critical concern. Large-scale AI models, 
especially in deep learning, demand enormous computational power that leads to 
significant energy consumption and water usage. Recent reports have shown that major 
tech companies are experiencing rising resource demands, which contribute to a growing 
carbon footprint. For example, Microsoft has faced a 34% increase  in water consumption 
as its data center continues to require more water. The commission would implement 
strategies — such as mandatory reporting on energy and water usage and requiring 


11 
developers to mitigate environmental impacts; to ensure that AI developments support 
the U.S. climate goals while encouraging innovation.  
Core Functions and Mandate 
The proposed Commision would have a clear mandate to address both immediate challenges and 
long-term governance of AI technologies. The core functions of the Commission include:  
1. Policy Formulation and Strategic Oversight:
The commission would develop a comprehensive national AI strategy that integrates
technological  innovation with ethical and environmental considerations. It would set
clear guidelines for AI ethics, mandate transparency in AI systems operations, and create
a roadmap for integrating AI into critical sectors like healthcare, defense, and public
administration. This strategy would ensure that AI deployment aligns with U.S. values
and enhances national security.
2. Regulatory Framework and Enforcement:
A critical role of the Commission would be to establish a regulatory framework that holds
AI developers accountable for harmful outcomes such as misinformation or biased
decision-making. This framework would require rigorous pre-deployment testing,
independent third-[arty audits for high-risk systems, and the imposition of penalties for
non-compliance with ethical or safety standards. Such measures would create
accountability not currently present in the fats-moving AI industry.
3. Interagency Coordination and Stakeholder Engagement:
Acting as the central coordinating body for AI policy, the Commission would work with
key federal agencies–including the Department of Defense, Energy, and the Office of
Science and Technology Policy – as well as engage private-sector stakeholders, academic
experts, and civil society groups.. This collaboration would ensure that best practices are
shared and that policies reflect the diverse perspective and needs of all affected parties.
4. Monitoring and Evaluation:
Given the rapid pace of AI advancements, continuous monitoring and evaluation are
crucial. There is a lack of regulation  in regards to AI policy on a federal level.  The
Commission would track metrics such as energy consumption, Carbon emissions, and
safety evaluations of AI systems. Regular assessment would enable the Commision to
ensure responsible development and deployment of AI technologies while adapting
regulations to emerging challenges.


12 
5. Balancing Innovation and Regulation:
Achieving the right balance between encouraging innovation and imposing necessary
safeguards is essential.  Over-regulation could stifle creativity and drive innovation
overseas, whereas under-regulation might expose society to significant risks. The
Commission would adopt a risk-based approach – imposing stringent controls on
high-risk AI systems used in critical infrastructure or public safety, while allowing
greater flexibility for lower-risk applications. In addition, it would promote voluntary
industry partnerships to develop technical standards and best practices, ensuring that
regulations remain adaptive and focused on protecting public interest without impeding
progress.
6. Accountability for Harmful Outcomes:
Holding AI developers accountable for negative outcomes is crucial for ensuring that AI
serves the public good. The Commission would have the authority to enforce penalties
for failures to meet established ethical, safety, or environmental standards. It would also
require public disclosure of AI system performance metrics, safety evaluations, and
resource usage. These measures would build public trust in AI technologies and provide a
mechanism for redress when harmful outcomes occur.
Operational Structure and Implementation: 
For effective operation, the Commission must be structured to encourage collaboration, 
accountability, and transparency. Its membership should include representatives from key federal 
agencies, industry experts, academic researchers, and civil society advocates. A clearly defined 
mandate, empowered by an executive order, would ensure that the Commission can take deceive 
action and report regularly to Congress and the public. Transparency and adaptive governance 
will be key to maintaining public confidence and ensuring that policies evolve with emerging 
technological challenges.  
Anticipated Challenges and Mitigation Strategies: 
The creation of a national AI Commision may face challenges such as resistance from industry 
groups and potential political gridlock. Some Stakeholders may argue that increased regulation 
could stifle innovation, while others may contend that AI poses minimal risks. The Commision 
must engage these stakeholders early in the policy development process, emphasizing that its 
goal is to protect both innovation and public safety. By adopting a flexible, risk-based approach, 
the Commision can avoid an overly burdensome regulatory framework while focusing on the 
most pressing concerns.  
Summary: 
The establishment of a White House AI Commission is critical for ensuring that the United 
States maintains its leadership in AI while addressing the ethical, societal, and environmental 


 
13 
challenges associated with this rapidly evolving technology. By creating a comprehensive, 
national strategy for AI governance, the commission would encourage innovation, safeguard 
public welfare, and protect the environment. With a strong focus on domestic priorities, the 
Commission would ensure that AI development benefits all Americans, strengthens our 
democracy, enhances national security, and supports long-term sustainability. 
 
Conclusion: 
The rapid advancement of AI presents both unprecedented opportunities and profound risks, 
particularly in the realms of misinformation, child safety, and environmental sustainability. 
Unregulated digital platforms – powered by engagement-driven algorithms – expose young users 
to manipulative content, deepfake misinformation, and echo chambers that distort public 
perception. Meanwhile, AI’s escalating energy and water consumption threaten global 
sustainability, exacerbating resource scarcity and environmental degradation. These issues 
demand immediate and enforceable policy interventions. Companies must be held responsible 
for AI-driven harm, from misinformation to environmental damage. By prioritizing ethical AI 
development, we can ensure technological progress aligns with public safety, democratic 
integrity, and environmental sustainability. The time for proactive, enforceable action is now 
before these challenges become irreversible.  
 
 


14 
Works Cited 
1.https://www.federalregister.gov/documents/2025/02/06/2025-02305/request-for-informati
on-on-the-development-of-an-artificial-intelligence-ai-action-plan
2.https://www.epa.gov/sustainability/learn-about-sustainability
3.https://journals.sagepub.com/doi/full/10.1177/17456916231185057#:~:text=Most%20cur
rent%20digital%2Dmedia%20algorithms,addictive%20(Munger%2C%202020b).
4.https://pmc.ncbi.nlm.nih.gov/articles/PMC10111082/
5.https://dictionary.cambridge.org/us/dictionary/english/deepfake?utm_
6.https://legaljournal.princeton.edu/the-high-stakes-of-deepfakes-the-growing-necessity-of-
federal-legislation-to-regulate-this-rapidly-evolving-technology/?utm
7.https://www.jstor.org/stable/26891938
8.https://onfido.com/blog/deepfake-law/?utm
9.https://neurosciencenews.com/social-media-behavior-misinformation-23752/?utm
10.https://source.washu.edu/2024/08/political-deepfake-videos-no-more-deceptive-than-othe
r-fake-news-research-finds/
11.https://resources.nvidia.com/en-us-sustainable-computing/ai-ener gy-efficiency
12.https://www.unep.org/news-and-stories/story/ai-has-environmental-problem-heres-what-
world-can-do-about?utm_
13.https://www.businessinsider.com/utilities-ai-natural-gas-power-microsoft-meta-amazon-2
025-2?utm
14.https://www.businessinsider.com/utilities-ai-natural-gas-power-microsoft-meta-amazon-2
025-2?utm
15.https://www.eia.gov/energyexplained/us-energy-facts/
16.https://www.nvidia.com/en-us/
17.https://bam.brookfield.com/press-releases/brookfield-invest-eu20-billion-frances-ai-infras
tructure
18.https://www.valicor.com/blog/the-environmental-impact-of-ai-water-scarcity-and-the-fut
ure-of-computing#:~:text=As%20AI%20models%20become%20increasingly ,in%20regio
ns%20facing%20water%20scarcity .
19.https://utulsa.edu/news/data-centers-draining-resources-in-water -stressed-communities/?u
tm_source=chatgpt.com#:~:text=Unfortunately%2C%20many%20data%20centers%20re
ly%20on%20water%2Dintensive%20cooling%20systems%20that%20consume%20milli
ons%20of%20gallons%20of%20potable%20(drinking)%20water%20annually .%20A%2
0single%20data%20center%20can%20consume%20up%20to%205%20million%20gallo
ns%20of%20drinking%20water%20per%20day%2C%20enough%20to%20supply%20th
ousands%20of%20households%20or%20farms.
20.https://thisis.caltech.edu/news/air-pollution-and-the-public-health-costs-of-ai?utm_source
=chatgpt.com#:~:text=The%20authors%20also,compensated%20at%20all.%22


 
15 
21. https://bidenwhitehouse.archives.gov/briefing-room/statements-releases/2025/01/14/state
ment-by-president-biden-on-the-executive-order-on-advancing-u-s-leadership-in-artificial
-intelligence-infrastructure/  
22. https://www.epa.gov/sustainability/learn-about-sustainability  
23. https://www.statkraft.com/newsroom/news-and-stories/2018/data-centres-the-new-power-
intensive-industry/#:~:text=Like%20a%20small%20city,for%20Statkraft's%20data%20c
entre%20initiative . 
24. https://www.valicor.com/blog/the-environmental-impact-of-ai-water-scarcity-and-the-fut
ure-of-computing#:~:text=As%20AI%20models%20become%20increasingly ,in%20regio
ns%20facing%20water%20scarcity . 
25. https://www.theverge.com/news/609367/roblox-discord-openai-google-roost-online-safet
y-tools?utm  
26. https://www.unesco.org/en/legal-affairs/recommendation-ethics-artificial-intelligence#:~:
text=Considering%20that%20AI,environment%20and%20ecosystems  
27. https://www.theguardian.com/technology/2025/feb/07/call-to-make-tech-firms-report-dat
a-centre-energy-use-as-ai-booms#:~:text=“In%20recent%20years,2022%2C%20up%202
0%. 
28. https://foe.org/news/ai-threat-report/#:~:text=Generative%20AI%20has,with%20its%20p
roducts. 
 
 
 
 


