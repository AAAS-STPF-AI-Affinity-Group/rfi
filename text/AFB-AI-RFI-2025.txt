March 15, 202 5 
Faisal D ’Sou za 
NCO 
2415 Eise nhower A venue  
Alexandria, VA  22314  
Via email  
RE: Request for Information on the Development of an Artiﬁcial Intelligence (AI) Action Plan  
Dea r Faisal D ’Sou za: 
Thank you for the opportunity to comment on the development  of an Ar tiﬁcial Intelligence 
Action Pla n. The American Foundation for the Blind (AFB) is a national nonproﬁt that 
creates equal opportunities and expands possibilities for people who are blind, have low 
vision, and are deafblind through advocacy, thought leadership, and strategic partnerships. 
AFB ’s research team recently conducted a  study using a  modiﬁed  Delphi methodology to 
understand what exper ts agree on when considering how AI will affect people with 
disabilities.1  The experts , who hail ed from academi a, industry, and policy profession s, 
agree that AI presents unique oppor tunities but also poses some signiﬁcant risks. Our 
research team is following  this initial study with a survey that explore s directly the 
experiences of individuals with disabilities  as more people begin to adopt AI -powered 
technolog ies for education , emp loyment, and independent living.  
AI could  power transformative new assistive technologies 
that support emplo yment , education, and indepen dent 
living. 
The  experts in our study agreed that there a re technologies that will clearly beneﬁt from the 
incorporation of AI to provide on -demand information and interpre tation. They clearly 
identiﬁed transp ortation as a secto r that could be neﬁt from AI as computer vision and 
object recognition te chnologies become cheaper and more re liable. The  use of apps that 
provide instantaneous  and accurate environment al information is like ly to improve 
1 Silverman, A., Baguhn, S., Vader, M., Romer o, E, & So, C.H.P.  (2025). Empowering or Excluding: Expert 
Insights on Inclusive Artiﬁcial Intelligence for People with Disabilities. American Foundation for the Blind . 
https://www.afb.org/research -and -initiatives/empowering -or-excluding  


navigation in unfamil iar environments for some people who are blind.  Such technol ogies 
could  also improve independent  living and employment by making it easier to i dentify 
unknown objects , such as w hen reading mail or identifying the buttons  on inaccessible 
office equipment.  Additionally, the use of technology to identify at scale the accessibility of 
a state o r localit y’s sidewalk network has the potential to speed up improvement s to 
pedestrian network connectiv ity and safety for nondrivers . 
The re were additional areas that exper ts identiﬁed as potential beneﬁts for people with 
disabilities, but whose beneﬁts depend on how the overall software, program , or use case 
is deﬁned. For  example, autono mous vehicles  have been touted as tra nsformative for 
independent  mobility for many blind people who typically cannot travel  alone in a v ehicle. 
Being a nondriver in our current transportation system creates dependenc ies o n friends or 
families o r requires people to spend extra time waiting on slow or unre liable transit  
systems.2 Autonomous vehi cles could make reliable , quick travel more available to 
nondrivers. However, the pool  of experts expres sed variation in their assessment of the 
beneﬁts of autonomous vehicles for several reasons. Some of the exp erts e xpressed 
concerns that the per -trip cost of using autonomous vehi cles will be unaffor dable for most  
people who are blind, many of who m are underemployed , live  in rural areas,  or are older 
adults on ﬁxed incomes. Others r aised questions about the cost of investing in 
autonomous vehicles compared to the cost of building robust public transportation 
systems  while others suggested that these investments should not be mutually exc lusive . 
Finally, some of the exp erts did not think that sufficient data has been collected to 
understand whether AVs  or other t ransportation uses of AI  will protect the  pedestr ian 
safe ty of people with disabilities.  
AI poses r isks of inaccuracy, discrimination, and 
inaccessibility . 
While we remain hopeful that AI will be used to maximize indep endence and opportunity 
for people who are blind, the experts in our stud y identiﬁed clear r isks to people who are 
blind. First, AFB has extensively documented the inaccessibility of num erous software 
appl ication s and website interfaces  and the resulting harms that such  inaccessibility 
poses.3 In this study, o ur AI expert  pool was skeptical that students with disabilities will be 
2 O’Day, B ., Chanes -Mora, P., & Roth, M. (2020). Project V ISITOR: P hase Two. American Foundation for the 
Blind . https://www.afb.org/sites/default/ﬁles/2020 -04/Project -VISITOR -Phase -Two -Report -Final.pdf  
3 Silverman, A., Baguhn, S., Amorosino, B., & Carranza, R. (2023). Barriers to Digital Inclusion: Digital Access 
Barriers for Americans who are blind, have low vision, or are deafblind. American Foundation for the Blind . 
https://afb.org/research -and -initiatives/bdis -series/barriers -digital -inclusion -survey  


able to  fully participate in the use of education al technology that inco rporates AI because 
of the problematic record o f educational technology companies in delivering accessib le 
technology interfaces. This skepticism is supported by  research about remote schooling 
that found that blind s tudents were expect ed to use num erous inaccessible online course 
materials .4 In addition, AFB found that m ore than fort y percent of respondents  from an 
earlier study reported seeking  out a different business es when apps or websites are 
inaccessible , about 65%  could not complete tasks a t all, and about 85% reported wasting 
time to solve the inaccessibility barrier.5 Another study found that blind people may spend 
2.4 additional  hou rs per we ek trying to use websites that are other wise accessible to 
sighted people.6 Thus, it is imperative  that software interfaces  that incorporate AI or that 
teach AI literacy skills  be made fully accessible to people who are blind.  
Sec ond, the experts in our AI study agree d that some uses of AI pose particular risks of 
discriminat ion or bias. For example, job screening applications may not be designed to 
account for the characteristics of disabled job applicants. Thes e biases range from the  
unique employment situations  that people with disabilities  may have  (e.g. gaps in 
employm ent), explicit bias (e.g. rejecting any  applications that mention disability), 
interactive testing that does not allow for reasonable accommodations (e. g. use o f 
assistive techn ology or the  need for a nonvisual interface), or video or image reco gnition 
biases (e.g. an auto mated interview feature that penalizes certain eye  gazes or speech 
patterns).  In addition, t he experts were concerned that healthcare or insurance decision 
tools are more likely to den y care to people with disabilities who often need both more 
frequent care and more unus ual care. Attempts to economize healthcare through AI run 
the risk o f reducing or slowing access to medical care for people with disabilities  because 
AI favors average  diagnosti c cases or typical health proﬁles . The representa tiveness of 
training data and the weig hting of models plays a role in determining whether a decision -
making  tool  has a disability -related bias.  
Third, the use case s of AI that will be neﬁt people who are blind require AI to achieve  a high 
level of consisten t accuracy  and quality. If a blind person needs to use a  comp uter vision 
4 Silverman, A. M., Munguia Rodriguez, G., Rhoads, C. R. & Bleach, K. (2022). Access and Engagement III: 
Reﬂecting on the Impacts of the COVID -19 Pandemic on the Education of Children Who Are Blind or Have 
Low Vision. American Foundation for the Blind. Access and Engagement: Examining the Impact of COVID -19 
on Students Birth -21 with Visual Impairments, Their Families, and Professionals in the United States and 
Canada.  American Foundation for the Blind. https://www.afb.org/research -and -
initiatives/education/covid19 -education -research/access -and -engagement -iii/access  
5 Silverman et al (202 3). 
6 Silverman, A. M., Abdolrahmani, A., Baguhn, S. J., Carranza, R. R. & Amorosino, B. B. (2024). Barriers to 
Digital Inclusion 2: Documenting digital access challenges for people who are blind or have low vision. 
American Foundation for the Blind. https://afb.org/research- and -initiatives/bdis -series/barriers -digital -
inclusion -2 


app to id entify  where they are or what something says, the standard of accuracy must be 
high in part because some one  who is blind may not be able to independently  judge the 
accuracy of the visual description. As an example, if a computer vision  app report s that the 
women ’s rest room is on the left, but it is actually on the right, trusting the app could result 
in embarras sment or conf rontation.  While  AI models today tend to r eport their answers 
with a high degree of conﬁdence,  performance  disparities  or hallucinations  may be more 
likely to affect people with disabilities who are unable to independently assess the 
accuracy of generative outputs , and automati on bias ma y lead individuals to overly t rust 
the outputs of AI based on marketing  claim s. 
The federal gove rnment should  promote research, 
innovation, oversight, and workforce development to 
promote the bene ﬁts and mi nimize harms from AI use.  
Cert ain uses of artiﬁcial intelligence require greater scru tiny to ensure that ou tcomes are 
fair for every American.  AFB urge s the a dministration to develop an AI action plan t hat 
accounts for vari able beneﬁts and risks of AI in different use cases. The use of AI to make 
decisions about funding, beneﬁts eli gibility, traffic safety, or employment poses greater 
economic and civil rights risks than the use of AI for general writing tasks, such as 
brainstorming  or editing a document.  The experts in our study , including those in industry, 
agreed that  the government should enact AI regulation s that  are proactive, account  for the 
harms of algorithmic bias, and include strong privacy and accessibility provisions . 
Federal uses of AI must be buil t on inclu sive data sets, prop erly weighted models, au diting 
and testing, and risk mitig ation.  If the government uses AI to make programmatic decisions 
or to create an information chatbot for employees o r the public, it is im perative that the AI 
models produce  consistently accura te information supported by the law and the 
government ’s guidance on implementing  the law. That information should be supported by 
citations to help users understand more about the model ’s “reasoning ” and how  to seek 
further  information. For example, it was concerning that when New York Ci ty developed a 
chatbot , it produced con ﬁdent answers that claimed landlords could discriminate ag ainst 
renters, that fun eral home s could con ceal prices, and that employers could withho ld tips 
from employees in contravention of the law.7  
7 Lecher, C. ( March 29, 2024). NYC ’s AI Chatbot Tells Businesses to Break the Law. The Markup . 
https://themarkup.org/news/2024/03/29/nycs -ai-chatbot -tells -businesses -to-break -the-law 


In additi on, a number o f algorithm ic models used for determining child welfare risk have 
been identiﬁed as using biased data, arbi trary w eights , and opaque  disclosures .8 For 
example,  parents with disabilities in Pennsylv ania  lost custody of their child  after  taking 
their sick child to the hospital, and they suspect that the  child services agency  use d an 
automated risk calculation system which  ﬂagged their unrelated record of having 
disabilit ies as a risk factor  in declaring them unﬁt to care for their child .9 In Michigan, the 
Michigan Integrated Data Automated System incorrect ly accused thou sands of people of 
unemployment insurance fraud, resu lting in citizens losing their homes, ﬁ ling for 
bankruptcy, and having to pay for lawyers to defend agains t the false claims.10 The federal 
government  should ensure that any algorithm ic decision making systems do not produce 
fals e information or improperly ﬂag indi viduals  as unqualiﬁed or high risk  based on 
unrelated  or inappropriate  individual  chara cteristics  
The federal government should invest in  research and development into uses of AI that 
maximize the beneﬁts of AI and  create  tools that measure potential harms.  The AI Action 
Plan should utilize fully the resource s of the National Institute of Standards and Technology 
and other scientiﬁc agencies to carry out the work  begun during President  Trump ’s ﬁrst 
administration to develop  voluntary industry standards for identifying and remediating risks 
with in AI models. In industries such as healthcare, there is currently  a substantial lack of 
invest ment in the tools ne eded  to verify that people with disabilities have the same health 
outcomes from the use of AI models as nondisabled people. By pr ioritizing research 
investments  and funding for responsible AI model development , the government can  drive 
innovation that serv es the gr eatest number of Americans.  
STEM education must be accessible to people who are blind or have low vision.  The Trump 
administration should ensure tha t blind stud ents are able to learn science, te chnology , and 
mathematics from the earliest level of schooling, so that career s in AI development are  
open  to all . Our research has identiﬁ ed frustrated parents who report that their children are 
not given the opportunity to partic ipate in sc ience lessons because the curricular materi als 
8 Trail, M. (February 6, 2024). Algorithmic Decision -Making in Child Welfare Cases and Its Legal and Ethical 
Challenges . The American Bar Association . 
https://www.americanbar.org/groups/litigation/resources/newsletters/childrens -rights/winter2024 -
algorithmic -decision -making -in-child- welfare -cases/  
9 Ho, S. & Burke, G. ( January 31, 2023). Child welfare algorithm faces Justice Department scrutiny . Associated 
Press . https://apnews.com/article/justice -scrutinizes -pittsburgh -child- welfare -ai-tool -
4f61f45bfc3245fd2556e886c2da988b  
10 Charette, R. ( January 24, 2018).  Michigan’s MiDAS Unemployment System: Algorithm Alchemy Created 
Lead, Not Gold . IEEE Spectrum .  https://spectrum.ieee.org/michigans -midas -unemployment -system -
algorithm- alchemy -that -created -lead -not-gold  


are inac cessible.11 Others have reported concerns that sighted children are encouraged to 
use the computer well before blind children receive even bas ic computer and assistive 
technology skills training.12 STEM education  accessibility is imperative for school age 
children as well as  in computer science programs at universities. Enfor cem ent of the 
Individuals with  Disabilities Education Act, the Americans with Disabilities Act , and Section 
504 of the Rehabilitation Act contributes to ensuring  that blind students  are able to 
become engineers and developers who create  AI models and software.  
Given that not every job seeker  aspires to become a developer, it is also imperative  that 
people who  are blind or have low vision can beneﬁt from advances in AI in the employment 
setting . As our econom y transitions to greate r use of AI software, workers who are skilled at 
using AI may have an advantage over workers who do n ot understand or cannot use AI. For 
that reason , AI literacy and upskilling courses must be accessible to people with 
disabilities regardless of whether  they are provided by the vocation rehabilitation system, 
wor kforce  develop ment  programs , employers, or a community college or university 
system.  
We apprecia te the opp ortunity to contribute to the A dministr ation’ s action plan on AI  and 
urge the administration to  adopt a comprehensive plan that promotes the  AI beneﬁts  for 
and use by people who are blind, have low vision, or have other disabilities. A coordinated 
whole -of-government app roach to accessibility, data representation, and workforce 
development will i mprove the oppo rtunities for blind people  to receive an receive a  quality 
education and compete in the  American economy. If you have any questions or if we can be 
of fu rther assistance, please do not hesitate to reach out to Sarah Malaier at 
Sincerel y, 
Stephanie Eny art 
Chief Public Policy and Research Officer  
11 Rosenblum, L. P., Chanes -Mora, P., Fast, D., Kaiser, J. T., Wild, T., Herzberg, T. S., Rhoads, C. R., Botsford, K. 
D., DeGrant, J. N., Hicks, M. A. C., Cook, L. K., & Welch -Grenier, S. (2021). Access and Engagement II: An 
Examination of How the COVID -19 Pa ndemic Continued to Impact Students with Visual Impairments, Their 
Families, and Professionals Nine Months Later, American Foundation for the Blind.  
12 Silverman et al (2022 ). 


