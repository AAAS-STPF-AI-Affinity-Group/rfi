From: Vogel, Andrew
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Tuesday, March 4, 2025 9:38:18 AM
I am writing to inform you about the development of the Artificial Intelligence (AI) Action  
Plan, as requested in the Federal Register notice (Document Number: 2025-02305).
Self-Efficacy with GTAs on AI
My current research focuses on utilizing AI tools for teaching and learning. I have
participated in book clubs with faculty members to analyze the challenges andsolutions that have emerged regarding AI. I have connected with other academictechnologists by presenting my VR meditation research at conferences like theEducational Technology Collaborative (Vogel, 2023). The collaborativepublished my paper on their website. The professional networking has equippedme with resources to share with my HESA cohort and OSU staff. Sharing theseresources has helped me employ multiple frameworks to develop meaningfulsolutions. For example, a colleague at the conference recommended JoyBoulamwini’s book Unmasking AI, which discusses the implications of AI onBIPOC communities (2023). As a straight white man, these perspectives enlightenme on how emerging technology can exhibit bias and further marginalize others.
Professional Knowledge
Writing about digital accessibility allowed me to develop skills in designingresearch projects with student subpopulations. Understanding students withdisabilities at OSU required developing research practices, such as exploringuniversity offices that work with digital accessibility. In the Advanced StudentDevelopment course, Orefice provided me with data points from the OSU offices.I researched how OSU's Student Life Disability Services (SLDS) and the DigitalAccessibility Center (DAC) support this subpopulation by offering training,resolving complaints, and processing exception requests. I examined how theseservices function and operate in the context of a large public university. I used mycoursework from my cognates, Understanding Organizations, to make out astakeholder analysis grid (Bryson, 2011). Furthermore, the AdvancedDevelopment course helped me find literature on the subpopulation of studentswith disabilities. Patton’s Critical Disability Theory (CDT), which discusses howthe identities of students with disabilities are complex and may not always beavailable, helped me understand the complexities of a large university supportinga range of accommodations (2016).
Transformation of Professional Knowledge
The discourse with my cohort in the Strategies and Leadership class challenged


my viewpoints and enriched my understanding of leadership in higher education.
As a straight white male, I initially struggled to understand how people of color
navigate their identity when viewed by different races in leadership roles. Hearingfrom other classmates and their experiences as managers at OSU helped me seetheir perspectives. As I transition into different roles at the university, I reflect onthese discussions, acknowledging how identities shape inputs and how theinstitution's identity creates the environment. These same conversationsintersected in the Educational Law course. My cohort would reference the sameissues in both courses, reflecting how the Supreme Court rescinded affirmativeaction (Howe, 2023) and how the leadership at the university is to move forward.The in-class leadership activities of having dialogue, such as the think, pair, andshare posters, have deepened my understanding of educational leadership'scomplexities and prepared me for future professional challenges.
Literature Review
Theoretical Framework: Self-Efficacy
Bandura's seminal work on self-efficacy outlines the concept as a critical factor inbehavioral change and its implications for various fields, including education andpsychology (1977). The framework is chosen to understand how GTA’s in ASCperceive their abilities using AI for teaching and learning. To aid myunderstanding, I will examine the four sources to multiple modes of induction.Bandura notes that positive feedback can lead to success. Regarding emotionaland physiological states, a positive mood bolsters self-efficacy, while negativemoods diminish it. I want to see if these self-efficacy patterns arise with the GTAsand the experiences with AI.
Much of the literature collected does not explicitly capture Bandura's frameworks;however, the research studies the connections between students' emotional states,critical thinking, and precautions regarding AI tools. The challenges ofresearching AI are due to the rapid change of states and volume of data (Lynch,2024). In the past three years, academia has developed 28 foundational AImodels, while the private industry has produced 108.
AI and Teaching
AI tools like Chat Generative Pre-Trained Transformers (GPT) have steadilygained traction in the mainstream since 2018 (Batsaikhan & Correia, 2024).Various scholars are developing and utilizing GPT tools in academia.
Blooms Taxonomy for the Modern Machine
Findings indicate that using Bloom's Taxonomy language paired with AI-generated content challenges students to move beyond validation andencourages seeking additional sources. The students mentioned strategieslike those used by knowledge workers, such as refining prompts to obtainmore optimized output (Gonsalves, 2024; Lee et al., 2025). Additionalresearch finds that creating assessments where students conduct


presentations and develop multimedia, such as websites (Rudolph et al.,
2023).
Research shows that GTAs reflect on how AI tools generate more
responsibilities and pedagogical frameworks while being diligent inrevising assessments and educating undergrads on the ethics of AI(Katsanakis, Wang, and Affejee, 2023). Additional scholars call for moreresearch from educators on the role of AI in learning (Carvalho, Martinez-Maldonado, Tsai, Markauskaite, and De Laat, 2022).
Self-Efficacy and AI in the Classroom for Instructors
A case study surveying the self-efficacy of 20 education GTAs regarding AI toolsfound that they are eager to learn how to use these tools but also seek furthertraining and support (Power, 2024). Another study revealed that teaching graduatestudents to use AI effectively increased their comfort levels from 12% to 60%(Wood & Moss, 2024). Additionally, research indicated that students use AI toolscautiously and doublecheck the generated output (“About the Project,” 2024;Chung et al., 2024; Lee et al., 2025). A thematic analysis survey reviewed datafrom over 8,000 undergraduates; 32% felt that the university guided them in usingAI, 28% expressed fear and 43% felt less intelligent because of AI (2024).Furthermore, scholars argue that educational leadership should prioritize creatingformal professional digital literacy programs instead of merely emphasizing theimplementation of AI policy (Baskara, 2025).
Brave New World of Academic Integrity
Educators took a direct approach to teaching their students about the ethics andlimitations of using AI tools, and they found that ten out of twenty students didnot view their final work with AI as cheating (Fyfe, 2023). Scholars identify aresearch gap regarding AI tools used by GTAs in their dual roles of teaching andlearning (Katsanakis, Wang, and Affejee, 2023). Furthermore, scholars haveoutlined several perspectives, but no consensus has been established on thegovernance of AI (Fyfe, 2023; Katsanakis, Wang, and Affejee, 2023).
Many institutions are developing guides or “AI Cookbooks” to train educators onhow to use AI tools effectively. (How to Productively Address AI-Generated Textin Your Classroom, n.d.; The Ohio State University, n.d., Missouri & Florida,2024). These guidebooks range from providing brief tips to entire lesson plans.An example is a writing center that developed a book of recommendations forfaculty on adopting best practices for using AI tools (Yee et al., 2024).Recommendations include looking for hallucinations of citations and having clearAI writing policies in the syllabus (University of Central Florida, n.d.).
Lie Gauges of Academia: AI Detectors
The scholars conducted a practice with engineering GTAs to evaluate if essaydata was AI-generated (Dugan et al., 2024). The research found that it isimpossible to determine if an essay was AI-generated with AI detectors from


third-party vendors, such as Turnitin. The results of false positives have led to
lawsuits involving the resending of scholarships (Hale, 2025). Reports show
vendors and universities turned off their AI detector capabilities due to falsepositives (Pratschke, 2024). More studies indicate that AI detectors are biasedagainst non-native writing students (Sadasivan et al., 2025).
Researchers found that AI, such as the grammar tool Grammarly, is more likely tobe flagged by AI detectors (Bordalejo et al., 2025). AI tools that replace andgenerate entire passages, such as Microsoft’s CoPilot, went undetected. Facultycenters found that students can use AI tools to disguise their text with tools likeQuillBot and WordAi (University of Central Florida, n.d.). Due to theunreliability of AI detectors, researchers recommend that academics mentorethical AI practices instead of blanket policies (2025). A university published astatement discouraging faculty from using AI detectors due to biases and falsepositives (University of Iowa, n.d.).
The Rebirth of Essays: Artificial Assessment
Experts claim that academia can no longer use essays as assessments due to AI.(Marche, 2022). Others have refuted these claims, stating that higher educationmust evolve formative assessments (Rim, 2022). Researchers found AI toolshelpful because they provide rapid feedback and enhance students’ writing skills,improving their self-efficacy (Gardner et al., 2021; Mollick & Mollick, 2023).Educators find there are additional ways to assess students, such as using paperand pen alongside AI tools (National Foundation for Educational Research, 2024;Sharples, 2022).
AI and Learning
Researchers find that students using AI tools to solve tasks improve their self-efficacy (Schei et al., 2024). Research has found that AI tools have outpaceddevelopment times for intelligence tutoring systems (ITS) (Weitekamp et al.,2020). However, developing AI tools is costly and has left academia behind theprivate sector by wide margins (Lynch, 2024).
Bias and Environmental Concerns
Scholars find several implications of AI tools, as AI serves as both a practical tooland a source of controversy in an arms race, shaping our global markets (Huang,2025). DeepSeek, a Chinese-developed AI, claims its product is better andcheaper than American products, which shocked the stock markets (2025). Therise of international AI raises privacy and national security concerns for theUnited States regarding data practices (2025).
Researchers caution about humanity's ethics and fate with the emergence of AItools (Roose, 2025). A report examines how AI’s rapid evolution can passcomplex assessments it failed to achieve a year earlier (Phan et al., 2025). Theassessments indicate AI will outsmart the most sophisticated problems developedby humans. Advocates for AI reform argue that the rapid development of AI


poses risks, including the potential for rogue AIs that can cause harm (Hendrycks
et al., 2023; Hoffman, 2023).
Creatives and artists have felt the impact of deepfakes. Large companies like
Meta have illegally scraped the internet to train their AI for the “Greater Good”(Udinmwen, 2025). Higher education institution, such as the University ofMichigan, have developed their own AI to navigate the concerns of bias andcopywriting (O’Connell, 2025).
Advocates for AI emphasize that higher education professionals must be aware ofthe ethical issues surrounding AI (Schei et al., 2024). For instance, an AIresearcher was prompted by an AI tool to commit suicide (Guo, 2025). Industryexperts predict that AI will evolve rapidly alongside high-performing computers,such as quantum computers (Xie et al., 2023). The problems with AI feedbackextend to bias and manipulation (Giray, 2024). Non-native speakers are morelikely to be flagged as false positives by an AI detector. These biases can arisefrom students generating outputs and false positives from the AI detectors. Lastly,there is growing concern about the environmental problems of AI, includinghigher CO2 emissions from large data centers (Kanungo, 2023) and plans to adoptnuclear energy (Hjelmeland et al., 2025).
This document is approved for public dissemination
 and contains no business-proprietary or
confidential information. The government may reuse its contents in developing the AI Action
Plan and associated documents without attribution.Sincerely,
Andy VogelInstructional DesignerCollege of Engineering/Engineering Technology Services475 Knowlton Hall275 W. Woodruff, Columbus, OH 43210


