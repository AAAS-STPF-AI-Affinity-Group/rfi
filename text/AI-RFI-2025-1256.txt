PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 87-y695-k5i3
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1256
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  The Greenlining Institute
General Comment
See attached file(s)
Attachments
Com m ent from  The Greenlining Institute Re RFI Developm ent for an AI Action Plan


March 13th, 2025 
Office of Science and Technology Policy 
1600  Pennsylvania Ave NW 
Washington, DC 20500 
Re: Development of an  Artificial Intelligence Action Plan  
Docket No. NSF_FRDOC_0001-3479 
The Greenlining Institute appreciates the opportunity  to provide comments to the Office of 
Science and Technology Policy's Request for Information in regards to the Development of the 
Artificial Intelligence Action Plan. As our federal government moves forward and builds anew to 
fit the needs of this digital-first era, we are hopeful that our policy recommendations will 
highlight how our shared goals to create prosperity and wealth for all Americans can be 
achieved through careful, deliberate, and equitable policymaking.  
The Greenlining Institute works t o build  a future where race is never a barrier to economic 
opportunity. For over 30 years, we have built a proven track record in accomplishing this goal. 
From passing the Community Reinvestment Act in 1978—which has supported banks in 
facilitating the growth of wealth and prosperity in formerly redlined communities—to creating 
pipelines that help people of color become successful small business owners, we have been at 
the frontline building a more just economy. Our work in technology equity has increased 
broadband access to low-income communities throughout the United States and informed 
financial institutions on the responsible use of AI and alternative data.  President Donald Trump’s Executive Or der on AI has created a federal landscape that positions 
American industry leaders to create the world’s leading innovations in artificial intelligence. We 
commend the goals that were laid out in the President’s 2020 Executive Order on AI: to create 
AI for American innovation, AI for American industry, AI for the American worker, and AI with 
American values. In order to ensure that the American people are able to reap the benefits of 
these goals, however, we believe that it is imperative that we create a regulatory framework 
that will promote a sustainable, competitive, and equitable environment. We can only win if the 
rules of the game are laid out clearly and fairly. Therefore, we implore the Administration to 
consider the following policy recommendations.  
1 


I. Energy Efficiency & Sustainability
Our pursuit of innovation  is limited by our material conditions. For AI, that material limitation is 
energy. Scientists anticipate that our global supply of nonrenewable energy sources, such as 
fossil fuels and oil, will be depleted within 30-70 years.1 
As AI’s demand for energy increases,  our pr oduction of the fossil fuels needed to power these 
data centers will be dramatically strained. The International Energy Agency estimated that 
global electricity demands from AI data centers will double between 2022 and 2026.2  In the 
United States, where the majority of our data centers are still fueled by nonrenewable energy 
sources, our claim to the share of the pot will shrink. Inevitably, we will fall behind other 
countries that have already transitioned to more sustainable energy sources.  
If left unhindered, the cost of this s train will be paid for by working American families who have 
no choice but to pay their rising energy bills at the end of each month. We saw this when New 
York households and small businesses paid an extra $204 million and $92 million annually, 
respectively, because of increased electricity consumption from cryptominers.3 The Mid-Atlantic 
regional grid, where several data centers are housed, is projected to see rate increases of up to 
20% by this year; between 2024 and 2025, their grid operators went from paying $2.2 billion for 
power to $14.7 billion.4 We saw how AI’s water depletion led to a devastating strain on 
California’s disaster response during the wildfires.5 When coupled with the fact that these data 
centers are more likely to be built near low-income communities and communities of color, we 
see these effects disproportionately impacting our most vulnerable American families.6 These 
impacts are dangerous, pervasive, and inequitable. The race to the bottom will not be against 
other nations—the race will be against ourselves.  Sustainable AI development mus t ma tch the pace of sustainable energy development; clear 
executive direction and deliberate regulatory guidance is key to accomplishing this balance. In 
just a few short decades, China went from being the world’s largest emitter of greenhouse gases 
6 https://gradientcorp.com/trend_articles/impacts-of-large-data-centers/#:~:text=Typically%2C%20data  
%20centers%20are%20built,jobs%20beyond%20the%20construction%20phase .  5 https://fortune.com/article/how-much-water-does-ai-use/  4 https://opc.maryland.gov/Portals/0/Files/Publications/RMR%20Bill%20and%20Rates%20Impact%20Report_  
2024-08-14%20Final.pdf?ver=V9hZfyTmjLeNVt2Dg3cTgw%3D%3D  3 https://bfi.uchicago.edu/insight/research-summary/when-cryptomining-comes-to-town-high-electricity-  
use-spillovers-to-the-local-economy/  2 https://iea.blob.core.windows.net/assets/6b2fd954-2017-408e-bf08-952fdd62118a/Electricity2024-Analysis
 
andforecastto2026.pdf  1 https://mahb.stanford.edu/library-item/fossil-fuels-run/  
2 


by volume to being the world’s leading producer of renewable energy. They were able to 
accomplish this by creating strategic investments in solar, wind, green hydrogen, and 
geothermal projects.7 Today, China has more than 80% of the world’s solar manufacturing 
capacity. Through executive direction, the country has been able to dominate the field and 
position itself as the sustainable global supplier of goods in an increasingly carbon-strained 
world.8 One of these goods, evidently, being AI.  
We can be a leader in powerful, sust ainable  AI by creating regulations that mimic future 
conditions. If tomorrow’s landscape requires AI that runs on limited energy, then today’s 
developers should be building AI that runs on limited energy. Furthermore, by investing in our 
green infrastructure and reducing AI’s energy consumption, we reduce our reliance on foreign 
oil and risks of energy disruption. Sustainability, efficiency, and affordability should be a point of 
pride in American innovation—our AI Action Plan can reflect that. Therefore, we propose the 
following recommendations:  1.Embolden the National Institute for Science and Technology to create standards for AI
energy efficiency — The NIST should provide information to developers and consumers
on which systems are most efficient. Look to the EU Energy Efficiency Directive, which
dictates standby power limits, ecodesign requirements, energy labeling, and data center
regulations, including the Power Usage Effectiveness (PUE) ratio.9
2.Require that AI developers and data centers record and disclose their annual AI energy
consumption — This data ought to be publicly accessible and used to inform the NIST
energy efficiency recommendations. Developers will be motivated to consider energy
efficiency in their design, acquire testing and certification to ensure that their devices
meet required efficiency standards, and comply in order to gain market access.
Businesses may argue that these common-sense r egula tions unnecessarily hinder innovation. 
We know, however, that innovation can thrive when we enact smart regulations that realistically 
prepare entrepreneurs for the future. We can create regulatory frameworks that anticipate the 
market’s energy constraints and provide clear, smart rules that will guide innovation. When 
early ARM chips were unable to compete with Intel on raw power, Apple pivoted and eventually 
created the chips that would sit in our iPhones. When SpaceX underwent budget restraints, 
9 https://energy.ec.europa.eu/topics/energy-efficiency/energy-efficiency-targets-directive-and-rules/energy-effici  
ency-directive_en  8 https://policy.asiapacificenergy.org/node/37  7 https://e360.yale.edu/features/china-renewable-energy  
3 


they designed reusable rockets that led to more cost-efficient space travel and the creation of 
Falcon 9. When Chinese developers were denied access to high-end American chips, they were 
forced to optimize their model architecture to create a more energy-efficient AI alternative: 
Deepseek. These types of constraints foster smart, efficient, and more sustainable solutions.  
More Fair and Accur ate Systems 
The United States’ streng th is rooted in its diversity. We are a nation that is the culmination of 
countless ideas, cultures, perspectives and experiences—these are the fuel to groundbreaking 
innovation. This also means that our AI systems must work accurately across racial, ethnic, class, 
gendered, and cultural lines.  
Eliminating ideological bias or engineered social ag endas within  AI means creating more 
accurate, less biased systems. The Greenlining Institute has been working to accomplish this 
mission for over five years. We understand that algorithmic bias against vulnerable 
households—low-income families, Americans living in formerly redlined zip codes, communities 
of color, working Americans with disabilities, and other groups not accurately reflected in 
training datasets—can lead to disparate impacts.10 Incomplete and inaccurate datasets reinforce 
existing biases and historical inequalities. Poorly designed models built on inaccurate data sets 
do not paint an accurate picture of our current realities. Every statistician, developer, and data 
analyst knows the age-old adage: garbage in, garbage out. If we want to be a global leader in AI, 
we need to create regulatory guardrails that ensure that the AI we build is better than garbage.  In order to ensure that our AI does not operat e with ideological biases, our systems must 
adhere to a standard of explainability. The market reflects this sentiment: across party lines, 
Americans want to be able to trust AI systems by learning what is happening underneath the 
hood.11 They want answers to questions like, “What factors were used to make this decision?”, 
“Where did the model get the data to make this prediction?”, or “What can I do to contest this 
decision?” Additionally, explainability requirements promote transparency and deliberate 
design: when developers are required to disclose their models’ decision-making logic, they are 
less inclined to imbue the model with their own biases or create models that are too 
complicated to explain. This builds trust between consumers and developers, facilitating the 
equitable, safe, and accurate adoption of American automated decision-making systems.  
11 https://www.brookings.edu/articles/making-ai-more-explainable-to-protect-the-public-from-individual-and-co  
mmunity-harms/#:~:text=We%20also%20need%20to%20know,of%20automated%20decision%2Dmaking%20tools.  10 https://greenlining.org/publications/algorithmic-bias-explained/  
4 


Furthermore, American companies miss out on significant market opportunities  when they 
build AI systems that exclude communities of color. Traditional credit scores, for example, have 
historically excluded over 26 million Americans from accessing loans due to their restrictive 
credit scoring models.12 When a risk-assessment algorithm is only trained to determine 
creditworthiness based on traditional, outdated data points—i.e. debt-to-income ratios, length 
of credit history, credit mix, etc.—then the portion of the market that the lender is able to 
service is significantly limited. Fintech companies like Block and Plaid, however, have taken 
advantage of this significant market gap by creating more inclusive and accurate models: their 
Alternative Credit Models factor in alternative data points, including gig economy data, rent 
payment history, spending patterns, and nontraditional assets.13 This intentional effort to 
expand financial inclusion in their AI models has significantly expanded the Block’s ability to 
serve the 20-25 million underbanked Americans in the United States. Their commitment to 
investing $100 million in Community Development Financial Institutions and Minority 
Depository Institutions has further informed their ability to create models that can identify 
creditworthiness by nontraditional means.14 If US guidelines for explainability and impact tes ting do not reach the regulatory standards 
upheld by the European Union, then we will never achieve American AI leadership. Clear 
regulations that enhance the quality and accuracy of our AI are key to establishing trust, access, 
and adoption in the global market. The EU AI Act should be the baseline. This has been 
demonstrated in Tesla’s diminishing claim to the global EV market share. European regulatory 
standards have consistently outpaced the American landscape. As people around the world lose 
faith in Teslas’ safety features, consumer anxieties and regulatory dissonance slow down the 
adoption of American technology abroad. In the last month alone, these concerns have led to 
Tesla stock dropping over 8% and European sales dropping by nearly 50%.15 This leaves more 
than enough room for our competitors from China to step in. Today, Chinese EVs account for 8 
of the top 10 best-selling EVs worldwide, with BYD growing its market share to 5%.16 The EU’s 
market holds $20.3 trillion in GDP . If we are unwilling to harmonize our regulatory guidelines to 
that of Europe, we will continue to miss out on our share of this pot.  Lack of regulatory over sight also means stunted adoption within the United States. The US’s 
trailing adoption of contactless payment demonstrates this. By the early 2010s, the technology 
16 https://autovista24.autovistagroup.com/news/byd-enjoys-significant-lead-in-global-ev-market/  15 https://www.morningstar.com/news/marketwatch/2025022573/tesla-sales-slid-by-nearly-50-across-europe-at-  
the-start-of-2025  14 https://block.xyz/block-impact-investments  13 https://plaid.com/resources/lending/alternative-credit-data/  12 https://www.consumerfinance.gov/about-us/blog/who-are-credit-invisible/  
5 


 
for contactless payment had been swiftly adopted by countries like Australia, UK, Czech 
Republic, Brazil, and Hong Kong. In European countries, tap-to-pay accounted for 92-97% of Visa 
transactions in 2017.17 This was in large part due to the proactive role that the EU took in 
adopting the Payment Services Directive, which implemented regulatory guardrails in the 
adoption of this technology, like transaction limits and chip standardization.18 Meanwhile, in the 
United States, tap-to-pay payments accounted for only .6% of our transactions prior to the 
pandemic. Without regulatory guardrails, business and consumers were anxious at the thought 
of adopting this new, risky technology. When the Covid-19 pandemic hit, American businesses 
and consumers were starkly unprepared and left behind in the global transition to contactless 
payment. If we want to be the global leaders in AI, we cannot be falling behind within our own 
country. We need guardrails that make consumers and businesses confident about taking on the 
risks that accompany these emergent technologies.  
 
Clear regulatory guidelines guide businesses in their embrace of innovation. The CFPB’s shift 
away from No-Action Letters, for example, presents the new Administration with an 
opportunity: in order to limit government waste on retroactive enforcement, federal agencies 
ought to implement proactive and preventative measures that ensure the safe, equitable, and 
accurate development of AI. Strong regulatory actions will set a high standard for American AI 
across the board. Therefore, we propose the following recommendations:  
 1. Establish Data Transparency and Quality Standards — Develop a robust data 
governance framework that defines data quality standards, processes, and roles. This 
helps create a culture of data quality and ensures that data management practices are 
aligned with organizational goals. These standards should include a commitment to 
accuracy, consistency, completeness, timeliness, and relevance, especially as they relate 
to communities of color and other vulnerable populations which may not be accurately 
represented in existing data.   
2. Establish Explainability and Accountability Standards — Automated systems that are 
responsible for making life-impacting decisions ought to be reasonably explainable and 
their decision-making logic should be made public to consumers. Regulatory bodies 
should develop frameworks that guarantee individuals the right to challenge and seek 
redress for decisions made by these algorithms, including a private right of action or the 
option to opt out of automated decision-making.  
18 https://www.globalpayments.com/insights/2021/09/30/everything-you-need-to-know-about-contactless-  
payment-limits#:~:text=Countries%20in%20the%20European%20Union,the%20payment%20the%20first%20time .  17 https://caribbean.visa.com/visa-everywhere/innovation/contactless-payments-around-the-globe.html  
6 


3.Regularly Conduct Impact Assessments — Harmonize US regulatory AI standards to that
of other nations in order to encourage global adoption and consumer trust. This should
include regular reviews and updates in order to ensure that AI systems are accurately
and fairly serving diverse populations. Regulatory agencies ought to be granted the
authority to fine developers that fail to pass their impact assessments and prevent them
from entering the market.
Government Efficiency  and Waste  
Our federal and stat e governments are operated by diligent and experienced career employees. 
The Greenlining Institute firmly believes that the work carried out by regulatory agencies and 
administrative departments are essential to protecting the rights of the American people. 
Reckless automation will not save government time or resources. However, we acknowledge the 
Administration’s push to automate these processes and usher in a new future for our 
government systems. We believe that, in order to prevent the accumulation of additional 
government waste, it is imperative that the Administration implements strong procurement 
standards for automation.  Reckless automation will was te government time, money, and resources. We have seen this 
before. In Michigan, state officials set out to design an automated system that would replace 
government workers in the Michigan Unemployment Insurance Agency. They procured a system 
known as MiDAS, the Michigan Integrated Data Automated System. With minimal regulatory 
oversight or comprehensive security management, the state developed an algorithmic 
decision-making model that would eliminate over 400 government workers, or one-third of the 
UIA staff.19 After $44,400,558 and 26 months, the MiDAS system resulted in a massive failure: 
from October 2013 to August 2015, the system issued over 60,000 fraud determinations with a 
93% error rate.20 When this system was finally halted and brought to court, the state was forced 
to pay a $55 million fine and return all of the money they had wrongly collected from 
applicants. All of this government waste could have been easily circumvented had Michigan 
incorporated strong procurement standards for their automated systems in the first place.  Well-designed automation, how ever, has the potential to effectively streamline processes and 
offer higher quality services to citizens. In order for this to happen, these efforts ought to be 
20 https://spectrum.ieee.org/michigans-midas-unemployment-system-algorithm-alchemy-that-created-lead-not-  
gold  19 https://audgen.michigan.gov/finalpdfs/15_16/r641059315.pdf  
7 


 
grounded in the realities faced by Americans. This means creating systems that provide options 
for vulnerable communities. In Australia, when government officials wanted to automate a 
punitive debt collection system, they understood that many segments of the population would 
not be able to realistically pay their fines. This included people facing health, financial or 
domestic hardship, people experiencing homelessness, people involved in the criminal justice 
system, and young people. In anticipation of this, they designed the NSW Revenue Vulnerability 
Model.21 This model identified these most vulnerable individuals and—rather than allowing the 
fines to accumulate only to never be paid—directed them to alternative options, including 
repayment agreements or an implementation of a Work and Development Order. The Australian 
government prevented the system from breaking down by combining an automated system 
with a human appeals process. They understood that these automated decision-making systems 
would not work for everyone and, accordingly, created a more efficient model that could 
anticipate these outcomes. Maintaining human-in-the-loop decision-making processes prevent 
vulnerable individuals from falling through the cracks. Our AI models ought to take this 
proactive approach: models that determine life-impacting decisions should be able to also 
identify which individuals may need additional support. Our procurement standards should 
reflect this in order to create better, more efficient automated systems.  
 
Strong government procurement standards can guide and incentivize innovation. Government 
agencies can develop frameworks that encourage developers to create new products and 
services that better serve government needs as well as that of the public. The excess of red tape 
and lack of clarity in government procurement standards can drive up the cost for developers 
seeking to create high quality automation systems, meaning that only large players who can 
afford the regulatory moat are able to participate. The Department of Homeland Security’s 
Procurement Innovation Lab, however, emphasizes that procurement elements like 
innovation-focused evaluation criteria, staged funding for R&D, early market engagement, and 
flexibility in contract terms that allow for experimentation and adaptation can drive up the 
value of government innovation.22 Clear procurement standards encourage developers to enter 
the market. Market diversity and competition will inevitably lead to the development of higher 
quality, more accurate, more equitable, and more energy-efficient products that maximize 
government efficiency.  
 
Automation, furthermore, should be paired hand-in-hand with significant investments in 
reskilling and education. If we are to be a nation that leads in innovation and progress, our 22https://www.dhs.gov/pil#:~:text=The%20Procurement%20Innovation%20Lab%20 21 https://www.ombo.nsw.gov.au/__data/assets/pdf_file/0004/138208/The-new-machinery-of-government-  
special-report_Annexure-A.pdf  
8 


displaced workers can be the minds that lead the charge. Significant investments in labor 
reskilling and AI education can push us forward. In the past year, China has already gotten a 
head start: the Chinese Ministry of Education has committed to strengthening AI education in 
primary and secondary schools.23 Their approach prioritizes bridging the gap between education 
in rural and urban schools. This nationwide initiative is one that can only take place through a 
concerted and coordinated effort. The United States Department of Education ought to be 
emboldened to implement AI literacy curriculum to our students across the country. California’s 
commitment to teaching AI literacy in schools, for example, will empower young students to 
better understand these systems while giving them the tools to push our nation forward.24 We 
need to be able to accomplish this on a national level.  A commitment to governmen t efficiency means that we ought to work smarter, not harder. This 
means that our leaders need to be able to anticipate how these AI systems will impact real 
people and, therefore, encourage the development of systems that work for real people. We 
recommend the following policy proposals for the AI Action Plan:  
1.Maintain technical AI expertise in the federal government — Technical competence is
vital to ensuring that these systems are implemented effectively and efficiently. By
maintaining Chief AI Officers across the federal government, American tax dollars are
saved and automated systems will be implemented in each department with the
necessary expertise and experience. In the Department of Defense, for example, the Chief
Data and Intelligence Officer has been able to effectively streamline the adoption of
responsible AI by combining institutional knowledge and technical expertise.2.Targeted Design and Procurement Standards — Policymakers should ensure that
automated systems in the federal government use comprehensive, data-driven criteria to
allocate resources. Procurement contracts should encourage developers to design
models that account for a broad spectrum of needs, ensuring that resources are directed
where they will have the greatest impact, as defined in consultation with a diverse groupof stakeholders. See our report on Equitable AI in Government for additional
procurement recommendations.25
25 https://greenlining.org/wp-content/uploads/2024/12/GLI_Equitable-AI-in-Government_6.pdf  24 https://a23.asmdc.org/press-releases/20241003-california-teach-ai-literacy-every-grade#:~:text=SACRAMENTO  
%2C%20CA%20%E2%80%94Governor%20Newsom%20has,K%2D12%20students%20in%20California.  23 https://www.globaltimes.cn/page/202412/1324230.shtml  
9 


3.Ensure that any models used to allocate government resources are built with
vulnerability assessment models — These vulnerability assessments are key to
minimizing government waste. Models should be trained to identify historical and
present-day barriers to access, especially if gaps exist in the data. This includes the
consideration of income, race, gender, ability/disability, housing, age, veteran status and
other indicators of vulnerability. Models should be able to direct individuals to alternate
options and include human oversight in the decision-making process.AI for Efficiency, Accuracy, and E quity 
The United States has the poten tial to become the world’s foremost leader in artificial 
intelligence. As this Administration considers our next steps forward, The Greenlining Institute 
implores the Office of Science and Technology Policy to consider the long term benefits that 
result from implementing these recommendations. Leading in AI means leading in efficiency, 
accuracy, and equity. In order to better serve the American people, allow all of our communities 
to reap the benefits of artificial intelligence, and lead the way for all other nations, we must 
commit to these principles.  The Greenlining Institute is commit ted to creating a just future that works for all. This means 
ensuring that our technology works for all. We look forward to additional opportunities to 
engage with the Administration on the next steps of the AI Action Plan.   
Sincerely,  
Angel Lin  
Tech Equity Policy Fellow  
The Greenlining Institute 
Mobile: (425) 
Email: 
Pronouns: she/her 
10 


