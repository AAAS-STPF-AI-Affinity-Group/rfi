        Artiﬁcial Intelligence (AI) Ac
       
National Science Foundation Request for Information on the Development of an Arti ﬁcial 
Intelligence (AI) Action plan 
Submission from iProov  
13th March 2025 
 
Key Message 
iProov welcomes the opportunity to respond to the request for information for the AI Action 
Plan, issued by the National Science Foundation.  The US has a clearly dominant position in AI  
by most relevant measures, and is well placed to reap economic and national security beneﬁts 
from this hegemony, grabbing  a major share of the new bene ﬁts as AI deployment fuels global 
economic gr owth.  However, there are indicators that suggest there are challenges to the US 
sustaining this current position of strength.  In this brief we highlight the threat posed to US 
dominance as a consequence of adoption and usage levels for AI in the US being below those 
of major rivals, such as China.   Behind the data on relatively low rates of adoption is a high 
level of citizen mistrust in the use of AI by government and business. Moreover, malicious 
actors, including adversarial nations, are increasingly arming themselves with the same 
sophisticated AI tools for purposes of committing identity fraud to steal money, intellectual 
property, sensitive business information and threaten national security.   Research shows that 
citizens with a high level of grievance against the government or business, for example as a 
consequence of a fear of fraud, have lower levels of adoption and use of AI tools.  Helpfully, the 
same research also shows that by increasing levels of trust the negative impact of grievance 
can be outweighed, driving AI adoption and usage upwards.  
As we explain, trust is an asset and serves to drive economic growth.  Increasing the 
trustworthiness of AI tools and digitally enabled channels drives trust and therefore adoption 
and usage.  The recommendations we make below are pragmatic and low-cost to government 
measures which would enhance trust in AI tools and digitally enabled channels by supporting 
citizens and organizations, including the government, in the battle against malicious use of AI 
tools. 
   
Background on iProov iProov provides mission-critical biometric face veri ﬁcation to protect go vernments and 
organizations from identity or imposter fraud. iProov uses advanced AI solutions to deliver the 
highest level of identity assurance by conﬁrming that the individual is the right person, a real 
person, who is authenticating in real time. Our products and processes are regularly subject to 
external auditing and accreditation. iProov is a technology innovator and market leader and is 
established as a trusted service provider in major markets globally. Founded in the UK in 2012 
and with a global presence including a growing team in the US, based out of Catonsville, 
Maryland, iProov is a research-led innovator with 24 registered patents. Not only is iProov a 
recognized world leader in identity veriﬁcation, but we are also  a highly successful supplier of 
services to important organizations in major markets. iProov customers include the U.S. 
Department of Homeland Security, the Australian Taxation Oﬃce, GovTech Singapore, the UK  
Home O ﬃce, the UK National Health Service (NHS) and others. We are a provider of identity 
veriﬁcation for the US IRS, in par tnership with ID.me, and our solution for strengthening border 
1 


Artiﬁcial Intelligence (AI) Ac
security is currently being trialled at major US airports, including Dulles and O’Hare.  iProov’s 
expertise is regularly recognised in analyst reports,  and our class-leading role was most 
recently featured in Acuity Market Intelligence’s 2024 Biometric Digital Identity Flagship 
Prism Report.  
As the only biometric veri ﬁcation vendor with in-production  data and intelligence through our 
cloud Security Operations Center (iSOC), we have been tracking the behaviors of threat actors 
over the last 13 years and have analyzed how their methodologies have evolved.   Our 
commitment to advancing biometric security has led to rigorous independent testing by the US 
Department of Homeland Security’s Science and Technology Directorate and cybersecurity 
leaders like Outﬂank, Jumpsec, and Kroll Redscan, v alidating our robust defense capabilities 
against emerging sophisticated attacks.  We regularly advise key organizations and 
governments, such as ENISA and MITRE, helping raise awareness of real-world threats and 
establishing best practices for biometric security. We share intelligence publicly on how 
malicious actors are adopting the latest AI tools through public reports, such as our 
class-leading Threat Intelligence Report, as well as on measures to effectively protect 
organizations and citizens against malicious use of AI to create fraudulent identities.   
The US Economic Opportunity Driving iProov 
The US is the leading AI superpower, by most objective measures. According to the Global 
Vibrancy Tool 2024 from the Stanford Institute for Human-Centred AI, the US is the leading 
country for developing machine learning models (61 vs 13 from China in 2023), for AI 
investment (over $67bn in 2023, vs $7bn in China), more than times the number of data centers 
than the next largest country (Germany) and an increasing majority as a destination for elite AI 
talent (75% of the top-tier AI talent, up from 58% in 2019), based on research from think-tank 
Marco Polo. Moreover, the United States remains far and away the leading destination for the 
world’s most elite AI talent (top 2%) and remains home to 60% of top AI institutions, according 
to the same tracker.    1
US dominance is not unassailable over the long-term, in particular with China now leading the 
registration of AI patents, with more than 61% in 2023 (vs the US at 20%), and the US falling 
behind Singapore, South Korea, China and Denmark on the measure of registrations per capita.  
A more immediate threat to job creation and innovation in AI is posed by relatively poor 
adoption and usage rates, with SAS reporting that Generative AI use in surveyed US 
organizations (65%)  lags behind levels in China (83%) and the UK (70%), and is only marginally 
ahead of Australia (63%).     2
In order to address the challenge of adoption and usage, it is critical  to understand what factors 
are driving the relatively low rates in the US.  Edelman’s 2024 Trust Barometer found that by 
nearly a three-to-one or more margin, respondents in the US (and other developed economies) 
reject the growing use of AI rather than embrace it. That contrasts to developing markets such 
as Saudi Arabia, India, China, Kenya, Nigeria and Thailand where acceptance is around 
2 Available at https://www.sas.com/en_us/news/press-releases/2024/july/genai-research-study-global.html  1 Available at https://archivemacropolo.org/interactive/digital-projects/the-global-ai-talent-tracker/ 
2 


        Artiﬁcial Intelligence (AI) Ac
       
two-to-one over resistance.   It is noteworthy that Americans respondents were much more 
likely to cite reasons associated with grievances with the technology and accountability, such as 
potential harm to society (61%), privacy concerns (52%) and lack of adequate testing and 
evaluation (54%) than to a fear of negative consequences for their jobs.  Edelman reports that 3
those with a higher sense of grievance or mistrust in Government or business have a lower 
level of trust in AI firms and in the use of AI by business. High levels of grievance with 
government and institutions is a global challenge, rather than one unique to the US, as reported 
in other global surveys.  However, Edelman’s research reports that the dampening effects of 4
high levels of grievance on AI adoption and use can be outweighed by the existence of high 
levels of trust.   The chart below illustrates Edelman’s research findings.  5
 
 
 
When considering actions to prioritise, we would respectfully invite the NSF to consider this 
research (and similar) on the underlying causes of low rates of adoption and usage in the US, 
and support measures which would serve to counter.  Speciﬁcally, we would propose  that the 
NSF focus on supporting measures to enhance levels of trust in AI in the US.  
 
The summarised research shows a signi ﬁcant positive relationship between  trust and 
economic growth, which has long been understood by economists.  As stated by Nobel Prize 
winning US economist Kenneth Arrow: "virtually every commercial transaction has within itself 
an element of trust, certainly any transaction conducted over a period of time. It can be 
plausibly argued that much of the economic backwardness in the world can be explained by 
the lack of mutual conﬁdence."   The relationship is also supported by empirical research 6
6 Arrow, K. J. (1972). Gift and Exchanges. Philosophy & Public Affairs, 1(4), 343-362. Retrieved from https://www.jstor.org/ 
stable/2265097  5 Available at https://www.edelman.com/trust/2025/trust-barometer  4 See, in particular, OECD Survey on Drivers of Trust in Public Institutions - 2024 Result.  Available at 
https://www.oecd.org/en/publications/oecd-survey-on-drivers-of-trust-in-public-institutions-2024-results_9a2055b-en.html  3 Available at https://www.edelman.com/trust/2024/trust-barometer 
3 


Artiﬁcial Intelligence (AI) Ac
showing that economies with higher levels of trust have higher levels of per-capita Gross 
Domestic Product (GDP).  Figure 1, taken from Zakharov et al ,  illustrates the relationship.   7 8
The relationship is also causative.  Higher trust levels lead to more e ﬃcient resource use as a 
consequence of reduced free riding, lower transactions costs and lower contract enforcement 
costs. In the context of digital and AI enabled channels, the typically transient nature of 
commercial relationships and absence of a physical engagement means that such compliance 
costs are greater than is the case in physical channels.  By increasing trust, valuable resources 
can therefore be diverted to activities which create more wealth and income.    9
By raising levels of trust in digital and AI enabled channels, reduced barriers to e ﬃcient 
transacting between organizations and between individuals generates improvements in Total 
Factor Productivity (TFP).   Coyle and Lu (illustrated in Figure 2)  model the positive impact of 10
trust on productivity (TFP), which feeds through to increased per capita GDP in their 
multi-country study.  Similar ﬁndings are presented in other studies.     11 1213
Figure 2 - Trust levels driving TFP and GDP per capita
13 Whiteley, P . F. (2000), Economic growth and social capital , Political Studies, 48(3), 443-466. 12 Knack, S., & Keefer, P . (1997),  Does social capital have an economic pay-off? A cross-country investigation . Quarterly Journal of 
Economics, 112(4), 1251-1288. Retrieved from https:// www.jstor.org/stable/2951271 11 Coyle, D & Lu, S (2020), Trust and Productivity Growth - An Empirical Analysis,  available at 
https://www.bennettinstitute.cam.ac.uk/wp-content/uploads/2020/12/Trust_and_Productivity_Coyle_Lu.pdf  10 Total Factor Productivity (TFP) is a measure of e ﬃciency, derived by comparing total outputs relative t o the total inputs used 
to produce those outputs. 9 Dasgupta, P , A Matter of Trust: Social Capital and Economic Development, May 2009, available at  
https://www.econ.cam.ac.uk/people-
ﬁles/emeritus/pd10000/publications/09/abcde09.pdf 8 Dmytro Zakharov, Svitlana Bezruchuk,  Vikt oriia Poplavska, Svitlana Laichuk and Hanna Khomenko (2020). The ability of trust to 
inﬂuence GDP per capita. Problems and Perspectives in Management, 18(1), 302-314. doi:10.21511/ppm.18(1).2020.26  7 Per capita GDP is generally accepted as the best metric for me asuring economic growth. 
4 


        Artiﬁcial Intelligence (AI) Ac
       
Critically for the purposes of retaining US AI dominance, organizations in markets with higher 
levels of trust also bene ﬁt from a lower cost  of equity, which may reduce cost barriers to 
investment and innovation (and job creation).  Firms operating in markets with higher trust 14
levels may be more pro ﬁtable as a consequence.   To illustrate the magnitude of the potential 15
impact of improved trust on growth, the World Economic Forum (WEF) estimates that (in 2019 
values) “a 5% point increase in digital trust results in an average increase in GDP per capita of 
$3,000”.    McKinsey and others have made similarly upbeat estimates of the impact of AI on 16
the US economy.   Microsoft estimates that Generative AI could contribute $3.8 trillion to the 17
US economy by 2038.   McKinsey suggests AI innovation could unlock between $11-$17 trillion 18
in increased total global economic value for business.   However, bene ﬁts will not be e venly 19
distributed, with the greatest gains going to those countries where adoption and usage is 
highest.  While this would suggest that the US economy will continue to beneﬁt signi ﬁcantly 
from AI, its hegemony is at risk due to lower rates of adoption and use than many rivals, with 
the gap to China increasing year-on-year. 
 
Measures to Enhance Trust in AI will Drive Economic Growth, Innovation and Job Creation, as 
well as National Security  
The AI Action Plan provides a critical opportunity to establish a pro-innovation and pro-growth 
policy environment for the purposes of underpinning current US dominance in AI and securing 
this lead into the future.  Economic research shows that for the US to secure the economic 
growth potential of AI it is the trust of users (US citizens and organizations) which is crucial to 
driving adoption and usage to levels which will incentivise innovation and reward investment. 
However, trust itself is an outcome with trustworthiness a necessary precondition.   Those very 
same AI tools which can fuel the sorts of economic growth the US has seen in recent decades, 
can also be used by malicious actors to render AI tools and AI-enabled digital channels 
untrustworthy.   The rapid growth of AI-based technology has introduced new challenges for 
remote identity systems, undermining the trustworthiness of digital economy channels. 
Innovative and easily accessible tools have allowed threat actors to become more 
sophisticated overnight, powering an increasing number of threat vectors due to new 
methodologies.  The growth of new attack vectors over the last 24 months has heavily 
impacted organizations. The Federal Trade Commission’s Consumer Sentinel Network 
documented a 45% increase in identity theft incidents in early 2024, with aggregate fraud losses 
exceeding $10.2 billion.  The second-highest reported loss amount came from imposter 20
20 As Nationwide Fraud Losses Top $10 Billion in 2023, FTC Steps Up Efforts to Protect the Public | Federal Trade Commission  19 Chui, Michael, et al. “The economic potential of generative AI: The next productivity frontier.” McKinsey Digital, McKinsey & 
Company, 14 Jun 2023, 
https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-product
ivity-frontier#business-value.  18 Available at 
https://blogs.microsoft.com/on-the-issues/2024/11/21/the-3-8-trillion-opportunity-unlocking-the-economic-potential-of-the-us-
generative-ai-ecosystem/  17 For example, see  https://www.thirdway.org/report/ai-and-the-us-economy-optimism-pessimism-or-realism  16 Digital trust: How to unleash the trillion-dollar opportunity for our global economy, World Economic Forum, August 2022.  
Available at  
https:/ /www .weforum.or g/agenda/2022/08/digital-trust-how-t o-unleash-the-trillion-dollar-oppor tunity-for-our-global-economy/  15 Hilary, G., & Huang, S. (2016). Trust and Contracting, (INSEAD Working Paper No.2015/42/ACC). Retrieved from 
https://papers.ssrn. com/sol3/papers.cfm?abstract_ id=2604974  14Gupta A, Raman K & Shang C (2018),Social capital and the cost of equity, Journal of Banking & Finance, Volume 87, 2018, 
Pages 102-117, ISSN 0378-4266, https://doi.org/10.1016/j.jbankﬁn.2017.10.002.  
(https://www.sciencedirect.com/science/article/pii/S0378426617302479) 
5 


Artiﬁcial Intelligence (AI) Ac
scams, with nearly $2.7 billion in reported losses, indicating a signi ﬁcant upward trajectory in 
ﬁnancial impact.  There is a technological arms race at play, with responsible organizations 
(including the US Government) investing in measures to protect their systems from malicious 
actors. However, even against this background of action and high pro ﬁle support for tighter 
controls on  identity fraud from agencies such as FinCen, fraud levels continue to grow.   In 21
more recent reporting, the Federal Trade Commission claims that consumer losses  in 2024 due 
to fraud have increased by 25% in the preceding 12 months to $12.5bn.  Losses due to imposter 
scams remains the second-highest category reported, at $2.95bn, an increase against the 
losses claimed in the preceding report (referred to above).  22
Malicious actors using these t ools also pose a real and present threat to US national security.  
Nation states which are adversarial to the US are increasingly making use of these same tools 
to attack US interests, put US security at risk and defraud US taxpayers.  Recent reports of 
North Korean cyber attacks on the US, whereby hackers stole the identities of US citizens and 
employed sophisticated face-swapping methods to secure jobs with US organizations for the 
purposes of stealing sensitive information, technical intellectual property and money from US 
companies and taxpayers, serve to illustrate a growing national security threat posed by 
malicious use of AI tools for the purposes of identity or imposter fraud.    23
As the FTC correctly notes, “scammers’ tactics are constantly evolving”. Synthetic identity fraud 
(SIF) is the fastest-growing type of fraud, combining legitimate data (such as valid Social 
Security numbers often stolen from children, elderly, or deceased individuals) with fabricated 
personal information to create convincing false identities. What makes SIF especially 
challenging to combat is its ability to evade traditional fraud detection systems. Unlike 
conventional identity theft, where systems can ﬂag stolen information based on  reports from 
real victims, SIF uses AI to create entirely new identities that incorporate both real and fake 
elements. Without a real victim to raise the alarm, and with some components of the identity 
being legitimate, traditional detection methods often fail to recognize these synthetic fraud 
patterns. 
Democratization and ease of use of AI tools, such as applications for native camera spoo ﬁng 
and face swaps, has fuelled the growth  of online Attacks-as-a-Service communities.  Malicious 
actors look to bypass security methods by combining these AI tools.  We track 127 face swap 
tools, 10 mobile device emulators and 91 virtual camera tools.  At a basic level, this means that 
there are 115,570 potential attack combinations using readily available (and often free to use) 
AI tools. As new tools and updates are introduced, combinations are constantly increasing. 
A 2025 deepfake consumer research report by iProov paints a picture of a society largely 
unprepared for the challenges posed by deepfake technology, with signiﬁcant gaps in 
23 See for example, 
https://www.justice.gov/archives/opa/pr/fourteen-north-korean-nationals-indicted-carrying-out-multi-year-fraudulent-informatio
n 22 Available at 
https://www.ftc.gov/news-events/news/press-releases/2025/03/new-ftc-data-show-big-jum-reported-losses-fraud-125-billion-2
024 21 See, for example https://www. ﬁncen.gov/news/news-releases/ ﬁncen-issues-analysis-identity-related-suspicious-activity  
6 


        Artiﬁcial Intelligence (AI) Ac
       
awareness, detection abilities, and response mechanisms.   Only 0.1% of participants 24
(including those from the US) could identify all synthetic media examples correctly, and there 
was a particularly low success rate (9%) for video deepfake detection.    Against this 
background of increasing complexity and human vulnerability, it is important to take a 
multi-faceted and evidence-based approach to safeguarding trust in AI and digital channels. 
 
Recommendations for Priority Actions to Secure Trust in AI 
An AI Action Plan which prioritizes measures to enhance capabilities and trust in the use of 
AI-enabled channels would fuel US AI innovation and underpin continued leadership.  We invite 
the NSF to consider four recommendations which we believe would enhance trust in AI and, as 
illustrated by economic research, propel innovation and economic growth. 
 1. Facilitate Research and Development in AI-Resistant Identity Veri ﬁcation  
AI-based attack tools are becoming democratized and more sophisticated. Many of the current 
identity veriﬁcation and KYC methods deplo yed by organizations, including banks, law 
enforcement and government, are not su ﬃcient to keep pace with  these evolving threats.  We 
would encourage the NSF to facilitate and sponsor industry-led research and development of 
novel identity veriﬁcation methods speci ﬁcally designed to be r obust against AI-generated 
deepfakes, synthetic identities, and other advanced spoo ﬁng techniques. This should include 
research into biometric technologies, liveness detection, and cryptographic solutions.  
 
2. Development of Standardized Evaluation Metrics and Testing Protocols for AI-Based 
Identity Veriﬁcation Systems 
A signi ﬁcant challenge is posed by inﬂated vendor claims and the consequent di ﬃculty 
organizations face in procuring  appropriate security technologies. NIST should be tasked with 
extending its world-leading efforts to establish standardized evaluation metrics and testing 
protocols to assess the effectiveness of AI-based identity veriﬁcation systems against 
sophisticated AI-driven  attacks, including those based on synthetic media and digital injection 
attacks.  
 
3. Strengthening Public-Private Partnerships for Threat Intelligence Sharing and 
Collaborative Defense  
Our work has served to show the importance of real-time threat intelligence and the need for 
continuous monitoring and adaptation. We would encourage the NSF to work collaboratively 
across stakeholders to foster stronger public-private partnerships for the purpose of facilitating 
the sharing of threat intelligence related to AI-based identity fraud. This should include the 
establishment of a central repository for reporting and analyzing attacks, as well as 
mechanisms for rapid dissemination of threat information to relevant stakeholders.  
 4. Focus on Education and Training to Address the Knowledge Gap in AI Security 
Our recent Threat Intelligence Report identi ﬁes a fundamental knowledge gap  regarding 
understanding and procuring appropriate remote veri ﬁcation technologies.  We would therefore 
recommend  that the NSF partner with relevant agencies and the private sector to support the 
24 https://www.iproov.com/press/study-reveals-deepfake-blindspot-detect-ai-generated-content  
7 


Artiﬁcial Intelligence (AI) Ac
development and rolling out of education and training programs to raise awareness of AI-driven 
threats and best practices for securing identity veriﬁcation systems. This should target both 
technical professionals and non-technical decision-makers within organizations. It could be 
operated on a verticals-basis, for example with FinCen overseeing the approach for regulated 
ﬁnancial services providers, Homeland Security responsible for the approach to border control, 
national security and law enforcement,  as well as horizontally under the leadership of the FTC. 
This document is approved for public dissemination.  The document contains no business-
proprietary or conﬁdential information. Document contents may be reused by the  government 
in developing the AI Action Plan and associated documents without attribution. 
8 


