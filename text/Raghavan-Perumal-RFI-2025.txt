AI Action Plan - Advancing U.S. Leadership in AI 
Raghavan Krishnasamy Lakshmana Perumal 
Member of IEEE Computer Society,  
Tampa, FL 33607 
USA 
March, 10 2025 
Faisal D’Souza, NCO 
2415 Eisenhower Avenue 
Alexandria, VA 22314 
USA 
Submitted by email to ostp-ai-rﬁ@nitrd.gov 
Re: Request for Information (RFI) on the Development of an Artiﬁcial Intelligence (AI) Action Plan 
This document is approved for public dissemination. The document contains no business-proprietary or 
conﬁdential information. Document contents may be reused by the government in developing the AI 
Action Plan and associated documents without attribution. 
Introduction 
America, as a global leader in AI innovation, has the unique opportunity and 
responsibility to establish the standards for a secure, ethical, and safe AI future. In 
support of the OSTP’s eﬀorts to de ﬁne the policy actions needed to sustain and enhance 
America's AI dominance, I present an action plan. 
This AI action plan centers on three pivotal pillars designed to propel America's 
leadership in AI innovation. It calls for enhancing AI security by developing and 
implementing robust measures to safeguard systems from cyberattacks and malicious 
use throughout their lifecycle. Additionally, it emphasizes strengthening AI data privacy 
by establishing clear guidelines and regulations that ensure the ethical and responsible 
use of data, thereby protecting privacy and security. Finally, the plan promotes AI safety 
through the development and deployment of systems that are safe, reliable, and aligned 
with human values, eﬀectively minimizing potential risks and unintended consequences. 
Key Initiatives 
To achieve these goals, this plan proposes the following key initiatives, prioritized based 
on their potential impact and urgency: 
1 


AI Security 
● Promote research on AI security technologies  
Invest in research and development of AI-speci ﬁc security solutions, such as defenses 
against data breaches, model poisoning, backdoor attacks and adversarial attacks .  1
● Establish a framework for AI risk management  
Develop a framework to assess and manage AI risks, including cybersecurity threats, 
data privacy breaches, and safety concerns.  The framework should provide guidance 
on risk assessment, mitigation, and best practices for secure AI development. 
Data Privacy and Governance 
● Establish guidelines for responsible AI 
Develop clear guidelines for the ethical and responsible use of AI, ensuring fairness, 
transparency, and accountability. This includes addressing concerns about 
unauthorized data use, biometric data concerns, and covert data collection . 2
Guidelines should ensure that AI systems do not perpetuate or amplify existing 
societal biases. 
● Promote data security best practices  
Encourage the adoption of data security best practices, such as encryption, access 
controls, and data anonymization, to protect sensitive information used in AI systems. 
This includes conducting regular audits to ensure compliance with privacy 
regulations. ● AI Legislation Reformation  
Analyze the current AI legislation landscape in the US and globally, including 
examples like the GDPR, EU AI Act, and Algorithmic Accountability Act. Identify areas 
where existing legislation may need to be updated or strengthened to address the 
unique challenges of AI, such as algorithmic transparency, data protection, and 
liability for AI-related harms. 
Cybersecurity Diplomacy ● Promote international standards  
America can play a critical role in leading international partnerships to develop and 
2 The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence: a comparative analysis of US, EU, and UK regulatory 
frameworks. https://pmc.ncbi.nlm.nih.gov/articles/PMC8320316/  1 Deep Learning Model Security: Threats and Defenses https://ui.adsabs.harvard.edu/link_gateway/2024arXiv241208969W/doi:10.48550/arXiv .2412.08969  
2 


promote clear standards and guidelines for AI security and privacy. This includes 
harmonizing regulations across borders to ensure interoperability and prevent 
regulatory fragmentation. 
● Collaborate on threat intelligence and response 
Establish mechanisms for sharing AI threat intelligence and collaborating on incident 
response with international partners to eﬀectively address cross-border AI security 
threats. This includes developing secure communication channels and protocols for 
sharing information about AI-related vulnerabilities and attacks . 3
Public Literacy 
● Public awareness and education 
Conduct public awareness campaigns and engage in open dialogues to educate the 
public about AI security and privacy risks and foster informed discussions about 
responsible AI development. This includes creating educational resources, hosting 
public forums, and engaging with civil society organizations to promote public 
understanding of AI. 
Timeline 
Under the forward-thinking leadership of President Trump and this Administration, this 
four-year roadmap outlines how to strengthen AI security, data privacy, global 
cybersecurity diplomacy, and public literacy. Each year focuses on key milestones that 
build on prior progress, 
Year 1 (2025–2026) ● AI Security 
○ Launch research projects on potential security threats and defense 
mechanisms in AI. 
○ Start developing prototypes for AI-driven cybersecurity tools. 
● Data Privacy and Governance 
○ Form a specialized task force dedicated to AI data privacy. 
○ Draft guidelines for responsible AI data usage, emphasizing transparency, 
fairness and accountability. 
● Cybersecurity Diplomacy 
3 Cyber diplomacy: defining the opportunities for cybersecurity and risks from Artificial Intelligence, IoT, Blockchains, and Quantum Computing 
https://www.tandfonline.com/doi/full/10.1080/23742917.2024.2312671  
3 


○ Begin discussions with international partners on AI standards and security 
goals. 
○ Lay the groundwork for collaborative threat intelligence sharing. 
● Public Literacy 
○ Identify key audiences and conduct surveys to determine their most 
pressing concerns about AI. 
○ Develop introductory, easy-to-understand educational materials. 
○ Partner with civil society, schools, libraries, and local governments to create 
a network for disseminating these resources. 
Year 2 (2026–2027) 
● AI Security 
○ Pilot AI-powered cybersecurity tools in real-world settings to measure 
eﬀectiveness. 
● Data Privacy and Governance 
○ Test data privacy frameworks within a closed group of hand-picked 
organizations. 
○ Use pilot results to re ﬁne and prepare broader privacy regulations. 
● Cybersecurity Diplomacy 
○ Actively participate in international forums to shape AI standards. 
○ Share early successes and lessons learned to encourage global 
consensus. 
● Public Literacy 
○ Integrate AI security and privacy lessons into school and university 
curricula, spanning both STEM and social sciences. 
○ Work with libraries and community centers to host educational sessions for 
diverse audiences. 
Year 3 (2027–2028) 
● AI Security 
○ Roll out AI security solutions on a larger scale, based on successful Year 2 
pilots. 
○ Continue enhancing defenses against emerging threats. 
● Data Privacy and Governance 
○ Finalize and adopt data privacy regulations industry-wide. 
○ Conduct regular audits to ensure compliance and address new challenges. 
● Cybersecurity Diplomacy 
4 


○ Establish joint research programs on AI security with international partners. 
○ Develop channels for ongoing intelligence-sharing to address cross-border 
threats. 
● Public Literacy 
○ Collaborate with experts and community leaders to produce culturally and 
linguistically relevant materials. 
○ Introduce clear credentialing that rewards individuals and organizations for 
completing AI literacy modules, boosting motivation for continued learning. 
Year 4 (2028 and Beyond) 
● AI Security 
○ Continuously evaluate and re ﬁne AI security measures to stay ahead of 
evolving threats. 
○ Maintain a cycle of updates and testing to ensure resilience. 
● Data Privacy and Governance 
○ Monitor and enforce data privacy regulations across all sectors. 
○ Adapt guidelines as AI applications expand or transform. 
● Cybersecurity Diplomacy 
○ Formalize frameworks for sharing real-time threat intelligence globally. 
○ Strengthen ties with international partners to develop uni ﬁed standards. 
● Public Literacy 
○ Involve newly trained community members and leaders in policy 
discussions at both local and national levels. 
○ Encourage public insight and feedback to continually improve AI 
governance. 
Metrics 
Measuring success is crucial for continuous improvement. Below are key performance 
indicators (KPIs) aligned with each initiative: 
● Adoption of Secure AI Development Practices 
○ Track and audit robust security protocols integrated into AI project 
lifecycles. 
○ Measure risk mitigation e ﬀectiveness before public release. 
● Reduction in AI-Related Cyber Incidents 
○ Monitor the frequency and severity of AI-based attacks. 
○ Evaluate response times and overall impact on national security and 
5 


consumer trust. 
● Increased International Collaboration 
○ Count the number of cross-border research initiatives, forums, and threat 
intelligence exchanges. 
○ Track progress toward harmonized global standards for AI security. 
● Improved Public Awareness 
○ Assess public understanding of AI security and privacy through surveys, 
feedback, and participation in training programs. 
○ Gauge adoption of safe AI practices by individuals, schools, and 
organizations. 
Resourcing the AI Action Plan 
Allocating resources to the following areas is essential for the success of this multi-year 
plan. 
● Funding: Allocate su ﬃcient funding for  
- Research and Development 
- Workforce Development, and the  
- Establishment of necessary infrastructure.  
This will involve securing funding from government agencies, private sector partnerships, 
and research grants.  
● Public-Private Talent: Recruit and train skilled personnel in AI security, data privacy, 
and AI safety to support the implementation of this plan. This includes cybersecurity 
experts, AI ethicists, data scientists, and legal professionals with expertise in AI. 
Recruitment eﬀorts should focus on attracting top talent from academia, industry, and 
government. Create rotational programs between,   
- National labs and tech companies   
- Regulatory agencies and startups   
- Military cyber units  and cloud providers   4
● Infrastructure: Invest in the necessary infrastructure, such as secure data centers, 
testing facilities, and collaborative platforms, to support secure and 
privacy-preserving AI development and deployment.  
Workforce Development 
To eﬀectively implement this AI Action Plan, a skilled workforce capable of addressing AI 
4 Defense Digital Service https://www.dds.mil/work 
6 


security and privacy challenges is essential. The following strategies will be employed to 
develop this workforce: 
● Education and Training: Invest in educational programs and training initiatives to 
equip individuals with the necessary skills in AI security, privacy, and ethics. This 
includes developing specialized curricula for universities and vocational schools, as 
well as providing online courses and certiﬁcations. 
● Upskilling and Reskilling: Support upskilling and reskilling programs for existing 
professionals in cybersecurity, data science, and related ﬁelds to enhance their 
knowledge of AI-speci ﬁc security and privacy challenges. 
● Recruitment and Retention: Implement strategies to recruit and retain top talent in AI 
security and privacy, including oﬀering competitive salaries, research opportunities, 
and professional development programs. 
● Immigration Reforms: To accelerate AI development in the US, the country should 
attract and retain global AI talent by simplifying immigration and o ﬀering incentives. 
Risks and Challenges 
Implementing this AI Action Plan may encounter the following risks and challenges: 
● The Evidence Dilemma: Policymakers face an "evidence dilemma"  in AI 5
policymaking, where AI capabilities are advancing faster than our ability to fully 
understand their risks and bene ﬁts.  
● Lack of awareness and expertise: A shortage of skilled personnel and a lack of 
awareness among developers and policymakers may hinder the eﬀective 
implementation of this plan.  
● Balancing innovation with security: Finding the right balance between fostering AI 
innovation and ensuring security and privacy requires a nuanced approach to AI 
governance that promotes responsible innovation while safeguarding security and 
privacy. ● International cooperation: Achieving international cooperation and harmonization of 
AI security standards may be challenging due to diverse regulatory approaches and 
existing geopolitical factors. ● Environmental Impact of AI: The increasing adoption of AI technologies requires 
enormous amounts of computing resources. This has signiﬁcant implications for 
energy consumption. Addressing this challenge requires research and development 
of more energy-eﬃcient AI systems and a focus on sustainable practices in AI 
5 Global Insights on AI Safety: A Citizen’s Perspective on the Landmark International Report 
https://moderndiplomacy.eu/2025/02/06/global-insights-on-ai-safety-a-citizens-perspective-on-the-landmark-international-report/  
7 


development and deployment. 
Bene ﬁts of Robust AI Security and Privacy 
A robust AI security and privacy will bring signi ﬁcant bene ﬁts and opportunities: 
● Increased trust and con ﬁdence in AI: Enhanced security and privacy measures will 
foster greater trust and con ﬁdence in AI technologies, encouraging wider adoption 
and responsible innovation. This will create a more favorable environment for AI 
development and deployment, leading to economic growth and societal bene ﬁts. 
● Economic growth and competitiveness: A secure and trustworthy AI ecosystem will 
promote economic growth and competitiveness by enabling the development and 
deployment of innovative AI solutions across various sectors. This includes 
applications in healthcare, ﬁnance, manufacturing, and transportation, among others. 
● Improved national security: Robust AI security will strengthen national security by 
protecting critical infrastructure and mitigating the risks of malicious use of AI. This 
includes protecting against AI-powered cyberattacks and ensuring the responsible 
use of AI in defense and intelligence applications. ● Enhanced societal well-being: Responsible AI will contribute to societal well-being by 
ensuring fairness, transparency, and accountability in AI systems. This includes 
mitigating the risks of bias and discrimination, promoting ethical AI development, and 
ensuring that AI is used to make humans more humane. 
Conclusion 
Under President Trump’s bold and visionary administration, America can retain and 
enhance its AI dominance. The initiatives proposed in this action plan aim to amplify the 
nation’s strengths while mitigating emerging risks. 
The path forward requires a thoughtful balance. Although robust security and privacy 
measures are critical, overregulation could stiﬂe the very innovation that drives AI 
progress. A measured approach, one that nurtures a dynamic, trustworthy AI ecosystem 
where security and innovation thrive side by side is essential. International collaboration 
will also be pivotal, allowing nations to share knowledge, harmonize standards, and 
collectively tackle the shared challenges of AI security. Ultimately, this plan reinforces 
America’s position as a global AI leader that serves the common good, empowers 
individuals, and bolsters national security while upholding human values. 
8 


