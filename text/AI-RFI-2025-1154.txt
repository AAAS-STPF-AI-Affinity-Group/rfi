PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 12, 2025
Status: 
Tracking No. m 86-30m d-7dym
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1154
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Andrew Dorph
Em ail:  
General Comment
To Whom  It May Concern,
I am  subm itting this com m ent in response to the Request for Inform ation (RFI) on the developm ent of the Artificial Intelligence (AI) Action
Plan, with a specific focus on the use, storage, and replication of actors’ and broadcasters’ im ages, likenesses, and biom etric data. As AI
technologies advance, it is im perative that the AI Action Plan incorporates robust protections for these individuals, drawing on existing
legislative efforts to address the intersection of artificial intelligence, data privacy, and intellectual property rights.
**Actors' and Broadcasters' Im age and Likeness Protection:** 
The rapid evolution of AI has m ade it increasingly feasible to replicate and m anipulate the im ages, voices, and likenesses of actors,
broadcasters, and other public figures, often without their consent. These attributes are not only integral to their professional identities but
also critical to their livelihoods. Existing legislative efforts, such as California’s AB 2602 (signed into law on Septem ber 17, 2024),
provide a strong foundation by requiring explicit consent and detailed contractual specifications for the use of AI-generated digital replicas
of a perform er’s voice or likeness. Sim ilarly, the federal “Nurture Originals, Foster Art, and Keep Entertainm ent Safe Act” (NO FAKES
Act), introduced in the U.S. Senate in July 2024 and the House in Septem ber 2024, aim s to establish a property right over digital replicas,
holding individuals and platform s liable for unauthorized use. I urge the AI Action Plan to build on these m easures by m andating consent
for any AI-generated use of likenesses—whether in entertainm ent, advertising, or beyond—and by im plem enting safeguards to prevent
m isuse, ensuring individuals retain autonom y over their im age, voice, and persona.
**Biom etric Data Usage and Privacy:** 
The proliferation of AI-driven technologies, such as facial recognition and voice synthesis, has heightened the risks associated with
biom etric data collection, storage, and replication. This highly sensitive data can be exploited, threatening individuals’ privacy, safety, and
dignity. Tennessee’s Ensuring Likeness Voice and Im age Security (ELVIS) Act, effective July 1, 2024, explicitly protects an individual’s
voice as a property right, offering a m odel for addressing biom etric data in AI contexts. Additionally, California’s AB 1836 (signed into
law on Septem ber 17, 2024) extends posthum ous protections by prohibiting unauthorized com m ercial use of deceased perform ers’ digital
replicas without estate consent. The AI Action Plan should adopt and expand upon these precedents by establishing stringent regulations
for biom etric data, including robust security m easures to prevent unauthorized access, clear rights for individuals to access and revoke
consent for its use, and m andates for data deletion when no longer needed.
**Transparency and Accountability:** 
Transparency is a cornerstone of ethical AI deploym ent. Actors and broadcasters m ust be inform ed about how their biom etric data,
im ages, and likenesses are utilized in AI system s. The federal “Content Origin Protection and Integrity from  Edited and Deepfaked Media
Act” (COPIED Act), introduced in July 2024, exem plifies this principle by requiring provenance data to identify AI-generated content,
em powering creators to track and control its use. Organizations leveraging such data should be held accountable through clear guidelines
on AI m odel training and data sourcing, as well as regular audits to ensure com pliance with privacy laws and ethical standards. The AI
Action Plan should integrate these accountability m echanism s to foster trust and responsibility in AI developm ent.
**Conclusion:** 


The AI Action Plan m ust prioritize com prehensive protections for actors, broadcasters, and others whose im ages and biom etric data are
im plicated in AI technologies. By drawing on existing bills—such as California’s AB 2602 and AB 1836, Tennessee’s ELVIS Act, and
federal proposals like the NO FAKES Act and COPIED Act—policym akers can craft a fram ework that safeguards individual rights,
ensures privacy, and prom otes ethical AI innovation. I appreciate the opportunity to contribute to this vital discussion and strongly
encourage the inclusion of these m easures in the AI Action Plan to address the challenges posed by AI in a rapidly changing digital
landscape.


