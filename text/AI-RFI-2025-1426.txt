PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-6a0r-dabm
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1426
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Corewell Health
General Comment
Please see attached file.
Attachments
031425 CH AI RFI response


March 15, 2025  
Faisal D’Sou za 
Networking and Information Technology Research and Development Program  
490 L'Enfant Plaza SW, Suite 8001  
Washington, DC 20024 
Dear Mr. D ’Souza,  
Corewell Health appreciates the opportunity to provide comments on the request 
for information (RFI) on the development of an Artificial Intelligence (AI) action 
plan. Corewell Health is a Michigan- based nonprofit integrated health system 
with a team of 60,000+ dedicated people including more than 11,500 physicians 
and advanced practice providers and more than 15,000 nurses providing care 
and services in 21 hospitals, and 300+ outpatient and several post -acute facilities  
locations. In addition, as an integrated health system, Corewell Health includes 
Priority Health, a health plan that insures more than a million lives. Corewell 
Health is not only Michigan’s largest health system but also Michigan’s largest 
private employer. Through experience and collaborat ion, we are reimagining a 
better, more equitable model of health and wellness. 
Executive Order 14179, “Removing Barrers to American Leadership in Artificial 
Intelligence,” is an important step forward in lifting American ingenuity in this 
field. Although the RFI does not call out health care, we urge you to balance 
sector- agnostic action items with the needs of specific sectors such as ours. 
Corewell Health utilizes AI in ways that are like other organizations but of course 
envisions utilizing AI in ways that are unique to health care. Additionally, both 
Corewell Health and Priority Health employ AI solutions developed internally as well as those provided by software vendors.   
AI has the potential to be a tool that can improve our patients’ health, our health 
plan’s customers’ experience, and lower overall costs across the system. For 
example, Corewell Health has piloted Abridge, an AI tool that listens with consent 
to patient -clinician conversations and converts relevant information in real -time 
into a digital template. This innovation eases the charting process, allowing 
physicians and caregivers to focus fully on their patients and their needs. One 
internal medicine physician noted that Abridge helps her cut down on the 9- 12 
hours per week of charting she does at home. With that context in mind, we offer 
the following comments and encourage you to consider health care as part of the 
AI Action Plan.  
Helping sy stems develop a governance structure 
The AI Act ion Plan should include public -private partnerships to help providers 
develop the AI governance infrastructure to manage risk and provide guardrails 
for deployment. Such a structure can help provide transparency to patients and consumers on how AI is used and can be beneficial in healthcare.  


Corewell Health has established an Artificial Intelligence Center of Excellence (AI 
COE) to oversee the process for onboarding and monitoring AI technologies going forward. Our goal is to develop a responsible and sustainable approach for using AI technology and similar tools in ways that improve our work while also protecting our patient and plan member information when there is high value and low risk.  
Other hospit als and providers may need resources to adopt a similar approach to 
our AI COE, and we too have appreciated tools developed by the federal government to ensure we are adopting best practices. Such tools should be flexible enough to be adopted by different types of stakeholders. For example, as required under the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the AI Risk Management Framework developed by the National Institute of Standards and Technology (NIST) has been a valuable resource. The NIST 
framework helps ensure that we are managing the potential risks of AI and promoting trustworthiness among staff, patients, and our community. We appreciate that it is a voluntary tool that is not specific either to sector or us e-
case.  
Creating a framework for responsibility between AI vendors and 
purchasers  
The Action P lan must include a pathway towards establishing a clear, 
comprehensive framework that identifies an AI vendor’s responsibilities to ensure legal and regulatory compliance to give providers of all sizes some assurances for its AI products.  
As a non- profit entity, we have dedicated resources to our AI COE at a 
considerable cost. This level of investment may not be feasible for smaller organizations, especially those serving as a safety -net provider for underserved 
or rural areas, or sustainable in the long term even for large health systems. For externally developed AI solutions, the Action Plan should move toward a framework for how vendors (i.e., any vendor integrating AI into their products) will demonstrate regulatory compliance to their customers. It would be helpful for key health and non- health agencies to provide clear guidance on how to effectively 
demonstrate and document sufficient compliance as AI technology continues to evolve.    
In addition to ensuring compliance, the performance of these tools is exceedingly 
important to validate and monitor – especially when the patient population and 
data some of these tools were trained on does not accurately reflect the patient population and data the tools will be used to treat. The responsibility for this type 
of validation and monitoring needs to be a shared responsibility between an AI vendor and the purchasing organization to ensure safe and effective use across all patient populations.  
Such assist ance would not only be beneficial to large integrated health systems 
like ours but also crucial to smaller providers, particularly in rural or underserved areas, to be confident in adopting AI solutions. Without clear guidelines, the federal gov ernment risks exacerbating a new type of digital divide within the 


health care sector with safety -net providers and their patients being unable to 
harness AI’s transformative power. Worse yet, there becomes an increasing risk 
of predatory AI vendors taking advantage of smaller, less resourced organizations in ways that both harm their financial standing and their patients.  
Developing a  talent pool  
Lastly, we  urge the AI Action Plan to consider a pipeline to develop more AI and 
cybersecurity professionals, including incentives to work in the health care sector. In adopting potential AI solutions, health plans and health systems are developing more in- depth reviews and implementation processes, which require 
substantial resources and administrative capacity. Health care providers operate on narrow margins yet must compete globally for talent with entities that have much larger access to capital.  
Should you hav e any questions regarding these comments or if you would like 
any additional information, please contact Oliver Kim, Senior Director of Public 
Policy, Corewell Health Government Relations & Public Policy, 
Sincerely,  
Rob Campbell  
Director, Data Science and AI  
Corewell Health  


