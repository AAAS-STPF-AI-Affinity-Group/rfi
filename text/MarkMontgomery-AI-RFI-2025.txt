March 15, 2025  
AI Action Plan       
Attn: Faisal D'Souza, NCO  
2415 Eisenhower Avenue,  
Alexandria, VA 22314, USA.  From: Mark Mo ntgomery  
Founder & CEO  
KYield, Inc.  
6975 Clark Hills Dr. NE 
Rio Rancho, NM 87144 
This docum ent is approved for public dissemination. The document contains no 
business -propri etary or confidential information. Document contents may be reused by 
the government in developing the AI Action Plan and associated documents without 
attribution.  
After r eading highly publicized submissions from our very-well funded competitors , I felt 
compelled to respond to the ‘AI Action Plan’ RFI. We bring a unique perspective that’s 
quite different than the big tech companies and LLM startups in San Francisco fueled by 
billions of dollars of investment.  
KYield is a  true pioneer in AI systems , self-funded from the theorem stage nearly three 
decades  ago. We have not enjoyed the publicity of our peers, so you may not have 
heard of us . I’ll provide an introduction in the form of quotes from a letter I sent to 
President Trump during his first administration, several years prior to the launch of ChatGPT , which triggered the AI arms race.    
“I am the founder of KYield and inventor of the KYield OS  (KOS) , which is a distributed 
AI operating system (OS). The foundational theorem yield management of 
knowledge …. posits that knowledge creation and transfer over distributed networks is a 
dynamic and complex undertaking consisting of …. properties with a malleable yield 
curve .... The KOS is now viable and timely for scaling due to recent exponential 
improvements in hardware and algorithmics. ” 
“The now patented core of the distributed K OS includes a rules -based governance 
system, (applications)  for business units or partners, and individual modules for each 
person (DANA) . The standard K OS provides an automated approach to workflow 
augmentation (a.k.a. enhancement or amplification) functioning behind the scene throughout the networked organization, thus enabling a very dynamic and high-performance distributed AI OS. While each module is transparent in describing algorithmic type and function, specific details are withheld as trade secrets. Customers retain data control and ownership with the exception of limited metadata for underwriters and/or regulators per agreement. ”  
I also sent letters  during President Trump’s first term  to the Secretary of Defense, Joint 
Chiefs of Staff, Congress and the National Governor’s Association warning about the risks from China  in AI. We could see patterns over time  that were quite disturbing, 
suggesting that China not only had more interest in our work than the U.S., but 
appeared to be investing significant resources  in an apparent  attempt to reverse 
engineer our work  in AI systems .  


These patterns led us  to stop publishing any disclosures on our most advanced AI 
research surrounding the Synthetic Genius Machine (SGM). Indeed, I decided not to 
pursue the three patents recommended by the USPTO after my initial application for the 
SGM, but rather maintain the body of work as tightly guarded trade secrets (2019).  
Once I fully realized that any system that can accelerate discover y can accelerate 
destruction, combined with the patterns in our web logs, we changed our polic ies. 
Unfortunately, most of my peers  continue to immediately publish emerging AI research 
to the web, driven mostly by competitive pressure and incentives from Big Techs.  
In contrast to many of our peers, rather than release advanced AI to the public prematurely , thereby  unleashing significant  risks, we made the choice to follow best 
practices in safety engineering required of other high- risk industries, including the 
handling of nuclear and biohazard materials. Our reward for doing the right thing in the current U.S. AI market has been severe financial punishment, whereas other companies 
in our industry have been rewarded with $10s of billions of dollars for doing what 
leading AI scientists have warned to be reckless , including causing existen
tial risk .  
In terms of private property  and economics , Big Techs and their LLM partners are in the 
process of transferring the knowledge economy to their companies by training their models on data owned by others  and monetizing it. The knowledge economy represents 
the majority of economic activity today in the U.S.  
Policy makers should understand that strong monopolies and oligopolies don’t need IP protection nearly as much as small potential competitors, which is presumably why Big 
Tech companies have worked to erode patents in the U.S. for the past two decades .  
Therein provides a glimpse of the problems with U.S. AI policy. The greatest problem is 
the lack of any governance whatsoever  beyond market power,  resulting in a market 
where perverse incentives  drive  behavior , which determines outcomes,  much of which  
is directly opposed to the interests of the U.S., its citizens, and the world.  
Identifying, understanding, overcoming and preventing such perverse incentives  in the 
future should be the priority for U.S. government  policy in AI,  as our following 
recommendations highlight . 
Respectfully submitted,  
Mark Mont gomery  
Founder & CEO  
KYield, Inc.   


Big Techs are driving U.S. AI policy. That needs to change.  
We advocate for AI policy based on actual evidence, rather than conflicted actors  and 
hype that often contains misinformation,  as is currently the case in our industry.   
Allow me to make some present -day comparisons to internal U.S. policy versus 
external. We are currently engaged in a trade war due to what the Trump Administration 
has described as  unfair trade policies , resulting in a recent U.S. trade deficit of $1.2 
trillion. As is widely understood in business, some of the non- tariff policies are also very  
damaging, including government -wide subsidies for strategic industries.  
For example, China’s predatory pricing at far below cost are legendary, and cause 
damage to nations and industries worldwide, but their subsidies pale basis i n 
comparison on a percentage basis  to the subsidies occurring in the AI industry.  
LLM startups  that have raised billions of dollars, some of which are backed by the most 
valuable Big Techs, are losing vast sums of money  in subsidizing customers , even 
though the majority aren’t paying for the data  their products are based on.  
“They are, in effect, receiving subsidies of hundreds of billions of dollars. The United St
ates will not be doing that any longer.” President Trump’s speech to a 
joint session of Congress on March 4th, 2025, referring to non- reciprocal tariffs . 
If it were not for the exceptionally large Big Tech investments in LLM startups, these 
subsidies would not be possible. The intent of the subsidies employed by Big Tech, LLM startups, and the CCP are quite similar —to protect strategic interests, destroy 
competition , increase dependencies and then increas e prices.  
Our position is that U.S. policy should discourage predatory subsidies, and U.S. policies on subsidie
s should be the same whether domestic or international.  
Obsession with scale 
Another negative influence on U.S. markets and economy in AI is the obsession with 
scale in LLMs, which is also driven by the strategic interests of Big Techs. Big Tech has 
dominated investment in AI research since the previous  AI winter , which ended  at the 
beginning of this century. The super majority of research that was commercialized by Big Techs has unsurprisingly been focused on the strategic interests of each company.  
Conflicts in research is the primary reason we remained lean and self-funded at KYi
eld 
for such an extended period—to allow us to follow the evidence to meet customer and societal needs rather than the needs of a conflicted  sponsor. One commonality Big 
Tech companies share is an increasingly impenetrable scale ceiling. LLMs are viewed 
as a potential solution as they require more cloud computing customers pay extra for, 
hence the unprecedented strategic investment s in LLMs and related infrastructure.  
Unfortunately for society, LLMs have inherent technical flaws , including unique 
catastrophic and cyber risks, the latter already being realized at scale. Catastrophic 
risks such as accelerating bioterrorism will take more time to manifest as it requires a 
physical lab. However, based on nearly  three decades of research at the confluence of 
human- caused catastrophes , AI systems, and prevention,  I have little doubt such efforts 
have been underway since the first consumer LLM  was unleashed to the public .  


Neurosymbolic AI  and other methods that focus on distillation and compression rather 
than scale are much more responsible than LLMs, but have been starved for funding 
due to the dominance of Big Tech in AI R&D. Many leading scientists have warned 
about the obsession with LLMs and AGI causing catastrophic risks, including existential . 
Rather than supporting LLMs and Big Techs, the U.S. should be focused on increased 
security , protection of human rights, private property, economic and environmental 
sustainability —AI systems that are more consistent with the U.S . construct  and values.  
Otherwise, we may lose leadership in technology as leaders with integrity may decide to 
locate in countries with more moral policies, fair competition, and functional markets.   
Consolidation of wealth and power  
Perhaps the most obvious  trend in AI is the ultra- consolidation of wealth in a small 
group of  companies headquartered in a few zip codes in the San Francisco and Seattle 
metro areas. One only needs to glance at the stock market for an indication of who 
investors perceive to be the primary beneficiaries of the AI/LLM boom , which is enabled 
by U.S. policies , or lack thereof .  
At the end of 2024, the so -called mag seven companies represented 35.4% of the S&P 
500’s market capitalization, or nearly three times the percentage of a decade earlier, 
peaking at nearly $20 trillion in market capitalization a few months ago. The enormous 
investment in the past two years is attributed to the expected growth in AI  dominated by 
Big Techs . This  concentration has resulted in warnings about systemic financial risk by 
central banks. We’ve been warning about  related systemic  risks for years.  
Unlike previous generations of new technology —when current market leaders were 
small, lean startups , and I and others assisted,  markets today are expecting incumbents 
to dominate AI markets. Big Techs are preventing others from having the opportunities provided to them, which I find unconscionable. Worse yet has been to observe the unhealthy relationships, increased government capture, and support for anti-market 
behavior by the U.S. government.  
This megatrend of consolidation in market power and wealth is directly counter to the 
best interests of the U.S. and its citizens, and it’s mostly due to the type of AI selected by Big Techs  (LLMs), lack of timely response by the courts in copyright and antitrust 
lawsuits, and the lack of prudent policies  by the U.S. government.  
With a wealth gap bouncing along at record levels, wide -spread market failure, and a 
host of socioeconomic challenges, the U.S. should be aggressively pursuing rich 
diversification in AI technologies, companies and regions.  
Conclusion 
Prior to the LLM hype- storm and unprecedented predatory investment, the primary  
commonality most of us shared working in AI was recognition of the great potential  to 
solve problems. Investment capital is necessary , and well -earned wealth creation 
welcome d, but the primary motivation was to accelerate discovery to cure diseases, 
prevent catastrophes, improve productivity to cure structural economic problems, and empower people to live healthier, happier lives .  


Beginning with the unleashing of consumer LLMs to the public  in November of 2022, 
which stunned many of us due to the known risks, AI was quickly repositioned to be just 
LLMs that are strategic vessel s to protect and extend the market power and market 
capitalization of Big Techs, a pathway to instant wealth for AI scientists and engineers, 
and a target for pump and dump schemes by some unscrupulous investors.  
Training on data owned by others for basic research was widely c onsidered acceptable, 
but monetizing products trained on data owned by others was considered so unethical  
most wouldn’t have considered it . I consider it to be the greatest theft in history. All of 
our rights are reflected in data today, including human rights, property rights and all other constitutional rights. If we don’t have control of our data, rights are exploited.  
Performing experiments with LLMs and other self -generating algorithms in labs was 
common, and didn’t create problems for society as the risk was contained in a 
controlled environment, not unleashed to the world, including every evildoer on the planet. All that changed when LLMs were unleashed to the public.  
Many of us find these trends very troubling, including quite a few of the most talented 
who made this boom possible with their intellectual contributions. If the U.S. government doesn’t aggressively change course and establish responsible AI policies, I fear that it 
may result in the U.S. losing our leadership position in technology.  
It is not the market power  or market capitalization that creates or maintains leadership in 
science- related industries like AI, but rather the genius of a relatively few people, most 
of whom have high moral standards, and are careful who they empower.    
I therefore recommend the following changes to U.S. AI policy  with the goal of solving 
problems rather than creating them:  
1.First, do no harm. Establish  and require safety engineering principles for AI .
2. Create prudent AI regulations  based on actual risk profiles. Self-generating models
trained on vast data for the public is  very high- risk and should be tightly regulated.
Most other methods are low-risk and require little regulation.
3.Require a review process for publishing emerging research involving high-risk
technologies. Invite and compensate expert  reviewers  from multiple disciplines with
real-world experience , including national security, not just LLM scientists.
4.Make it a felony to knowingly introduce any type of high- risk technology to the
public , and aggressively enforce it.
5.Leverage the entire U.S. government in collaboration with states to diversify  AI
rather than further consolidate one of the strongest oligopolies in history.
6.Reinforce human rights and private property rights, including an outright ban oftraining on data owned by others without an explicit license.
7.Instruct the SEC and other regulators to help rein in predatory subsidies and pumpand dump behavior —it has a toxic influence on markets and building companies.
8.Lead a whole- nation approach to creative destruction, including reforming
procurement systems that are often corrupted. Restore bias for the ‘little guy’.
Email:   Email submissions should be machine -readable and not  be copy -protected. 
Submissions should include “AI Action Plan” in the subject line of the message.  


