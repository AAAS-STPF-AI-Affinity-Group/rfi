Adobe Comments on the National Science Foundation’s  
Request for Information on the Development of an Artificial Intelligence Action Plan  
Introduction  
Adobe welcomes the Administration’s efforts to establish U.S. policy for sustaining and 
enhancing artificial intelligence (“AI”) innovation in the U.S. in order to promote human 
flourishing, economic competitiveness, and national security, and we appreciat e the opportunity 
to submit recommendations on the Administration’s development of an AI Action Plan. Unlocking 
the full potential of AI will require a dynamic and flexible policy framework that enables the 
private sector to spur AI innovation in the U.S.,  while providing clear guidance to organizations 
on how they can leverage industry standards to inspire consumer confidence and accelerate 
adoption. By taking this approach, the U.S. can achieve the Administration’s goal of continuing 
to lead the world on AI. 
This document is approved for public dissemination. The document contains no business -
proprietary or confidential information. Recommendations in this d ocument may be reused by 
the government in developing the AI Action Plan without attribution.  
Background  
At Adobe, our mission is to change the world through personalized digital experiences. Since our 
founding in December 1982, we have pioneered transformative technologies that allow our 
customers —who range from emerging artists to global brands —to channel t heir imaginations, 
unleash their creativity, and power their businesses.  
As technology evolves and becomes more advanced, we are committed to innovating responsibly. 
This means making sure our technologies and the processes we go through to develop them are 
accountable, responsible, and transparent so that we can rapidly innova te while assuring 
consumer confidence in our products. We believe that our approach to development strikes the 
right balance to promote human advancement and cement U.S. technological leadership and 
should serve as an industry standard for all technology c ompanies.  
Adobe’s business is comprised of three cloud -based solutions: Creative Cloud, Document Cloud, 
and Experience Cloud. Across each cloud and in our products, Adobe is building on a decade -long 
legacy of Al innovation by leveraging the power of Al to deliver h undreds of intelligent capabilities. 
For example, in Creative Cloud, Al powers many creative functions including advanced image 
editing features in Photoshop, making it easier for everyone to tell their story with simpler and 
more intuitive tools. In Docum ent Cloud, Adobe Acrobat’s AI Assistant leverages AI technology 
to provide users with powerful document interaction capabilities such as the ability to generate 
summaries, answer questions, and provide insights across multiple document types. And as part 
of our Digital Experience offerings, Adobe’s customers can use Al -driven features to deliver 


relevant and meaningful insights and personalized digital experiences to the vast number of 
visitors on their websites.  
 
In March 2023, Adobe launched Firefly , our family of creative generative AI (“GenAI”) models 
that are both creator -focused and safe for commercial use. Starting with GenAI image generation, 
Firefly allows users to channel their creativity in ways they never imagined possible by simply 
typing in a prompt and generating images in seconds and is available in multiple Adobe 
applications like Photoshop, Illustrator, and Adobe Express. Adobe is also bringing Firefly GenAI 
capabilities to our audio and video tools and plans to continue to expand into  other modalities 
such as 3D. To date, Firefly has been used to generate over 18 billion images across Adobe’s 
creative tools including Photoshop, Express, Illustrator and more.  
 
We believe that Al done right will amplify human creativity and capabilities to new levels with 
deeper insights, accelerated task performance, and improved decision -making ability.  
Executive Summary  
Adobe supports the Administration’s goal of enhancing AI dominance and support for shared 
democratic values globally through private sector innovation to promote human flourishing, 
economic competitiveness, and national security. Our response and accompany ing 
recommendations highlight the following themes:  
 
• Strengthen American Leadership in AI Technical Standards that Support Innovation 
and Protect Online Speech : Adobe supports the advancement of U.S.-led open technical 
standards to enhance AI transparency, safeguard national security, and protect free 
speech by providing consumers with reliable tools to verify the provenance of digital 
content for themselves.  
• Promote a Risk -Based Approach to AI Development That Fosters Free Market AI 
Innovation : Adobe supports a risk -based approach to AI development which allows 
innovation to rapidly accelerate by reducing unnecessary regulatory barriers and 
inspiring consumer confidence.  
• Unlock the United States’ AI Potential by Guaranteeing Long Term Access to High 
Quality AI Training Data: We urge the Administration to take a pro -innovation approach 
to data access that removes regulatory uncertainty for AI developers and safeguards 
creators from commercial misuse.  
• Explore an AI Testing Pilot and Standardization Benchmarks : We urge the Administration 
to promote AI innovation, while ensuring secure standards, by establishing an AI Testing 
Pilot and developing standardized test datasets, enabling companies to evaluate their 
models through a scalable, industry -driven framework  that fosters public trust.  
• Unleash the Power of AI to Modernize the U.S. Federal Government: Adobe is 
supportive of efforts to leverage AI to enhance efficiency, reduce costs, and improve 
public services across the Federal Government.  
 
Strengthen American Leadership in AI Technical Standards that Support Innovation and 


Protect Online Speech.  
 
As referenced in recent White House communications on enhancing America’s AI leadership , 
the Administration has stated its intent to strengthen American leadership in AI technical 
standards. Adobe recommends that the U.S. move quickly and with intentionality to ensure 
continued global leadership in promoting and developing AI -related open te chnical standards 
to ensure that international regulatory regimes foster the creation of AI technologies, rather 
than strangle them. Understanding that U.S. leadership in global AI standards depends on the 
involvement of various stakeholders within this ec osystem, the Administration should look to 
further develop and promote private sector -led, U.S. AI standards globally. Our approach to 
accomplishing this goal aligns with the instructions provided in Executive Order 14149, 
Restoring Freedom of Speech and Ending Federal Censorship , where the Administration can 
promote American solutions internationally that give consumers the tools they need to help 
make decisions about online content without interference or censorship from government or 
industry.  
 
Methods to improve awareness and transparency regarding the origins of digital content is ripe 
for U.S. -led global standardization. This is particularly relevant in identifying whether content is 
AI-generated or AI -edited, along with more comprehensive inf ormation about the content's 
origins, history, and context. Thanks to advancements in Al, developing, editing, and distributing 
content has become more powerful and accessible for consumers. However, the same tools 
enhanced by the power of Al to make and s hare legitimate content can also be weaponized to 
undermine national security, and sow political and cultural discord. It is critical to protect the 
integrity of online speech by ensuring Americans have access to tools that verify the authenticity 
of digit al content.  
 
As the Administration formulates the AI Action Plan to enhance America’s global AI dominance, 
we urge the government to leverage industry standards such as the consensus -based, 
interoperable standard pioneered by the Coalition for Content Provenance and Authenticity 
(“C2PA”) , which is now providing consumers with a simple, reliable method of determining the 
provenance and authenticity of the content they are consuming online. This technology, called 
Content Credentials , provides a ‘nutrition label’ for content that can show information about 
images, videos, documents, audio files and more, such as how they were created, the creator’s 
name, the date created, and edits that were made along the way.  
 
With Content Credentials, creators can indicate not only whether GenA I was used, but how it 
was used. This level of transparency helps consumers to make more informed decisions about 
whether to trust the content they see online and helps ensure government and big tech never 
become the sole arbiters of truth. The Adobe -led Content Authenticity Initiative (“CAI”)  is a global, 
cross industry coalition, supported by over 4,000 members, working to advance free, open -
source implementations of Content Credentials’ provenance technology. At Adobe, we have 
promoted this level of transparency by integrating Content Creden tials into popular products 
such as Photoshop, Lightroom and Firefly.  
 


By driving adoption of industry standards like the C2PA and promoting technologies like Content 
Credentials, the U.S. can set a global benchmark for AI transparency and help keep the 
government and big tech out of the censorship business. To achieve these goals, we recommend 
the following actions:  
 
• Set the Global Standard for Content Provenance with the C2PA. We recommend that the 
Administration leverage its convening authority and work through international bodies, to 
which the U.S. is a party, to advance the development and adoption of existing open technical 
standards for digital content provenance (i.e. C2P A).  The C2PA is currently working with the 
International Organization for Standardization’s (“ISO”) TC 171/SC 2 technical committee, 
whose charter includes content authenticity, to establish Co ntent Credentials as an open 
standard from a recognized, international standards developing organization.   
 
• Adopt Content Credentials to Foster Trust in Government Content. To strengthen public 
confidence in the integrity of the U.S. Government’s digital content, we urge the White 
House to issue guidance directing government agencies to implement the C2PA standard 
and Content Credentials for all government digital content, su ch as images, videos, audio, 
and document content they post on official government websites and communications. 
The broad adoption of the C2PA standard would enable the government to share tr usted 
resources and information with the American public and help prevent consumers from 
falling victim to harmful deepfakes or synthetic content spread by bad actors. We 
recommend the White House stand up a federal interagency task force to promote the 
inspection of the C2PA standard and global adoption of Content Credentials by the U.S. 
government and its partners.   
 
• Protect the Authenticity of Online Speech and Protect Consumers from Censorship by 
Ensuring Online Platforms Maintain and Display Content Credentials . For Content 
Credentials to be maximally effective, they must reach consumers in all the places where 
they consume information, such as major internet platforms. Currently, Content 
Credentials are often stripped away on internet platforms, depriving consu mers of 
critical information and context about the content they are consuming.  We urge the 
Administration to require online platforms to maintain and display any Content 
Credentials present in digital content on their systems. If a piece of content has Content 
Credentials attached, those Content Credentials should not be stripped away. With 
access to the impor tant context that Content Credentials provide, we can empower 
consumers with a free -market solution to make their own decisions about what to trust 
online, rather than being subject to the determinations of the platforms where content 
is hosted.  
 
• Encourage Smartphones to Implement Content Provenance . Provenance must be 
integrated at every stage of the content lifecycle, from point of capture to editing to 
publication. This also includes the devices most commonly used today for capturing 
digital content, such as smartphones. We have already seen signi ficant progress around 
implementing the C2PA open technical standard for Content Credentials into cameras. 


Now it’s time for smartphone manufacturers to follow suit. In order for this solution to 
be maximally effective we need to ensure this technology is available wherever 
consumers capture content, which of course includes  smartphones. We urge the 
Administration to encourage smartphone manufacturers to implement provenance 
capabilities, so that users have the option to attach content provenance metadata to all 
newly created and captured content.  
 
Promote a Risk -Based Approach to AI Development That Fosters Free Market AI Innovation . 
 
As the Administration considers its approach to reducing regulatory barriers to promote AI 
innovation as set forth in Executive Order 14179 , Adobe encourages consideration of the 
adoption of a risk -based approach to evaluating AI that enables companies to rapidly innovate 
while ensuring consumer confidence in AI technologies.  Adobe envisions a world where the most 
promising AI is developed, with widespread adoption, making us all more prosperous and more 
productive.  
 
Countries around the world are looking to regulate AI.  We have seen varying approaches to AI 
regulation such as analyzing AI model size, scrutinizing potential catastrophic safety implications, 
and implementing onerous, and trade secret -compromising, training data transparency 
requirements. None of these approaches achieve the goal of spurring innovation and driving 
widespread adoption of AI by consumers. To balance these objectives and ensure global 
leadership in AI, it is critica l that the U.S. government promote policies that enable companies to 
go to market faster while making sure that consumers feel comfortable and confident in using AI. 
These policies, done right, will avoid an overly precautionary regulatory regime, while en suring 
that all Americans benefit from AI technology. This is an opportunity for the Trump 
Administration to establish a framework for AI governance that can and should be adopted 
globally.  
 
Adobe believes that a risk -based approach achieves these goals, and we urge the U.S. 
government to consider Adobe’s approach to AI development as a framework that should be 
encouraged globally.  
 
Beginning in 2019, Adobe proactively and voluntarily developed a layered, multi -disciplinary 
process for responsible innovation to enable the company to rapidly develop AI while ensuring 
the confidence of our users to take advantage of this new technology.  This development process 
included establishing an Al governance program with a comprehensive review process that 
includes an impact assessment, ensuring models are free from ideological bias. As such, we have 
suggested the following key elements that we b elieve should be incorporated into the 
Administration’s AI Action Plan to promote a risk -based approach to AI development:  
 
• Promote a Risk -based Approach to Foster Innovation. Establishing a risk -based approach 
to AI governance that focuses on only the most high -risk use cases will foster innovation 
with the added benefit of requiring organizations to conduct a more rigorous and 
thorough review of high -risk Al systems. At Adobe,  we have a multipart review process 


with an integrated Al impact assessment that is designed to assess the impact of an Al 
product or feature, including mitigation of any ideological bias. If an initial assessment 
shows the AI product or feature is low -risk and the feature meets our internal  standards, 
the feature is approved and goes to market. For example, an Al feature that recommends 
a set of fonts based on a document template would move through a faster review process. 
Al features that have a higher potential impact, like the possibility  of displaying an 
ideological bias, go through a more rigorous testing process, including a review by the Al 
Review Board.  A risk -based approach like this will be critical moving forward as AI 
continues to advance and the United States works to promote innovation, while also 
ensuring that consumers have confidence in the AI technology they utilize.  
•Encourage Companies to Solicit Ongoing Feedback.  Community feedback can help
mitigate potential biased, inaccurate and harmful outputs of AI systems and equip
consumers to trust the AI that they are using.  At Adobe, when we launch new generative
AI features, we generally do so first in a beta format to  seek input from our employees,
customers, and broader creative community. In addition, we design our generative AI
features (like those powered by Adobe Firefly) with a built -in feedback mechanism so
users c an easily report if a feature produces a result they perceive as biased or inaccurate.
This feedback data allows our product and engineering teams to help identify harmful
outcomes and address them appropriately. In our view, this constant feedback loop wi th
our user community is the best way to help ensure our tools minimize bias and produce
accurate results. A feedback mechanism creates transparency for our customers and
eliminates the need for government to intervene and require onerous reporting
require ments that risk compromising trade secrets.
•Leverage Public -Private Partnerships. Over the past several years, Al development has
occurred at a rapid pace across various sectors of industry. Many companies, including
Adobe, have garnered valuable experience and knowledge in navigating the rapid growth
of this cutting -edge technology and  mitigating against potential harms. We urge the
Administration to leverage industry learnings and industry collaboration as they continue
to identify ways to accelerate Al innovation in the U.S.
Unlock the United States’ AI Potential by Guaranteeing Long Term Access to High Quality AI 
Training Data.  
As stated in Executive Order 14179, Removing Barriers to American Leadership in Artificial 
Intelligence , it is the policy of the United States to sustain and enhance America's global AI 
dominance in order to promote human flourishing, economic competitiveness, and national 
security. With the right Government policies, we can solidify our position as the glo bal leader in 
AI and secure a brighter future for all Americans. We believe providing AI systems developed by 
Americans will need decades of high -quality data to meet these objectives. We would like to 
offer a few policy recommendations that will help the United States lead the world in developing 
AI systems based on the availability of high -quality training data.  


The Administration has a world -leading opportunity to establish a data access framework that 
fosters AI innovation, while incentivizing creativity for decades to come. Other nations are 
actively considering opt -out standards for AI training data, and the U.S. has a chance to set a 
global preced ent. By implementing a long -term approach, the U.S. can ensure that companies 
of all sizes —including startups —have access to the data needed to build competitive AI models, 
while also giving those who create training data some fundamental safeguards from t heir work 
being commercially misused.  
In order to accomplish these goals, the U.S. should consider the following policy positions:  
•Be Declarative on Copyright Fair Use of Training Data.  In the absence of clear regulatory
guidance on whether the use of data to train AI is considered fair use under copyright
law, we encourage the Administration to take a bold, pro -innovation stance and be
declarative on the issue, giving American AI develo pers of all sizes a clear framework and
certainty in the marketplace as AI systems are developed.
•Facilitate an Opt -Out Standard.  While it is essential that government establish a
framework that enables broad access to data, it is also important to recognize that there
is no clear, globally accepted, standard for creatives to opt -out of having their works
used to train Al models. Th erefore, the Administration should, in parallel, advance an
opt-out standard that enables creators to indicate this preference for specific pieces of
content. As explained in greater detail below, the global open standard aro und Content
Credentials  can be leveraged to meet this need; creators can use Content Credentials to
attach a “do not train” tag to an individual piece of content that remains associated with
the work wherever it goes. Therefore, Content Credentials can provide a tamper -evident
way to help ensure that an individual’s AI training preferences are respected, and their
content is treated the same across all sites where they may choose to publish it.
•Establish Anti -Impersonation Rights for Creators.  As the Administration considers some
of the important questions raised by GenAI, we believe it should consider supporting a
new specific protection for creators that copyright law currently doesn’t cover. One of the
core questions raised by Adobe's custom ers is, what happens when someone uses an Al
model to replicate their style, in direct economic competition with their original work?
Adobe believes the intentional misuse of Al tools in this way could pose a legitimate issue
for the creative community. In response, Adobe has proposed establishing a new anti -
impersonation right to address this type of economic harm in the U.S. Such a law would
provide a narrow ability for a person to protect their most valuab le assets from being
intentionally and commercially used to impersonate their work and style through Al tools.
This right would provide a new mechanism for artists to protect their livelihood from
people misusing this new technology without having to rely solely on mismatched existing
laws around copyright. Paired with this protection, the U.S. can implement a framework
that broadly gives more access to data while minimizing the risk of AI harms, therefore
unlocking  an abundant supply of AI training data available to AI developers for decades
to come.


The combination of the recommendations above will ensure the U.S. solidifies its position as 
the global leader in AI through the abundant supply of AI training data, securing a brighter future 
for all Americans.  
Explore an AI Testing Pilot and Standardization Benchmarks.  
Adobe recognizes the importance of the Administration’s goal to develop AI systems that are 
free from ideological bias and engineered social agendas as stated in Executive Order 14179 . 
That is why we have established a comprehensive AI Governance Program that includes rigorous 
testing, training, and oversight by our AI Review Board. Rather than imposing burdensome 
government requirements that could restrict private sector AI developmen t and deployment, 
the Administration has an opportunity to take an alternative regulatory approach, unique to the 
U.S., by establishing robustness, resilience, and safety standards and an AI Testing Pilot to
ensure that users, including younger users, can interact safely and appropriately with AI
systems.  The AI Testing Pilot would include developing robust benchmark test datasets that
companies can use to evaluate their AI models.
Standards provide consistent guidelines to ensure quality, safety, and interoperability for AI 
systems, ensuring consistency across different industries. At the same time, standards 
encourage responsible development, that allows companies to build trust wi th their customers, 
by giving companies clear guidelines without imposing unnecessary restrictions.   
The Federal Government is best situated to convene the multitude of stakeholders and 
perspectives needed to develop these standards and create benchmarking, testing systems that 
companies can test their Al models against to ensure they meet these standards. The 
benchmarks would be focused on allowing companies to push the boundaries of AI technology 
without unnecessary restrictions, while ensuring that users —especially parents —have the right 
tools and information to make informed decisions about wh ich AI systems to interact with or 
let their children interact with. The benchmarks could address categories such as violence, 
sexual content, and self -harm.   
In addition, the Federal Government could establish a classification system to communicate the 
level of adherence to these standards and benchmarks. This will help users and stakeholders 
make informed decisions about content and technology and whether it i s suitable for specific 
applications. By highlighting potential concerns, such as explicit content or AI bias, classification 
systems help protect vulnerable audiences, including children. This approach preserves 
innovation and freedom, allowing new ideas to flourish while maintaining public trust.   
 To ensure consistency and maximum benefit, we propose:  
•Partner with the Private Sector to Develop Benchmark Test Datasets.  Encouraging
collaboration between the private sector and federal agencies in building standards,
classification systems, and benchmark test datasets would create a regulatory


framework that prioritizes both innovation and responsibility. This would help create an 
environment for a scalable and industry -driven approach that fosters consumer trust 
without hampering technological progress.   Rather than burdening AI companies with 
restrictive compliance measures, this approach would incentivize them to refine their 
models through transparent, standards -driven evaluation, ensuring AI development 
remains innovative, effective, and globally competitive.   Benchmark test datasets would 
need to be established across various verticals, industries, markets, and use cases. There 
is an opportunity for the private sector to partner with agencies to establish appropriate 
datasets in each case. Benchmark test datasets may also open the door to a self-
certification regime of compliance, which would, in turn, build greater consumer trust.  
•Establish a Self -Certification Process for Companies. By establishing a self -certification
process for AI systems, the Government can set the norms for the robustness, resilience,
and security standards of Al models. Companies are accountable for their development
of AI and have an incentive to participate, a s it creates a safe harbor against future
litigation. Companies can use third -party auditors to verify that they meet benchmarks,
creating legal certainty for companies and assuring governments and cons umers that Al
was soundly developed. For example, together with industry, government could establish
certain acceptable ranges of outcomes for sexual content for different use cases of AI
models. These outcomes could be established as standards that compan ies strive to meet
depending on the use case of their specific AI model. Then, government and industry work
together to create testing and evaluation datasets that companies can run their AI models
against to determine whether they fall into the standard r ange and do further testing and
refining if needed. Then, a company could self -certify that they have met the accepted
standard. This will not only allow companies to innovate and test in a more efficient and
secure way, but will also create much needed co nsistency, assurance and clear consumer
understanding of the AI they are interacting with.
Unleash the Power of AI to Modernize the U.S. Federal Government.  
Executive Order 14158  establishes the President’s Department of Government Efficiency 
(DOGE) and instructs the DOGE Service Administrator to commence a Software Modernization 
Initiative to improve the quality and efficiency of government -wide software, network 
infrastructure, and information technology (IT) systems. As such, Adobe encourages the 
Administration to utilize AI tools to assist with the required modernization of Federal technology 
and software to maximize government efficiency and productivity. AI can be adopted and  
leveraged to meet the Executive Order’s requirements by enhancing efficiency, reducing costs, 
and improving public services across the Federal Government.  The Administration also has the 
opportunity to expedite the acquisition of AI solutions and unleash untapped AI capabilities 
within existing software, already utilized by agencies, that meet Executive Order 14179's  
standard of being free of ideological bias or engineered social agendas. AI systems produced by 
American companies, especially those that are commercially safe or trained only on licensed 
content, or content where permission is not required by law, are pr ime for this express 


acquisition process. 
As a result of rapid advancements in AI, the U.S. Government has a tremendous opportunity to 
implement AI -driven solutions in areas such as digital service delivery and content creation, 
streamlining operations and providing more accurate and timely respon ses to public needs. By 
adopting AI technologies, the government can better manage resources, predict and respond 
to challenges, and deliver higher quality services to its citizens. GenAI will enable federal 
employees to be more productive and increase pub lic access to federal services.   
Below are several recommendations where the federal government could take advantage of 
GenAI and machine learning capabilities to improve agency missions and business operations, 
while simultaneously meeting the Administration’s goal of modernizing legacy software and 
increasing efficiency:   
•Unlock Existing AI Tools Within Government Software . Many secure, U.S. -Sourced AI
tools are already built into software utilized by Federal employees but are inaccessible
to them due to overly complex and often distorted usage guidelines. These tools, if
unlocked, will empower federal workers to automate routine tasks, rapidly analyze vast
datasets, and make data -driven decisions, sign ificantly boosting productivity and
enabling them to focus on high -value initiatives.
•Streamline Procurement of Commercially Safe AI Systems. The Administration released
Executive Order 13859 , which encourages federal agencies to reduce barriers to
government acquisition and use of AI. Prioritizing procurement of AI tools can serve to
increase federal worker’s productivity and maximize government efficiency.
Commercially safe AI tools, those t hat train only on licensed content, or content where
permission is not required by law, are ripe for expedited procurement, as they mitigate
some concerns posed by other AI systems.
•Use AI to Optimize Information Processing and Data Analysis . Government employees
can leverage GenAI systems to revolutionize information management and data analysis.
AI-powered tools can rapidly search and simplify information from complex documents,
extract insights from multiple disjointed internal sources, an d automate the
summarization and reporting of external requests from citizens.  By implementing
industry -leading AI tools, government agencies can significantly enhance their efficiency
in handling the vast amounts of information they receive, improve decision -making
processes, and ultimately deliver more responsive and informed services to citizens, all
with less burden placed on Federal workers.
•Create and Deliver Content More Efficiently Using AI . By leveraging AI tools, the Federal
Government will be able to train non -technical communicators to create images or
videos that leverage pre -approved templates, logos, or style guides, to quickly generate
informational content to be distributed within m inutes across digital touch points. This
reduces dependencies on IT staff to hard code content while enabling communications


and marketing teams to respond in real time. Government can also pair generated 
content with a content management system, allowing organizations to generate and 
manage AI content from creation to publication to deletion.  
As AI development continues to accelerate, the U.S. Government should work to implement AI -
driven solutions in digital service delivery to optimize their operations and better address 
federal worker and public needs. Initiatives to do so, such as unlocking  existing AI systems, are 
key to not only meet the requirements laid out in Executive Order 14158 , but also to enhance 
government efficiency, reduce agency costs, and improve public services across the Federal 
Government.   
Conclusion  
Adobe appreciates the opportunity to provide feedback on the Administration’s development 
of the AI Action Plan. We appreciate that the National Science Foundation has taken important 
steps to consult with interested stakeholders as the Administration form ulates its AI policy 
priorities.  
We look forward to continuing the discussion with the Office of Science and Technology Policy  
and the National Science Foundation and are eager to engage collaboratively on these 
important issues.  


