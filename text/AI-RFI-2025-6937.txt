PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-0vva-m 7ab
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-6937
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Jocel yne Fajardo  
General Comment
Generative AI, since its inception in 2021, has proven to be not only unethical, but dangerous to everyone. 
For exam ple, the FBI charged a m an last year for creating 10,000 CSAM with generative AI:
https://www.theguardian.com /technology/article/2024/m ay/21/child-sexual-abuse-m aterial-artificial-intelligence-arrest
This is one way in which generative AI poses a danger to children. 
Another is how generative AI has m ade it easier to m ake inappropriate deepfakes of young teens by their fellow peers as a way to bully
and harass their victim s, which has unfortunately caused suicide to occur: https://www.theguardian.com /society/2024/jan/26/im -victim -of-
failing-system -m ia-janins-father-says-after-inquest-into-girls-death
Speaking of suicide, generative ai chat bots have been noted to encourage teens to kill them selves, and unfortunately, one teen did in fact
com m it suicide: https://apnews.com /article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0
Som ewhat recently, a principal got in trouble for saying racist and antisem itic com m ents, but it turned out that a co-worker faked the voice
audio using generative ai. Had it not been for the co-worker leaving behind evidence of doing so, it is hard to say whether or not the
principal would have proven his innocence: https://www.theverge.com /2024/4/25/24140556/ai-voice-cloning-baltim ore-school-m isuse
Considering how m uch easier it is to m anipulate voices, videos, and im ages as a result of generative ai, allowing generative ai to get better
and better would be a genuine negative im pact to our national security. 
Furtherm ore, a book on how to forage for m ushroom s written with generative ai led to an entire fam ily to be poisoned and end up in the
hospital. It is worth noting that the listing for the book online did not disclose that it was written with generative ai:
https://www.aol.com /fam ily-uses-m ushroom -identification-book-010036132.htm l
Continuing on with generative ai and inform ation, a study conducted by the Tow Center for Digital Journalism  found that generative search
tools "provided incorrect answers to m ore than 60 percent of queries": https://www.cjr.org/tow_center/we-com pared-eight-ai-search-
engines-theyre-all-bad-at-citing-news.php
Generative ai has also polluted the internet. A project studying hum an language was cancelled because no one "has reliable inform ation
about post-2021 language usage by hum ans": https://www.404m edia.co/project-analyzing-hum an-language-usage-shuts-down-because-
generative-ai-has-polluted-the-data/
Generative ai has also negatively im pacted artists from  all creative fields, as generative ai not only uses artists' work, but has led to som e
industries to not hire artists, im pacting their livelihoods: https://www.forbes.com /sites/robsalkowitz/2024/05/23/new-tech-gives-artists-a-
fighting-chance-in-the-battle-against-generative-ai/


Generative ai is also causing unprecedented am ounts of pollution, increased electricity usage, and increased water consum ption:
https://news.m it.edu/2025/explained-generative-ai-environm ental-im pact-0117
Overall, there is absolutely nothing useful about generative ai. It is a danger to children, it is a danger to artists, it is a danger to all civilians
and our institutions. 


