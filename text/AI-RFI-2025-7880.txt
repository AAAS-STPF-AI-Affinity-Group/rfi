PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-1yii-9a68
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7880
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Aaron Gaskill
General Comment
Here is m y argum ent against the investm ent in AI:
Ethical Concerns and Misinform ation:
Generative AI has the potential to create m isleading or entirely false inform ation that can spread quickly. AI-generated content, including
im ages, videos, and text, can be indistinguishable from  real m aterial, m aking it easier for m alicious actors to deceive the public, influence
elections, or spread propaganda.
Deepfakes, for exam ple, can be used to create fake videos of public figures, leading to serious consequences like defam ation,
m anipulation, or even threats to national security.
Job Displacem ent and Econom ic Inequality:
As generative AI becom es m ore advanced, there is a growing risk of m assive job displacem ent. Fields like journalism , content creation,
design, program m ing, and even som e areas of healthcare m ay see significant job loss as AI takes over tasks traditionally done by hum ans.
This could exacerbate econom ic inequality, as the benefits of AI will likely be concentrated in the hands of a few large corporations and
tech com panies. The displacem ent of workers without adequate social safety nets or retraining program s could lead to social unrest and
widen the wealth gap.
Loss of Hum an Creativity and Skills:
As generative AI tools becom e m ore accessible, there is a concern that hum ans m ay rely too heavily on them , leading to the erosion of
traditional creative processes and critical thinking skills. Artists, writers, and other creators m ight use AI to autom ate parts of their work,
reducing the value of original hum an creativity.
Over tim e, this could result in a world where content becom es form ulaic and uninspired, as AI lacks the true em otional depth and personal
experience that hum ans bring to their work.
Bias and Lack of Accountability:
Generative AI system s are trained on data sets that are often biased, reflecting the prejudices and stereotypes present in society. These
biases can be inadvertently reinforced by the AI, leading to harm ful and discrim inatory outputs.
Additionally, AI m odels lack accountability. If AI generates harm ful content or m akes errors that lead to negative consequences, it is
unclear who should be held responsible â€” the developer, the com pany, or the AI itself? This lack of clarity in accountability raises serious
legal and ethical concerns.
Environm ental Im pact:
Training large generative AI m odels requires significant com putational power, which consum es vast am ounts of energy. Data centers and
the hardware required to run these m odels contribute to a growing environm ental footprint. As AI m odels becom e m ore sophisticated,
their energy dem ands are likely to increase, which could have a detrim ental effect on global efforts to reduce carbon em issions.
Dependence on Technology:


Generative AI, if integrated too deeply into daily life, could create a dangerous over-reliance on technology. If AI system s are used to
create content for social m edia, news, or even personal relationships, people m ight becom e disconnected from  genuine hum an interaction
or even fail to develop their own thinking skills, trusting AI too m uch for problem -solving and decision-m aking.
This growing dependence on m achines m ight underm ine individual autonom y and critical thinking, leaving society vulnerable in the event of
technical failures or cybersecurity breaches.
Security Risks and Misuse:
As generative AI becom es m ore powerful, it could be used for m alicious purposes, such as creating m ore advanced cyberattacks or
weaponizing AI to m anipulate financial m arkets or infrastructure.
Cybercrim inals could use AI to autom ate phishing attacks, craft convincing fake com m unications, or even sim ulate legitim ate voices to
steal personal inform ation, thereby increasing the scale and efficiency of cybercrim es.


