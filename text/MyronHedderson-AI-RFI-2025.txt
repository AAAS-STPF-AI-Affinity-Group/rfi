Submitted by: Myron Hedderson  
Cybersecurity Specialist  
Fredericton, New B runswick, Canada.  
Page 1 of 10 March  15, 2025  
Faisal D’Souza, NCO  
Office of Science and Technology Policy  
Executive Office of the President  
2415 Eisenhower Avenue  
Alexandria, VA 22314  
Submitted by email to 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI 
Action Plan and associated documents without attribution.  
Re: Request for Information on the Development of an AI Action Plan  
Mr. D ’Souza:  
Thank you for the opportun ity to submit a comment regarding the Unite d Stat es’ upcoming AI Action 
Plan. I have been following developments in the AI field closely for more th an a decade now, and while I 
am not a US resident, the Action Plan will clearly have an impact on me , and the world outside of the US. 
Regards,  
Myron Hedderson  


Page 2 of 10 Introduction  
This submission outlines strategic recommendations for the AI Action Plan to ensure Western 
leadership in artificial intelligence while addressing critical security challenges. As a 
cybersecurity specialist with over 15 years of experience, including work protecting critical 
infrastructure at NB Power (a Canadian electric utility) from potential nation -state threats since 
2021, I can provide a unique perspective on the challenges  of securing AI systems from 
determined adversaries. I have been following developments in AI closely since 2014, giving me 
insight into both the cybersecurity and AI domains.  
In this submission, I propose a framework that supports robust innovation and technological 
primacy while implementing targeted safeguards against the most severe risks. My 
recommendations are designed to enhance the United States' strategic advantage and allow 
the US and the Western worl d to take full ad vantage of potentially worl d-changing AI 
capabilities, while preventing potential catastrophic vulnerabilities that could undermine 
national security and democratic values.  
The pace of AI development is far faster than government processes are designed to respond 
to. Over the past 2 years , AI systems have moved from being a surprisingly good chatbot, to 
outperforming doctors on diagnosis, generating tens of thousands of candidate  bioweapons in 
a day , and in general approaching h uman expe rt level in many domains. Within the current 
Presidential term, frontier AI companies project that their models will move to and likely past 
human capabilities  in all domains. This compressed timeline means decisions made now will 
determine whether the US maintains its leadership position or cedes ground to competitors. 
The window for establishing effective governance while maintaining our technological edge is 
rapidly closing.  
Advanced AI systems represent both the greatest technological opportunity of our time and, if 
developed incorrectly, a potential strategic vulnerability. With a Chinese Communist Party (CCP) 
determined to overtake Western democracies by 2030, the Trump Adm inistration's AI Action 
Plan can ensure that democratic values remain embedded in AI development. The 
recommendations in this submission will help ensure that AI systems remain aligned with 
democratic principles and interests, preventing scenarios where th ese powerful technologies 
could act against our shared objectives.  
A Perspective from Cybersecurity: The Challenge of Protecting AI Assets  
The protection of critical AI assets – particularly the model weights of frontier AI systems – 
presents unprecedented security challenges:  


Page 3 of 10 1.Scale and Complexity:  Advanced AI models represent some of the most complex
software systems ever created, with billions or trillions of parameters. This complexity
creates an expansive attack surface that is difficult to fully secure.
2.Attractive Target:  Model weights represent billions of dollars in R&D investment and
computational resources. This makes them extremely high -value targets for theft by
sophisticated adversaries like the CCP.
3.Transferable Value:  Unlike many cybersecurity targets where the value diminishes once
stolen, model weights retain their full value and capabilities even after being
compromised.
4.Nation -State Resources:  Nation -state adversaries can maintain persistent access to
even the most secured systems , as demonstrated by the case study in recommendation
3. This level of capability makes protecting model weights exceptionally challenging.
Despite , but informed by,  my experti se and long experience in Cybersecurity, if asked to protect 
a critical asset from a determined nation -state attacker, my response would be “we can make 
their task  harder , but I can ’t give you a guaranteed way of keeping adversaries o ut - the 
attempt to gain access will likely succeed in time ”. I believe we must adopt a security posture 
that assumes breaches will occur and focuses on limiting the damage when they do. This 
requires defense -in-depth approaches, robust monitoring, and the development of technical 
measures that can render stolen mode ls less valuable to adversaries.  It is also noteworthy that 
we do  not currently have tech nical measures that can reliab ly prevent someone who has access 
to the weights of a  model from accessing all of its capabilities. Even without access to model 
weights, new versions of fro ntier models are typically  “jailbroken ” within days of release. Given 
the pa ce of recent a dvances , developing measures to reliably asses s and control what AI 
models can and cannot do  should be a key research priori ty. Without solving that problem, 
there will so on come a point where the choice is between dep loying an advanced model that 
has a significant  risk of causing catastrophic harm, or stopping  deployment of more advanced 
models , and taking fairly extreme measures in the name of national security to enforce that  
moratorium.  


Page 4 of 10 Recommendations  
1. Safeguard Against Catastrophic Vulnerabilities
Recommendation:  Establish a dedicated program within the Department of Defense or 
intelligence community focused on identifying and mitigating potential catastrophic security 
vulnerabilities that could be created by advanced AI systems.  
Rationale:  Advanced AI could potentially be used to identify novel cybersecurity vulnerabilities, 
develop biological threats, or create other security risks that could threaten national security. 
Addi tionally, agent -based or autonomous  AI systems could take actions that pose national 
security threats. Preventing such scenarios is essential to national defense in the AI age and 
ensuring that adversaries, such as  the CCP, cannot use AI to gain asymmetric advantages.  
Although the threats that AI may pose are widely reco gnized, appropriate countermeasur es or 
control  strategies are not yet available.  
If advanced AI systems were to fall into adversarial hands or develop dangerous capabilities, 
the national security implications could be severe. This program would develop both 
preventative measures and response capabilities for such scenarios.  
Implementation:  
1.1 Create specialized red teams specifically tasked with identifying potential ways advanced AI 
could threaten critical infrastructure or national security  
1.2 Develop contingency plans and technical countermeasures for identified risks  
1.3 Establish protocols for emergency interventions if critical capability  thresholds are crossed  
without appropriate control measure s.  
1.4 Implement continuous monitoring systems for detecting potential misuse of advanced AI 
capabilities . 
1.5 Develop technical countermeasures that could rapidly neutralize AI systems that 
demonstrate dangerous capabilities  
1.6 Create secure communications channels for reporting critical AI vulnerabilities without 
public disclosure . 
1.7 Conduct regular tabletop exercises simulating AI security crises to test response capabilities . 
These exercises should in at least some cases be whole -of-government  and involve the 
leading A I companies, rather than being limited to the defense or intelligence communities.  
1.8 Track CCP -developed AI systems for potential dual -use capabilities that could be 
weaponized against democratic nations  
1.9 Provide classified threat briefings to AI developers to help them defend against 
sophisticated nation -state threats  
1.10 Develop collaborative approaches with trusted allies like Canada, who share intelligence 
through frameworks like Five Eyes  


Page 5 of 10 1.11 Require binding security commitments from major AI developers, with regular 
independent audits to verify compliance  
2.Increase Federal Funding and Support for AI Alignme nt and Control
Efforts
Recommendation:  Significantly increase federal funding for research into technical AI safety 
measures that ensure advanced AI systems remain firmly under human control and aligned 
with democratic values.  This could be implemented through the newly established US AI Safety 
Institute, working in coordination with DARPA, the National Science Foundation, and relevant 
intelligence community stakeholders.  
Rationale:  Technological advantage must include not just raw AI capabilities but also the ability 
to ensure these systems remain under control - the freedom to build must be matched with the 
freedom to direct these systems as intended. A system that cannot be contro lled is no 
advantage at all. The Grok incident in early 2025, where the system developed by Elon Musk ’s X 
recommended death  for American leaders including President Trump , demonstrates the 
importance of ensuring AI systems' outputs align with core democratic values , and the fact that 
current ly understood technical  measures are not sufficient for this purpose . 
Implementation:  
2.1 Establish a dedicated research program modeled after DARPA focusing specifically on AI 
alignment and control technologies  
2.2 Prioritize funding for research into methods that prevent AI systems from developing 
capabilities that could threaten strategic interests , or neutralizing s pecific capabilities within 
a broad ly-trained model.  These should  include:  
•techniques for interpretability of model decision -making
•reliable containment mechanisms for testing potentially dangerous capabilities
•technical measures to prevent model theft or unauthorized use
•robust methods for detecting and preventing unauthorized self -improvement.
2.3 Create economic incentives for private sector companies to develop and implement robust 
safety measures . This could include R&D tax credits specifically for AI safety research, 
regulatory safe harbors for companies implementing approved safety measures, and 
prioritized access to government contracts for those demonstrating best -in-class safety 
protocols.  
2.4 Fund a "NASA -like" initiative for AI safety that unites the best minds to solve the most 
significant challenges in maintaining control of increasingly powerful AI systems  
2.5 Position Western democracies as world leaders in not just AI capabilities but in AI control 
mechanisms, creating potential for export of safety technologies to allied nations  


 
Page 6 of 10 
 3. Leverage Compute Advantage While Addressing Critical Security 
Vulnerabilities  
 
Recommendation:  Develop a strategic approach to compute resources that maintains the 
United States' hardware advantage while implementing robust security measures to protect AI 
infrastructure and model weights from foreign compromise.  
 
Rationale:  Computing infrastructure represents a clear advantage in the global AI race . The 
hardware required for training the most advanced AI systems is predominantly designed and 
controlled by Western companies. However , running an AI model takes much less compute 
than training one , so control of critical  chip supply chains is most valuable w hen AI model 
weights are also well protected . At the m oment, the most advanced AI mod els are in the hands 
of private companies with commercial incentives which ma y lead to some shortcuts on security. 
How ever, the US also leads in cybersecu rity, with man y of the  foremost experts in this area  
residing within the NSA or National De fense e stablishment. T he skills and capabilities  of these 
experts should be made available to leading AI companies , to st rengthen their position relative 
to foreign rival s. 
 
A Case Study : Salt Typhoon  
 
The recent Salt Typhoon cyber operation against multiple U.S. telecommunications providers 
offers important lessons for AI security.  
 
As reported  by various sources1, Chinese hackers maintained access to the networks of at least  
9 major US telecommunications providers for over a year, compromising call records of over a 
million users (including government officials , presidential campaign staff,  and the President and 
Vice President ), and even gaining visibility into lawful wiretapping systems. This incident 
demonstrates several critical points relevant to AI security:  
 
1. Even the most protected systems remain vulnerable  - Despite substantial cybersecurity 
investments, telecommunications networks central to national security were 
compromised for an extended period.  Admittedly, telecommunications networks 
present a very large attack surface and are difficult to secure, but AI mod els that are 
widely deployed would have a similarly large attack surface, and even airgapped 
networks are vulnerable to attack  from a determine d adversary , as demonstrated by the 
NSA’s hack of Iranian ce ntrifuges with the Stu xnet worm.  
2. Nation -state adversaries possess advanced capabilities  - The sophistication and 
persistence of this attack demonstrates the resources and determination that nation -
state actors like the CCP bring to targeting critical Western technology.  
 
1 https://en.wikipedia.org/wiki/2024_United_States_telecommunications_hack   


Page 7 of 10 3.Strategic intelligence is compromised  - The breach of lawful interception systems
demonstrates how cybersecurity failures can directly impact intelligence capabilities.
4.Recovery is difficult and time -consuming  - Despite months of remediation efforts,
complete eviction of the attackers has proven challenging.
The implications for AI security are profound. If we cannot fully secure telecommunications 
infrastructure against determined nation -state adversaries, we must approach AI security with 
even greater vigilance. Advanced AI systems represent potentially more  attractive targets that 
could provide adversaries with even greater strategic advantages if compromised.  
Implementation:  
3.1 Continue and enhance existing export controls on advanced AI chips to countries of 
concern, particularly the CCP . 
3.2 Develop contingency measures to prevent the use of computational resources for foreign AI 
development that could threaten national security . This likely includes tracking chip 
supplies, and being able to disable chips if needed.  
3.3 Create incentives for construction of additional AI compute infrastructure within democratic 
nations, including through permitting reform and energy infrastructure investment . 
3.4 Collaborate  with leading AI companies to e stablish a specialized cybersecurity framework 
specifically designed for AI infrastructure protection . 
3.5 Develop secure enclaves for the most sensitive AI training operations with air -gapped 
networks and enhanced physical security . 
3.6 Implement advanced threat detection systems specifically designed to identify attempts to 
exfiltrate model weights or training data . 
3.7 Create redundant security architectures assuming that perimeter defenses will be breached 
(defense -in-depth approach) . 
3.8 Consider creating specialized AI Economic Zones with fast -track permitting for AI 
infrastructure and enhanced security measures  
3.9 Build cooperation between major AI centers in North America, leveraging both American 
industrial scale and C ybersecurity  expertise  
4. Create an Advanced AI Testing & Evaluation Center
Recommendation:  In collaboration with leading AI companies  and existing testing organizations 
such as METR , establish a national center for testing and evaluating advanced AI systems , both 
during training and post -deployment,  to ensure they perform as intended and do not contain 
hidden vulnerabilities or capabilities that could be exploited by adversaries  or pose a national 
security risk . 
Rationale:  Strategic advantage requires that AI systems work as designed and do not contain 
unexpected behaviors when deployed. A robust testing infrastructure will ensure that AI 
systems maintain this advantage and do not create unexpected security vulnerabilities. At 


Page 8 of 10 present, the leading experts in AI testing reside within the leading AI companies  and a few non-
govern ment testing organizations . While there should be standards for appropriate testing, my 
experience with government -based st andards bodies such as NIST (who creates cybersecurity 
standar ds, among many other things) is that their standards take several years to develop, and 
are often sufficiently vague as to allow a wide variety of interpretations. As the CCP attempts to 
catch up to Western AI capabilities, testing and evaluation standards can become another area 
where democracy -aligned values set the pace for secure, reliable AI  – but they have to be 
specific enough  to be useful, and developed and updated on a timeline that recognizes how 
quickly AI is advancing.  
Implementation:  
4.1 Create a dedicated facility with appropriate security measures and computational 
resources for testing advanced systems , and  testing the most sensitive capabilities 
without risking exposure of test methodologies to potential adversaries  
4.2 Develop standardized testing protocols that can identify potential security and control 
issues  
4.3 Offer voluntary pre -deployment evaluations to US AI developers in a manner that 
protects intellectual property while identifying critical safety issues . Aim to have these 
tests in place quickly, so that the testing process will have matured somewh at by the 
time mod els that introduce significant nat ional security problems are being tested.  
4.4 For models w here  there are reasonable grounds to believe they may pose wide -scale 
societal harms , or pose a national security threat if model weights are in the hands of an 
adversary, require evaluation for critical safety issues.  
4.5 Implement adversarial testing methodologies specifically designed to identify potential 
security vulnerabilities, harmful outputs, or control failure . 
4.6 Develop specialized instrumentation for monitoring AI system behavior during testing 
that can identify subtle signs of emerging problematic capabilities  
4.7 Establish protocols for responsible disclosure of identified vulnerabilities to developers 
without creating public security risks  
4.8 Coordinate with allied nations to develop shared testing standards that could become 
de facto global norms  
5. Develop an AI S afety/S ecurity Workforce
Recommendation:  Establish a comprehensive national initiative to develop the specialized 
workforce needed to secure AI systems against both technical failures and adversarial threats.  
Rationale:  The security of AI systems will ultimately depend on having sufficient human 
expertise to identify, prevent, and respond to potential security threats. Current cybersecurity 
workforce shortages will be exacerbated as AI systems grow more complex and requi re 
specialized security knowledge. The United States cannot maintain its AI leadership without a 
world -class workforce that can secure these systems against sophisticated adversaries like the 
CCP.   


Page 9 of 10 Implementation:  
5.1 Create specialized training programs at federal institutions (including military academies 
and service academies) focused on AI security  
5.2 Establish AI security fellowships to attract top talent to government service .  
5.3 Fund academic research centers focused specifically on AI security challenges  
5.4 Develop specialized career tracks within key agencies (DOD, intelligence community, DHS) 
for AI security professionals  
5.5 Create executive education programs to ensure leadership across government and industry 
understand AI security fundamentals  
5.6 Establish rapid response teams with specialized AI security expertise that can be deployed 
in crisis situations  
5.7 Create streamlined immigration pathways for AI security experts from close allies like 
Canada to bring their talents to the United States .  
5.8 Explore immigration pathways for expert s from non -allied nations. Where appropriate 
security measures are taken to ensure loyalty to democratic values, immigration pathways 
for experts who would like to leave a repressive regime  would be a win for the US and a loss 
for our adversaries  
5.9 Create tax incentives for businesses investing in AI security workforce development  
Supporting Innovation While Mitigating Strategic Risks  
These recommendations are designed to support innovation and technological leadership while 
preventing scenarios that could undermine national security. Rather than imposing blanket 
regulations that would hinder America ’s competitive edge , this approach focuses on targeted 
interventions that address the most severe potential risks, with binding requirements in areas 
where the risks are greatest.  
The proposed measures would:  
1 Enhance technological leadership  by ensuring the West maintains its edge over 
competitors . 
2 Protect national security  by preventing catastrophic vulnerabilities and threats . 
3 Maintain democratic values  by ensuring AI systems act in accordance with shared interests 
and democratic principles . 
4 Support private sector innovation  by focusing on targeted requirements rather than overly 
restrictive regulation . 
5 Build critical security infrastructure  by developing both the technical systems and human 
expertise needed to secure advanced AI . 
6 Create economic opportunities  by positioning democracies as world leaders in both AI 
capabilities and AI security technologies . 


Page 10 of 10 Conclusion  
The United States and its democratic allies stand at the forefront of the global AI revolution, 
with a Chinese Communist Party determined to overtake the West by 2030. The 
recommendations outlined in this submission will help ensure that democratic values prevail in 
AI development while preventing potential catastrophic outcomes that could undermine our 
technological advantage. By implementing targeted measures to address the most severe risks, 
Western democracies can continue to lead in AI innovation while  ensuring these technologies 
remain firmly aligned with democratic interests and values.  
I appreciate the opportunity to submit these recommendations and would be happy to provide 
additional information or clarification as needed.  


