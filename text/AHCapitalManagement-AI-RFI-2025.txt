Faisal D’Souza, NCO 
Office of Science and Technology Policy 
Executive Office of the President 
2415 Eisenhower Avenue 
Alexandria, VA 22314 
March 14, 2025 
AH Capital Management, LLC’s Response to the Request for Information 
on the Development of an Artificial Intelligence (AI) Action Plan1 
AH Capital Management, LLC (“Andreessen Horowitz” and “a16z”) appreciates the 
opportunity to provide comments in response to the Request for Information on the Development 
of an Artificial Intelligence (AI) Action Plan submitted by the National Science Foundation in 
support of the Networking and Information Technology Research and Development National 
Coordination Office (the “RFI”).2 Andreessen Horowitz was one of the earliest investors in 
artificial intelligence companies and innovations, and today has over $45 billion in committed 
capital.3 We manage pooled vehicles which hold investments in more than 100 AI development 
firms, including as a leading investor in startups and open-source AI developers. As both an 
early investor in AI and one of the largest investment advisors today, a16z is well-positioned to 
understand the potential impact and importance of a National AI Action Plan (the “Plan”) that 
fosters American AI competitiveness, and we welcome the opportunity to contribute to this vital 
discussion. 
3  For more detail on our involvement in AI, please see “AI + a16z” on our firm’s website at https://a16z.com/ai.  2 90 Fed. Reg. 9088 (Feb. 6, 2025). 1 This document is approved for public dissemination. The document contains no business-proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. 
1 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


I.Introduction
Artificial intelligence has the potential to improve our world. Recent AI advancements
will allow AI to produce measurable social and economic benefits for humanity.4 For example, 
AI has the potential to help doctors and scientists create new medicines and treatments to 
improve health outcomes; to improve our transportation infrastructure; to expand our 
communication capabilities; and to change how we work and educate our children. In short, AI 
can improve the human experience.5  
Today, the United States leads the world in AI.6 The foundation of this leadership position 
comes not only from large tech platforms, but also from Little Tech. As we have written, “the 
vanguard of American technology supremacy has always been the startup. From Edison and Ford 
to Hughes and Lockheed to SpaceX and Tesla, the path to greatness starts in a garage.”7 
American startups have always been a principal driver of American competitiveness,8 and they 
already have played an important role in AI: more than 5,000 AI startups have been funded 
between 2013-2023, and Little Tech has the potential to continue serving as a cornerstone of 
8 See, e.g., JF Gauthier & Christopher Haley, Unlocking economic growth: The first global ranking of startup 
policies, World Economic Forum (Feb. 3, 2025) (setting out that US startups account for 14% of GDP, leading G20 
nations), available at 
https://www.weforum.org/stories/2025/02/first-startup-policy-ranking-supports-economic-growth. 7 Marc Andreessen & Ben Horowitz, The Little Tech Agenda, Andreessen Horowitz (Jul. 5, 2024), available at 
https://a16z.com/the-little-tech-agenda. 6 Alexi Mostrous, Joe White & Serena Cesareo, The Global Artificial Intelligence Index 2024, Tortoise Media (Sept. 
19, 2024), available at https://www.tortoisemedia.com/2024/09/18/the-global-artificial-intelligence-index-2024; see 
also Bipartisan House Task Force, Report on Artificial Intelligence at v, 118th Congress (Dec. 2024) (highlighting 
the United States as a global leader in “AI research, the number of AI companies, private sector AI investment, and 
industry adoption of AI” and attributing this leadership to “two of our longstanding strengths: we have cultivated a 
thriving innovation ecosystem and a flexible sectoral regulatory framework”), available at 
https://www.speaker.gov/wp-content/uploads/2024/12/AI-Task-Force-Report-FINAL.pdf.  5 Id. 4 See generally, e.g., Marc Andreessen, Why AI Will Save the World, Andreessen Horowitz (June 6, 2023), available 
at https://a16z.com/ai-will-save-the-world. 
2 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


American AI.9 Little Tech can continue to play an important role in fostering American 
leadership in AI, but only if the regulatory environment does not tilt the playing field in favor of 
large platforms. It therefore is imperative that the National AI Action Plan enable Little Tech to 
compete with larger platforms with more resources and deeper pockets, to ensure that the United 
States continues its leadership in AI.10 
In consideration of the vital role Little Tech plays in the American AI landscape, we 
propose that the National AI Action Plan:  
●Promote American competitiveness in AI, including by establishing the federal
government’s leadership role in regulating the AI model market;
●Adopt a position of regulating harm rather than models; and
●Strengthen American competitiveness by investing in AI infrastructure and talent.
II.The National AI Action Plan should promote American competitiveness in AI,
including by establishing the federal government’s leadership role in regulating the
AI model market.
A.Promote American competitiveness in AI.
In January, President Trump declared in an Executive Order that “[i]t is the policy of the 
United States to sustain and enhance America’s global and AI dominance in order to promote 
human flourishing, economic competitiveness, and national security.”11 This policy position 
should take center stage in each aspect of the National AI Action Plan.   
11 Removing Barriers to American Leadership in Artificial Intelligence, Exec. Order. No. 14179, 90 Fed. Reg. 8741 
(Jan. 23, 2025). 10 See generally Ben Horowitz et al., AI For Startups, Andreessen Horowitz (Nov. 1, 2024) (setting out the 
importance of startups in the AI economy in a joint piece with Microsoft), available at 
https://a16z.com/ai-for-startups. 9 See Marcus Lu, Mapped: The Number of AI Startups By Country, Visual Capitalist (May 6, 2024) (setting out that 
there were 5,509 newly-funded AI startups in the United States from 2013-2023), available at 
https://www.visualcapitalist.com/mapped-the-number-of-ai-startups-by-country. 
3 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


Failing to establish a national AI policy that advances American competitiveness 
ultimately may slow American AI development such that foreign countries—including countries 
of concern—could supplant the United States as the AI gold standard. In early 2025, this 
competitive threat became even more evident, with Chinese startup DeepSeek and Chinese tech 
giant Alibaba releasing AI models with capabilities that rival Silicon Valley giants.12 Chinese 
tech companies have expanded their offices in Silicon Valley, working to hire top US talent,13 
and Chinese companies continue to expand their footprint in chip manufacturing, cloud services, 
computing power, and networking products.14 Quite simply, other nations are catching up, and 
this may have profound implications: will the United States build the leading AI tools of the 
future, or will China?  
B.Emphasize the leadership role of the federal government in regulating the AI
model market while leaving room for states to police conduct within their borders.
14 See Evelyn Cheng, Nvidia Warns of Growing Competition from China’s Huawei, Despite U.S. Sanctions, CNBC 
(Feb. 27, 2025), available at 
https://www.cnbc.com/2025/02/27/nvidia-warns-of-competition-from-china-huawei-despite-us-sanctions.html; see 
also Nvidia Corp., Form 10-K for Fiscal Year Ended January 26, 2025, S.E.C. (2025), available at  
https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/177440d5-3b32-4185-8cc8-95500a9dc783.pdf 
(highlighting Huawei as a top competitor in areas critical to AI infrastructure and solutions). 13 Eleanor Olcott, Chinese Tech Groups Build AI Teams in Silicon Valley, Financial Times (Nov. 18, 2024), available 
at https://www.ft.com/content/da8c29b0-0a90-4d2a-8535-c8459ccc7bb4. 12 See, e.g., Kevin Roose, Why DeepSeek Could Change What Silicon Valley Believes About AI, New York Times 
(Jan. 28, 2025), available at 
https://www.nytimes.com/2025/01/28/technology/china-deepseek-ai-silicon-valley.html; John Liu, Alibaba 
Launches DeepSeek Rival, Sending Stock Surging, CNN (Mar. 6, 2025), available at 
https://www.cnn.com/2025/03/06/tech/china-alibaba-ai-model-deepseek-hnk-intl/index.html; see also Alex Rampell, 
Why DeepSeek Is a Gift to the American People, The Free Press (Jan. 28, 2025) (highlighting the success of 
DeepSeek while reinforcing that the “regulatory regime in the U.S. [], unlike China’s, appreciates 
entrepreneurship”), available at https://www.thefp.com/p/why-deepseek-is-a-gift-to-the-american. 
4 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


AI model development is an issue of national concern that should be regulated on a 
national level.15 It is critical to American national security, geopolitical objectives, and the 
nation’s economic and social welfare.16 Given that the AI model market is national in scope and 
directly implicates interstate commerce, the federal government should take the lead in its 
promotion and regulation to provide uniformity and certainty for US model developers. In the 
last two years, the regulatory landscape for AI developers has shifted away from uniformity and 
toward an increasingly onerous patchwork of state-specific regulations. This patchwork creates 
compliance burdens that hinder advancement in model development.  
Because the AI development market is inherently a national one with potential significant 
impacts in commerce, national security, and foreign relations, the federal government is 
best-positioned to regulate this market. The Administration, therefore, should work with 
Congress to pass legislation that creates a national AI model market and preempts state-specific 
restrictions on model development and legislation that promotes access to AI infrastructure, data, 
and talent.  
Of course, states also have a vital role to play.17 States possess the power to regulate 
against harms committed within their borders and against their citizens, a role they are 
well-suited to play because of their understanding of the needs of the communities they serve.18 
States also traditionally have served as policy laboratories for exploring different approaches to 
regulating conduct within their borders, teeing up different approaches from which other 
lawmakers can draw from. Furthermore, the federal and state governments serve a joint role in 
criminal and civil law enforcement, including consumer protection. 
18 See generally Section III.A, infra. 17 See generally, id. 16 Id. 15 See also Matt Perault, Setting the Agenda for Global AI Leadership: Assessing the Roles of Congress and the 
States, Andreessen Horowitz (Feb. 4, 2025), available at 
https://a16z.com/setting-the-agenda-for-global-ai-leadership-assessing-the-roles-of-congress-and-the-states/ 
(advocating for a national approach to AI policy while leaving room for states to enforce existing laws and serve as 
laboratories of experimentation). 
5 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


III.The National AI Action Plan should adopt a position of regulating harms rather
than models.
Much of the policy conversation around AI regulation, both in the United States and
Europe, has focused on potential harms. But concerns about the harmful misuse of a tool are not 
unique to AI: a hammer may be used to build a house or to hurt someone. When a person uses a 
hammer for harm, they violate the law and are subject to punishment. However, this possibility 
of misuse does not mean that manufacturers are required to conduct detailed impact assessments 
before they make a hammer, or that they are required to replace metal with rubber to ensure that 
their hammers are softer. Such requirements would make the market less competitive and reduce 
the utility of the product. 
A similar approach in AI regulation would have similar consequences. Although certain 
uses of AI may pose a risk of harm to consumers and individuals, such concerns counsel in favor 
of punishing those who cause such harms rather than preemptively burdening developers with 
onerous requirements designed to prevent myriad “what if” scenarios that may never come to 
fruition.  
Restrictions on AI model development make it harder to build AI models, and because 
they typically impose significant compliance burdens that are harder for smaller companies to 
navigate, they make it harder for Little Tech to compete with larger platforms. 
Development-oriented regulation in Europe stands as a cautionary tale, where stringent AI and 
privacy laws have posed challenges for companies developing or deploying AI in Europe.19 
Because of the challenges and burdens associated with regulating model development, 
governments similarly should not require developers to make broad, subjective disclosures. Any 
obligations to disclose information about AI models should be limited. The Supreme Court has 
held that the government may enact disclosure obligations only where they impose a minimal 
19 After DeepSeek, America and the EU Are Getting AI Wrong, The Economist (Feb. 12, 2025), available at 
https://www.economist.com/leaders/2025/02/12/after-deepseek-america-and-the-eu-are-getting-ai-wrong. 
6 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


burden on businesses and require disclosure only of objective, factual information.20 These 
constitutional requirements are important for Little Tech, since smaller companies may struggle 
more than their larger competitors to comply with disclosure requirements and are unlikely to 
have the same resources to litigate these issues than more established companies. 
Furthermore, the Ninth Circuit held in two recent cases that California could not compel 
(a)online providers to prepare reports opining on the risk that children could be harmed by their
use the provider’s services, including the risk that they would come across harmful content on
the site;21 or (b) social media services to prepare content moderation reports defining hate
speech, misinformation, and other categories along with information about how often the service
takes such content down.22 In both cases, the Ninth Circuit reasoned that the compelled
disclosures went beyond purely factual information, were not commercial speech in the sense of
proposing a transaction, and forced regulated parties to speak subjective opinions on highly
contentious issues of public policy.23 Transparency or disclosure obligations, therefore, should
require only factual information about the model and developer such that it provides objective
information to consumers.
The National AI Action Plan should adopt a similar approach regarding AI-created 
harms: do prohibit the harms and punish the bad actors, but do not require developers to jump 
through onerous regulatory hoops based on speculative fear.24 
24 See Matt Perault, Regulate AI Use, Not AI Development, Andreessen Horowitz (Jan. 27, 2025), available at 
https://a16z.com/regulate-ai-use-not-ai-development/ (“Policymakers will be more successful in protecting 
consumers if they follow historic principles of technology regulation. To ensure that the technology can achieve its 
potential and that Little Tech can compete with larger platforms, policy should focus on how AI is used, not how AI 
is built.”). 23 See NetChoice, 113 F.4th at 1115-22; X Corp., 116 F.4th at 898-903. 22 X Corp. v. Bonta, 116 F.4th 888 (9th Cir. 2024). 21 NetChoice v. Bonta, 113 F.4th 1101 (9th Cir. 2024). 20 See Zauderer v. Off. of Disciplinary Counsel, 471 U.S. 626, 651 (1985) (“We recognize that unjustified or unduly 
burdensome disclosure requirements might offend the First Amendment by chilling protected commercial speech.”); 
accord Milavetz v. U.S., 559 U.S. 229, 249-50 (2010) (setting out that companies have a minimal First Amendment 
interest in refusing to provide “required factual information[,]” but “[u]njustified or unduly burdensome disclosure 
requirements offend the First Amendment by chilling protected speech….”). 
7 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


A.Protect individuals by enforcing existing laws and focusing on harms.
Burdening AI development rather than punishing AI misuse not only cripples 
competition, but it also fails to protect people from situations where AI is deployed in a way that 
causes harm. As we recently explained, “Creating complex compliance regimes based on the 
math that an engineer uses to build an AI model will make it harder for Little Tech to build new 
AI models, but will not change whether a criminal is held liable when they use AI to commit 
fraud, to violate a person’s civil rights, or to share intimate imagery without consent.”25 The most 
effective approach to protecting consumers is to focus public policy on protecting consumers 
from AI misuse, rather than on regulating the development of AI models. Focusing on use aligns 
with the historical approach to technology regulation in the United States; “[n]o single law 
regulates how computers are built, for instance, but if a person uses a computer to commit a 
crime, or a company uses a computer to harm a consumer, then the perpetrator is held liable.”26 
Certain harms caused by AI misuse may violate laws and regulations already on the 
books. In such cases, existing enforcement mechanisms can and should be used against those 
who misused AI to break the law. Nothing in existing law prevents this enforcement approach: 
using AI is not a defense. Some states have issued guidance expressly reiterating that if 
something is illegal without the use of AI, it is still illegal when AI is used.27 The federal 
government should take a similar approach, and the Department of Justice should issue guidance 
27 See, e.g., Attorney General Advisory on the Application of the Commonwealth’s Consumer Protection, Civil 
Rights, and Data Privacy Laws to Artificial Intelligence, Mass. Office of the Att’y Gen. (Apr. 16, 2024), available at 
https://www.mass.gov/doc/ago-ai-advisory-41624/download; Guidance from Attorney General Ellen Rosenblum: 
What you should know about how Oregon’s laws may affect your company’s use of Artificial Intelligence, Or. Dep’t. 
of Justice (Dec. 24, 2024), available at 
https://www.doj.state.or.us/wp-content/uploads/2024/12/AI-Guidance-12-24-24.pdf; Guidance on Algorithmic 
Discrimination and the New Jersey Law Against Discrimination, N.J. Office of the Att’y Gen. (Jan. 2025), available 
at https://www.nj.gov/oag/newsreleases25/2025-0108_DCR-Guidance-on-Algorithmic-Discrimination.pdf. Each of 
these highlight the application of existing consumer protection and unfair trade practices, consumer privacy, and/or 
anti-discrimination laws to use of AI systems.  26 Id. 25 Matt Perault, Regulate AI Use, Not AI Development, note 17, supra. 
8 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


 
setting out this key tenet of criminal and civil law enforcement, demonstrating that new, 
AI-specific prohibitions are largely unnecessary. There may be cases, however, in which AI may 
pose incremental risks of harm. In these instances, any new laws and regulations should target 
evidence-based gaps in existing law, continuing to focus on harms rather than setting restrictions 
at the model level.28  
 
B. Clarify the proper relationship between copyright law and model development.  
 
Access to training data is now the most important factor in determining global AI 
leadership. As open-source models proliferate and AI inference is being commoditized, the true 
differentiator between AI developers will be the degree to which they can leverage large volumes 
of data to provide the most accurate and complete model training. But, in the United States, 
legacy media companies, among others, are waging war against using their data for AI training, 
advancing misguided arguments that this infringes their copyrights.29 Andreessen Horowitz 
stands with creators in ensuring their works are protected, but such an aggressive interpretation 
of copyright law places US developers at a significant disadvantage over those from countries 
with different views of IP protections, such as China.30 In addressing the pivotal need for training 
data and to help developers avoid needless legal challenges to necessary model 
training—challenges that would have a disproportionate impact if brought against Little 
Tech—the federal government should take several steps to clarify that existing copyright law 
protects the ability of developers to train models even using copyrighted works.  
 
30 See, e.g., Daniel Tencer, Is DeepSeek Training its AI on Copyrighted Music Without Permission?, Music Business 
Worldwide (Feb. 17, 2025), available at 
https://www.musicbusinessworldwide.com/is-deepseek-training-its-ai-on-copyrighted-music-without-permission. 29 See, e.g., Bobby Allyn, ‘The New York Times’ takes OpenAI to court., NPR (Jan. 14, 2025), available at 
https://www.npr.org/2025/01/14/nx-s1-5258952/new-york-times-openai-microsoft. 28 Rishi Bommasani et al., A Path for Science- and Evidence-based AI Policy (“[W]e firmly believe AI policy should 
be informed by scientific understanding of AI risks and how to successfully mitigate them. [...] Advancing 
significant legislation without clear understanding of risks it intends to address may lead to more negative 
consequences than positive outcomes.”) (open letter), available at https://understanding-ai-safety.org. 
9 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


First, neither the Copyright Office nor any other government agency should release 
guidance related to this issue—or other issues critical to American competitiveness in AI—until 
the conclusion of the National AI Action Plan process.31 Any rulemaking, report, guidance, or 
policy statement that was prepared by prior administration appointees is unlikely to reflect the 
current administration’s policy preferences. The current Administration should take time to study 
these issues while the development of the National AI Action Plan is in process, ensuring that 
ongoing agency activities are not in conflict with the overall goals of promoting AI development. 
And the Department of Justice should consider filing statements of interest in pending AI 
copyright litigation, explaining to the court that model training is fair use because it is 
transformative, uses no more data than necessary to train the models, and poses no risk to the 
market for the original work. These statements should also emphasize that any contrary holding 
would contravene US economic and national security interests.32 
IV.The National AI Action Plan should strengthen American competitiveness by
investing in AI infrastructure and talent.
Promoting American competitiveness will require government investment in
infrastructure and talent. As compared to traditional software, developing AI models is 
exceptionally resource intensive. While the largest technology companies can afford to invest in 
compute power, leverage their other products to collect training data, and attract and retain top 
talent, startups are likely to have fewer resources to devote to model development, and may be at 
a competitive disadvantage as a result.33 To lower these barriers to AI model development, the 
National AI Action Plan should include government investment in reliable, affordable 
infrastructure. Furthermore, the federal government should invest in workforce development 
33 Guido Appenzeller, Matt Bornstein, & Martin Casado, Navigating the High Cost of AI Compute, Andreessen 
Horowitz (Apr. 27, 2023), available at https://a16z.com/navigating-the-high-cost-of-ai-compute/ (highlighting that 
“many companies spend more than 80% of their total capital raised on compute resources” and “access to compute 
resources—at the lowest total cost—has become a determining factor for the success of AI companies”). 32 See Andy Warhol Found. v. Goldsmith, 598 U.S. 508, 527 (2023) (setting out the fair use factors). 31 See U.S. Copyright Office, Artificial Intelligence Study (noting that the final part of the Office’s Report on AI and 
copyright “will address the legal implications of training AI models on copyrighted works, licensing considerations, 
and the allocation of any potential liability”), available at https://www.copyright.gov/policy/artificial-intelligence.  
10 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


initiatives in order to ensure that the best AI talent continues to be trained in the United States 
and work for American companies. 
A.Support and provide direct access to AI infrastructure through a newly-created
National AI Competitiveness Institute.
 To expand access to computing power and make AI markets more competitive, the 
federal government can leverage its own data and infrastructure. In order to administer access to 
this technology and data, the National AI Action Plan should establish a National AI 
Competitiveness Institute (“NAICI”)—housed within the NIST— through which researchers, 
nonprofits, and startups may access infrastructure they need, including compute, data, 
benchmark and evaluation resources. For Little Tech, the NAICI will help to level the playing 
field, making it easier to compete with larger platforms in building and testing AI models. 
Barriers to entry may further be reduced by expanding access to public data for NAICI 
participants. As part of the National AI Action Plan, the government can take steps to develop 
and implement a national “AI-Ready Data Initiative” through which the NAICI could provide its 
participants with access to standardized datasets (based on research data already held by the 
federal government) and purpose-built synthetic datasets. To advance this idea, the government 
may require future grant award recipients to make available through the NAICI data or research 
papers they generated as part of the funded research.  
These resources might not be exclusively cloud-based or headquartered in Washington, 
but could also include regional, on-premise options as well. Regional AI hubs could provide 
startups with access to high-performance computing without requiring massive capital 
investment.34 These facilities can be distributed strategically to support AI development across 
different regions of the country, ensuring innovation is not confined to traditional tech centers. 
34 Kevin Frazier, Your Town Needs AI Experts, Not Just More GPUs, Lawfare (Mar. 4, 2025) (setting out proposals 
for regional AI hubs), available at 
https://www.lawfaremedia.org/article/your-town-needs-ai-experts--not-just-more-gpus. 
11 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


This is analogous to the approach taken in earlier eras of computing, for example, when the 
federal government established a National Center for Supercomputing Applications at University 
of Illinois Urbana-Champaign,35 which resulted in the development of the first web browser.36 
In addition to providing infrastructure directly, the government should work to expand 
access to commercial services through public-private partnerships. Although the marketplace for 
computing power is still in early stages of development,37 the market has an increasing array of 
commercial services that offer cloud computing or other infrastructure access as a way for 
companies to outsource their compute power.38 Access to these commercial services can be 
supported directly, such as through cloud computing vouchers or grants, and by incentivizing 
public-private partnerships, including through preferential procurement terms for cloud providers 
offering startup discounts, tax benefits tied to startup support programs, and making startup 
access a condition for participation in major government AI initiatives. 
Finally, Little Tech will require access to affordable energy to maintain its ability to 
compete in the AI-driven economy. By 2028, up to 12% of US electricity will be consumed by 
the AI industry.39 To ensure that America’s energy infrastructure can provide startups with the 
energy they need to be competitive with larger developers in the United States and with 
developers in China, the Council on Environmental Quality should issue regulations that allow 
for a substantial buildout of the US power grid. With countries like China, Japan, and Saudi 
39 Dep’t of Energy, DOE Releases New Report Evaluating Increase in Electricity Demand from Data Centers, Press 
Release (Dec. 20, 2024), available at 
https://www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand-data-centers#:~:text
=The%20report%20finds%20that%20data,total%20U.S.%20electricity%20by%202028. 38 Juan Pablo Perex, The AI Boom Is Giving Rise to “GPU-as-a-Service”: The Industry Harvests Idle Compute for 
AI Startups That Need It, IEEE Spectrum (Jan. 20, 2025), available at https://spectrum.ieee.org/gpu-as-a-service.  37 Alexander Osipovich, AI Needs a Lot of Computing Power. Is a Market for ‘Compute’ the Next Big Thing? Wall 
St. J. (Jan. 29, 2025), available at 
https://www.wsj.com/tech/ai/ai-needs-a-lot-of-computing-power-is-a-market-for-compute-the-next-big-thing-23021
33c.  36 See NCSA, NCSA Mosaic, Univ. of Ill. Urbana-Champaign, available at 
https://www.ncsa.illinois.edu/research/project-highlights/ncsa-mosaic. 35 For more information on the NCSA, please see its homepage at https://www.ncsa.illinois.edu. 
12 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


Arabia racing to build out their own AI infrastructure, it is important that America’s energy 
investment—and public policy enabling that investment—keeps pace.  
B.Help to establish robust talent pipelines, including by strengthening education and
by ensuring access to top talent from around the world.
The National AI Action Plan should set policies to help ensure that US AI companies of 
all sizes can continue to be able to attract and leverage the best talent. To do so, the government 
should support workforce development initiatives that align education and training with industry 
needs. In particular, federal support should focus on improving foundational STEM education as 
well as expanding opportunities for education in advanced AI specializations and graduate 
research programs. The United States has been a leader in providing world-class education and 
post-graduate opportunities in technology—including through research fellowships, residency 
programs, and government research positions. Expanding and supporting these programs, while 
also ensuring these researchers have access to AI infrastructure and data to support their work, 
will help efforts to ensure a robust pipeline of talent to support this specialization.  
In addition to improving education and related research opportunities, it is important that 
the government work to create structured pathways into AI careers, whether by modernizing 
existing frameworks or adopting newer ones purpose built to enable AI workforce development. 
For example, Administration should support efforts to modernize the National Apprenticeship 
Act,40 which established an apprenticeship system under which 94% of participants find 
post-completion employment,41 but wasn’t designed for emerging fields like AI and computing. 
Additionally, the government should establish a public-private partnership through which 
Americans are trained in AI labeling—an essential task in model training—and partnering 
companies commit to hiring labelers who demonstrate proficiency throughout the program. 
China has invested in AI labelers, and it has provided Chinese AI companies a competitive 
41 ApprenticeshipUSA, Explore Registered Apprenticeship, U.S. Dep’t of Labor (updated April, 2024), available at 
https://www.apprenticeship.gov/sites/default/files/DOLIndFSApprent101-043024-508.pdf. 40 Act of Aug. 16, 1937, ch. 663, 50 Stat. 664 (codified as amended at 29 U.S.C. § 50). 
13 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


advantage.42 Longer term, basic AI literacy should become part of public education and extend to 
adult learners and working professionals, increasing overall AI awareness and creating a baseline 
of knowledge that may be supplemented with more specialized training.  
C.Continue support for open-source models.
One of the ways the federal government can promote model development is to signal 
their continued support for open-source models. Open-source models provide important benefits, 
including (a) reducing barriers to entry and promoting innovation; (b) increasing competition; 
and (c) providing transparency into how models are developed. Open-source models increase the 
opportunities for startups to compete. In its Report on Dual-Use Foundation Models with Widely 
Available Model Weights, the NTIA highlighted the benefits of open-source foundation models, 
including that they “diversify and expand the array of actors, including less resourced actors, that 
participate in AI research and development. They decentralize AI market control from a few 
large AI developers. And they enable users to leverage models without sharing data with third 
parties, increasing confidentiality and data protection.”43 
V.Conclusion.
American technology innovation and leadership has long been led from the bottom up,
with startups and entrepreneurs blazing the technological trail for the world to follow, and 
advancements in AI are no different. By adopting a policy agenda that promotes American 
43 Nat’l Telecomms. and Info. Admin., Dual-Use Foundation Models with Widely Available Model Weights Report 
(Jul. 30, 2024), available at 
https://www.ntia.gov/programs-and-initiatives/artificial-intelligence/open-model-weights-report; see also Bipartisan 
House Task Force, Report on Artificial Intelligence, p. 160 (concluding that concluded that open-source AI models 
“encourage innovation and competition” and highlighting that “[m]any of the most important discoveries in AI were 
made possible by open-source and open science.”). 42 See, e.g., Jeanna Whalen, Hottest job in China’s hinterlands: Teaching AI to tell a truck from a turtle, Washington 
Post (Sept. 26, 2019), available at 
https://www.washingtonpost.com/business/2019/09/26/hottest-job-chinas-hinterlands-teaching-ai-tell-truck-turtle. 
14 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


innovation and competitiveness, the federal government can help ensure that the United States 
retains its place as the global AI leader and that Little Tech continues to have a seat at the table: 
“The future isn’t just about algorithms—it’s about the policies and culture that enable them to 
thrive.”44 
We urge the Office of Science and Technology Policy to set out a National AI Action 
Plan that enables Little Tech to thrive by promoting competitiveness, regulating harms rather 
than models, and investing in AI infrastructure and talent. 
Respectfully Submitted, 
AH Capital Management, LLC 
By: 
________________ 
Jai Ramaswamy 
Chief Legal Officer 
________________ 
Collin McCune 
Head of Government Affairs 
________________ 
Matt Perault 
Head of AI Policy 
44 Rampell, Why DeepSeek Is a Gift to the American People, note 12, supra. 
15 
Docusign Envelope ID: 1B4283BA-4F53-4DA5-92C9-DA66A38DD229


