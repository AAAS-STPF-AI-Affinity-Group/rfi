 
   3/11/2025 via FDMS  
Chuck Slavin  
Public Comment on Protecting Actors' and Broadcasters' Image, Likeness, and Biometric Data 
Usage in the Development of the AI Action Plan Esteemed National Science Foundation, I am 
submitting this comment in response to the Request for Information (RFI) on  the development of 
the Artificial Intelligence (AI) Action Plan, with a specific focus on the use, storage, and 
replication of actors’ and broadcasters’ images, likenesses, and biometric data. As AI 
technologies advance, it is imperative that the AI Actio n Plan incorporates robust protections for 
these individuals, drawing on existing legislative efforts to address the intersection of artificial 
intelligence, data privacy, and intellectual property rights. Actors' and Broadcasters' Image and 
Likeness Prote ction The rapid evolution of AI has made it increasingly feasible to replicate and 
manipulate the images, voices, and likenesses of actors, broadcasters, and other public figures, 
often without their consent. These attributes are not only integral to their  professional identities 
but also critical to their livelihoods. Existing legislative efforts, such as California’s AB 2602 
(signed into law on September 17, 2024), provide a strong foundation by requiring explicit 
consent and detailed contractual specific ations for the use of AI -generated digital replicas of a 
performer’s voice or likeness. Similarly, the federal “Nurture Originals, Foster Art, and Keep 
Entertainment Safe Act” (NO FAKES Act), introduced in the U.S. Senate in July 2024 and the 
House in Sept ember 2024, aims to establish a property right over digital replicas, holding 
individuals and platforms liable for unauthorized use. I urge the AI Action Plan to build on these 
measures by mandating consent for any AI -generated use of likenesses —whether in  
entertainment, advertising, or beyond —and by implementing safeguards to prevent misuse, 
ensuring individuals retain autonomy over their image, voice, and persona. Biometric Data 
Usage and Privacy The proliferation of AI -driven technologies, such as facial  recognition and 
voice synthesis, has heightened the risks associated with biometric data collection, storage, and 
replication. This highly sensitive data can be exploited, threatening individuals’ privacy, safety, 
and dignity. Tennessee’s Ensuring Likenes s Voice and Image Security (ELVIS) Act, effective 
July 1, 2024, explicitly protects an individual’s voice as a property right, offering a model for 
addressing biometric data in AI contexts. Additionally, California’s AB 1836 (signed into law on 
September 1 7, 2024) extends posthumous protections by prohibiting unauthorized commercial 
use of deceased performers’ digital replicas without estate consent. The AI Action Plan should 
adopt and expand upon these precedents by establishing stringent regulations for b iometric data, 
including robust security measures to prevent unauthorized access, clear rights for individuals to 
access and revoke consent for its use, and mandates for data deletion when no longer needed. 
Transparency and Accountability: Transparency is a cornerstone of ethical AI deployment. 
Actors and broadcasters must be informed about how Actor's and Broadcaster's biometric data, 
images, and likenesses are utilized in AI systems. The federal “Content Origin Protection and 
Integrity from Edited and Dee p faked Media Act” (COPIED Act), introduced in July 2024, 
exemplifies this principle by requiring provenance data to identify AI -generated content, 
empowering creators to track and control its use. Organizations leveraging such data should be 
held accounta ble through clear guidelines on AI model training and data sourcing, as well as 
regular audits to ensure compliance with privacy laws and ethical standards. The AI Action Plan 
should integrate these accountability mechanisms to foster trust and responsibil ity in AI 
development. Conclusion The AI Action Plan must prioritize comprehensive protections for 


actors, broadcasters, and others whose images and biometric data are implicated in AI 
technologies. By drawing on existing bills —such as California’s AB 2602 and AB 1836, 
Tennessee’s ELVIS Act, and federal proposals like the NO FAKES Act and COPIED Act —
policymakers can craft a framework that safeguards individual rights, ensures privacy, and 
promotes ethical AI innovation. I appreciate the opportunity to contribute to this vital discussion 
and strongly encourage the inclusion of these measures in the AI Act ion Plan to address the 
challenges posed by AI in a rapidly changing digital landscape. In Unity, Chuck Slavin  


