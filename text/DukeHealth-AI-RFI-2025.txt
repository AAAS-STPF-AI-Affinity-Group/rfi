Page 1 of 3 
 NOTE: This document is approved for public dissemination. The document contains no business -
proprietary or confidential information. Document contents may be reused by the government in 
developing the AI Action Plan and associated documents without attribution . 
 
March 1 4, 2025  
 
Faisal D'Souza  
NCO /NITRD  
2415 Eisenhower Avenue  
Alexandria, VA 22314  
 
Dear Mr. D’Souza , 
 
Thank you for the opportunity to provide comments on the development of a national Artificial 
Intelligence (AI) Action Plan. As one of the leading healthcare  organizations in the world , we 
appreciate the opportunity to respond to this RFI.  
 
Duke Health integrates the Duke University Health System (all of our  hospitals , clinics , and the 
Duke Health Integrated Practice ), Duke University School of Medicine, Duke -NUS Medical 
School, Duke University School of Nursing, and incorporates the health and health research 
programs within the Duke Global Health Institute as well as those in schools and centers across 
Duke University, including the Duke Robert J. Margolis Center for Health Policy.   
 
Our organization is committed to excellence through the adoption of AI innovations to improve 
patient outcomes, reduce adminis trative burden, and streamline care delivery. To achieve this, 
we established the Algorithm -Based Clinical Decision Support (ABCDS ) Oversight Committee 
in 2020. This committee governs and reviews AI solutions for patient care. At that time, AI 
quality and ethical considerations were not widely understood or adopted by stakeholders, and 
FDA guidance was still under development. Over the past four years, we have worked to balance 
innovation with high -quality, ethical care, ensuring responsible deployment of A I solutions.  
 
Based on our experience over the past four years, Duke Health offers the following 
considerations for the AI Action Plan directed by the Presidential Executive Order of January 23, 
2025:  
 
Risk -Based Approach to AI Assurance and Review  
Duke Health employs a risk -based approach to evaluate AI tools, tailoring the required evidence 
to the potential benefits and risks  within the context of use . High -risk AI solutions, such as those 
posing critical safety risks (e.g., death), require extensi ve evidence demonstrating adherence to 
ethical and quality principles, along with detailed monitoring plans. Conversely, low -risk 
solutions, like those reducing administrative burden (e.g. back office functions) with de-minimis 
safety implications, require  less rigorous evidence. Core quality and ethical principles must be 
met for all AI tools , but a risk -based evaluation p ermits  streamlined testing (local validation) 
with documented methods, results, and conclusions often leading to an expedite d deployment , 
provided there's ongoing safety surveillance. This approach  also ensures appropriate and efficient 

Page 2 of 3 
 allocation of resources  throughout the evaluation process  and the ongoing quality assurance 
efforts.  
 
Transparency  
AI solution s should be transparent. Deve lopers should utilize methods like nutrition labels, 
model cards, and comprehensive documentation  to ensure  basic  transparency  about the solution 
itself, but also maintain intellectual property (IP)  protections . This  transparency  includes 
detailing intende d use, patient populations used for testing and training, model performance and 
outcomes, safety events, and other relevant issues, with contextual information about testing in 
specific settings  and routine updates when changes occur . This transparency bui lds consumer 
confidence, and facilitates  faster testing and adoption.  
 
A contractual framework  can streamline procurement and enhance  accountability  across all 
parties involved in the AI development and deployment process . Within the terms of the 
contracts, vendors should  inform institutional customers if AI is being added or modified, and to 
share with customers how the new/modified AI has been teste d and/or validated.  Clear definition 
of roles and responsibilities in change management plans between developers and implementers, 
coupled with open communication about safety risks, performance,  data use,  and outcomes 
between implementers and developers, fosters continuous improvement and maximizes the 
potential of AI innovations.  
 
Post-market surveillance and health AI outcomes registries  
National health AI registries can empower AI solution developers to showcase the impact of 
their products on improving  health outcomes. These registries would provide consumers and 
implementers with quick and easy access to information on tested and utilized AI solutions, 
including their benefits. This transparency fosters a competitive market focused on developing 
benefi cial AI solutions. Furthermore, national registries can be seamlessly integrated with 
individual organizations' registries for efficient AI solution inventory management.  
 
Voluntary use -case/tool registries can also  provide a pathway to achieve local (user) 
accountability for AI safety and efficacy . We envision the development of public -private 
partnerships to share testing , implementation , evaluation best practices , impact/ROI results, and 
adverse events  to further inform future development efforts .   
 
Below are some editorials and articles that experts at Duke Health amongst others have 
published related to these topics:  
 
• National  registries: https://pubmed.ncbi.nlm.nih.gov/39133500/  
• Registration information: https://academic.oup.com/jamia/article -
abstract/31/ 3/705/7455696   
• Model cards:  https://chai.org/draft -chai-applied -model -card/  and 
https://www.nature.com/articles/s41746 -020-0253-3 
• The Regulation of Uncertainty: https://paragoninstitute.org/private -health/the -regulation -
of-uncertainty/   
 
 

Page 3 of 3 
 Closing  
Our phenomenal faculty, researchers, and physician scientists are some of the best in the world, 
and have served  the Executive Branch  and Congress as experts on a wide -range of topics. We 
hope you will utilize Duke Health as you think about the future of AI in healthcare .  
 
Sincerely . 
 
 
 Jeffrey Ferranti, MD, MS  
Senior Vice President and Chief Digital Officer  
Duke Health  Michael J. Pencina, PhD  
Chief Data Scientist  
Duke Health  

