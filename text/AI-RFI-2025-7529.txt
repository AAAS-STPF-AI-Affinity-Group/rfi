PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-1jsf-lqlr
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7529
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Andre Stillo
Address:
General Comment
Let m e m ake it abundantly clear at the beginning of this com m ent: I am  a form er com puter science student currently considering attending
a graduate program  for m achine learning. I am  well aware of the power AI holds. However, I think we, as a society, are: 
1. Allowing advancem ents in a previously stagnant field to lead us to believe the technology is m ore advanced than it is.
2. Threatening the livelihood of m any people in the way we use AI.
In regards to the first point, it is worth noting that the field of AI rem ained m ostly stagnant for years, and up until the introduction of the
GPT type of LLM in 2018 it rem ained that way. This advancem ent has led a lot of people and com panies into believing that AI has
reached AGI (artificial general intelligence, the theoretical point where an AI reaches hum an levels of intelligence). However, m ost of the
people spouting this are com pany heads and investors, rather than engineers of AI itself. The people actually reasearching into AI m ostly
will say AGI is still years, if not decades away. However the rhetoric that it has been reached is still present, which leads com panies and
investors to over-invest into AI. 
I firm ly believe that this over-estim ation is leading to an AI bubble, that is waiting to pop. The GPT m odel, whike powerful, is still lim ited,
and will actively m ake m istakes due to com puters, by design, doing exactly what they are told. 
Regarding the second point: there are m any fields that would directly be affected by reliance on AI being norm alized. Art, m usic, writing,
film , sciences in regards to calculations, software developm ent...the list can go on. This leads m e to m y second point: in order for the
security of m ultiple industries in Am erica to exist, there needs to be a way to not allow AI to train on copyrighted data, or data that a
person otherwise does not want to subm it to train.
The solution to this is very sim ple, and is that copyrighted m aterials need a lisence to be used for training, and publicly posted m aterials
can be opted in or out on a platform  by platform  basis (i.e. hypothetically X m ight allow AI to train on publicly posted m aterial, but
bluesky m ight not. These exam ples were chosen off the very reason for a m ass exodus from  X back in novem ber of 2024).
Both of these points lead m e to a very sim ple conclusion: AI is a very powerful tool, m eant to m ake lives easier. However, if we were to
fully rem ove the guardrails, we are banking on a volatile, subject to change technology, that realistically m ay destroy m ultiple job
industries. In the best interest of Am erica, while AI is worth studying m ore, it is not worth rem oving guardrails and allowing AI to train off
all data unrestricted.


