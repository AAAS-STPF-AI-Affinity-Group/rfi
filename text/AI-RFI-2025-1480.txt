PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-am 1w-g8js
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1480
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Am erican College of Em ergency Physicians
General Comment
On behalf of our nearly 40,000 m em bers, the Am erican College of Em ergency Physicians (ACEP) appreciates the opportunity to provide
input on the request for inform ation on the developm ent of an artificial intelligence (AI) action plan. Please see the attached docum ent for
our full com m ents.
Attachments
ACEP AI Action Plan RFI Response_


March 14 , 2025  
Kirk Dohne 
Actin g Director  
Networking and Information Technology Research and Development (NITRD)  
National Coordination Office (NCO) 
490 L’Enfant Plaza SW, Suite 8001  
Washington, DC 20024, USA  
Michael Krat sios 
Acting Director  
White House Office of Science and Technology Policy 
1600 Pennsylvania Ave  
Washington, DC 20500  
RE: Request for Infor mation: Development of an Artificial Intelligence Action 
Plan 
Dear Acting Di rectors Dohne and Kratsios: 
On behalf o f our nearly 40,000 members, the American College of Emergency 
Physicians (ACEP) appreciates the opportunity to provide input on the request for 
information on the development of an artificial intelligence (AI) action plan. AI has the 
opportunit y to revolutionize the practice of emergency medicine with the potential to 
provide highly personalized care, while reducing physician burdens and improving the physician -patient relationship.  
As a leader  in advancing the responsible use of AI in emergency medicine,  ACEP is 
engaged in policy development work on AI through our AI Task Force, Health Innovation Technology Committee, and Disaster Medicine Committee.  We are 
committed to i dentif ying and exploring opportunities and threats posed  by new  
developments in artificial intelligence to the emergency medicine workforce  as well as 
how new technologies such as machine learning and AI can be leveraged to innovate  
approaches to quality and safety work.  As th is work get s further underway, we welcome 
an opportunity to participate in a more nuanced development of guidelines. 
ACEP believ es that h ealth care AI must be designed, developed, and deployed in a 
manner which is ethical, responsible, accurate, transparent, and evidence -based . The u se 
of AI in health care delivery requires clear national governance policies to regulate and 
continuously update its adoption and utilization. To that end, ACEP recommends three 
major policy priorities to ensure that the U.S. remains the global leader in AI -driven 
health  care innovation while enhancing emergency patient care and physician effi ciency . 
Ensuring Clin ician Oversight in AI Integration  
While ACEP  believes that AI t ools can be helpful in enhancing patient care, use of AI


in health care delivery requires clear , transparent, and specific  national governance policies to regulate its adoption 
and utilization, with strict compliance standards. AI should support, not replace, clinical judgment, with emergency 
physicians maintaining  ultimate oversight to ensure safe and effective patient care.  AI-driven clinical decision support 
tools must be designed with built -in safeguards that allow emergency physicians to verify recommendations and 
intervene when necessary.   
Emergency p hysicians are best equipped to  identify the most appropriate uses of AI -enabled technologies in 
emergency medicine practice, and they should be the ultimate drivers of setting the standard of appropriate AI use in 
delivery of emergency care. To that end, emergency physicians,  clinical experts, and informaticists  should be the 
leading voice in developing best practices for AI integration in emergency medicine, including, but not limited to automated signal processing, speech recognition, AI scribe s, and predictive analytics . Any clinician using AI support 
tools should use their clinical expertise to oversee and validate AI-assisted diagnose s, treatment recommendations, 
and produced notes. 
Developing Bes t Practices and Risk Mitigation Strategies  
As stated ab ove, e mergency physicians should be the ultimate drivers of setting the standard of appropriate AI use in 
delivery of emergency care.  In addition to describing best practices, emergency physicians should establish guidelines 
for AI-driven documentation, including large language model ( LLM)- based patient discharge summaries, autonomous 
coding, and against medical advice ( AMA ) risk documentation, ensuring emergency physician review before 
finalization. AI risk management should minimize potential negative impacts of health care AI systems while 
providing opportunities to maximize positive impacts, such as reducing administrative burden and time away from patient care. Whilst AI tools can be helpful in minimizing burnout, health care practices and institutions should not 
utilize AI systems or technologies that introduce overall or disparate risk that is beyond their capabilities to mitigate. 
Implementation and utilization of AI should avoid exacerbating clinician burden and should be designed and deployed 
in harmony with the clinical workflow. 
Further, a s implementation of AI -enabled tools and systems increases, it is essential that use of AI in health care be 
transparent to both patients and physicians. Transparency is one of the most critical elements to build trust in new AI-enabled technologies and serves to help both physicians and patients understand when and what they are engaging 
with when AI is involved in the care experience.  We recommend requiring transparency for AI -enabled technologies 
with clinical applications that contribute to medical decision making  and suggest that the Administration develop 
transparency frameworks for other uses of AI, such as AI with administrative applications, with careful consideration of liability concerns and data privacy protections. 
Advancing Data S tandardization and Interoperability  
A longstanding priority of the Department of Health and Human Services (HHS), establishing a foundation of 
standards to build interoperable health information technology (HIT) across health systems  allows delivery of the 
highest quality of patient care to remain our focus by increasing ease of communication through data standardization. 
This concept should extend to the development and integration of AI tools in health care delivery. Standards and 
benchmarks around AI development should be established and evaluated for continuous improvement to ensure 
reliability, interoperability, and ease of use. D ata integrity, patient privacy, and production of clear, interpretable AI 
outputs that physicians can trust must be incorporated and given utmost consideration when interoperability 
standards are created and assessed.  
Conclusion and Fur ther Considerations  
AI holds trem endous potential to transform emergency medicine, with a significant opportunity t o enhance patient 
care, improv e operational efficiency,  and strengthen  the physician- patient relationship. However, rigorous standards 
for responsible AI implementation, compliance, and risk mitigation, with emergency physicians leading the 
development of best practices and ensuring physician oversight, should be of the utmost priority to ensure patient safety, quality of care, and ethical responsibility.   


We apprec iate the Administration’s request for information on the development of an AI action plan, and we l ook 
forward to working with you to prioritize focus on health care AI and to promote policies that ensure the safety and 
wellbeing of our patients. Should you have any questions or wish to discuss further, please contact Erin Grossman n, 
ACEP’s Regulatory and External Affairs Manager, at 
Sincerely , 
Alison Haddock , MD, FACEP 
ACEP President  


