PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-uej5-ncjf
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-3440
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Mark McDonald  
General Comment
See attached file(s)
Attachments
Com m ent on governm ent AI action plan


Targeted Safeguards to Strengthen National Security and Economic Competitiveness 
Dear OSTP, 
As a chemical engineer specializing in optimization techniques, I recognize both the 
transformative potential and the existential risks of artificial intelligence. I urge the Administration 
to prioritize AI safety regulations to protect American national security and critical infrastructure 
from chemical, nuclear, cyber, and biological threats that could arise from the unchecked 
development and deployment of advanced AI systems. 
The United States must lead in AI innovation while ensuring that bad actors, including both 
foreign adversaries and domestic threats, do not exploit AI to undermine national security. 
AI-driven cyberattacks, AI-assisted synthesis of chemical weapons, and AI-enhanced biological 
threats pose unique risks that demand proactive, strategic intervention. The private sector must 
remain unburdened by unnecessary restrictions, but targeted, intelligent safeguards will 
enhance America's AI dominance by preventing catastrophic failures. 
To protect America’s interests and promote economic competitiveness, I recommend: 1.AI-Enabled National Security Monitoring  (fighting AI with AI). AI should be leveraged
to identify and neutralize threats in cybersecurity, nuclear safety, and biosecurity before
they manifest. Investing in AI-driven threat detection will bolster both national defense
and private-sector resilience. For example, AI-driven monitoring of wastewater could be
used to check for viral DNA suggestive of a biological weapon.2.Public-Private Sector Collaboration  on AI Safety Standards. The Administration
should foster partnerships with industry leaders and with nonprofit institutes to establish
robust AI safety protocols that align with economic and security priorities. Specific
institutes that have already dedicated significant resources to this task include the
Center for AI Safety (CAIS), the Alignment Research Center (ARC), the Machine
Intelligence Research Institute (MIRI), and the Center for Security and Emerging
Technology (CSET). Their existing expertise should be leveraged as much as possible to
avoid inefficiently duplicating work.3.Export Controls on High-Risk AI Applications. Given the risk of AI-assisted
development of chemical and biological weapons, export controls should ensure that
U.S.-developed AI models do not fall into the hands of adversaries who seek to exploit
them.4.Preventing AI-Enabled Biological Threats. Advanced AI models could dramatically
accelerate biological research, including the design of synthetic pathogens. Past
incidents, such as journalists acquiring a modified smallpox genome without scrutiny [1],
illustrate the underappreciated risks of synthetic pathogen development. With AI
advancements, such risks could be magnified. The U.S. should establish targeted
oversight mechanisms to prevent the misuse of AI in bioengineering, ensuring that
AI-driven research in virology and synthetic biology prioritizes safety and does not
facilitate the creation of engineered pandemics.


a.Of specific worry are “wildfire pandemics,” or pathogens engineered using AI
technology to have the transmissibility of measles and the deadliness of ebola,
which could be used by an adversary to decimate the US population before the
medical establishment can mount a response, and “sleeper pandemics,” which
have a long enough incubation period that they will spread across the population
before we realize they are there.5.Research and Governance for Advanced Autonomous AI Alignment. The
development of highly advanced AI systems, potentially surpassing human intelligence,
poses long-term existential risks. The Administration should invest in research on AI
alignment and control mechanisms to ensure that AI remains aligned with human values
and national interests, preventing scenarios where AI systems act counter to U.S.
security and economic priorities.a.For example, an advanced AI that is given the goal of optimizing financial gains
on the stock market might purposely engineer a catastrophic event so that it can
short the stock market during the resulting downturn. Or, an advanced AI tasked
with optimizing military logistics might develop unpredictable escalation
strategies. Mandatory safety testing on advanced AI systems, and other
guardrails to prevent this misalignment with national interests, are vital to the
future success of the country. By taking a leadership role in AI safety, the U.S. will not only safeguard its people but also 
strengthen its global standing as the premier hub for AI innovation. A failure to act risks enabling 
adversaries and criminals to leverage AI against American interests. Smart regulation focused 
on national security and economic competitiveness is the key to unlocking AI’s full potential 
while mitigating its most pressing dangers. 
Sincerely,  
Mark N. McDonald, Ph.D. 
1.Journalists order smallpox genome from synthetic DNA labs:
https://www.theguardian.com/science/2006/jun/23/weaponstechnology.guardianweekly


