Comment in Response to the Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan 
To: 
Agency: NITRD NCO , National Science Foundation 
Document Citation: 90 FR 9088 
Document Number: 2025-02305 
Publication Date: February 6, 2025 
Filing Date: March 15, 2025 
Name: Michael Huang 
Statement: This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without attribution. THE TRUMP DOCTRINE 
“There are alway s [AI] risks, and it’s the first question I ask: how do you absolve yourself 
from mistake, etc., because it could be the rabbit that gets away. We’re not going to let 
that happen.” 
-President Donald Trump1
“I think the danger of AI is  much gr eater than the danger of nuclear warheads by a lot 
and nobody would suggest that we allow anyone to build nuclear warheads if they want. 
That would be insane. And mark my words, AI is far more dangerous than nukes. Far. So 
why do we have no regulatory oversight? This is insane.” -Elon Musk2
“Artificial intellig ence  is the future, not only for Russia, but for all humankind. It comes 
with colossal opportunities, but also threats that are difficult to predict. Whoever 
becomes the leader in this sphere will become the ruler of the world.” 
-Russian President Vladimir Putin3
3 RT, “'Whoever Leads in AI Will Rule the World’: Putin to Russian Children on Knowledge Day,” September 1, 2017, 
https://www.rt.com/news/401731-ai-rule-world-putin/. 2 Catherine Clifford, “Elon Musk: ‘Mark My Words — A.I. Is Far More Dangerous than Nukes,’” CNBC, March 13, 
2018, https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html. 1 Stephanie Lai, “For AI Watchers, Asked If He Had Any Concerns about Artificial Super Intelligence, Trump Said: 
‘There Are Always Risks. And It’s the First Question I Ask, How Do You Absolve Yourself from Mistake, Because It 
Could Be the Rabbit That Gets Away, We’re Not Going to Let That Happen.’ Https://T.Co/2bW1gsKMQI,” Tweet, 
Twitter, January 26, 2025, https://x.com/stephaniealai/status/1883336725700948036. 
1 of 6 


Given the following assumptions: 
●That the country that leads in AI will likely rule the world
●That America should continue to be the world’s AI leader and leading superpower
●That foreign nations seek to overtake America’s lead
●That AI will present both extreme opportunities and extreme risks
One can conclude: 
●That limiting and containing AI development in foreign nations is as important to
maintaining America’s AI leadership as domestic AI development
There is a tradition in American foreign policy to describe a key goal or position as a presidential 
doctrine. The Trump administration should consider formally proclaiming a Trump Doctrine: 
It is the policy of the United States of America to use every means at its disposal to 
achieve and maintain a monopoly in frontier artificial intelligence. 
It would not only be an America First policy but an America Only policy. America was arguably at 
the peak of its power when it held a nuclear monopoly after World War II, from August of 1945 
to August of 1949.4 America could experience the same dominance again with an AI monopoly. 
The potential for peace and prosperity in a new Pax Americana would be a lasting legacy of the 
Trump administration, a fulfilment of its Make America Great Again promise. 
Enforcement of the Trump Doctrine 
The American government currently has in place export controls on chips that are essential for 
AI development. However, widespread chip smuggling is undermining these export controls. 
One of the first tasks of enforcing the Trump Doctrine is to crack down on this illegal trade that 
undermines national security.5 
The recent paper “Superintelligence Strategy” by Hendrycks, Schmidt and Wang6 introduced the 
concept of Mutual Assured AI Malfunction (MAIM), where preventative sabotage prevents rival 
6 Dan Hendrycks, Eric Schmidt, and Alexandr Wang, “Superintelligence Strategy,” 2025, 
https://www.nationalsecurity.ai/. 5 Tim Fist and Erich Grunewald, “Preventing AI Chip Smuggling to China,” Center for a New American Security, 
October 24, 2023, https://www.cnas.org/publications/reports/preventing-ai-chip-smuggling-to-china. 4 George H. Quester, Nuclear Monopoly (New Brunswick: Transaction Publishers, 2000). 
2 of 6 


AI projects from taking off. The Trump administration should use elements from this strategy to 
enforce the Trump Doctrine: 
●Espionage
●Covert or overt sabotage
●Covert or overt cyberattacks
●Kinetic strikes on datacenters
Diplomacy and the Trump Doctrine 
“The leadership demonstrated by the United States over these decades in avoiding 
nuclear war, slowing nuclear proliferation, and shaping an international order that 
provided decades of great-power peace will go down in history as one of America’s most 
significant achievements. 
Today, as the world confronts the unique challenges posed by another unprecedented 
and in some ways even more terrifying technology—artificial intelligence—it is not 
surprising that many have been looking to history for instruction.” -Henry Kissinger and Graham Allison7
Diplomacy is another method of achieving the Trump Doctrine. As much as the Cold War was 
shaped by nuclear weapons and nuclear non-proliferation, the era of AI will be shaped by AI 
non-proliferation. 
The Treaty on the Non-Proliferation of Nuclear Weapons slowed down the spread of nuclear 
weapons. America’s promise to be a nuclear umbrella, to shield non-nuclear allies, has also 
contributed to non-proliferation. If America commits to sharing the benefits of AI to non-AI 
states, this “AI umbrella” could lead to an AI non-proliferation treaty. 
While China is a potential adversary, it is still worthwhile to pursue treaties and agreements, but 
only if compliance can be verified. One recent example is the agreement not to allow nuclear 
arsenals to be controlled by AI.8 
8 Jarrett Renshaw and Trevor Hunnicutt, “Biden, Xi Agree That Humans, Not AI, Should Control Nuclear Arms,” 
Reuters, November 17, 2024, sec. World, 
https://www.reuters.com/world/biden-xi-agreed-that-humans-not-ai-should-control-nuclear-weapons-white-hous
e-2024-11-16/.7 Henry A. Kissinger and Graham Allison, “The Path to AI Arms Control,” Foreign Affairs, October 13, 2023, 
https://www.foreignaffairs.com/united-states/henry-kissinger-path-artificial-intelligence-arms-control#. 
3 of 6 


Industry and the Trump Doctrine 
The national interest, to protect and defend the United States of America, and the interests of 
AI and tech companies, to become the largest and most profitable companies in the world, are 
not always aligned. AI companies may express opposition to the Trump Doctrine since it 
prevents them from developing and selling AI products and services to foreign nations. The 
stereotype of the arms dealer who cynically encourages a war in order to sell to both sides has a 
parallel in the AI company that promotes an AI arms race between nations so they can sell to all 
sides. President Eisenhower once warned that “we must guard against the acquisition of unwarranted 
influence, whether sought or unsought, by the military-industrial complex.”9 The Trump 
administration should similarly guard against the acquisition of unwarranted influence by a 
technology industry that will be tempted to put their own interests above the national interest. 
Humankind and the Trump Doctrine 
“Mitigating the risk of extinction from AI should be a global priority alongside other 
societal-scale risks such as pandemics and nuclear war.” 
-Statement on AI Risk10
“Only a 20% chance of annihilation.” 
-Elon Musk11
The Trump Doctrine is aligned with the interests of AI safety and security researchers. 
Researchers fear that an AI race, between companies or between countries, will lead to 
corner-cutting and unsafe AI practices, putting humankind itself at risk. By reducing the number 
of developers, the Trump Doctrine makes it easier and more likely that the developers will 
coordinate to reduce these profound risks. 
11 Ana Altchek, “Elon Musk Says There’s ‘only a 20% Chance of Annihilation’ with AI,” Business Insider, March 1, 
2025, https://www.businessinsider.com/elon-musk-only-chance-of-annihilation-with-ai-2025-2. 10 Center for AI Safety, “Statement on AI Risk,” 2023, https://www.safe.ai/work/statement-on-ai-risk. 9 Dwight Eisenhower, “President Dwight D. Eisenhower’s Farewell Address (1961),” National Archives, September 
29, 2021, https://www.archives.gov/milestone-documents/president-dwight-d-eisenhowers-farewell-address. 
4 of 6 


Further measures to reduce risk include creating an “AI football”, similar to the nuclear football 
that accompanies the President at all times. If the worst case scenario does happen, the 
President should have the option of taking down AI systems when the necessity arises.12 
12 vitruvian potato [@vitrupo], “PJ Maykish: AGI Arrives next Presidency. We Know How to Break AI Systems, but No 
Framework to Stop Rogue AGI or Autonomous Cyberattacks. Will the President Get a Kill Switch? 
Https://T.Co/oSXnP6Wp8Q,” Tweet, Twitter, January 13, 2025, 
https://x.com/vitrupo/status/1878606726343413887. 
5 of 6 


Bibliography 
Altchek, Ana. “Elon Musk Says There’s ‘only a 20% Chance of Annihilation’ with AI.” Business 
Insider, March 1, 2025. 
https://www.businessinsider.com/elon-musk-only-chance-of-annihilation-with-ai-2025-2
. 
Center for AI Safety. “Statement on AI Risk,” 2023. 
https://www.safe.ai/work/statement-on-ai-risk.  
Clifford, Catherine. “Elon Musk: ‘Mark My Words — A.I. Is Far More Dangerous than Nukes.’” 
CNBC, March 13, 2018. 
https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nucl
ear-weapons.html.  
Eisenhower, Dwight. “President Dwight D. Eisenhower’s Farewell Address (1961).” National 
Archives, September 29, 2021. 
https://www.archives.gov/milestone-documents/president-dwight-d-eisenhowers-farew
ell-address. 
Fist, Tim, and Erich Grunewald. “Preventing AI Chip Smuggling to China.” Center for a New 
American Security, October 24, 2023. 
https://www.cnas.org/publications/reports/preventing-ai-chip-smuggling-to-china.  
Hendrycks, Dan, Eric Schmidt, and Alexandr Wang. “Superintelligence Strategy,” 2025. 
https://www.nationalsecurity.ai/.  
Kissinger, Henry A., and Graham Allison. “The Path to AI Arms Control.” Foreign Affairs , October 
13, 2023. 
https://www.foreignaffairs.com/united-states/henry-kissinger-path-artificial-intelligence
-arms-control#.Lai, Stephanie. “For AI Watchers, Asked If He Had Any Concerns about Artificial Super 
Intelligence, Trump Said: ‘There Are Always Risks. And It’s the First Question I Ask, How 
Do You Absolve Yourself from Mistake, Because It Could Be the Rabbit That Gets Away, 
We’re Not Going to Let That Happen.’ Https://T.Co/2bW1gsKMQI.” Tweet. Twitter, 
January 26, 2025. https://x.com/stephaniealai/status/1883336725700948036.  
Quester, George H. Nuclear Monopoly . New Brunswick: Transaction Publishers, 2000. 
Renshaw, Jarrett, and Trevor Hunnicutt. “Biden, Xi Agree That Humans, Not AI, Should Control 
Nuclear Arms.” Reuters, November 17, 2024, sec. World. 
https://www.reuters.com/world/biden-xi-agreed-that-humans-not-ai-should-control-nu
clear-weapons-white-house-2024-11-16/. 
RT. “'Whoever Leads in AI Will Rule the World’: Putin to Russian Children on Knowledge Day,” 
September 1, 2017. https://www.rt.com/news/401731-ai-rule-world-putin/.  
vitruvian potato [@vitrupo]. “PJ Maykish: AGI Arrives next Presidency. We Know How to Break 
AI Systems, but No Framework to Stop Rogue AGI or Autonomous Cyberattacks. Will the 
President Get a Kill Switch? Https://T.Co/oSXnP6Wp8Q.” Tweet. Twitter , January 13, 
2025. https://x.com/vitrupo/status/1878606726343413887.  
6 of 6 


