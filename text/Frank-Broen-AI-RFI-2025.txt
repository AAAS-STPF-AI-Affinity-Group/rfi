 
   Frank Broen  
I support the government's role in providing guard rails to the development of AI. AI has proven 
to be both a useful tool and capable of providing completely fake answers. Any policy must 
provide guardrails to ensure that the data used to train AI does not  contained bias. That bias is 
being encouraged through the current political climate, and may impact the 'decisions' made by 
the AI tool. The Arbinger Institute provides excellent guidelines that could be used in human to 
human interactions, by identifying  "self justification." People will often self justify their own 
believes, especially if they are not aware of the "box" that they trap themselves in. AI should be 
required to identify and report the bias that influences the decision process.  
 


