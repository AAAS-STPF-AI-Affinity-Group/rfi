 1 This commentary is written by Averill Campion, PhD.  
 
“This document is approved for public dissemination. The document contains no business -
proprietary or confidential information. Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without 
attribution.”  
 
This commentary provides insights about how America’s AI dominance is protected by  actualizing 
its leadership role at the global level as a competitor, partner, and standard setter to enable AI 
development that promote s human flourishing and openness. A proactive U.S. strategy must aim to  
build up  the normative, legal, and capacity building structure that will provide  a substantive 
alternative to  the techno -authoritarian  interests seeking to fill these voids . By promoting inclusive AI 
governance, the U.S. can help ensure that  local concerns and needs shape  how AI technologies are 
developed and deployed in different contexts . Community empowerment  and grassroots initiatives  
can provide  a buffer against the institutionalization of top -down, centralized interests that prioritize 
censorship, control, and the deterrence of opposition . Countering techno -authoritarian AI adoption 
requires  a style of  economic competition that understands cost -pricing c hoices for AI products and 
infrastructure are just as important as international cooperation at the company, state , and individual  
levels to build a shared consensus  about the boundaries of unacceptable technology end -use. 
Boundaries must  be set about the red lines of AI, but placing parameters does not have to hamper 
innovation , if done correctly.  The goal is to guide  power competition in a way that will prioritize 
national security , while also  avoid ing the complete balkanization of AI  development and adoption.  
 
The main policy actions  provided  are derived from the concepts of tech -diplomacy, innovation 
statecraft, counter -techno -authoritarianism, and contextual international collaboration . The key 
point s are that: (1)  engagement  with countries in the Global South should help  empower governance 
decision making and capacity building for  AI development  in a collaborative and multi -stakeholder 
manner , (2) the widespread  adoption  of U.S. based foundational models used for fine -tuning and 
commercial product development requires compute power support and data collection/processing 
that captures cultural nuances and languages  in order to create AI tools that are adequately 
address ing unique challenges and problems facing different societi es, (3) differentiating the AI -
ecosystem offerings  from  competitors is about building  long-term interaction  through  personal , 
business , and educational relationships  (4) and that informal and formal venues for interaction  and 


 2 information exchange should be institutionalized through mission driven networks, partnerships, 
and collaborative efforts  that value  human centered AI development . 
Based on these points, it is recommended that the following five policy recommendations should be 
considered in the AI Action Plan:  
 
• The U.S. must re-engage its Transatlantic allies and form a  Western bloc for AI 
techno -diplomacy  to counter techno -authoritarian normative and legal influence . 
 
• Innovation statecraft must be more AI oriented; Enhance the current science and 
technology capacity building programs at The State Department to ensure that AI 
receives special attention/funding in these critical soft power strategies.  
 
• The widespread adoption of U.S. AI open -source foundational models is tied to the 
type of licensing permitted for commercial use; stay abreast in monitoring any 
licensing changes by competitors, rather than narrowly focusing on performance 
benchmarks . 
 
• Carefully categorize techno -authoritarianism and techno -authoritarian technology, to 
consider appropriate engagement strategies with actors based on and understanding 
about the underlying economic versus value -based motives.  
 
• The creation of a Human -Centered AI Institute (HCAII) is a way to structure 
research, evaluation, and monitoring about the relationship between AI and human -
decision making to better understand the conditions in which AI encroachment on 
human autonomy coul d be undesirable or negative and to identify solutions that 
protect both innovation and human flourishing.  
 
 
 
 
 


 3  
 
 
1. POLICY ACTIONS: AI Governance, International Collaboration  
 
The U.S. must partner with its Transatlantic allies and form a Western bloc for AI techno -
diplomacy to counter techno -authoritarian normative and legal influence.  Partners bring 
different competitive advantages and influential capabilities  to the table,  which when 
combined , provides  a substantial  buffer against Sino -AI influence in the global AI 
governance arena.  
 
The extent of Chinese influence on legal systems and the normative interpretations of AI 
development is complex  and difficult to measure . However, the  CCP is clearly active in  its global 
positioning as a standard setter  with its “China Standards 2025” framework for emerging 
technologie s, as well as  the promotion of its own set of interests for AI governance through 
concepts like AI sovereignty and related digital/cyber sovereignty  across countries in the Global 
South  as an “ organizing principle  of internet governance that envisions a world of national 
internets ,” in contrast to “U.S. support for a global, open secure internet .” For example , in Thailand , 
the autocratic government “is passing cybersecurity laws that resemble Chinese regulations” and in  
Nigeria ’s digital information stack , China has leverage of the network infrastructure layer, the device, 
application, content, and governance layers that incorporates China’s influence to use state -led 
control over the internet and citizen’s data.  Moreover, legal and regulatory constraints are a 
prominent barrier for cloud adoption  in Africa such as data residency and data protection laws in 
Algeria, Gabon, Niger, and Morocco that “require regulated data (such as personal information) to 
be localized within a country’s borders ,” making public cloud use for data sets extremely difficult.  
 
Therefore, while AI and data regulation is not a priority for domestic  U.S. AI policy, it may  be a 
strategic priority in terms of international AI leadership as it can  serve to counter the adoption of 
legislation and  norms  that serve Sino interests in the Global South. Since the EU has experience in 
data privacy and AI regulation and has seen some similar structural adoptions  of the AI Act , like a 
risk based approach in countries such as  South Korea and Brazil , this EU competitive advantage  in 
AI regulation  could be modified to promote a broader framework and opportunity to collaborate on 
a country -by-country basis to develop legal interpretations that favor open internet and AI 


 4 technology that deter control/censorship  objectives , for instance.  Countries like France are 
producing celebrated  AI startups like Mistral and Huggin Face , exemplifying that  the EU is not 
completely detached from the AI -eco system and has plenty potential to contribute to a like-minded  
bloc to guide AI governance that is more open and non -threatening to democratic values.  The idea  
is to create an identifiable , democratic -friendly alternative that can be used as a reference , while also 
enabling individual countries to set their own normative interpretations and decision -making on AI 
governance.  More unity is needed between like -minded allies to emphasize the importance of 
collaborative, bottom -up governance that is guided by numerous actors from civil society, 
government, business, and academia.  
 
Innovation statecraft must be more AI oriented; Enhance the current science and 
technology capacity building programs at The State Department to ensure that AI receives 
special attention/funding in these critical soft power strategies.  
 
The U.S. should convene innovative statecraft tools for capacity building in the Global South that 
can complement the data collection efforts and grassroots initiatives at local levels which are aimed 
at capturing contextual distinctions to produce relevan t AI tools, solutions, and responses. This 
requires ensuring that political will and stakeholder support is in place  promote such collaborative, 
industry partnerships for capacity building.  Decentralized, grassroots -based  initiatives  for data 
collection  are forming across the Global South  using mobilized networks of volunteers , in some 
cases , like in Argentina where the benefits of these collaborative mapping solutions are about 
producing people -centered, needs based solutions t o addresses data collection limitations  in a short 
time period . Yet, the data dimension is only one aspect of widespread AI adoption .  
 
Currently, compute power , as part of a wider effort for capacity building , is lacking in the Global 
South . Improving  the compute access dimension  would help AI developers create products and 
tools that are tailored to community needs, ultimately contributing to trust building towards A I. 
Compute power  as an aspect capacity building can be implemented  through  financial assistance in 
terms of cloud services  that could  improve digital access  in terms of storage, processing, and data 
analysis by avoiding the hardware constraints. Amazon Web Services (AWS) through its AWS 
Activate program  has offered over 2,600 companies in South Africa around R340 million in AWS 


 5 Promotional Credits from 2018 -2022 for example and worldwide is offering startups no cost access 
to training resources, business support, and promotional credits.   
 
AI capacity building  also involves dimensions beyond  compute power like improving energy 
demands and infrastructure, labor and skills development, and basic AI literacy and education . There  
are numerous opportunities to help build up capabilities. Therefore, c apacity building should remain 
a priority for U.S. leadership because o ne important shift taking place is that China’s stance on state-
led digital governance  is changing. The CCP was once opposed bottom -up, multistakeholder 
approaches ( which are more a ssociated with Western approaches ), but now seems to be adopting 
some aspects of this by embracing “cooperative Chinese AI industries and industrial alliances” for 
capacity building in the Global South, as conveyed in the CCPs recent AI Capacity -Building Action 
Plan for Good and for All.  As Figure 1 conveys below, most  capacity building proposals by the CCP 
seem to be  state-led in nature but  will leverage more industry alliances through community 
engagement that fosters best practices and norms, even in the open -source community.  This 
exemplifies the classic dilemma that if a more coordinated approach from the U.S. is not 
implemented, then China will continue to attempt to fill these voids  and shape global dynamics to 
serve its own interests . Plus, U.S. industry can benefit as well using  innovation statecraft through  this 
type of positive  reputation building and benevolent actions  that genuinely empower local 
stakeholders —a win -win scenario.  
 
Figure 1: AI Capacity Building Approaches  
AI Capacity 
Building Elements  
(for the Global 
South)  China’s Approach  
(via MFA doc)  Considerations for the U.S. 
Approach to Capacity Building  
 
AI development: local 
reality  
 China has plans to help GS 
develop AI language and data 
resources that are locally oriented  The U.S. must provide genuine local 
empowerment initiatives for AI 
development through strategic multi -
stakeholder collaboration and 
differentiate its approaches from CCP 
calls for AI sovereignty.  
Professional skills: 
exchanges, training, best 
practices  
 China plans to provide GS with 
educational resources, joint 
education and exchange 
programs  The U.S. must cultivate an 
understanding of the professional AI 
communities in GS to customize 
collaborative skills development 
opportunities; on -site learning and 
exchanges encourage  socialization  


 6 AI literacy  
 China plans to focus on 
increasing AI literacy in GS 
public  The U.S. must prioritize AI literacy 
and public education in GS, especially 
through civic/multi -stakeholder 
initiatives -good opportunity for 
grassroots; native languages and local 
context critical for understanding 
unique concerns and challenges.  
Global data sharing 
platform  
 China proposes that data sharing 
should occur on centralized data 
sharing platform, potentially 
under guise of data privacy and 
security  The U.S. must investigate different 
forms of data sharing data/flows to 
strengthen a more decentralized 
approach to data sharing.  
Joint AI development: 
build laboratories and 
infrastructure; R&D 
cooperation -AI models  China proposes assisting GS in 
development of AI laboratories 
and infrastructure; collaborate on 
R&D of AI models  The U.S. must be proactive in both 
university collaboration in GS for AI 
and to partner w/ and develop AI 
labs to promote open tech 
values/culture, credits and API access 
for foundational models use and tool 
development.  
Chinese AI 
industry/alliance 
engagement  China plans to use Chinese 
industry alliances to promote 
best practices, open -source, AI 
communities, create multilevel 
cooperation system  The U.S. must offer a more attractive 
combo of tech partners, culture, and 
products; it is still uncertain how 
much freedom Chinese industry will 
in such engagement.  
AI workshops  The CCP government plans to 
convene AI workshops that 
focus on human resource 
cooperation  Inter -personal interaction is a key in 
trust-building; rather than state -led, 
the U.S. should partner with 
informal/formal responsible 
networks to  provide an alternative 
guide to responsible implement ation 
of AI in the workplace  
*Please note the source for the Chinese capacity building elements and approach comes from the CCP Ministry of 
Foreign Affairs document: https://www.mfa.gov.cn/eng/wjbzhd/202409/t20240927_11498465.html  
 
 
2. POLICY ACTIONS: Competition and innovation, open -source models, national security  
 
The widespread adoption of U.S. AI open -source foundational models is tied to the type of 
licensing permitted for commercial use; stay abreast in monitoring any licensing changes by 
competitors , rather than narrow ly focus ing on performance benchmarks . 
 
Coordination must put in place that enables political authorities to stay abreast on changes to 
competitor licenses to adjust “open -source model” competition strategies accordingly. Open -source  


 7 foundational models vary in the type of  licenses that permit  commercial use terms. Rather than 
using a subscription structure like OpenAI, the so -called  open -source DeepSeek tools like DeepSeek 
Chat model  and DeepSeek Reasoner  model  charge users according to their token usage  with pricing 
tiers based on input/output capacity . The Llama pricing mechanism is only slight different  for 
token -based consumption . Since pricing may remain similar across open -source  models, the main 
differentiation outside of performance benchmarks are the types of licensing permits. Therefore, 
understanding the role of licensing in market access is important for policy making. For example,  the 
licensing terms DeepSeek currently deploys may put it at a competitive advantage in terms of model 
reproduction and distribution, in comparison to Llama, which includes broad usage rights and 
royalty -free terms, but more restrictions on distribution, c ommercial, and acceptable use. In 
conclusion , a lack of attention paid to the role of  licensing types across open -source foundational 
models could get  in the way of its market penetration and commercial competition strategies.  
 
Widespread adoption  of AI foundational model aspect of the AI -ecosystem involves on the one -
hand  through the ability to fine -tune for commercial use and to make customized apps or tools , and 
on the other -hand the general performance capabilities. It is important to track how open -source 
licensing can combine with other economic tools to provide addition support like compute, as well 
as to track if certain licensing terms result in the increased production of certain categories of 
commercial applica tions to paint a more holistic picture between the interactions of these 
components. Due to the inability to compete much on terms of pricing mechanisms, techno -
diplomacy will become an even more important mechanisms for open -source model competition as 
personal relationships and interaction help build trust and differentiate model adoption choices.   
 
Carefully categorize techno -authoritarianism and techno -authoritarian technology, to 
consider appropriate engagement strategies  with actors  based on and understanding about 
the underlying economic versus value -based  motives.  
 
Tech -diplomacy must incorporate a  lens that differentiates a nation state’s adoption of techno -
authoritarian technology because of economic reasons like cost/pricing appeal versus an adoption of 
techno -authoritarian technology  because it appeals  ideological values like control and censorship . 
Countering techno -authoritarianism on the economic strategic side should employ a number of 
tools such as incentivizing the AI product development to create AI choices that can counter 


 8 oppressive technologies in terms of freedom -enhancing capabilities, pricing/cost/subsidiary options 
to differentiate AI offerings from competitors, and relationship building based on a local and 
regional understanding of technological needs. On the values  side, it must first be understood that 
autocratic regimes  vary in their degrees of severity and desire for power. Ultimately, a regime’s desire 
for power and influence in the global arena is what makes it a systemic competitor  to the U.S. In 
contrast,  an autocratic regime that  incorporates  technology to uphold oppressive  values like  buying  
facial recognition  that enables the government to  monitor and track citizens, can be for reasons like 
cost offerings —or the reception of an offering in general from a company —combined with 
promises to “ reduce crime ” as a band -aid to often deeper societal problems, for example. With a 
more nuanced understanding, engagement can be devised on a case -by-case basis in order to  tailor 
strategies that  truly address a problem definition,  since attempting value -change  is not same as 
incentivizing a purchase of AI technology based on a competitive price or economic package .  
 
The U.S. should be c autious about  how it frames this debate, especially since major U.S. companies 
have commercial interests in a variety of regimes, in that such a  business -technological presence in 
those countries does  indeed  help accomplish an American AI dominance objective , or at least, a 
balance of economic power . As such , questions about whether providing  cloud servers, compute 
centers, or mass surveillance systems to autocratic -leaning regimes may result in  tricky  answers that 
require  a complex worldview of costs  and benefits.  Therefore, writing -off engagement, especially 
economic, with autocratic regimes is not always desirable, especially when a government does not 
pose an immediate systemic rivalry to democracy. When it comes to the values conundrum , such as  
the supply of authoritarian -friendly AI technology , a more long -term perspective is required . 
Processing the trade -off between market access to sell U.S. AI products , that may be used in ways 
that enable autocratic control o ver citizens, is more grey than black and white.  The end goal , to 
diffuse AI technology that promote human flourish ing rather than serve as a tool for repression , 
should be pursued both diplomatically and economically. In the process,  choosing the type of means 
to that end may not always be clean -cut, but a  consistent  humans -in-the-loop feature is key . 
 
 
 
 
 


 9  
 
The creation of a Human -Centered AI Institute (HCAII) is a way to structure research, 
evaluation, and monitoring about the relationship between AI and human -decision making 
to better understand the conditions in which AI encroachment on human autonomy could 
be undesirable or nega tive and to identify solutions that protect both innovation and human 
flourishing.  
 
As an alternative to the more risk -based approach  of the AI Safety Institute , the establishment of a 
U.S. Human Centered AI Institute (US HCAII)  could structure AI research to a mission of ensuring 
that humans are at the center of AI technology. The goal could be identifying sector -by-sector, 
product type -based challenges and opportunities for the placement of human decision making  
throughout the AI lifecycle. Such checks and balance institution could help keep companies in line 
with the best practices for ensuring that humans have control about consequences for AI 
incorporation into society without hampering innovative capabilities . More broadly, the create of a 
purpose drive AI -research network on human centered AI could help achieve the policy goal of 
human flourishing because it helps provide a safeguard and guarantee s about  when limitations 
should be set about AI’s influence over human life .  More research is needed about boundaries for 
AI technology as a replacement or substitute to human in teraction, insight, or wisdom . Even from 
an organizational structure perspective, clear roles must be defined about who is overseeing the 
incorporation and implementation of AI tools in a business for example, especially if it is 
transforming employee routines and/or replacing tasks. Furthermore, this type of network could be 
an additional vehicle for international cooperation  to complement responsible AI networks , even 
with strategic competitors, because human flourishing is a  broad  and appealing objective.  
 
Such a mission is differentiated from current international concepts  like “AI for the public interes t” 
or “AI for the public good,” which focus on identifying unifying projects  climate change, or 
agriculture that can be enhanced through the application of AI technology,  but are nonetheless 
ambiguous in interpretations about when individual freedom may be permitted to be overridden  for 
such a n aim , for instance.  The replacement of human decision making with AI is not appropriate in 
all situations, sectors, job types, and tasks, and more examination is needed to identify key off -limit 


 10 scenarios/contexts/applications. H umans must always have avenues for control over the evolution 
of AI’s technological influence on society.  
 
References  
1. Lorci , E. 2025. Shaping the Digital Oder: China’s Role in Technology Standards and the 
Implications for Taiwan. Global Taiwan Institute. 
https://globaltaiwan.org/2025/02/shaping -the-digital -order -chinas -role-in-technology -
standards -and-the-implications -for-taiwan/   
2. Dagher -Margosian, M. 2024. CCP Cyber Sovereignty Contains Lessons for AI’s Future. The 
Jamestown Foundation. https://jamestown.org/program/ccp -cyber -sovereignty -contains -
lessons -for-ais-future/  
3. Segal, A. 202. China’s Alternative Cyber Governance Regime. Council on Foreign Relations. 
https://www.uscc.gov/sites/default/files/testimonies/March%2013%20Hearing_Panel%20
3_Adam%20Segal%20CFR.pdf   
4. Barros, B., Kohlenberg, N., Soula, E. China and the Digital Information Stack in the Global 
South. GMF. https://www.gmfus.org/news/china -and-digital -information -stack -global -
south  
5. Andrews, K. 2025. South Korea’s AI Basic Act puts another AI governance regulation on 
the map. IAPP. https://iapp.org/news/a/south -korea -s-ai-basic -act-puts-another -ai-
governance -regulation -on-the-map  
6. Atanasovska, D., Robeli, L. 2025. Brazil’s AI Act. GDPR Local. 
https://gdprlocal.com/brazils -ai-act-a-new-era-of-ai-regulation/  
7. Blumberg, S., Gelle, J., Tamburro. 2024. Africa’s leap ahead into cloud: Opportunities and 
barriers. McKinsey. https://www.mckinsey.com/capabilities/mckinsey -digital/our -
insights/africas -leap-ahead -into-cloud -opportunities -and-barriers   
8. UNDP. Decentralized Grassroots Data Collection. https://www.undp.org/latin -
america/digitalhub4/projects/decentralized -grassroots -data-collection  
9. Gelvanovska -Garcia, N., Rossotto, M., Maciule, V. 2024. Bridging the digital divide: 
Harnessing data through cloud computing. World Bank. 
https://blogs.worldbank.org/en/digital -development/bridging -the-digital -divide --
harnessing -data-through -cloud -compu  
10. Valchanov, I. DeepSeek Pricing: How much Does it Cost & Is It Worth It in 2025? Team 
GPT. https://team -gpt.com/blog/deepseek -pricing/  
11. Editorial Team. 2025. Byte Plus. 
https://www.byteplus.com/en/topic/386156?title=deepseek -vs-llama -cost-a-
comprehensive -comparison  
12. Kosinski, R. 2025. Understanding the DeepSeek model license: Balancing openness and 
responsibility. Black Duck. https://www.blackduck.com/blog/deepseek -license.html  
13. Mantellassi, F. 2023. Digital Authoritarianism. GCSP. 
https://www.gcsp.ch/publications/digital -authoritarianism -how-digital -technologies -can-
empower -authoritarianism -and 


 11 14. Jili, B. 2023. What is driving the adoption of Chinese surveillance technology in Africa? 
Atlantic Council. https://www.atlanticcouncil.org/in -depth -research -reports/issue -
brief/what -is-driving -the-adoption -of-chinese -surveillance -technology -in-africa/  
15. Feldstein, S. 2019. The Global Expansion of AI Surveillance. Carnegie Endowment for 
International Peace. https://carnegie -production -assets.s3.amazonaws.com/static/files/WP -
Feldstein -AISurveillance_final1.pdf  
16. Elysee. 2025. The Paris Charter on AI in the Public Interest. 
https://www.elysee.fr/en/emmanuel -macron/2025/02/11/the -paris-charter -on-artificial -
intelligence -in-the-public -interest   
 


