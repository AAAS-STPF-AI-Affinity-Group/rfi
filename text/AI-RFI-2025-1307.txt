PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 88-gun3-txh3
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1307
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Mariya Gudima 
General Comment
Hello, I'm  writing to you as a writer, editor and fiber artist that is against our governm ent investing in generative AI. Generative AI m odels
that are currently out there are trained on copyright protected works: books, articles, illustrations that were stolen without any
consideration for the people who created these works. The com panies did not com pensate the people without whose work their
generative AI m odels would not be able to generate anything. My partner's painting were certainly scrapped and used without notice or
solicitation of consent. If you take away the training data, the m odels cannot function--they cannot generate anything; this m akes the
training data crucial. Com panies like OpenAI have said tim e and again that if they are m ade to actually pay the people whose work m akes
their m odels functional, they will go bankrupt (https://arstechnica.com /tech-policy/2025/03/openai-urges-trum p-either-settle-ai-copyright-
debate-or-lose-ai-race-to-china/). Com panies like Meta have harvested the work of people without consent or com pensation, using
m ethods that have been illegal in the United States for decades--pirating books and infringing on the right of published authors and
publishers, as detailed in this article: https://arstechnica.com /tech-policy/2025/03/m eta-m ocked-for-raising-bob-dylan-defense-of-
torrenting-in-ai-copyright-fight/ . If you cannot m ake your com m ercial product without using other people's intellectual property, you
should pay the people whose work m akes your product possible and the governm ent should not be em powering you and ripping away
copyright protection from  literally m illions of writers and artists to prop up your business. 
The United States governm ent should be protecting Am erican creative industries, supporting the artists and writers, who pour their soul
into their, work not upending the already flim sy and difficult to enforce (unless you have m oney and access to stellar legal representation)
copyright protections we barely enjoy. These m odels com pete directly with our work while being trained on work that was stolen from  us
and now they are trying to say that it's okay for them  to steal our work to develop their product, never com pensate us, and that they
should be allowed to do this to all creatives in all creative fields in perpetuity? How is that fair or right? How does that support the pursuit
of liberty and happiness for anyone but these com panies? If these com panies are forced to pivot to som ething else, they will and they will
be fine; people in creative fields have spent decades honing their craft and skill into a livelihood will not be fine. Why should the
governm ent endorse creatives being pushed out of their jobs just so that a handful of com panies can m ake record profits. Every artist,
writers, anim ator, film m aker, actor, etc, who this forces out of a job is another person who will need to seek welfare. This isn't good for
our econom y or the vast m ajority of people who work in creative industries. Do not give these com panies a reward from  ripping off
regular people who are just trying to m ake a living with the skills they've spent m ost of their live honing. 
People do not reach for a video gam e or a book or go to see a Picasso exhibit just to consum e som ething, they want to connect with and
support other people and genAI robs people of that true connection all the while pushing out the creatives it sucked dry to m anifest.
And that's before we get into the environm ental and energy consum ption (https://www.bloom berg.com /graphics/2024-ai-data-centers-
power-grids/). Long story short, data centers for generative AI research draw so m uch power, the likes of Microsoft was looking into
acquiring their own dedicated nuclear power plant. Our power grid is old and straining--we need to invest in its repair so regular every
day people do not die of heatstroke in sum m er (Pacific Northwest) and freeze to death in winter (Texas). The governm ent should not
place the desires of billionaire com pany owners for m ore electricity and water above the needs of everyday people trying to light, heat and
cool their hom es and be able to have enough water to drink, to cook with, to wash their kids hair with.
Attachments


harm  and hypocrisy of ai art - m att corrall
why we don't know ai's true water footprint - techpolicy press
m aking_ai_less_thirsty_ai_water_consum ption_analysis
California wildfires raise alarm  on water-guzzling AI like ChatGPT _ Fortune
What the data center boom  in Texas m eans for the grid _ The Texas Tribune
kicking datacenter's drinking habit is nearly im possible - the register
how rise in ai im pacts data centers and the environm ent - techtarget
ai uses m ore energy and water than Google search without ai
as use of ai soars o does energy and water it requires yalee360
ERCOT overchrged for electricity in Texas by 16billion during freeze - texas tribune
Texas Power Grid Run by ERCOT Set Up the State for Disaster - The New York Tim es
ERCOT overcharged for electricity in Texas during freeze - Texas tribune
The Texas Electric Grid Failure Was a Warm -up-Texas Monthly
ai-insatiable-need-for-energy-straining-global-power-grids
m eta_m ocked_for_raisig_Bob_Dylan_defense_torrenting_in_ai_copyright_fight


The harm & hypocrisy of AI art
“How easy it is to create and maintain the illusion of understanding, hence perhaps of
judgement deserving of credibility... A certain danger lurks there.”
— Joseph Weizenabum
(Disclaimer: The views expressed here are my own personal opinions, and not those of Sony Interactive Entertainment)
For anyone who works in tech, generative artificial intelligence (AI) has been the hot topic of 
the last couple of years. We’ve seen an explosion of interest around the tech world, with companies big and small scrambling to adopt AI tools and weave AI features into their software. Everyone is seemingly terrified of missing out on what we’re told is the next big thing; even Photoshop - the old reliable friend of graphic design - includes AI tools, now. Stories appear daily about how AI will change society and propel us all into a brighter future, their writers proclaiming a raft of utopian assertions from the end of poverty to making everyone an artist.
I’ve started to see AI image generators and other tools popping up with startling frequency in 
the daily work and discussions I have with my peers. Engineers ask 
ChatGPT to write code, 
managers use Midjourney  to fill their PowerPoints with bespoke images, and even designers 
ask Dall-E  to create UI concepts for them. Nearly everyone seems awed by the novelty and 
magic of this new toy, and I often hear the same mantra - everyone’s job will soon rely on this. Emb
race it, or risk being left behind.Home About Spatial
Portfolio Private CoursesSpeaking
Writing Career
MusicMatt CorrallThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
1 of 36 3/14/2025, 2:34 AM


UI mockups auto-generated by Midjourney. Source: https:/ /t.ly/B6HlH
The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
2 of 36 3/14/2025, 2:34 AM


So I started digging into both how AI works, and what impact it’s having, particularly on the 
creative industry I’m proud to be a part of. This article has been a long time coming for me. The more I’ve learned, the more I’ve become first alarmed, then angry, then compelled to speak out. As a designer in the tech world, I want to put forward a different view to one we usually hear, and to explain clearly why I for one, am appalled by the arrival of AI.
AI in 2024
Machine or deep learning models - that which we now brand AI - have been around in a basic 
form since the 1950s, but thanks to recent advancements in GPUs, have made a huge leap forward in capacity.  What separates AI from say, the cloudy metaverse visions of last year, is 
that AI is already shipping and impacting our lives for the worse - even if it’s not quite the stuff of everyday pub debate.
Using generative AI tools like 
ChatGPT , and Stable Diffusion ,  people can type a request into a 
browser in straightforward English, and get back a whatever they asked for - be that a recipe, 
an illustration, or even a faked photo or video. With gadgets like the Humane AI Pin , people can 
also do the same by speaking out loud, in a manner reminiscent of the sci-fi movie, Her .The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
3 of 36 3/14/2025, 2:34 AM


The Humane AI Pin. Source: https:/ /shorturl.at/qWZ58
When using an AI generator the images and articles that come back are often uncanny and 
strange, but still strikingly realistic - good enough to pass for something written, painted or photographed by a real person. Yet it’s in the details where they still fall over - at least for now - showing hands with seven fingers, writing repetitive prose, or drawing what should be text as gibberish symbols. Despite the limitations, the appeal of cheap, instantly available art and writing holds obvious appeal for the commercial world, and AI companies have quickly amassed colossal profits. 
OpenAI   for example, making an incredible $1.6 billion  last year.
How it works
What we call AI today is nothing like the sentient robots of sci-fi movies - an ‘AI’ is a 
mat hematical model, written in computer code, that is good at spotting patterns and 
correlations in data. In most cases, ‘data’ means a big pile of text or images - millions of photos or online articles, for example. AI companies can feed their models huge libraries of photos or books, and by analysing everything it’s fed, the model can then generate its own versions The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
4 of 36 3/14/2025, 2:34 AM


which look pretty close to the real thing. At first the model is likely to produce complete 
garbage, but through a trial and error process can be ‘trained’ by an engineer to generate some impressive results.
The sample image Stable Diffusion currently use to introduce their AI tool. Source: https:/ /shorturl.at/kuvFH
Training a model requires a vast amount of ‘data,’ and also  comes at a not insignificant cost in terms or energy, carbon emissions and human labour. All that ‘data’ has so far mostly been scraped from the internet - taken in secret from people who didn’t know and didn’t consent to handing it over.
Low-paid workers are used to manually filter offensive and upsetting images out of the 
datasets, and to type out description tags for the millions of images, so that the machine knows what its looking at. Programmes like Amazon’s 
Mechanical Turk  - which pays a pittance 
to people for each image they tag - hides struggling workers behind a curtain whilst giving the The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
5 of 36 3/14/2025, 2:34 AM


impression of a shiny, automated front-end.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
6 of 36 3/14/2025, 2:34 AM


Source: https:/ /www.smbc-comics.com/comic/rise-of-the-machines
What AI can and can’t doThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
7 of 36 3/14/2025, 2:34 AM


Everything an AI is fed must first be categorised and converted to numerical data, in order to 
be consumed. There is a process of abstraction and reduction that must happen,  turning a digital image into a numerical matrix of RGB pixel colours and positions. This abstraction means a whole lot of nuance, detail and context that we understand as humans - anything that can’t be easily quantified - is lost as data is fed into the machine. The Mona Lisa becomes just more numbers in the pile. 
AI will also amplify any inherent bias in its training dataset. For example, if a model is trained on 
a police database and told to suggest jail sentences in a courtroom - 
something which is
already happening in the US  - it will have inherited any racial bias that was present in the 
records of arrests, and be more likely for example, to suggest harsher sentences for black def
endants. Famously too, if one prompts Dall-E with the word ‘CEO,’ it will only produce 
images of white men.
AI models are highly dependent on the input dataset - what it contains, what’s conspicuously 
absent, who curated it and to what end, all affect the results. Without any governance whatsoever, that means Silicon Valley tech companies get to decide exactly which way the models lean and what they do - and the more widely AI is used, the more their particular world view and biases propagate.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
8 of 36 3/14/2025, 2:34 AM


The process of training an AI model on vast quantities of input data
Source: https:/ /forbytes.com/blog/ai-models-explained
When someone asks the machine to generate an image, the model scans over everything in its dataset and makes a calculation - out of everything it has, which combination of colours, shapes and lines best fits the request? It’s a mathematical brute force approach, not unlike the classic adage of infinite monkeys at typewriters  - feed the AI enough data and it will eventually give you something about right. The machine doesn’t draw or paint - it can only break down its dataset into billions of parts, and recombine them to deliver mash-ups of what came before, as strange and uncanny as they may be.
In this way, an AI model is technically incapable of producing anything new. It’s limited view of 
the world is based entirely on the abstracted number set it was given. An AI model amazes only because it has devoured so much raw material, to remix at your behest. As clever as it may be at spotting patterns, it cannot adapt, interpret or imagine like a human being can. What it can do very well however, is copy an artists’ style or fake a photo with disturbing accuracy.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
9 of 36 3/14/2025, 2:34 AM


Illustrations by artist Hollie Mengert  (left) & AI output based on her stolen work (right)
Source: https:/ /thealgorithmicbridge.substack.com/p/why-generative-ai-angers-artists
The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
10 of 36 3/14/2025, 2:34 AM


Entirely AI-generated fake photos - alarmingly difficult to tell from the real thing
Part of the branding exercise around AI tools has been about building mystique. AI enthusiasts 
talk about its limitless potential  to transform society for the better, by taking over more and more decisions for us. There is an almost religious zeal for this in some quarters, from which predictions flow of utopian futures where all problems are solved through learning to embrace the wisdom that flows from these machines; but as we’re seeing, these machines are far cruder and more flawed than the hype suggests.
“Generative AI is the key to solving some of the world’s biggest problems, such as climate
change, poverty, and disease. It has the potential to make the world a better place foreveryone”
— Meta CEO, Mark Zuckerberg
One aspect of AI’s working which perhaps fuels these beliefs, is the opaqueness of its The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
11 of 36 3/14/2025, 2:34 AM


decisions. As models are trained, they make myriad correlations and connections which are 
never fully visible to the engineers. Whilst not truly a ‘black box,’ models nevertheless produce output without us fully knowing what’s going on inside. This lack of accountability means it would be unforgivable to say, trust them with decisions that affect people’s lives. By the same token, the box of mystery can appear as if magical - the machine really looks like it’s thinking and understanding, prompting some to proclaim that in time anything is possible. AI is not intelligent, however. It blindly connects and calculates, no matter how misguided or illicit the task.
For now, AI-generated images can be spotted via the mistakes they make with fine details - 
such as human fingers - but we can expect this to changeSource: https:/ /t.ly/HPduD
“Generative A.I. art is vampirical - feasting on past generations of artwork even as it sucks thelifeblood from living artists. Over time, this will impoverish our visual culture.”
— Molly CrabappleThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
12 of 36 3/14/2025, 2:34 AM


The Vampire Machine
It’s important to understand that OpenAI  (creator of Dalle-E), StabilityAI  (creator of Stable 
Diffusion) and Midjourney  - the big three image generators - all trained their successful 
models by scraping millions of other peoples’ images from the internet - apparently entirely 
wit hout the owners’ knowledge or permission. Lawsuits surrounding this are still ongoing.
This is worth reiterating: The billion-dollar-making generators we see today appear trained on the copyrighted works of far poorer artists, illustrators and photographers; taken directly from their portfolios and community sites like 
DeviantArt.  This is copyright infringement on a 
completely unprecedented scale, and in my opinion corrupt, cynical and immoral. Paying users can
 even directly prompt the image generators to produce artwork in the style of an artist by 
typing their name - making no secret of the fact that their work was absorbed by the model.
The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
13 of 36 3/14/2025, 2:34 AM


‘Dragon Cage’ by artist Greg Rutkowski (top), whose name has been used tens of thousands 
of times as a prompt in Stable Diffusion to generate lookalike images (below).Source: https:/ /www.businessinsider.com/ai-image-generators-artists-copying-style-thousands-images-2022-10?r=US&IR=T
Only because this has never happened at such scale and speed before, has the law been slow 
to respond, and the AI companies so far have got away with it.  Much like Uber, it seems they knew that if they moved fast and broke things, they could make their money and be established before the law caught up with them - whilst claiming to disrupt and innovate for the common good. It seems some in Silicon Valley have claimed the right to appropriate artists’ work in order to mechanically process it, and sell it back to us. 
“All that we’ve been working on for so many years has been taken from us so easily with AI... It’s
really hard to tell whether this will change the whole industry to the point where human artistswill be obsolete. I think my work and future are under a huge question mark”
— Greg Rutkowski
Following the outcry from the many artists whose work was used, OpenAI and Midjourney are now facing copyright infringement lawsuits from the likes of 
Getty Images  and the New York
Times . AI companies thus far seem unrepentant, which is perhaps unsurprising given the 
profits they’re making.
Democra tising art
The big three image generators claim some noble and lofty goals whilst making their money 
off of others’ work. Midjourney for example, claims to be “expanding the imaginative powers of 
the human species”  whilst StabilityAI say they are “building the foundation to activate 
humanity’s potential.”  The story sold to us is similar across the board - that art is being 
‘democratised’ - pulled from the clutches of those entitled artists and mechanised - converted into a tool that will instead make everyone an artist.
By its fans, ‘AI art’ is often described as a new medium or frontier, where humans forgo the The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
14 of 36 3/14/2025, 2:34 AM


effort of making their own art or building any skill - instead pushing buttons to have art appear 
instantly. Rather than discovering the joy of creating, we’re told instead it’s better we learn to think as the computer thinks, and become experts at writing prompts because, hey.. it’s the same thing.
‘Les Demoiselles d’Avignon’’ by Pablo Picasso. A painting which disrupted modern art without 
hurting artists. Source: https:/ /t.ly/zIiLI
By its nature, art has always been something society struggles to firmly define, and that makes any discussion around its definition difficult. As soon as we establish a common idea of what constitutes art, an artist like 
Picasso  or Duchamp  is compelled to push the boundaries - 
making it an ever evolving and expanding field. The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
15 of 36 3/14/2025, 2:34 AM


But ‘AI art’ is something very different. Boundary-pushing art never threatened the careers of 
other artists before, or threatened to monopolise the means of creation - it simply challenged our ideas about ourselves and our world. New art might shock us or make us uncomfortable, but it’s never had this much destructive power, nor generated this much money for a handful of men so quickly.
“Everyone is looking for the hack - the secret to success without hard work”
— OpenAI CEO, Sam Altman
Art and illustration is everywhere in our world - it captures our imagination on book covers, 
brightens our homes, brings magazine articles to life, and adds richness to the environments of video games. The artists who create all of this are the under-appreciated workforce that breathe life and meaning into our everyday. They love their work, spend their entire lives honing their skills, and are often short-changed considering the value they give their employers. They’re expected to produce exceptional art to ever-shrinking timescales for often mediocre money. But they do it anyway, because this is what they love - bringing beauty and soul to the world.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
16 of 36 3/14/2025, 2:34 AM


A piece by Mario Klingemann . Producing images with AI image generators, Mario describes 
himself as a full-time “AI artist.” Source: https:/ /t.ly/53-mv
Over the last two years, commercial adoption of AI image generators has meant that real 
illustrators and artists are losing paid work and control of their own images. Now, the companies who would have previously hired artists can turn to a cheap, mechanical equivalent, and as long as this option is available some won’t be able to resist. AI images may be inferior in the details, but they’re incredibly cost efficient and near instantaneous. The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
17 of 36 3/14/2025, 2:34 AM


Automating this is about seeing art as simply ‘content,’ and what matters is that it keeps 
coming quickly and cheaply. Someone can be hired to touch-up any problems with the images at far less expense to the company. These workers are also lower skilled, disempowered and more interchangeable than they were before. 
This type of automation is a common corporate path. People don’t necessarily lose their jobs, 
but algorithmic management instead takes away their power, and lowers their pay and protections. 
Far from ‘democratising’ art, AI tools are instead having the opposite effect - privatising and 
automating it. AI is pushing skilled people out of the process and handing control to a handful of tech companies in a race to reduce and commodotise.
‘House of Earth and Blood’ by Sarah J. Maas. Publisher Bloomsbury used an AI-generated 
stock image for the book’s cover. Source: https:/ /t.ly/smdNo
The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
18 of 36 3/14/2025, 2:34 AM


The entirely AI-generated title sequence to Marvel’s ‘Secret Invasion’ TV show. Source: 
https:/ /t.ly/qFjR8
The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
19 of 36 3/14/2025, 2:34 AM


Videogame art assets, automatically generated with AI, instead of created by a game 
environmental artist. Source: https:/ /shorturl.at/kARXZ
Art is intrinsically human
To call AI-generated images equivalent to real art, is - in my opinion - to entirely miss the point. 
The effortless, instantaneous nature of AI generation prevents it from having real meaning. It’s disposable. AI companies truly misunderstand art in thinking that the image is what matters, rather than the intent and the labour.
Art has always been intrinsically human. It comes as much from our flaws and mistakes as it 
does our successes. Through the process of making it, we express what’s inside us - our joy and frustration,  longing and sadness - in a way which is instinctive and deep-rooted. It’s only through experiencing life as human beings that we have something to express and put to canvas or page. More often than not, we discover what the artwork is to be through the process of creation, rather than having a firm vision at the outset and simply assembling it, as a machine does.
We all know it when we see it - that painting that holds our attention or music that speaks to us. 
Through the sweat and the hours they put in, the artist communicates those feelings to us, the viewer, and that’s part of the joy of engaging with art. We feel understood and more connected as human beings as a result.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
20 of 36 3/14/2025, 2:34 AM


Photo by Ari He. Source: https:/ /t.ly/3XFiS
Take away that substance, and what do you have? A lifeless matrix of pixels. With AI art, there 
is no feeling to communicate, no creative process, and therefore no value imbued in the ‘content.’
As any designer knows, the act of making art is also a way of observing, thinking and problem 
solving. The creative mindset is something which must be exercised, and which can be applied in so many other areas of life. It’s at the heart of all design and architecture. By letting a machine think for us, we are robbing ourselves of the joy and reward of creation.
AI models are an inherently conservative technology. By thinking on your behalf, and by 
reducing creative decisions to an algorithmic, wholly quantitative process, they severely constrain the possible outcomes, and no true artistic surprises or discoveries are possible. The models simply crunch the data they’re fed and serve a mash-up back to you. Nothing more.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
21 of 36 3/14/2025, 2:34 AM


The inevitability myth
But - AI enthusiasts have often told me - now the genie is out of the bottle, it' can’t be put back 
in. We should adopt AI or be left behind. The idea that we should fight to help destroy a vital part of our society’s culture so corporations can benefit, is deplorable to me. There’s nothing inevitable about technological change. Any development takes time, effort, money and determination, as well as a clear intent - continuously reinforced so that a team of people can work towards a common goal.
Technological change is a political and commercial process, shaped by the interests of the 
corporations and governments that surround us, who make deliberate and resolute choices. So the AI tools we have today are a choice, and a different choice can be made at any time. If we want to see AI work differently, or even pull the plug altogether, we can collectively do so.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
22 of 36 3/14/2025, 2:34 AM


Source: https:/ /shorturl.at/dizYZ
One has to wonder - when we could use AI models for so many different purposes, why try to 
automate illustration, and not something we’d all much rather not do, like tax returns? As artist The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
23 of 36 3/14/2025, 2:34 AM


Molly Crabapple said: “I cannot understand why someone would burn a tonne of carbon, just to 
take away a job people love to do, and give it to a machine.” It’s entirely possible that Silicon 
Valley tech men just thought they were tinkering with an interesting maths challenge, and didn’t think what the consequences might be for other people. Perhaps these engineers share a reductionist world view, where the human brain is seen as a computer, and everything in life can be expressed through equations and code. Heartbreakingly, perhaps this even extends to art.
Photo by Ivan Samkov. Source: https:/ /shorturl.at/clEIN
The long term impact
If we continue on the path AI tools have set, then creative careers such as illustration and 
journalism will be far less viable, and far fewer young people will enter the creative fields. They may disappear entirely. 
Art is often undervalued today, but by automating it we drive that appreciation even further The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
24 of 36 3/14/2025, 2:34 AM


down. Art would be regarded as something that can be produced instantly at scale, and more 
worryingly, given precious little thought or effort. 
We’d have fewer artists, writers or musicians, and those we do have will be from the same 
wealthy, privileged segment of society. That narrowing of experience means any real art we get will be all the poorer, and with fewer people able to spend their time creating art, we can expect less evolution and growth of the field. There’d be no more Grayson Perrys or David Bowies. Art may ultimately become regarded as something machines do, not us - which is backwards and perverse.
“As we invent more species of AI, we will be forced to surrender more of what is supposedly
unique about humans. Each step of surrender—we are not the only mind that can play chess,fly a plane, make music, or invent a mathematical law—will be painful and sad.”
— Kevin Kelly
As AI-generated images fill the internet, there will be less real art to train the models on, so if demand keeps growing, we can expect them to be fed more AI-generated images instead. It’s easy to see where that leads - a steady degradation of quality as copies are copied over and over again, and the richness of the original work fades from memory. AI art is ultimately a race to the bottom. 
Whilst the AI companies claim to be taking us towards the future, I for one find their vision  to 
be cynical and cold. Follow this through, and it leads to a world where humans express creativity only through a corporate-owned platform which we pay for on a monthly subscription. Do we really want the means to create art to be taken and privatised? This is the direction we’re headed, unless we decide to say no.
The fight back
All of this is rather depressing - and it should be - but there is good news, too. Many people 
aren’t taking this lying down, and a strong and steadfast call for change is growing by the day.
At the grassroots level, professional artists and illustrators have been staging protests by filling The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
25 of 36 3/14/2025, 2:34 AM


community sites like DevinatArt  and ArtStation  with a tidal wave of protest placards. In 
addition, many of the companies that produce the software and sites creatives use, have 
fou nd themselves needing to clarify their stance in the face of widespread unrest. Where 
companies have always claimed to be supportive of artists, now they’re being asked to prove it through their actions - by for example, banning AI art from their sites.
Simultaneously, New-York based illustrator Molly Crabapple has posted an open letter  and 
petition, calling for book and magazine publishers to take a stand with artists and refuse to use The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
26 of 36 3/14/2025, 2:34 AM


AI art. Letters like this have become focal points for thousands of supporters, and Crabapple’s 
includes signatures from high profile people such as author Naomi Klein and actor Jon Cusack. 
But some artists have been brave enough to take their challenge all the way to court. After 
discovering that her work has been used to train AI models without her consent, concept artist 
Karla Ortiz  - along with two other artists - is driving a class-action lawsuit against StabilityAI, 
Midjourney and DeviantArt. Their legal challenge cites copyright infringement, unfair com
petition and reputational harm. Karla’s fight has helped bring public attention to the plight 
of artists and raise awareness about the real human impact of AI.
“If we’re going to talk about what really stops people from pursuing art, it’s those economic
issues. It’s issues like a lack of universal health care, few meaningful grants for artists, and thefact that most of us are just a missed paycheck away from homelessness and hunger. Thisdoesn’t solve that.”
— Karla OrtizThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
27 of 36 3/14/2025, 2:34 AM


Illustration by Karla Ortiz. Source: https:/ /shorturl.at/avCX1
At the time of writing, big players such as The New York Times  and Getty Images  have also 
launched their own lawsuits, adding significant weight behind the call for justice. With all this 
mou nting pressure, it seems unlikely that image generators will be able to continue as they 
have been for much longer.
Last year, an art competition at the Colorado State Fair was unwittingly won by an Midjourney-
generated image. Jason Allen, the man behind it, only admitted using AI after he had won the competition, and was subsequently disqualified. Nevertheless, he contested the decision amid heated debate over what constituted both ‘art’ and ‘artist,’  
Around the same time, a man named Stephen Thaler tried to get US copyright for  an image he 
produced with AI which he called ‘A Recent Entrance to Paradise.’ In court, he argued that an AI model should be granted a copyright because we’ve been using mechanical devices like cameras for years. He didn’t convince the federal judge however, who ruled that "human authorship is an essential part of a valid copyright claim."The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
28 of 36 3/14/2025, 2:34 AM


I firmly agree with that judge. Whilst artists regularly use different devices to produce art, they 
are always the source of imagination and skill, and always directly controlling the tools. With AI art, the user is no longer in any real control of what comes out, and so should not be considered its author.
‘Théâtre D’opéra Spatial’ - made by Midjourney from a prompt by Jason Allen - which 
contraversially won first prize in the 2023 Colorado State Fair art competition. Source: https:/ /shorturl.at/fhkow
The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
29 of 36 3/14/2025, 2:34 AM


‘A Recent Entrance to Paradise’ - made by AI from a prompt by Stephen Thaler - who tried and 
failed to win a copyright issue for the machine as an author. Source: https:/ /shorturl.at/eoALO
Copyright law, design registration and similar legal frameworks exist to protect the livelihoods of creatives. They’re old and far from perfect, but nevertheless deserve to be protected. Copyright law reinforces the value of their work and ensures artists - many of whom are self-employed - get some small amount of pay when sick or something in retirement. If AI can just ignore copyright law, then it can take away what little income protection artists have.
Art software giant Adobe are now attempting a more ethical take on generative AI with 
Firefly . 
Targeted at creatives, Firefly claims to retain an evidence trail linking results to the original 
inp ut images, though how well this will work is still unclear. Adobe and others are also trying to 
establish some governance with a universal ‘Do Not Train’ tag which might protect artists’ work from being scraped by AI models. One has to ask though, why the onus should be on the The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
30 of 36 3/14/2025, 2:34 AM


artists to enforce protection, rather than reigning in AI in the first place.
Firefly - Adobe’s first attempt at a more ethical image generator. Source: https:/ /t.ly/mxNZq
Another way artists can protect their work is with Glaze . A software tool created by a team at 
the University of Chicago, Glaze allows artists to invisibly encrypt their digital artworks to 
pre vent AI models using them.
Whilst the images remain unchanged to the human eye, they will now completely confuse AI models attempting to train on them. It’s an active digital watermark that just might afford creatives some genuine protection and peace of mind whilst the legal and commercial worlds struggle to catch up.The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
31 of 36 3/14/2025, 2:34 AM


Glaze offers artists protection against unwanted scraping by AI models
Source: https:/ /shorturl.at/apvL3
Constructive criticism
I’m never one to just complain without offering a better suggestion, so the last thing to address 
is - what’s a more positive way forward?
Ideally, I would love to see AI image generators disappear in their current form. I’m a designer, 
and the reason I became one in the first place was to make technology revolve around people. If we don’t know how something will benefit people, then why should we bring it into the world in the first place? If it actively harms people, then we should stop immediately, and rethink what we’re doing. That’s why I’d like to see these tools rethought by people with a stronger understanding of the impact on working artists.
The money and resources put behind AI tools today could be redirected towards goals that 
really benefit society. It would be encouraging to see a human-centric exploration of how AI could be put to better use and to have the outcomes thought through, prototypes trialled and communities’ feedback sought, before anything is launched. 
I would like to see copyright law updated and reinforced to tackle this new type of problem, 
with a focus on protecting the livelihoods of working artists, and recognition of the value their The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
32 of 36 3/14/2025, 2:34 AM


art brings to society. Hopefully the lawsuits happening at the time of writing will set a 
precedent for this and lead to greater legal protections.
I learned recently that Stable Diffusion allows people to train their own custom AI models 
using their own training datasets. If people were legally required to own or have permission to use all the data they put into models, that would certainly be a step in the right direction - perhaps by requiring companies to keep copies of the original datasets - though this alone would not undo the damage that’s already been caused.
Photo by Elena Mozhvilo. Source: https:/ /shorturl.at/sxGN8
A wonderful legacy
But above all else, perhaps this drama could remind us all of the value of art and how it 
enriches our lives. We’re coming precariously close to destroying something that in no small part makes the world a  place worth living in, and enables society to function through expression, reflection and connection. We’re lost without art, and we cannot afford to take it The harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
33 of 36 3/14/2025, 2:34 AM


for granted.
What if we all decided to say no to AI, and instead worked up the courage to try and draw, or 
paint, or sculpt by ourselves? What if the strange, artificial taste of ‘AI art’ left us dissatisfied, and curious enough about creativity to start doodling with a biro in our notebook? It might feel good, and it might spark a flicker of creative confidence. After all, we all drew as children, but as we’ve got older, we’ve forgotten how.
What a wonderful legacy AI art might have, if it disappeared and made all of us into artists. 
Artists who need nothing more than pencil, paper and our own feelings as inspiration. We had everything we needed, all along.
Further reading & listening
Podcasts
•Why AI is a Threat to Artists w/ Molly Crabapple  : Tech Won’t Save Us Podcast, Episode
174
•AI Criticism has a Decades-Long History w/ Ben Tarnoff  : Tech Won’t Save Us Podcast,
Episode 182
•The Human Side of the AI Underclass w/ Joanne McNeil  : Tech Won’t Save Us Podcast,
Episode 196
•The Future of the State w/ James Plunkett  : Jon Richardson & The Futurenauts, Season
3, Episode 4
Books
•Blood in the Machine: The Origins of the Rebellion Against Big Tech  by Brian Merchant
•Resisting AI: An Anti-Fascist Approach to Artificial Intelligence  by Dan McQuillan
• Hello World: Being Human in the Age of Algorithms – Hannah Fry
ArticlesThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
34 of 36 3/14/2025, 2:34 AM


•AI-Generated Art Controversy: The Future of Creativity or a Replacement for Human
Talent?  by Adam Hencz for Artland
•Restrict AI from Publishing: An Open Letter  by Molly Crabapple for The Center for
Artistic Inquiry and Reporting
•Independent Artists Are Fighting Back Against A.I. Image Generators With Innovative
Online Protests  by Richard Whiddington for Artnet
•Molly Crabapple Has Posted an Open Letter by 1,000 Cultural Luminaries Urging
Publishers to Restrict the Use of ‘Vampirical’ A.I.-Generated Images  by Jo Lawson-
Tancred for Artnet
•No, teaching AI to copy an artist’s style isn’t ‘democratization.’ It’s theft  by Soleil Ho for
The San Fransisco Chronicle
•Stability AI swerves copyright infringement allegations in response to Getty lawsuit by
Tim Smith and Kai Nicol-Schwarz for Sifted
•Glaze protects art from prying AIs  by Natasha Lomas for TechCrunch
•US judge: Art created solely by artificial intelligence cannot be copyrighted'  by Jon
Brodkin for ArsTechnica
•The US Copyright Office says an AI can’t copyright its art  by Adi Robertson for The
Verge
•Weizenbaum’s Nightmares: How the inventor of the first chatbot turned against AI by
Ben Tarnoff for The Guardian
•AI Machines aren’t ‘hallucinating,’ but their makers are  by Naomi Klein forThe Guardian
•How Adobe is managing the AI copyright dilemma, with general counsel Dana Raoby
Nilay Patel for The Verge
•Why Generative AI Angers Artists but Not Writer s by Alberto Romero for The
Algorithmic Bridge
•AI: Digital artist's work copied more times than Picasso  by Clare Hutchinson & Phil John
for BBC News
•This artist is dominating AI-generated art. And he’s not happy about it  by Melissa
Heikkiläarchive page for MIT Technology ReviewThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
35 of 36 3/14/2025, 2:34 AM


Matt Corrall
© Copyright Matt Corrall 2023
All Ultraleap content © Copyright Ultraleap Ltd 2023How to get into XR as a
designerai - aiart - generativeai - art - artists - illustration - technology - automation -
disruption - tech•Artists slam Marvel over AI-generated credits in Secret Invasion  by Mark Sellman for
The Times
•Courts are using AI to sentence criminals. That must stop now  by Jason Tashea for
Wired
•The New York Times is suing OpenAI and Microsoft for copyright infringement  by Emma
Roth for The Verge
•Getty gets tough on London-based AI firm  by William Charrington and Hoi-Yee Roper for
Farrer & CoThe harm & hypocrisy of AI art — Matt Corrall https://www.corralldesign.com/writi crisy
36 of 36 3/14/2025, 2:34 AM


WINTER STORM 2021
ERCOT overcharged power companies $16
billion for electricity during winter freeze,ﬁrm says
An independent market monitor for the Public Utility Commission of Texas wrote
in a letter that the power grid operator kept market prices too high for nearlytwo days after widespread outages ended.
BY ERIN DOUGLAS  AND MITCHELL FERMAN MARCH 4, 2021 UPDATED: 8 PM CENTRAL SHARE
The Electric Reliability Council of Texas made a $16 billion error in pricing during the week
of the winter storm that caused power outages across the state, according to a ﬁling by its
market monitor .
Potomac Economics, the independent market monitor for the Public Utility Commission of
Texas, which oversees ERCOT, wrote in a letter to the Public Utility Commission that ERCOT
kept market prices for power too high for nearly two days after widespread outages ended
late the night of Feb. 17. It should have reset the prices the following day.
That decision to keep prices high, the market monitor claimed, resulted in $16 billion in
additional costs to Texas power companies. The news of the overcharging was ﬁrst reported
by Bloomberg.
Some of the providers that were charged during the high price period could pass the costs to
customers, depending on the type of contract they have, according to Detlef Hallermann,
director of the Reliant Energy Trade Center at Texas A&M University.
In Texas, wholesale power prices are determined by supply and demand: When demand is
high, ERCOT allows prices to go up. During the storm, PUC directed the grid operator to set
wholesale power prices at $9,000 per megawatt hour — the maximum price. Raising prices is
intended to incentivize power generators in the state to add more power to the grid.
Companies then buy power from the wholesale market to deliver to consumers, which they
are contractually obligated to do.
Because ERCOT failed to bring prices back down on time, companies had to buy power in
the market at inﬂated prices.ERCOT overcharged for electricity in Texas by $16 billion during freeze... https://www.texastribune.org/2021/03/04/ercot-texas- llion/
1 of 3 3/14/2025, 3:23 AM


The error will likely result in higher levels of defaults, wrote Carrie Bivens, a vice president
of Potomac Economics, the ﬁrm that monitors the grid operator. She said the PUC should
direct ERCOT to remove the pricing interventions that occurred after outages ended, and
allowing them to remain would result in “substantial and unjustiﬁed” economic harm.
At least $1.5 billion could be passed on to retail electric providers and their customers.
Some retail providers have already begun to ﬁle for bankruptcy.
“They’re going to suffer the most,” Hallermann said.
Retail power providers have been in ﬁnancial distress  across Texas since the storm; many
were forced to buy power on the wholesale market at extremely high prices.
Brazos Electric Power Cooperative Inc., Texas’ largest power cooperative, has already ﬁled
for bankruptcy protection  after incurring $2.1 billion in combined charges owed to ERCOT,
according to court documents ﬁled Monday.
Many retail power providers complained in ﬁlings to regulators that generators of
electricity, which were unable to produce enough power during the storm, proﬁ ted and left
retail companies scrambling.
“The ERCOT market was not designed to deal with an emergency of this scale,” wrote
Patrick Woodson, CEO of ATG Clean Energy Holdings, a retail power provider based in
Austin, to the Public Utility Commission. The pricing failure, he wrote, “has pushed the
entire market to the brink of collapse.”
Bivens wrote that while she recognizes that retroactively revising the prices is “not ideal,”
correcting the error will reﬂect the accurate supply and demand for power during the period
after the outages.
Cathy Webking of the Texas Energy Association for Marketers told lawmakers during a
Texas Senate Committee on Business and Commerce meeting Thursday that prices should
be set back to what the market value would have been.
“There are more defaults imminent. Immediate action is required,” Webking said.
A spokesperson for ERCOT declined to comment on the matter.
Kenan Ogelman, the ERCOT vice president of commercial operations, who testiﬁed during a
Texas Senate committee hearing Thursday, was not asked by state senators about ERCOT’s
$16 billion mistake. Sen. Kelly Hancock, R-North Richland Hills, who chairs the BusinessERCOT overcharged for electricity in Texas by $16 billion during freeze... https://www.texastribune.org/2021/03/04/ercot-texas- llion/
2 of 3 3/14/2025, 3:23 AM


and Commerce committee, did not indicate what action he or other senators would take on
the various ﬁnancial ripple effects from the winter storm.
“There are ﬁnancial concerns — let’s put it that way — that we have to address,” Hancock
said.
Reese Oxner and Shannon Najmabadi contributed to this report.
Learn about The Texas Tribune’s policies, including our partnership with
The Trust Project to increase transparency in news.ERCOT overcharged for electricity in Texas by $16 billion during freeze... https://www.texastribune.org/2021/03/04/ercot-texas- llion/
3 of 3 3/14/2025, 3:23 AM


How T exas ʼ Drive for Energy
Independence Set It Up for Disaster
T exas has refused to join interstate electrical grids and railed against energy regulation.
Now itʼs having to answer to millions of residents who were left without power in last
weekʼs snowstorm.
By Clifford Krauss, Manny Fernandez, Ivan Penn and Rick Rojas
Published Feb. 21, 2021 Updated May 13, 2021
HOUSTON — Across the plains of West Texas, the pump jacks that resemble giant
bobbing hammers define not just the landscape but the state itself: Texas has been built
on the oil-and-gas business for the last 120 years, ever since the discovery of oil on
Spindletop Hill near Beaumont in 1901.
Texas , the nation’s leading energy-producing state, seemed like the last place on Earth
that could run out of energy.
Then last week, it did.
The crisis could be traced to that other defining Texas trait: independence, both from big
government and from the rest of the country. The dominance of the energy industry and
the “Republic of Texas” ethos became a devastating liability when energy stopped flowing
to millions of Texans who shivered and struggled through a snowstorm that paralyzed
much of the state.
Part of the responsibility for the near-collapse of the state’s electrical grid  can be traced to
the decision in 1999 to embark on the nation’s most extensive experiment in electrical
deregulation, handing control of the state’s entire electricity delivery system to a market-
based patchwork of private generators, transmission companies and energy retailers.
The energy industry wanted it. The people wanted it. Both parties supported it.
“Competition in the electric industry will benefit Texans by reducing monthly rates and
offering consumers more choices about the power they use,” George W. Bush, then the
governor , said as he signed the top-to-bottom deregulation legislation.https://www.nytimes.com/2021/02/21/us/texas-electricity-ercot-
blackouts.htmlTexas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
1 of 9 3/14/2025, 3:22 AM


Mr . Bush’s prediction of lower-cost power generally came true, and the dream of a free-
market electrical grid worked reasonably well most of the time, in large part because
Texas had so much cheap natural gas as well as abundant wind to power renewable
energy. But the newly deregulated system came with few safeguards and even fewer
enforced rules.
With so many cost-conscious utilities competing for budget-shopping consumers, there
was little financial incentive to invest in weather protection and maintenance. Wind
turbines are not equipped with the de-icing equipment routinely installed in the colder
climes of the Dakotas and power lines have little insulation. The possibility of more
frequent cold-weather events was never built into infrastructure plans in a state where
climate change remains an exotic, disputed concept.
“Deregulation was something akin to abolishing the speed limit on an interstate highway,”
said Ed Hirs, an energy fellow at the University of Houston. “That opens up shortcuts
that cause disasters.”
The state’s entire energy infrastructure was walloped with glacial temperatures that even
under the strongest of regulations might have frozen gas wells and downed power lines.
But what went wrong was far broader: Deregulation meant that critical rules of the road
for power were set not by law, but rather by a dizzying array of energy competitors.
Utility regulation is intended to compensate for the natural monopolies that occur when a
single electrical provider serves an area; it keeps prices down while protecting public
safety and guaranteeing fair treatment to customers. Yet many states have flirted with
deregulation as a way of giving consumers more choices and encouraging new providers,
especially alternative energy producers.
California, one of the early deregulators in the 1990s, scaled back its initial foray after
market manipulation  led to skyrocketing prices and rolling blackouts.
States like Maryland allow customers to pick from a menu of producers. In some states,
competing private companies offer varied packages like discounts for cheaper power at
night. But no state has gone as far as Texas, which has not only turned over the keys toSign up for Your Places: Extreme Weather.   Get notified about extreme
weather before it happens with custom alerts for places in the U.S. you
choose. Get it sent to your inbox.Texas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
2 of 9 3/14/2025, 3:22 AM


the free market but has also isolated itself from the national grid, limiting the state’s
ability to import power when its own generators are foundering.
Consumers themselves got a direct shock last week when customers who had chosen
variable-rate electricity contracts found themselves with power bills of $5,000 or more.
While they were expecting extra-low monthly rates, many may now face huge bills as a
result of the upswing in wholesale electricity prices during the cold wave. Gov. Greg
Abbott on Sunday said the state’s Public Utility Commission has issued a moratorium on
customer disconnections for non-payment and will temporarily restrict providers from
issuing invoices.
A family in Austin, Texas, kept warm by a fire outside their apartment on Wednesday. They lost power early
Monday morning. Tamir Kalifa for The New York TimesTexas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
3 of 9 3/14/2025, 3:22 AM


There is regulation in the Texas system, but it is hardly robust. One nonprofit agency, the
Electric Reliability Council of Texas, or ERCOT, was formed to manage the wholesale
market. It is supervised by the Public Utility Commission, which also oversees the
transmission companies that offer customers an exhaustive array of contract choices
laced with more fine print than a credit card agreement.
But both agencies are nearly unaccountable and toothless compared to regulators in
other regions, where many utilities have stronger consumer protections and submit an
annual planning report to ensure adequate electricity supply. Texas energy companies
are given wide latitude in their planning for catastrophic events.
Into a snowstorm with no reserves
One example of how Texas has gone it alone is its refusal to enforce a “reserve margin” of
extra power available above expected demand, unlike all other power systems around
North America. With no mandate, there is little incentive to invest in precautions for
events, such as a Southern snowstorm, that are rare. Any company that took such
precautions would put itself at a competitive disadvantage.
A surplus supply of natural gas, the dominant power fuel in Texas, near power plants
might have helped avoid the cascade of failures in which power went off, forcing natural
gas production and transmission offline, which in turn led to further power shortages.
In the aftermath of the dayslong outages, ERCOT has been criticized by both Democratic
and Republican residents, lawmakers and business executives, a rare display of unity in a
fiercely partisan and Republican-dominated state. Mr . Abbott said he supported calls for
the agency’s leadership to resign and made ERCOT reform a priority for the Legislature.
The reckoning has been swift — this week, lawmakers will hold hearings in Austin to
investigate the agency’s handling of the storm and the rolling outages.
For ERCOT operators, the storm’s arrival was swift and fierce, but they had anticipated it
and knew it would strain their system. They asked power customers across the state to
conserve, warning that outages were likely.
But late on Sunday, Feb. 14, it rapidly became clear that the storm was far worse than
they had expected: Sleet and snow fell, and temperatures plunged. In the council’s
command center outside Austin, a room dominated by screens flashing with maps,
graphics and data tracking the flow of electricity to 26 million people in Texas, workers
quickly found themselves fending off a crisis. As weather worsened into Monday
morning, residents cranked up their heaters and demand surged.Texas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
4 of 9 3/14/2025, 3:22 AM


Power plants began falling offline in rapid succession as they were overcome by the frigid
weather or ran out of fuel to burn. Within hours, 40 percent of the power supply had been
lost.
The entire grid — carrying 90 percent of the electric load in Texas — was barreling
toward a collapse.
Much of Austin lost power last week due to rolling blackouts. Tamir Kalifa for The New York Times
In the electricity business, supply and demand need to be in balance. Imbalances lead to
catastrophic blackouts. Recovering from a total blackout would be an agonizing and
tedious process, known as a “black start,” that could take weeks, or possibly months.
And in the early-morning hours last Monday, the Texas grid was “seconds and minutes”Texas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
5 of 9 3/14/2025, 3:22 AM


away from such a collapse, said Bill Magness, the president and chief executive of the
Electric Reliability Council.
“If we had allowed a catastrophic blackout to happen, we wouldn’t be talking today about
hopefully getting most customers their power back,” Mr . Magness said. “We’d be talking
about how many months it might be before you get your power back.”
Earlier warnings of trouble
The outages and the cold weather touched off an avalanche of failures, but there had been
warnings long before last week’s storm.
After a heavy snowstorm in February 2011 caused statewide rolling blackouts and left
millions of Texans in the dark, federal authorities warned the state that its power
infrastructure had inadequate “winterization” protection. But 10 years later , pipelines
remained inadequately insulated and heaters that might have kept instruments from
freezing were never installed.
During heat waves, when demand has soared during several recent summers, the system
in Texas has also strained to keep up, raising questions about lack of reserve capacity on
the unregulated grid.
And aside from the weather , there have been periodic signs that the system can run into
trouble delivering sufficient energy, in some cases because of equipment failures, in
others because of what critics called an attempt to drive up prices, according to Mr . Hirs
of the University of Houston, as well as several energy consultants.
Another potential safeguard might have been far stronger connections to the two
interstate power-sharing networks, East and West, that allow states to link their electrical
grids and obtain power from thousands of miles away when needed to hold down costs
and offset their own shortfalls.
But Texas, reluctant to submit to the federal regulation that is part of the regional power
grids, made decisions as far back as the early 20th century to become the only state in the
continental United States to operate its own grid — a plan that leaves it able to borrow
only from a few close neighbors.
The border city of El Paso survived the freeze much better than Dallas or Houston
because it was not part of the Texas grid but connected to the much larger grid covering
many Western states.
But the problems that began with last Monday’s storm went beyond an isolated electricalTexas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
6 of 9 3/14/2025, 3:22 AM


grid. The entire ecosystem of how Texas generates, transmits and uses power stalled, as
millions of Texans shivered in darkened, unheated homes.
A surplus supply of natural gas, the dominant power fuel in Texas, near power plants might have helped
avoid the cascade of failures. Eddie Seal/Bloomberg
Texans love to brag about natural gas, which state officials often call the cleanest-burning
fossil fuel. No state produces more, and gas-fired power plants produce nearly half the
state’s electricity.
“We are struggling to come to grips with the reality that gas came up short and let us
down when we needed it most,” said Michael E. Webber , a professor of mechanical
engineering at the University of Texas at Austin.Texas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
7 of 9 3/14/2025, 3:22 AM


The cold was so severe that the enormous oil and natural gas fields of West Texas froze
up, or could not get sufficient power to operate. Though a few plants had stored gas
reserves, there was insufficient electricity to pump it.
The leaders of ERCOT defended the organization, its lack of mandated reserves and the
state’s isolation from larger regional grids, and said the blame for the power crisis lies
with the weather , not the overall deregulated system in Texas.
“The historic, just about unprecedented, storm was the heart of the problem,” Mr .
Magness, the council’s chief executive, said, adding: “We’ve found that this market
structure works. It demands reliability. I don’t think there’s a silver-bullet market
structure that could have managed the extreme lows and generation outages that we
were facing Sunday night.”
In Texas, energy regulation is as much a matter of philosophy as policy. Its independent
power grid is a point of pride that has been an applause line in Texas political speeches
for decades.
Deregulation is a hot topic among Texas energy experts, and there has been no shortage
of predictions that the grid could fail under stress. But there has not been widespread
public dissatisfaction with the system, although many are now wondering if they are
being well served.
“I believe there is great value in Texas being on its own grid and I believe we can do so
safely and securely and confidently going forward,” said State Representative Jeff Leach,
a Republican from Plano who has called for an investigation into what went wrong. “But
it’s going to take new investment and some new strategic decisions to make sure we’re
protected from this ever happening again.”
Steven D. Wolens, a former Democratic lawmaker from Dallas and a principal architect of
the 1999 deregulation legislation, said deregulation was meant to spur more generation,
including from renewable energy sources, and to encourage the mothballing of older
plants that were spewing pollution. “We were successful,” said Mr . Wolens, who left the
Legislature in 2005.
But the 1999 legislation was intended as a first iteration that would evolve along with the
needs of the state, he said. “They can focus on it now and they can fix it now,” he said.
“The buck stops with the Texas Legislature and they are in a perfect position to
determine the basis of the failure, to correct it and make sure it never happens again.”
Clifford Krauss  reported from Houston, Manny Fernandez and Ivan Penn from Los Angeles, and Rick Rojas from
Nashville. David Montgomery contributed reporting from Austin, Texas.Texas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
8 of 9 3/14/2025, 3:22 AM


Clifford Krauss  is a national energy business correspondent based in Houston. He joined The Times in 1990 and
has been the bureau chief in Buenos Aires and Toronto. He is the author of “Inside Central America: Its People,
Politics, and History.” More about Clifford Krauss
Manny Fernandez  is the Los Angeles bureau chief. He spent more than nine years covering Texas as the Houston
bureau chief. He joined The Times as a Metro reporter in 2005, covering the Bronx and housing. More about
Manny Fernandez
Ivan Penn  is a Los Angeles-based reporter covering alternative energy. Before coming to The Times in 2018 he
covered utility and energy issues at The Tampa Bay Times and The Los Angeles Times. More about Ivan Penn
Rick Rojas  is a national correspondent covering the American South. He has been a staff reporter for The Times
since 2014. More about Rick Rojas
A version of this article appears in print on , Section A, Page 1 of the New York edition with the headline: Texas Ofﬁcials Had Few
Rules For Power GridTexas Power Grid Run by ERCOT Set Up the State for Disaster - The ... https://www.nytimes.com/2021/02/21/us/texas-electr out...
9 of 9 3/14/2025, 3:22 AM


WINTER STORM 2021
ERCOT overcharged power companies $16
billion for electricity during winter freeze,ﬁrm says
An independent market monitor for the Public Utility Commission of Texas wrote
in a letter that the power grid operator kept market prices too high for nearlytwo days after widespread outages ended.
BY ERIN DOUGLAS  AND MITCHELL FERMAN MARCH 4, 2021 UPDATED: 8 PM CENTRAL SHARE
The Electric Reliability Council of Texas made a $16 billion error in pricing during the week
of the winter storm that caused power outages across the state, according to a ﬁling by its
market monitor .
Potomac Economics, the independent market monitor for the Public Utility Commission of
Texas, which oversees ERCOT, wrote in a letter to the Public Utility Commission that ERCOT
kept market prices for power too high for nearly two days after widespread outages ended
late the night of Feb. 17. It should have reset the prices the following day.
That decision to keep prices high, the market monitor claimed, resulted in $16 billion in
additional costs to Texas power companies. The news of the overcharging was ﬁrst reported
by Bloomberg.
Some of the providers that were charged during the high price period could pass the costs to
customers, depending on the type of contract they have, according to Detlef Hallermann,
director of the Reliant Energy Trade Center at Texas A&M University.
In Texas, wholesale power prices are determined by supply and demand: When demand is
high, ERCOT allows prices to go up. During the storm, PUC directed the grid operator to set
wholesale power prices at $9,000 per megawatt hour — the maximum price. Raising prices is
intended to incentivize power generators in the state to add more power to the grid.
Companies then buy power from the wholesale market to deliver to consumers, which they
are contractually obligated to do.
Because ERCOT failed to bring prices back down on time, companies had to buy power in
the market at inﬂated prices.ERCOT overcharged for electricity in Texas by $16 billion during freeze... https://www.texastribune.org/2021/03/04/ercot-texas- llion/
1 of 3 3/14/2025, 3:23 AM


The error will likely result in higher levels of defaults, wrote Carrie Bivens, a vice president
of Potomac Economics, the ﬁrm that monitors the grid operator. She said the PUC should
direct ERCOT to remove the pricing interventions that occurred after outages ended, and
allowing them to remain would result in “substantial and unjustiﬁed” economic harm.
At least $1.5 billion could be passed on to retail electric providers and their customers.
Some retail providers have already begun to ﬁle for bankruptcy.
“They’re going to suffer the most,” Hallermann said.
Retail power providers have been in ﬁnancial distress  across Texas since the storm; many
were forced to buy power on the wholesale market at extremely high prices.
Brazos Electric Power Cooperative Inc., Texas’ largest power cooperative, has already ﬁled
for bankruptcy protection  after incurring $2.1 billion in combined charges owed to ERCOT,
according to court documents ﬁled Monday.
Many retail power providers complained in ﬁlings to regulators that generators of
electricity, which were unable to produce enough power during the storm, proﬁ ted and left
retail companies scrambling.
“The ERCOT market was not designed to deal with an emergency of this scale,” wrote
Patrick Woodson, CEO of ATG Clean Energy Holdings, a retail power provider based in
Austin, to the Public Utility Commission. The pricing failure, he wrote, “has pushed the
entire market to the brink of collapse.”
Bivens wrote that while she recognizes that retroactively revising the prices is “not ideal,”
correcting the error will reﬂect the accurate supply and demand for power during the period
after the outages.
Cathy Webking of the Texas Energy Association for Marketers told lawmakers during a
Texas Senate Committee on Business and Commerce meeting Thursday that prices should
be set back to what the market value would have been.
“There are more defaults imminent. Immediate action is required,” Webking said.
A spokesperson for ERCOT declined to comment on the matter.
Kenan Ogelman, the ERCOT vice president of commercial operations, who testiﬁed during a
Texas Senate committee hearing Thursday, was not asked by state senators about ERCOT’s
$16 billion mistake. Sen. Kelly Hancock, R-North Richland Hills, who chairs the BusinessERCOT overcharged for electricity in Texas by $16 billion during freeze... https://www.texastribune.org/2021/03/04/ercot-texas- llion/
2 of 3 3/14/2025, 3:23 AM


and Commerce committee, did not indicate what action he or other senators would take on
the various ﬁnancial ripple effects from the winter storm.
“There are ﬁnancial concerns — let’s put it that way — that we have to address,” Hancock
said.
Reese Oxner and Shannon Najmabadi contributed to this report.
Learn about The Texas Tribune’s policies, including our partnership with
The Trust Project to increase transparency in news.ERCOT overcharged for electricity in Texas by $16 billion during freeze... https://www.texastribune.org/2021/03/04/ercot-texas- llion/
3 of 3 3/14/2025, 3:23 AM


Illustration by Tyler Comrie
ENERGY
The Texas Electric Grid
Failure Was a Warm-up
One year after the deadly blackout, o ﬃcials have done
little to prevent the next one—which could be far worse.
By 
February 2022Russell Gold
The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
1 of 29 3/14/2025, 3:21 AM


Anthony Mecke had drifted to sleep in the break room when a loud
knock roused him at 1:23 a.m. “We just got the call,” a coworkersaid.
Mecke, a moonfaced 45-year-old, is the manager of systems
operation training at CPS Energy, the city-owned electricity provider that
serves San Antonio. He started at the company not long after high school,working at one point as a cable splicer, a job he performed in hot tunnelsbeneath the sidewalks of San Antonio. He thought he’d seen it all. But whenhe hustled from the break room, where he’d sneaked in a power nap after anall-day shift, into the company’s cavernous control room, housed in atornado-proof building on the city’s East Side, what he witnessed unsettledhim. 
This was Monday, February 15, 2021. A winter storm had brought unusually
frigid temperatures to the entire middle swath of the United States, from theCanadian border to the Rio Grande. In San Antonio, it dropped to 9 degrees.In Fort Worth, the storm’s icy arrival a few days earlier had led to a 133-vehicle pileup that left 6 dead. Abilene and Pﬂugerville had advised residentsto boil their water, the ﬁrst of thousands of such warnings that wouldeventually aﬀect 17 million Texans. Across the state, families hunkered downand did anything they could to stay warm. The overwhelming majority ofTexas homes are outﬁtted with electric heaters that are the technologicalequivalent of a toaster oven. During the most severe cold fronts, residentscrank up those ineﬃcient units, and some even turn on and open electricovens and use hair dryers.     
The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
2 of 29 3/14/2025, 3:21 AM


The control room at CPS Energy, in San Antonio.
Photograph by Jeff Wilson
Mecke could track the spiking energy use in real time. One wall of the control
room is covered in enormous computer monitors displaying maps and data.He scanned for one particular piece of information. The state’s electricityreserves, which are tapped to prevent emergencies, were already depleted.The problem wasn’t just surging demand. Power plants all across the gridwere shutting oﬀ, incapacitated by frozen equipment and a dearth of naturalgas, the primary source of fuel.
The Texas power grid was, at that moment, like an airplane low on fuel that
needed to jettison cargo to stay aloft. That’s what the call had been about.The state’s grid operator, the Electric Reliability Council of Texas, or ERCOT,had just told CPS Energy and ﬁfteen of the state’s other electric utility
companies to immediately begin turning oﬀ power  for portions of theirThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
3 of 29 3/14/2025, 3:21 AM


companies to immediately begin turning oﬀ power  for portions of their
service areas. The result would be blackouts.
Nobody yet knew just how widespread the blackouts would become—that
they would spread across almost the entire state, leave an unprecedented 11million Texans freezing in the dark for as long as three days, and result in asmany as 
seven hundred deaths. But neither could the governor, legislators,
and regulators who are supposed to oversee the state’s electric grid claim tobe surprised. They had been warned repeatedly, by experts and by previouscalamities—including a major blackout in 2011—that the grid was uniquelyvulnerable to cold weather. 
Unlike most other states that safely endured the February 2021 storm, Texas
had stubbornly declined to require winterization of its power plants and, justas critically, its natural gas facilities. In large part, that’s because the state’spoliticians and the regulators they appoint are often captive to the oil andgas industry, which lavishes them with millions of dollars a year in campaigncontributions. During the February freeze, the gas industry failed to delivercritically needed fuel, and while Texans of all stripes suﬀered, the gasindustry scored windfall proﬁts of about $11 billion—creating debts thatresidents and businesses will pay for at least the next decade.
Since last February, the state has appointed new regulators and tweaked
some of its statutes. But despite the misery, death, economic disruption, andembarrassment that Texas suﬀered, 
little has changed. The state remains
susceptible to the threat that another winter storm could inﬂict
blackouts as bad as—or even worse than—last year’s catastrophe. Despitepromises from public oﬃcials to rectify these problems, we remain largelydefenseless and can only hope we aren’t thrashed by another Arctic blast.Even as forecasters predict a relatively warm winter on average, 
there is
compelling evidence that such extreme weather phenomena are becoming
more common. To understand the danger, it’s worth examining how closethe Texas grid came last year to a meltdown that could have left much of thestate without power for several weeks, or even months.
The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
4 of 29 3/14/2025, 3:21 AM


Aerial view of Dallas’s Highland Meadows neighborhood on February 15, 2021.
Isaac Murray/Getty
Two days before Mecke was awakened in his oﬃce, ERCOT had held an
emergency conference call to warn the state’s utilities and rural electriccooperatives that blackouts were likely. ERCOT oﬃcials said the grid mighthave to shed as much as 7,500 megawatts—eﬀectively darkening roughly oneof every eight homes in the state. That’s nearly twice as much as the lastcontrolled load shed, in 2011, when rolling blackouts had lasted as long aseight hours, which in turn was four times longer than the previous large-scale blackout, in 2006. 
The worst-case scenario ERCOT had gamed out, what it called “extreme
winter,” contemplated a record-setting demand of 67.2 gigawatts. Electricityconsumption blew past that mark at 7 p.m. on February 14. Meanwhile,electricity supply continued to dwindle as underinsulated power plants wentdown, one after another.
F
or the grid to function properly, the supply of electricity must always matchThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
5 of 29 3/14/2025, 3:21 AM


or the grid to function properly, the supply of electricity must always match
demand; this equilibrium is reﬂected in the grid’s frequency, which usually
remains steady at 60 hertz. Power plants across the state are tuned in to thefrequency, and they automatically increase or decrease generation tomaintain equilibrium. The grid is like a giant synchronized machine, itscomponents linked across hundreds of miles, from Midland to Houston,from Amarillo to Brownsville. On this night, as demand drastically outpacedsupply, the frequency dropped and the vast machine began churning faster.But eventually it couldn’t compensate on its own.
By 1:23 a.m., ERCOT could no longer delay action. An operator in its control
room picked up the hotline phone, which was wired to sixteen of the state’sutility companies, and ordered a thousand-megawatt load shed statewide.“You practice for this for years,” Mecke said. “You hope it never happens.” 
In fact, a few hours earlier, he’d run his coworkers through a simulation of a
nearly identical load shed. When the time came to carry out the operationfor real, there were no hiccups. “It was surprisingly calm,” he said. “It wassmooth.” Within seconds, electricity in parts of San Antonio began to blinkoﬀ. Mecke, hopeful that the grid would stabilize, breathed a sigh of relief. Thecalm was short-lived.
The frequency should have risen after the load shed, but instead it kept
falling. It was “nerve-racking,” said Mecke. 
At 1:47 a.m., the hotline phone rang again. Everyone in the CPS control
center stopped what they were doing. ERCOT needed another thousandmegawatts cut. Because of coronavirus precautions, CPS executives weren’tin the control room. Rudy Garza, the chief customer oﬃcer, tracked thefrequency’s dangerous decline on his phone, texting back and forth withindustry friends and former coworkers from across the state. “We werescared,” he said.
CenterPoint Energy, a utility in Houston, runs a control room similar to that
of CPS. Eric Easton, CenterPoint’s vice president of real-time operations,was hastening to execute the second round of blackouts when the hotline
phone rang for the third time, at 1:51 a.m. ERCOT ordered another threeThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
6 of 29 3/14/2025, 3:21 AM


phone rang for the third time, at 1:51 a.m. ERCOT ordered another three
thousand megawatts—more than the ﬁrst two combined. “Calls started
coming in so fast that they were overlapping,” said Easton. “When are wegoing to stop shedding load?” he wondered.
But the situation was only growing more dire. At the precise time of the third
call, the frequency reached a critical threshold: 59.4 hertz. The Texas grid,which has been around in some form since World War II, had only once in itshistory fallen this low. Automated turbines across the state began spinningeven faster to produce more electricity, but when the frequency dips below59.4 hertz, the turbines reach speeds and pressures that can causecatastrophic damage to them, requiring that they be repaired or replaced.This scenario was unlikely because, to prevent it, the grid automaticallytriggers a nine-minute countdown when it strikes 59.4 hertz. If thefrequency did not rise in time, power plants would shut down and the gridwould begin turning itself oﬀ completely. This would leave all 26 millionTexans who relied on the ERCOT grid without power for weeks or months. 
A few more minutes ticked by. The frequency kept falling, touching 59.302
hertz, yet another alarming precipice. At 59.3 hertz, human operators aretaken out of the equation: they are too slow to make the urgent adjustmentsthat are needed to stabilize the grid. The system is programmed toautomatically start blacking out as many areas as are necessary to balancepower supply and demand. But in this scenario, that fail-safe may not haveworked because so many areas had already been manually cut oﬀ. “We wereon the very edge,” said Easton. 
In a last-ditch eﬀort to prevent the grid’s collapse, ERCOT placed a fourth
hotline call, at 1:55 a.m., and ordered another 3,500 megawatts. All acrossTexas, grid operators were moving as quickly as they could, blacking outmore and more neighborhoods, but they were running out of options. As thecountdown approached zero, the frequency suddenly shot back up. Theimmediate crisis was over—the last-second load shed had worked—but formost of the following day, the grid remained dangerously unstable. 
The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
7 of 29 3/14/2025, 3:21 AM


Bill Magness, former CEO of ERCOT, testifying at the Texas House.
Eric Gay/AP
It is hard to fathom the devastation a total shutdown would have wreaked.
Bill Magness, then the CEO of ERCOT, would explain as much to the TexasSenate ten days later. Magness is a lawyer with a buzz cut and ramrod-straight posture who spent time in the nineties and aughts as a practicingBuddhist. “What my team and the folks at the utilities in Texas would bedoing is an exercise called ‘black start,’ ” he said. A black start would haverequired carefully rebooting a few power plants at a time and using them tojump-start others, thereby restoring the grid piece by piece. It’s not a matterof ﬂipping switches. The steps required for a black start are numerous,complex, and delicate. No one knows how long that process would take,because no one has ever needed to do it. Magness said it would have beenweeks at least. 
Most of the state’s residents would have been without heat, potable water, or
light, as would almost all of the businesses on which they depend. Traﬃclights wouldn’t have worked. Caravans of trucks, likely escorted by theNational Guard, would have delivered fuel to generators to keep hospitals(many of which were nearly at max capacity because of COVID-19), ﬁre
departments, and other emergency services operating. When the freezeThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
8 of 29 3/14/2025, 3:21 AM


Idepartments, and other emergency services operating. When the freeze
lifted and the roads thawed, many would have attempted an exodus into
neighboring states—all of which, with a few brief exceptions, kept power—but even that would have proved diﬃcult because gas pumps run onelectricity. Magness looked grimly around the Senate chamber as hedescribed the doomsday scenario. “Imagine: the suﬀering that we saw [wouldhave been] compounded.”
An Oncor power substation in Waco on February 18, 2021.
Photograph by Matthew Busch
n her ground-ﬂoor apartment on Uvalde Road, a busy commercial
thoroughfare in the Cloverleaf community, just east of Houston, MaryGee liked to sit by the window, watching the people and cars passingby. Across the way were an auto-parts store, a car wash, and a Tex-Mexrestaurant. There was always something happening. But the snow and
ice in February brought Uvalde to a standstill. 
The neighborhood lost power early Monday morning, February 15. After the
sun rose, a few neighbors ventured out. Word passed in Gee’s complex, theHavenwood, that a nearby Burger King was open—that would have meantnot only food but warmth. Some decided to check it out. This wasn’t anoption for Gee. She was relatively healthy, but at 84, walking more than amile on slippery sidewalks was out of the question.
“It kind of felt like the end of the world,” said Christion Jones, who lived a
few doors down from Gee. Other residents sat in cars to warm up, theirengines idling, the exhaust forming small clouds in the frigid air. But Gee hadstopped driving years before and had given the last car she owned to a god-granddaughter. 
Gee had grown up with eight brothers and sisters, and much of her childhood
was spent in a rural house with a wood-burning heater in the small town ofNormangee, between Houston and Waco. She had worked as a nurse formore than twenty years at Houston Methodist hospital. On weekends, sheThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
9 of 29 3/14/2025, 3:21 AM


and her husband, Herman, had kept a shed at a local ﬂea market selling
clothes, LPs, purses, electronics—a little bit of everything. Gee liked to chatup the regulars. 
Herman died in 2018, and she tragically lost her only child, Michael, the next
year. But Gee wasn’t alone. Most of her siblings had moved to Bryan andHouston, which meant she was surrounded by nieces and nephews. Sheoften spoke with them on the phone, calls that would stretch at least half anhour as Gee asked about relatives one by one. If any were struggling, shewould pray for them. 
The day Gee lost power, her niece Zona Amerson tried to call her, but no one
picked up. Amerson, who’s 64, was concerned, but there was no way to driveacross town to check on her. The roads were impassable. Then one ofAmerson’s pipes burst, with no plumbers available to ﬁx it. She wasdistracted by her own crisis. 
Vehicles at a standstill on Interstate 35 near Temple on February 18, 2021.
Joe Raedle/GettyThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
10 of 29 3/14/2025, 3:21 AM


Power lines surrounded by snow in Dallas on February 18, 2021, as power was still out for many.
Photograph by Nitashia Johnson
On Thursday, Amerson heard from a relative that her aunt had died. A Harris
County medical examiner ruled that the cause was hypothermia. Gee wasone of hundreds of Texans who died because of the lack of electricity. (Thestate recently updated the death toll to 246, 
a number that falls far short of
the total that experts on mortality say is the true measure of the cost in
lives of this disaster, which accounts for those who, for example, had a heartattack and couldn’t get to a hospital.) Others included a centenarian in asenior living community in Houston who’d also succumbed to hypothermia;she’d received a college degree in the thirties and had taught elementaryschool in a single-room schoolhouse in Wisconsin. An 87-year-old Austinwoman died of a fast-moving urinary tract infection after her catheter froze.Two men in Garland are believed to have died of carbon monoxide poisoning—neighbors said they were running a gas-powered generator inside anapartment unit. In Sugar Land, southwest of Houston, a family used their
ﬁreplace to stay warm. The house caught ﬁre, and a grandmother and threeThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
11 of 29 3/14/2025, 3:21 AM


ﬁreplace to stay warm. The house caught ﬁre, and a grandmother and three
of her grandchildren died. The mother survived. “Most of all, I think, what I
will miss is just seeing them grow into these amazing human beings that Iknew that they would be,” 
she told the Houston Chronicle.
Of the millions of Texans who lost electricity during the blackouts, whichlasted from Monday through Thursday, most experienced it as a week ofcompounding problems. Millions either lost water or needed to boil water.When the water ﬁnally came back on, burst pipes began to ﬂow, causingbillions of dollars in damage. Plumbers were so overwhelmed with calls thatsome homeowners 
had to wait months for repairs. Economists at the
Dallas Federal Reserve estimated that the blackouts cost the state’s economysomewhere in the $80 to $130 billion range, potentially making it the mostexpensive disaster in state history. 
Even Texas newcomer Elon Musk, the chief executive of Tesla and the
world’s richest person, was aﬀected. “I was actually in Austin for thatsnowstorm in a house with no electric, no lights, no power, no heating, nointernet—couldn’t actually even get to a food store,” he said at an investormeeting in October. 
Dan Meador, an engineering manager at Austin tech ﬁrm Anaconda, also lost
power. He and his pregnant wife bedded down in their living room in front oftheir ﬁreplace. When they woke in the morning, it was 7 degrees outside with
a windchill factor of −8. He used the ﬁre to boil cowboy coﬀee and cookOf the millions of Texans who lost
electricity during the blackouts, mostexperienced it as a week of compoundingproblems.The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
12 of 29 3/14/2025, 3:21 AM


Ta windchill factor of −8. He used the ﬁre to boil cowboy coﬀee and cook
sausages in a cast-iron pan. The following days were devoted solely to
meeting basic needs: ﬁnding ﬁrewood and preparing meals. When aneighbor’s cedar tree splintered and fell under the weight of ice, he fetchedhis chain saw—before remembering it was electric. Meador, a formerlinebacker for the University of Arkansas football team, used a hacksawinstead. When I spoke to him eight months later, he was still shaken by theexperience. “You turn your water faucet on, water comes out,” he said.“There’s a lot of faith that we have in this stuﬀ just showing up.”
A family outside their powerless Austin apartment, warming up next to a fire made by burning a
discarded armoire.
Photograph by Tamir Kalifa
he Texas Legislature was still in the early stages of its biennial
gathering in Austin when the blackouts occurred. Lawmakers andstaﬀ were told to stay oﬀ the icy roads. This appears to be the ﬁrsttime in state history that winter weather forced legislators to stayhome. 
Of course, that didn’t stop politicians from pointing ﬁngers. Rick Perry,former governor and former U.S. secretary of energy, tried to preempt callsto increase federal oversight of the state’s grid. In a striking display ofinsensitivity to the families who were grieving the loss of loved ones, heclaimed that Texans were willing to forgo power “for longer than three daysto keep the federal government out of their business.” Lieutenant GovernorDan Patrick was one of many politicians to blame wind turbines. “Ourrenewables aren’t reliable,” he said on Good Morning America. GovernorGreg Abbott appeared on Sean Hannity’s Fox News show and argued that theblackouts showed how the Green New Deal, which was then a subject ofintense debate in Washington, D.C., would be a “deadly deal for the UnitedStates.” 
Blaming renewables was, of course, a politically convenient lie. Yes, some
wind farms in West and South Texas had frozen up—their operators hadn’t
invested in blades with internal warming coils that allow windmills toThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
13 of 29 3/14/2025, 3:21 AM


invested in blades with internal warming coils that allow windmills to
function perfectly ﬁne in other states and regions, including north of the
Arctic Circle in Norway. But many windmills kept working, helping toprevent a worse disaster. Even Abbott admitted, while the blackouts wereongoing, that the biggest culprit was power plants that ran on gas. 
As the death toll climbed, the politicians’ bluster ebbed. Abbott added a new
item to the legislative session: winterizing the state’s power system. Patrickpromised, “We’re going to get to the bottom of this and ﬁnd out what the hellhappened, and we’re going to ﬁx it.” 
Such promises had been made before. A decade earlier, in February 2011,
temperatures in Texas plunged into the single digits, and ERCOT institutedrolling blackouts that aﬀected 3.4 million homes and businesses (but for onlya matter of hours, rather than days). David Dewhurst, a Republican who wasthen the lieutenant governor, blamed a lack of “winterization andpreparation.” Weeks later, the Legislature held a hearing on the blackouts,and Troy Fraser, a Republican state senator representing the Twenty-fourthDistrict, demanded, “How are we going to make sure that doesn’t happenagain?”The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
14 of 29 3/14/2025, 3:21 AM


Suzanne Mitchell in her Dallas home after her pipes burst and her roof caved in.
Photograph by Nitashia Johnson
A Fiesta Mart in Houston during the blackout.
Go Nakamura/Getty
The answer came in the form of a bill introduced by Senator Glenn Hegar, a
Republican from Katy. It required the Public Utility Commission, whichoversees ERCOT and the state’s electricity utilities, to review power plants’weatherization plans. If any plan was deemed insuﬃcient, the PUC couldrequest more detail, but it had no enforcement authority. (The bill didn’tmention the need to winterize natural gas pipelines, an omission thatrendered the measure eﬀectively meaningless, since those power plants,even if fully operational, can’t produce electricity without a steady supply ofgas.) Craig Estes, a Republican senator from Wichita Falls, tried to put someteeth on the bill with a substitute that required power plants to comply with
the state’s ﬁndings. But a few days later, Hegar’s original bill was back, withThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
15 of 29 3/14/2025, 3:21 AM


Estes’s changes stripped out. Hegar, who later left the Senate and was elected
state comptroller in 2014, ensured the PUC was little more than a gloriﬁedpaper collector.
DeAnn Walker reiterated as much when, on February 25 of last year, the
Senate business and commerce committee held a fourteen-hour hearing todetermine what had happened this time around. Walker, the chair of thePUC, testiﬁed that her agency’s job was simply to gather and warehouse theplans. “I don’t believe we, as the PUC, have authority to requireweatherization,” she said. 
Representative Chris Paddie looking on as Greg Abbott signs a pair of ERCOT reform bills
on June 8, 2021.
Montinique Monroe/Getty
For many of the lawmakers, the lengthy hearing was a crash course in the
labyrinthine mechanics and bureaucracy of the state’s grid. The federalgovernment regulates all of the country’s regional grids except for ERCOT,which operates wholly inside Texas. (When regional grids experienceblackouts, they are able to import power from neighboring grids; because theTexas grid is an island unto itself, with only a few small connections toMexico and other states, importing large amounts of power isn’t an option.)The ERCOT grid covers almost all of Texas, though El Paso and parts of EastTexas are plugged into other regional grids. ERCOT is overseen by the PUC,whose three commissioners are appointed by the governor. Since the 2011freeze and blackouts, all the agency’s commissioners have been picked byAbbott and Perry. (The PUC was later expanded to include ﬁvecommissioners.) 
A separate body, the Railroad Commission of Texas, regulates the state’s oil
and gas industry—or at least it’s supposed to. In practice, it seldom does. Itsthree commissioners are elected, and their campaign coﬀers are ﬁlled by oiland gas industry executives. Following the 2021 blackout, the commissionersexpressed little interest in learning why the February storm caused
statewide outages only in Texas, not in neighboring states and states far toThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
16 of 29 3/14/2025, 3:21 AM


statewide outages only in Texas, not in neighboring states and states far to
the north. They instead aggressively defended the industry they’re supposed
to regulate, arguing publicly that the state’s failure to require winterizationof natural gas providers played no role in the disaster. At the Februarycommittee hearing, Christi Craddick, then the Railroad Commission chair,tried to pin the blame on electric power producers, claiming that the gasindustry was hamstrung by lack of electricity, not the other way around. “Theoil ﬁeld simply cannot run without power,” she testiﬁed. 
That claim, however, doesn’t withstand scrutiny. Craddick was well aware of
problems with the gas supply before the blackouts began, something Idiscovered while reviewing records of dozens of phone calls, emails, andtexts among those responsible for keeping the lights on. Five days before theblackouts began, Walker, the PUC chair, received an unwelcome call from anexecutive at Vistra, an Irving-based company that is the largest powerproducer in ERCOT. The executive warned that the company would beunable to meet the rising demand for electricity because it would soon facenatural gas shortfalls at several of its plants. Texas normally produces about29 billion cubic feet of gas a day. By February 11, when temperatures hit22 degrees in Midland, about 915 million cubic feet were already oﬄine,according to a federal report on the blackout. (Six days later, around the peakof the blackouts, 3.7 billion cubic feet were oﬄine. All but 591 million of thatwas caused by the failure of gas infrastructure.)
That morning, Walker called Craddick. “We are going to have gas problems
at our gas plants,” Walker said. The next day, the Railroad Commission
issued an emergency order intended to help power plants get access to gas,“Yes, it can happen again.” That’s what
Curt Morgan, chief executive of the powercompany Vistra, told me.The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
17 of 29 3/14/2025, 3:21 AM


Sissued an emergency order intended to help power plants get access to gas,
but the order added to the growing confusion. There was only so much
natural gas to go around, and the Railroad Commission wasn’t sure exactlywho should get it. On February 13, two days before the blackouts began, 22gas processing plants had been disrupted by cold weather conditions. Not asingle one was disrupted by loss of electric power. 
State senator Charles Schwertner in the Texas Capitol.
Photograph by Jeff Wilson
tate senator Charles Schwertner, an orthopedic surgeon from
Georgetown and a conservative Republican, knew little about thegrid when his home’s power went out that week. But he was a quickstudy. A few weeks after the initial February hearing, LieutenantGovernor Patrick asked him to carry the main bill to ﬁx the grid.
Schwertner later told me he concluded right away that the PUCcommissioners were “derelict” in their oversight duties. 
I met him in his Capitol oﬃce, which is adorned with prints of the Battle of
Gettysburg and the Confederate attack on Fort Sumter. He was proud of thebill he wrote. It created a government body to ensure coordination betweenthe gas and power industries. (As reliant as these industries are upon eachother, no such formal body had existed before.) The bill directed the PUCand the Railroad Commission to levy a $1 million ﬁne each day on powerplants, pipelines, and natural gas facilities that failed to winterize, and itallocated an initial $21 million to the Railroad Commission to hire about ahundred inspectors to verify that the gas industry was preparing for coldweather.
When Schwertner sent his bill to the House, the legislation also created a
committee to map the gas-electric supply chain and determine which gasfacilities were critical to the operation of power plants. It authorized theRailroad Commission to use its hundred new employees to inspect and, ifnecessary, ﬁne gas companies. When the bill returned from the House,
though, the language had been revised: only companies “prepared to operateThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
18 of 29 3/14/2025, 3:21 AM


though, the language had been revised: only companies “prepared to operate
during a weather emergency” were considered critical. This created a
troubling loophole. Once the bill had passed, the Railroad Commission wasresponsible for implementing it, and the agency proposed a rule allowing gascompanies to exempt themselves from winterizing simply by paying a $150ﬁling fee and claiming that a facility wasn’t prepared to stay operational—adizzying bit of circular reasoning. 
Schwertner told me that requiring winterization for one part of the grid (the
electric power providers) but not another (those who provide gas to theelectricity providers) reﬂected the political power of the gas industry. “Therewas some pushback by industry,” he said, citing natural gas producers andpipeline operators. He said he didn’t like the House changes, especially theweakening of “weatherization requirements of natural gas.” Some of hiscolleagues were less diplomatic. 
During a Senate committee hearing in September, Lois Kolkhorst, a
Republican senator from Brenham, reamed out Railroad Commissionexecutive director Wei Wang for not eﬀectively implementing the law.Kolkhorst called the $150 opt-out fee “disturbing.” At the same hearing,Senator John Whitmire, a Houston Democrat, oﬀered Wang a compliment ofsorts. “You’ve uniﬁed this body—let me just thank you for that. You’vebrought the family together here . . . Your rule-making proposal sucks.”Schwertner wrapped up the conversation by demanding change. 
The Railroad Commission didn’t budge, and it was roundly condemned.
Then, in late November, it appeared to reverse course, at least rhetorically. Itannounced that most pipelines and gas processing plants, along with manywells, would be required to winterize. But thus far the commission hasengaged in delay tactics. These rules won’t be ﬁnalized until sometime laterthis year—after the winter. Perhaps the rules will be potent enough tocompel real change. But if past is prologue, the new rules are likely to beineﬀectual—a repeat of what happened in 2011. 
Savannah and Sam Peyton, huddled in their Austin home after more than three days without power, on
February 18, 2021.The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
19 of 29 3/14/2025, 3:21 AM


TFebruary 18, 2021.
Photograph by Tamir Kalifa
he week of the blackout produced staggering, hard-to-fathom
energy bills Texans will be paying for years. That’s because thestate’s electricity market broke sometime around midday onMonday, February 15. In the hours after the blackouts, ERCOTtried to shore up electricity reserves to stabilize the grid. The
computer system that runs the market, though, interpreted this as anoversupply (in the middle of blackouts!) and dropped prices. When ERCOTand the PUC realized what was happening, oﬃcials decided to bypass themarket and, on Monday evening, manually set prices at the maximum of$9,000 per megawatt hour. (By comparison, the average hourly price in 2020was $25.73.) For fear that restarting the market and letting prices ﬂuctuate inthe midst of blackouts would lead to instability, oﬃcials kept prices at thatartiﬁcially inﬂated level until Friday.
As a result, Texans spent an exorbitant amount on electricity during a week
in which most of them couldn’t get much electricity. For the entirety of 2020,Texans paid $9.8 billion to keep the juice ﬂowing. On February 16 alone, theyspent roughly $10.3 billion. Costs for the month of February totaled morethan $50 billion. 
The bill for this pricing disaster is coming due. The Legislature approved the
issuance of what will likely end up being about $5 to $6 billion in bonds topay back some of these costs. That form of borrowing creates an obligation ofabout $200 for every adult and child in Texas. 
Of the 2,500 participants in the ERCOT market—power plant owners,
electricity marketers, electric cooperatives, creditors, and traders—many areprivately held and don’t disclose their proﬁts and losses. But some of the bigshareholder-owned electricity generators were stuck with major lossesbecause, while electricity prices were astronomical, natural gas prices wereeven higher. 
As a result, anyone who had natural gas to sell came away a winner. Large
Dallas-based pipeline owner Energy Transfer posted a net proﬁt of $3.29The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
20 of 29 3/14/2025, 3:21 AM


Dallas-based pipeline owner Energy Transfer posted a net proﬁt of $3.29
billion for the ﬁrst three months of 2021; it had never posted even a $1 billion
quarterly margin before. The company chalked up its proﬁts to preparation—it had forked over the money to winterize parts of its facilities, so theyremained up and running during the storm. Kinder Morgan made $1.41billion, its best quarter ever. British oil giant BP , which supplies more gas inthe U.S. than any other company, was coy. “It was a very exceptional quarterin gas trading,” CEO Bernard Looney told Bloomberg, which pointed to anestimate suggesting that the ﬁrm reaped $1 billion during that stretch. Gasproducer Comstock Resources president Roland Burns put it much moreplainly, saying it was “like hitting the jackpot.”
Houstonians lining up to refill propane tanks on February 16, 2021.
Brett Coomer/Houston Chronicle via APThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
21 of 29 3/14/2025, 3:21 AM


Pastor Jessie Prince and his son Josiah handing out water at their Plano church.
Tony Gutierrez/AP
According to Bloomberg, about $8.1 billion was spent on gas burned to
generate electricity during that week. Another $3.3 billion went for gas solddirectly to homeowners, a ﬁgure that’s publicly available only because theRailroad Commission approved the issuance of bonds to compensate threegas utilities that paid exorbitant prices for fuel that week. These bonds willbe paid oﬀ through extra charges on customers’ monthly bills, though it’s notyet clear for how long. Even more was spent by city-owned gas companies,many of which have tacked on additional charges to customers’ bills to payoﬀ the enormous costs the companies ran up over a few days.
It’s possible that some of the massive proﬁts made by gas companies were
illicit. The Federal Energy Regulatory Commission is looking into potentialmarket manipulation by Texas pipeline companies, which are subject to theleast regulation and oversight of any pipelines in the country. Thosecompanies operate in a regulatory penumbra. For their pipelines operatingonly in Texas, they’re generally exempt from reporting tariﬀs and othermarket information the federal government requires of interstate pipelines.This makes it diﬃcult to determine whether gas prices were manipulated. InSeptember, FERC chair Richard Glick told Congress, “We have found a
number of anomalies.” FERC later disclosed that two cases of possibleThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
22 of 29 3/14/2025, 3:21 AM


number of anomalies.” FERC later disclosed that two cases of possible
natural gas market manipulation were being investigated, though it wouldn’t
identify the two companies involved. (Disclosure: Texas Monthly’s chairmanis Randa Duncan Williams, who is also chairman of the general partner ofEnterprise Products Partners, a major pipeline company whose gas pipelinesare located entirely within Texas. Company executives say they’ve receivedno inquiries from FERC.) 
At the same September hearing, Kansas senator Roger Marshall asked a
panel of FERC commissioners, “Was there price gouging, and who made themoney?” None of the four commissioners came up with an answer. 
Most Texas politicians have shown little interest in even asking this
question. The chief executive of every major power plant in Texas testiﬁedrepeatedly before state lawmakers. But Kelcy Warren, the chair of EnergyTransfer, never appeared. Warren then gave a $1 million campaigncontribution to Abbott on June 23, shortly after the legislative session ended—a session in which Abbott, despite his initial calls to ﬁx the grid, resistedmuscular new regulation of the gas industry. (Oil and gas executives,employees, and political action committees contributed about $16.6 millionof the $79 million that Abbott raised from 2017 through 2020, according toan analysis by Texans for Public Justice.) 
For his part, Texas attorney general Ken Paxton, who’s awaiting trial on
felony securities fraud charges, hasn’t announced that his oﬃce isinvestigating any energy price gouging. I recently asked PUC chair PeterLake, whom Abbott appointed in the spring, after DeAnn Walker resigned, toassess who proﬁted from the disaster. “I’m not sure anybody has a fullpicture of the complexity of all these ﬁnancial transactions,” he saidcautiously. It’s telling that Lake, who was supposedly brought in to ﬁxERCOT and the electricity market, dodged a question about who stood togain and lose the most from maintaining the status quo. 
Though it may be hard to believe today,The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
23 of 29 3/14/2025, 3:21 AM


The most prominent Texan who appears to be itching for a confrontation
with gas companies is Paula Gold-Williams, the longtime head of CPSEnergy, the city-owned utility in San Antonio. Days after the crisis ended,two gas suppliers owned by Energy Transfer sent CPS an email asking for$317.5 million. “Due to the unprecedented weather event over the past 10days, the price of natural gas rose dramatically,” the email said. It demandedthat CPS pay cash or provide a letter of credit.
CPS refused to pay. Instead, it ﬁled a lawsuit claiming price gouging. In its
downtown San Antonio oﬃces, Gold-Williams had watched electricity andgas prices carefully before and during the debacle. A native of San Antonio’sEast Side, she trained as an accountant and worked as a regional controllerfor Time Warner and as a vice president at Luby’s before joining CPS, whereshe worked her way up to CEO. “We will pay every legitimate price and cost,”she promised, but not a dollar more. Working with her staﬀ, she determinedthat about $40 per unit of gas was reasonable. Anything above that? The$500 price Energy Transfer had demanded? That was unconscionable.When I reached out to Energy Transfer about the ﬁnancial tug-of-war, thecompany sent a statement saying CPS was responsible for the costs becauseit didn’t prepare for the storm. “CPS is trying to play politics and place blameon others,” the statement said.
But when I talked to Gold-Williams, she was resolute. “I am absolutely
focused on getting to the bottom of this,” she said. In October, sheannounced her retirement, but she promised to stay engaged with thecompany—speciﬁcally to assist with the lawsuit.Though it may be hard to believe today,
Texas’s grid became a pioneer in the
world of electricity generation anddistribution two decades ago.The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
24 of 29 3/14/2025, 3:21 AM


YIdle drilling rigs near Midland.
Matthew Busch/Bloomberg via Getty
es, it can happen again.” That’s what Curt Morgan, chief executive
of the power company Vistra, told me when I asked about thepotential for another electricity crisis. Vistra lost about $2 billionduring the storm, and it plans to spend more than $80 million bythe end of this year to prepare its plants for the next Arctic blast. 
In November, I visited one of those plants, in Odessa. During the Februarystorm, ice had accumulated and clogged the air-intake system, so Vistra isinvesting $2.5 million to make sure that doesn’t happen again. From atop anyof the plant’s four 10-story boilers, which produce the high-pressure steamthat’s converted into electricity, you could look out toward the horizon andsee a landscape dotted with pipelines, pump jacks, and ﬂare stacks. The ironywas stark: the plant sits in the heart of one of the world’s largest oil and gasﬁelds, yet when blanketed by extreme temperatures, it couldn’t get the gas itneeded to stay operational. 
Though Vistra is ensuring its own plant will be able to sustain such
conditions, the same can’t be said for its neighboring gas producers, whichmeans its own investment may be futile. “I worry about the gas system,”Morgan told me. “The area that I’m most concerned about is the RailroadCommission oversight.” He’s not alone. 
You might think that the natural gas industry, having scored a multibillion-
dollar windfall at the expense of other Texans, might show somemagnanimity in victory and agree to take steps to ensure against futureblackouts. But you would be wrong. The gas industry continues to ﬁghtferociously to avoid the kinds of regulations that are commonplace in otherstates. It has boosted by millions of dollars its campaign contributions tofriendly politicians, including the three oﬃcials leading the RailroadCommission. 
Meanwhile, Governor Abbott promised in November that “everything thatThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
25 of 29 3/14/2025, 3:21 AM


Meanwhile, Governor Abbott promised in November that “everything that
needed to be done was done to ﬁx the power grid.” The Texas Tribune
reported that in December, after the blackouts became an issue in hisreelection campaign, Abbott went a step further by 
enlisting oﬃcials at
ERCOT and the PUC to launch an optimistic public relations oﬀensive. Butwhen I interviewed nearly a dozen experts in natural gas and electricity, theconsensus was that little has been done to secure our electric grid. ERCOTitself has admitted we could face blackouts this winter. Just before the newyear, the agency released a report in which it suggested it had enough powergeneration to easily manage “normal” winter weather. Doug Lewin, anAustin-based energy consultant, blasted this conclusion on Twitter: “To saywe have enough power in normal weather is not helpful.” 
Days later, on January 2, a cold front passed through West Texas. The
temperature in Midland hit a low of 14 degrees before rebounding to 56 thenext day. During that brief spell, the gas infrastructure faltered, withproduction falling by 25 percent, according to market intelligence ﬁrm S&PGlobal. Still, the approach of our governor and legislators and regulatorsboils down to hoping we don’t see extreme temperatures anytime soon.
Indeed, forecasters predicted a relatively warm winter this year. Some might
reason that if the planet is warming, Arctic storms are less likely. There isgrowing evidence, however, that the opposite is true. Judah Cohen, a visitingscientist at Massachusetts Institute of Technology, has published twoinﬂuential papers on the topic, the ﬁrst in 2018 and 
another this past
September. The second paper, which appeared in Science, a prestigious peer-reviewed publication, explained that as the earth warms, conditions areoccurring more frequently that enable a blast of Arctic air to push far intoNorth America, even all the way down to Texas. In other words, the overallwarming of the planet disrupts weather systems in ways that increase thechances for occasional extreme-cold events.
Cohen told me it all has to do with the polar vortex, an atmospheric river that
circles around the Arctic at an average of 90 miles an hour. Typically, it trapsthe cold air in the far northern latitudes, but as Arctic Sea ice melts and the
world warms, the polar vortex is more likely to wobble and stretch. InThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
26 of 29 3/14/2025, 3:21 AM


Tworld warms, the polar vortex is more likely to wobble and stretch. In
January and February of 2021, a warm mass of air from Eurasia banged into
the vortex, causing it to dip southward and push cold air as far down as theRio Grande Valley. “Where the polar vortex goes, so goes the cold air,” Cohenexplained.
So what would it cost to winterize all the wells in Texas, as most other states
do, and ensure the electricity ﬂows the next time an Arctic blast hits theLone Star State? Dallas Federal Reserve economists cite a 2011 estimate thatit would cost each gas power plant $50,000 to $500,000 to winterize.Statewide, it would cost between $85 and $200 million annually—the roughequivalent of one or two days of revenue from the Texas gas industry, andless than one-ﬁftieth the cost that the industry charged during the Februarydisaster. 
It’s worth noting that much of the cost of winterization would remain in the
Texas economy. One of the world’s leading manufacturers of heat-tracingequipment, Thermon Group Holdings, is based in Austin and operates amajor factory in San Marcos. A few years ago, it winterized an oil complex onRussia’s Sakhalin Island—where the average low temperature in January is3 degrees Fahrenheit—for $12 million. “All of this technology exists,” saidThermon CEO Bruce Thames. “We just haven’t invested in it in the state ofTexas.” 
Power lines in Austin.
Photograph by Jeff Wilson
his is particularly shameful to hear for anyone versed in Texas’s
history as an energy leader. 
Though it may be hard to believe today, Texas’s grid became a
pioneer in the world of electricity generation and distribution two
decades ago. Under Governor Perry, Texas spent $6.9 billion on an ambitiousprogram to build 3,600 miles of new high-voltage transmission lines. One setof lines stretched from Dallas to the Panhandle, forming a looping ﬁgure that
came to be known colloquially as “the horsehead.” Other lines began inThe Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
27 of 29 3/14/2025, 3:21 AM


came to be known colloquially as “the horsehead.” Other lines began in
Central Texas and headed west, reaching toward Midland and Odessa and
into the windy counties where the Chihuahuan Desert meets the GreatPlains. In other states, the construction of comparable transmission linesoften gets delayed for years, mired in bureaucratic morasses and landownerlawsuits. Texas completed its entire network in a relatively brisk nine years.
These lines were a boon to renewable energy developers, connecting the
large population centers along Interstate 35 (and east to Houston) towestern parts of the state, where land is cheap, landowners are welcoming,and wind and sun are plentiful. In 2020 Texas generated more renewableelectricity than any other state by far. California was a distant second. By allaccounts, Texas, long famed for being a global powerhouse in oil and gas, hadcemented its leadership in the next generation of energy. 
And then came the February blackouts. Our folly was laid bare: it’s as if we’d
built a powerful, expensive car and then tried to pinch pennies by not buyingantifreeze for it. 
Despite this embarrassment, Texas still enjoys unmatched expertise in
energy engineering, ﬁnancing, and manufacturing. Some of the technologyand gear developed to frack oil and gas is now being repurposed to taprenewable energy. Shipyards that once made vessels to install oﬀshore oilrigs are now adapting for oﬀshore wind turbines. Taking advantage of theseresources would create tens of thousands of good jobs, including for workersdisplaced as oil and gas exploration inevitably declines. 
Low-carbon grids are the future, and Texas has a multiyear head start. But
before this opportunity can be grasped, the state needs political leaders andregulators who are focused on the jobs and well-being of average Texansrather than on the narrower incumbent interests of owners and executives offossil fuel companies.
This article originally appeared in the February 2022 issue of Texas
Monthly with the headline “It Could Happen Again.” 
Subscribe today .The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
28 of 29 3/14/2025, 3:21 AM


The Texas Electric Grid Failure Was a Warm-up – Texas Monthly https://www.texasmonthly.com/news-politics/texas- ure...
29 of 29 3/14/2025, 3:21 AM


© Mapbox © OpenStreetMap
AI IS ALREADY WREAKING HAVOC
ON GLOBAL POWER SYSTEMS
Technology | The Big Take
June 21, 2024
Gift this articleSaudi ArabiaIrelandMalaysia UAEAustraliaSouth Korea US IsraelNetherlandsDenmarkPhilippinesSouth AfricaIndonesiaThailandPortugalJapanFrance IndiaBelgiumTaiwanIreland’s data center
energy usage was
equal to
53%
of its renewable
energy supply
in 2022AI’s Insatiable Need f or Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
1 of 19 3/14/2025, 2:02 AM


Like much of Northern Virginia, Loudoun County was
once known for its horse farms and Civil War battle sites.
But over the past 15 years, many of this community’s
ﬁelds and forests have been cleared away to build the
data centers that form the backbone of our digital lives.AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
2 of 19 3/14/2025, 2:02 AM


The rise of artiﬁcial intelligence is now turbocharging
demand for bigger data centers, transforming the
landscape even more and taxing the region’s energy
grids.AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
3 of 19 3/14/2025, 2:02 AM


On a crisp afternoon this spring, the newest facility was
nearing completion. When it’s done, this 200,000-
square-foot building could use as much energy as
30,000 homes in the US.AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
4 of 19 3/14/2025, 2:02 AM


But ﬁrst, it needs to get enough power...AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
5 of 19 3/14/2025, 2:02 AM


The energy supply can’t come soon enough for
DataBank, the data center provider that owns the
Virginia facility. An unnamed "big tech" client leased the
entire facility and was so eager to tap into the complex
to access computing resources for AI applications that
it had servers ready in the building before DataBank
was scheduled to have electricity for them.
“That’s the thing with AI. They need a lot of power and as soon as you
have it, they want it right away,” said James Mathes, who manages some
DataBank facilities. “Right now, it’s like a blank check for AI."
The almost ov ernight surge in electricity demand from data centers is now
outstripping the available power supply in many parts of the world,
according to interviews with data center operators, energy providers and
tech executives. That dynamic is leading to years-long waits for
businesses to access the grid as well as growing concerns of outages and
price increases for those living in the densest data center markets.
The dramatic increase in power demands from Silicon Valley’s growth-at-
all-costs approach to AI also threatens to upend the energy transition
plans of entire nations and the clean energy goals of trillion-dollar tech
companies. In some countries, including Saudi Arabia, Ireland and
Malaysia, the ener gy required to run all the data centers they plan to build
at full capacity exceeds the available supply of renewable energy,
according to a Bloomberg analysis of the latest available data.
By one o ﬃcial estimate, Sweden could see power demand from data
centers roughly double over the course of this decade — and then double
again by 2040. In the UK, AI is expected to suck up 500% more energy
over the next decade. And in the US, data centers are projected to use 8%
of total power by 2030, up from 3% in 2022, according to Goldman Sachs,
which described it as “the kind of electricity growth that hasn’t been seen
in a generation.”AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
6 of 19 3/14/2025, 2:02 AM


Globally, there are more than 7,000 data centers built or
in various stages of development, up from 3,600 in 2015.
These data centers have the capacity to consume a
combined 508 terawatt hours of electricity per year if
they were to run constantly. That’s greater than the totalAI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
7 of 19 3/14/2025, 2:02 AM


annual electricity production for Italy or Australia.
By 2034, global energy consumption by data centers is
expected to top 1,580 TWh, about as much as is used by
all of India.AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
8 of 19 3/14/2025, 2:02 AM


These are only estimates and there remains a high degree of uncertainty
about how the current AI frenzy  will play out. There’s also a diﬀ erence
between the projections for how much electricity data center developers
want and how much generation actually gets built.
While tech companies are quick to point out that data centers account for
less than 2% of global energy use even with all the expansion, an April
report from Goldman Sachs estimates that ﬁgure could rise to 4% by the
end of the decade. Any percentage point increase is monumental, given
overall electricity demand has remained almost ﬂat for years — if not
declining in some regions.
In the US, power demand is expected to grow by 40% over the next two
decades, compared with just 9% growth over the past 20 years, according
to John Ketchum, chief executive o ﬃcer at NextEra Energy Inc., the
world’s biggest builder of wind and solar energy that isn’t backed by a
government. Data centers are the biggest reason for that demand boom,
Ketchum said, citing electriﬁcation and manufacturing as other factors.
Asked why data centers were suddenly sucking up so much power, his
answer was blunt: “It’s AI,” he said, citing the energy needs for training
models and also the inference process by which AI draws conclusions
from data it hasn’t seen before. “It’s 10 to 15 times the amount of
electricity.”
Altogether, data centers use more electricity than most
countries
Only 16 nations, including the US and China, consume moreAI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
9 of 19 3/14/2025, 2:02 AM


2000 2004 2008 2012 2016 2020 202450100150200250300350 TWh
Sources: Bloomberg analysis of BloombergNEF and DC Byte data
Note: Data center energy consumption through Q1 2024. National energy consumption levels
are actual through 2022 and projected for 2023 and 2024.
The biggest cloud services providers, Amazon.com Inc. , Microsoft Corp.
and Alphabet Inc. ’s Google, have announced goals to run their data
centers entirely on green energy — Amazon by next year, Google and
Microsoft by 2030. All three say they are working on technological
methods to use less power or balance the demand on the grid more
eﬃciently. That can include wringing more e ﬃciency from chips and
servers, laying out equipment in ways that require less cooling and shifting
loads  to diﬀ erent areas based on where energy — particularly green
energy — is available.
But some tech leaders like OpenAI CEO Sam Altman  have said an energy
breakthrough — likely from nuclear power — is needed to adapt to this
new picture. Microsoft and Amazon are also betting on nuclear energy ,
with Amazon recently buying a nuclear-powered data center in
Pennsylvania and indicating it’s open to more. For now, the path forward
remains unclear. Microsoft recently admitted that its AI push is
jeopardizing its long-held goal to be carbon negative by 2030.
“We need terawatts and terawatts more of traditional green energy,
whether it’s wind or solar, and that’s across the globe,” said Amanda
Peterson Corio, Google’s global head of data center energy, speaking
broadly rather than solely about AI demands. For context, a single terawatt
is equivalent to the output of about 1,000 nuclear power plants. “Of course
we want to decarbonize ourselves, but if we’re just decarbonizing
ourselves and not the whole grid, what’s the point?”
Global renewable energy supplies under pressure
As new data centers are built, their energy usage could equal or exceed
some countries’ renewable energy supplyAI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
10 of 19 3/14/2025, 2:02 AM


Planned Consumption (2034)
Live Consumption (2022)Renewable Energy Supply (2022)
Sources: Bloomberg analysis of BloombergNEF and DC Byte data
Note: These 20 countries have the highest energy consumption from data centers relative to
their renewable energy supply. The latest available data for renewable electricity supply is for
2022.
In today’s data centers, you might ﬁnd thousands of Nvidia Corp. ’s coveted
H100 chips  — the engine of the generative AI boom — each of which
draws as much as 700 watts, or nearly eight times the power used by a
typical 60-inch ﬂat screen TV. Data centers built for training AI models
require even more. Microsoft, for example, strung together tens of
thousands of Nvidia processors inside a facility used to develop OpenAI’s
technology. These are fed by networking and other types of chips which,
combined with machinery in data centers used to prevent the gear from
overheating, saps up even more power.
And the conventional wisdom in Silicon Valley is that the amount of energy
needed will only go up. Nvidia’s newest chip, the B100, can consume
nearly twice as much power as the H100. Nvidia contends companies will
be able to do more with fewer chips, but Ian Buck, the company’s head of
accelerated computing, admits it’s likely AI deployments will increase.
“People like to ﬁll their data centers,” he said.
AI development is evolving fast, too, with a feverish push toward
developing ever larger artiﬁcial intelligence models. The Microsoft
supercomputer built in 2020 that trained OpenAI’s GPT-3 system used
10,000 of what was then the latest AI chip. A November 2023 Microsoft
supercomputer relied on 14,400 of the top of the line Nvidia H100 chips
and the next one, which is already being designed, will be 30 times more
powerful, according to a May slide presentation by Microsoft Azure Chief
Technology Oﬃcer Mark Russinovich .
Meanwhile, Nvidia CEO Jensen Huang  said many nations will push to build
their own “sovereign”  AI systems to stay competitive and process dataAI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
11 of 19 3/14/2025, 2:02 AM


locally. The global battle for AI supremacy may well depend on which
countries have enough data centers and power to support the technology.
If so, Loudoun County is a vision of what’s to come for the rest of the
world — and the challenges other countries will face keeping up.
The data center capitals of the world
Over the past ﬁve years, Dominion Energy Inc. , the power company that
services Loudoun County, also known as “data center alley,” has
connected 94 data centers that consume about four gigawatts of
electricity, combined. Now it’s ﬁelding requests for data centers campuses
that would consume multiple gigawatts — enough to power hundreds of
thousands of homes — two or three of which could use as much electricity
combined as all the facilities hooked up since 2019.
The surge in demand is causing a backlog. Data center developers now
have to wait longer to hook their projects up to the electric grid. “It could
be as quick as two years, it could be four years depending on what needs
to be built,” Dominion Energy Virginia president Edward Baine said in an
interview.
Related: The Big Take Podcast
Listen and subscribe to The Big Take  on iHeart,  Apple , Spotify  and  The Terminal
Dominion is trying to build out the infrastructure to support it. New power
lines hang from massive metal towers and run along roads and over
creeks to feed electricity to these towering, windowless data centers. The
company is building a large new wind farm o ﬀ the coast and a lot of solar
farms, but coal and gas powered plants could also stay online longer .
In late 2022, Dominion ﬁled a previously unreported letter to its regulators
asking for permission to build new substations and power lines to serve
“unprecedented” load growth. In the letter, Dominion said it experienced
18 load relief warnings in the spring of that year. These warnings occur
when the grid operator tells the company that it might need to shed load,
the technical term for the controlled interruption of power to customers,
which could include rotating outages.
“This is far outside of the normal, safe operating protocol,” Dominion told
regulators.
AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
12 of 19 3/14/2025, 2:02 AM


A DataBank location in Ashburn, Va. Photographer: Moriah Ratner/Bloomberg
Virginia is not alone in struggling to keep pace with demand. In West
London, historically considered a hub for data centers, new facilities have
to wait until 2030 to connect to the grid, according to David Bloom,
chairman of UK-based data center operator Kao Data. “We are now being
pushed into new locations,” he said. Likewise, in the south of Sweden, a
strong market for renewables, there is so much demand to get connected
that businesses may have to wait years. “We have one queue, and you
need to get your ticket,” said Peter Hjalmar, German utility E.ON SE’s
regional manager for southern Sweden. And across the US, many new AI
data centers are expected to consume 100 megawatts each, according to
a recent Morgan Stanley analysis, prompting the analysts to wonder “how
all of the proposed data center projects will be powered in a timely
manner.” Demand is so high that large tech companies are having bidding
wars over data center sites with ready access to power, according to
NextEra.
Data center growth, as it’s being forecast, may also run up against the
limits of how much power can be carried through transmission lines, said
Ali Farhadi, CEO of the Allen Institute for AI. “I don’t think we can move
that much electricity around the globe, forget about generating it,” he said.
Data centers will get more e ﬃcient over time, energy analysts say, but
they’re also getting signiﬁcantly bigger. The average size of data center
facilities worldwide is now 412,000 square feet, an almost ﬁvefold
increase from what it was in 2010, according to data from DC Byte, a
market intelligence ﬁrm.
More powerful data centers require more land
1990LIVE: 11K SQ.FT. | 1 MW
Owned by TIM
Located in Palermo, Italy
Building Area (square feet)
Includes building area in
development stages1M5M 10MAI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
13 of 19 3/14/2025, 2:02 AM


2000
2010
2020LIVE: 13M SQ.FT. | 50 MW
Owned by Apple
Located in Mesa, AZ
PLANNED: 10M SQ.FT. | 1228 MW
LIVE: 1.6M SQ.FT. | 184 MW
Owned by CloudHQ
Located in Ashburn, VA
AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
14 of 19 3/14/2025, 2:02 AM


Source: Bloomberg analysis of DC Byte data
Note: Values are shown on a logarithmic scale. Includes all data centers built since 1930.
The surge in data center demand, combined with heavy investments from
power companies like Dominion on new substations, transmission lines
and other infrastructure to support it, are also increasing the likelihood
customers will see their energy prices go up, experts say. The cost of
some upgrades are typically allocated among electricity customers in an
entire region, showing up as a line item on everyone’s monthly utility bill.
Goldman Sachs estimates that US utility companies will have to invest
roughly $50 billion in new power generation capacity to support data
centers. “That’s going to raise energy prices for both wholesale energy
and retail rates,” said power market analyst Patrick Finn of energy
consultancy Wood Mackenzie.
Costs including grid improvements are divided among each customer
class, from residential to industrial, based on how much it actually costs to
serve each, according to a Dominion representative. As a result, residential
customers have seen their share of transmission costs drop in recent
years while data centers have seen their portion rise, the representative
said.
In Ireland, another heavily saturated market, there are some early signs of
rate increases. Blessed with a moderate climate, Ireland has attracted so
many data centers from Microsoft, Amazon and others that these facilities
are forecast to consume a third of the country’s energy by 2026, up from
18% in 2022.
Wholesale power prices in Ireland have been a third higher on average this
year than the rest of Europe. Other factors, including the country’s
geography, play a role, but Sarah Nolan, senior modeler at Cornwall
Insight, said growing data center demand can contribute — and that’s in a
country that took strong steps to limit buildout just before the AI craze
kicked o ﬀ.
To manage energy constraints, Ireland’s state-owned electricity operator
imposed a moratorium in Dublin in early 2022 and set out conditions to
connect new data centers to the grid, including a preference for thoseAI’s Insatiable Need for Ener gy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
15 of 19 3/14/2025, 2:02 AM


generating their own electricity. The operator has “comprehensive” plans
to build out the grid, said Donal Travers, the head of technology, consumer
and business services for IDA Ireland, the state agency tasked with
attracting foreign direct investment. But he said restrictions on large new
connections are expected to continue “probably until 2028 or
thereabouts.”
In the meantime, other regions are all too eager to open their doors.
A new data center under construction in Gainesville, Va. on March 20, 2024. Photographer:
Moriah Ratner/Bloomberg
The next Virginia
When Rangu Salgame  looks at Malaysia, he sees the next Virginia “in the
making.” Johor, the southernmost state in peninsular Malaysia, has a
policy to speed up clearances for data centers. Crucially, it’s also a short
drive to Singapore, a longtime data center hub that imposed a moratorium
for several years on new facilities to manage energy growth on the tiny
island.
Once a sleepy ﬁshing village, the suburbs of the city of Johor Bahru are
now marked by vast construction sites. Microsoft and Amazon are
investing in the region, as is Salgame’s company, Princeton Digital Group
(PDG). At Sedenak Tech Park, a sprawling complex about 40 miles south
of Johor Bahru’s city center, towering cranes dot the sky. PDG’s new 150
megawatt data center occupies one corner of the park, across from
similar facilities from other providers.
“We have gone from shovel to production in 12 months,” said Salgame,
who expects to have 300 megawatts of capacity in Johor within two
years. “Not all parts of the world can execute at this speed and scale.”
But even markets eager to streamline data center buildout face
constraints. What’s missing in Johor, especially for an industry like tech
that is known for its climate pledges, is renewable energy. The power
supply at Sedenak comes from Tenaga Nasional Berhad, which uses coal
or gas-ﬁred plants. While Malaysia has ambitious goals to bolster
renewables, including plans to build a 500-megawatt solar farm in Johor,
today it relies on coal for more than a third of its generation. Most of
Malaysia’s data center capacity is not in use yet, but factoring in
everything under construction, the amount of electricity used just by data
centers would exceed the country’s total renewable output in 2022, the
latest year for which data is available, a Bloomberg analysis found.AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
16 of 19 3/14/2025, 2:02 AM


A data rush in Southeast Asia
Driven by Malaysia, the region has 153 new data centers that could
potentially be built in the near future, adding a potential 5,419 MW of
capacity
Source: Bloomberg analysis of DC Byte data
Like Malaysia, Texas has emerged as one of the fastest growing data
center markets in the US, thanks in part to the promise of shorter wait
times on its independent and deregulated grid. Texas sites can get on the
grid in the one to two years it takes to build data centers, said Bobby
Hollis, the vice president of energy at Microsoft, which is the largest player
in Texas by megawatt, according to DC Byte.
Texas o ﬀers plentiful solar power and, in the state’s panhandle, some of
the best access to wind power in the world, Hollis said. But a hotter
climate and strained water supplies are pushing Microsoft and Google to
try weaning their data center cooling gear o ﬀ water. Alternate approaches,
however, require more energy — about 5% more on average, according to
Microsoft.
While power in Texas looks plentiful, there are limits. Solar panels and
other gear needed for clean power are starting to see some supply
constraints, Hollis said. The Electric Reliability Council of Texas also
recently cautioned that it has underestimated demand in the San Antonio
area, where Microsoft’s big data center campus is located, potentially
causing cascading outages statewide in the future.
Back in Virginia, opposition to data centers is growing. At a March
supervisors meeting in Prince William County, frustrated residents spoke
out against a zoning change that would allow data centers on a speciﬁc
plot of land to be built about twice as tall. One woman told o ﬃcials that
data centers were turning her quiet neighborhood into a “dystopian
nightmare.”
A 48-year-old homemaker named Rachel Ellis spoke remotely to say the
change would mean more demand on a grid that’s already strained. “It’sPlanned
Malaysia
Malaysia is adding
2,855 MW
of capacity by 2026 -
a tenfold increase.
More than a third
of that new capacity
is locat ed in the
state of JohorLocated
in Johor
SingaporeIndonesia
ThailandPhilippinesTotal Energy Capacity (MW)
Live
50 100 200AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
17 of 19 3/14/2025, 2:02 AM


reckless governing to continue to approve data centers without knowing
the full impacts of where this electricity will come from,” she said.
After hearing a dozen people speak against the zoning change, the
supervisors voted. The bigger data centers were approved.
Related tickers:
MSFT (Microsoft Corp.)
AMZN (Amazon.com Inc.)
NVDA (NVIDIA Corp.)
GOOGL (Alphabet Inc.)
D (Dominion Energy Inc.)
NEE (NextEra Energy Inc.)
By:
Josh Saul
 , 
Leonardo Nicoletti
 , 
Saritha Rai
 , 
Dina Bass
 , 
Ian King
  and 
 Jennifer Duggan
for 
 Bloomberg 
 T echnology
With assistance from:
 Olivia Solon
 , 
Eamon Farhat
 , 
Lars Paulsson
 , 
Dan Murtaugh
 , 
Matt Day
 , 
Seohee Song
 , 
Matthias Kimmel
  and 
 Rodrigo Quintero
 for 
 Bloomberg 
 T echnology
Edited by:
 Seth Fiegerman
 , 
Chloe Whiteaker
 , 
David Ingold
  and 
 Lynn Doan
for 
 Bloomberg 
 T echnology
Source for satellite images: Google Earth (USGS, Airbus, Maxar Technologies, USDA/FPAC/
GEO, Commonwealth of Virginia)
Methodology
Data collection
Bloomberg collected data on the energy capacity of data centers globally, including active
facilities and those under construction, from DC Byte, a market intelligence ﬁrm. Bloomberg
also relied on DC Byte data to determine the location and size of thousands of facilities around
the world. Using BloombergNEF, a research service, Bloomberg gathered data on electricity
consumption and generation by fuel type for every country. Bloomberg excluded data centers
intended for cryptocurrency mining from the analysis.
Calculations
Bloomberg converted data center capacity values to energy consumption estimates using the
following formula: MWh = (capacity) * (hours in a year) * (utilization rate) * (Power Usage
Eﬀectiveness)  where capacity  is the installed IT capacity, utilization rate  is 70% and Power
Usage E ﬀectiveness (PUE)  is equal to an average of 1.5. This calculation assumes that data
centers are running 70% of the time and that their PUE -- a ratio to determine a data center's
eﬃciency -- is 1.5 on average. These numbers can vary from facility to facility, but Bloomberg
had energy experts review these calculations.
Renewables
Bloomberg calculated the ratio of available renewable electricity (as of 2022, per latest data) to
data center electricity consumption (estimate) for each country. In some countries, the data
center electricity consumption estimate is nearly equal to, or greater than, the supply of
renewable electricity.
Gift this article
Stock Market 2025
Predictions: Wall Street Braces
for Trump, AI, and China
Jan. 1, 2025How 9 Popular YouTubers
Helped Trump Win a Second
Term
Jan. 22, 2025Trump Cabinet Picks:
Conﬁrmations Reveal Wealth of
JD Vance, Hegseth
Jan. 29, 2025Trump Tariﬀs Target Trade
Deﬁcit Goods Like
Smartphones, TV Equipment
March 13, 2025AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
18 of 19 3/14/2025, 2:02 AM


Terms of Service Do Not Sell or Share My Personal Information Trademarks Privacy Policy
Careers Made in NYC Advertise Ad Choices Help
©2025  Bloomberg L.P. All Rights Reserved.Florida, California Home
Insurance Market Infused by
Riskier Carriers
Dec. 3, 2024German Election 2025: How
Voting Works Under
Proportional Representation
System
Feb. 18, 2025US Black Workers See
Progress Stall With
Conservatives’ Anti-DEI Push
Dec. 20, 2024Gaza Damage Map: What
Buildings Are Left With War
Unresolved
March 5, 2025AI’s Insatiable Need for Energy Is Straining Global Power Grids https://www.bloomberg.com/graphics/2024-ai-data rids/
19 of 19 3/14/2025, 2:02 AM


Credit: Pgiam | E+
Meta mocked for raising “Bob Dylan defense” of torrenting in AI copyri... https://arstechnica.com/tech-policy/2025/03/meta-m g-b...
1 of 6 3/14/2025, 12:42 AM


ARS VIDEO
What Happens to the Developers When AI Can Code? | Ars Frontiers
the resultant code that comes out highly likelyMeta mocked for raising “Bob Dylan defense” of torrenting in AI copyri... https://arstechnica.com/tech-policy/2025/03/meta-m g-b...
2 of 6 3/14/2025, 12:42 AM


Meta mocked for raising “Bob Dylan defense” of torrenting in AI copyri... https://arstechnica.com/tech-policy/2025/03/meta-m g-b...
3 of 6 3/14/2025, 12:42 AM


Meta mocked for raising “Bob Dylan defense” of torrenting in AI copyri... https://arstechnica.com/tech-policy/2025/03/meta-m g-b...
4 of 6 3/14/2025, 12:42 AM


Meta mocked for raising “Bob Dylan defense” of torrenting in AI copyri... https://arstechnica.com/tech-policy/2025/03/meta-m g-b...
5 of 6 3/14/2025, 12:42 AM


Meta mocked for raising “Bob Dylan defense” of torrenting in AI copyri... https://arstechnica.com/tech-policy/2025/03/meta-m g-b...
6 of 6 3/14/2025, 12:42 AM


Making AI Less “Thirsty”: Uncovering and Addressing the
Secret Water Footprint of AI Models
Pengfei Li
UC RiversideJianyi Yang
UC RiversideMohammad A. Islam
UT ArlingtonShaolei Ren1
UC Riverside
Abstract
The growing carbon footprint of artificial intelligence (AI) has been undergoing public scrutiny. Nonethe-
less, the equally important water (withdrawal and consumption) footprint of AI has largely remained under
the radar. For example, training the GPT-3 language model in Microsoft’s state-of-the-art U.S. data centers
can directly evaporate 700,000 liters of clean freshwater, but such information has been kept a secret. More
critically, the global AI demand is projected to account for 4.2 – 6.6 billion cubic meters of water withdrawal
in 2027, which is more than the total annual water withdrawal of 4 – 6 Denmark or half of the United King-
dom. This is concerning, as freshwater scarcity has become one of the most pressing challenges. To respond
to the global water challenges, AI can, and also must, take social responsibility and lead by example by ad-
dressing its own water footprint. In this paper, we provide a principled methodology to estimate the water
footprint of AI, and also discuss the unique spatial-temporal diversities of AI’s runtime water efficiency.
Finally, we highlight the necessity of holistically addressing water footprint along with carbon footprint to
enable truly sustainable AI.
1 Introduction
•“Water is a finite resource, and every drop matters.” — Facebook (now Meta) Sustainability Report 2020 [1].
•“Fresh, clean water is one of the most precious resources on Earth ... Now we’re taking urgent action to
support water security and healthy ecosystems.” — Google’s Water Commitment 2023 [2].
•“Water is a human right and the common development denominator to shape a better future. But water
is in deep trouble.” — U.N. Secretary-General Ant ´onio Guterres at the U.N. Water Conference 2023 [3].
•“Historic droughts threaten our supply of water ... As the source of both life and livelihoods, water
security is central to human and national security.” — The U.S. White House Action Plan on Global Water
Security 2022 [4].
Artificial intelligence (AI) has enabled remarkable breakthroughs in numerous areas of critical impor-
tance, including tackling global challenges such as climate change. On the other hand, many AI models, es-
pecially large generative ones like GPT-4, are trained and deployed on energy-hungry servers in warehouse-
scale data centers, accelerating the data center energy consumption at an unprecedented rate [5]. As a result,
AI’s carbon footprint has been undergoing scrutiny, driving the recent progress in AI carbon efficiency [6,7].
However, AI’s water footprint — many millions of liters of freshwater consumed for cooling the servers and
for electricity generation — has largely remained under the radar and keeps escalating. If not properly ad-
dressed, AI’s water footprint can potentially become a major roadblock to sustainability and create social
conflicts as freshwater resources suitable for human use are extremely limited and unevenly distributed.
As acknowledged in Google’s sustainability report [8] and the recent U.S. Department of Energy study
[5], the expansion of AI products and services is a key driver of the rapid increase in data center water con-
sumption. Even excluding the water usage in leased third-party colocation facilities, Google’s self-owned
data centers alone directly withdrew 29 billion liters and consumed (i.e., evaporated) more than 23 billion
liters of freshwater for on-site cooling in 2023, nearly 80% of which was potable water [8].2This amount of
annual water consumption even rivals that of a major household-name beverage company [9]. Importantly,
Google’s data center water consumption increased by ∼20% from 2021 to 2022 and by ∼17% from 2022 to
2023 [8], and Microsoft saw ∼34% and ∼22% increases over the same periods, respectively [10]. Further-
more, according to the U.S. Department of Energy, the total annual on-site water consumption by U.S. data
1Corresponding author: Shaolei Ren ( University of California, Riverside.
2The detailed difference between water withdrawal and water consumption is presented in Section 2.1.
1arXiv:2304.03271v4  [cs.LG]  15 Jan 2025


centers in 2028 could double or even quadruple the 2023 level, reaching approximately 150 – 280 billion
liters and further stressing the water infrastructures [5].
AI represents the fastest expanding workloads in data centers [5, 8]. For example, a recent study sug-
gests that the global AI could consume 85 – 134 TWh of electricity in 2027 [11], whereas a more aggressive
projection by the U.S. Department of Energy predicts that AI servers’ electricity consumption in the U.S.
alone will surpass 150 – 300 TWh in 2028 [5]. Even considering the lower estimate, the combined scope-1
and scope-2 water withdrawal of global AI is projected to reach 4.2 – 6.6 billion cubic meters in 2027, which
is more than the total annual water withdrawal of 4 – 6 Denmark or half of the United Kingdom.3Simulta-
neously, a total of 0.38 – 0.60 billion cubic meters of water will be evaporated and considered “consumption”
due to the global AI demand in 2027. Moreover, these global estimates will be exceeded by the total water
withdrawal and consumption attributed to AI in the U.S. alone in 2028 if the U.S. Department of Energy’s
projection comes to fruition.
Despite its profound environmental and societal impact, the increasing water footprint of AI has received
disproportionately less attention from the AI community as well as the general public. For example, while
the scope-2 carbon emissions are routinely included as part of AI model cards, even scope-1 direct water
usage (either withdrawal or consumption) is missing, let alone scope-2 water usage. This may impede inno-
vations to enable water sustainability and build truly sustainable AI. Crucially, water and carbon footprints
are complementary to, not substitutable of, each other for understanding the environmental impacts. In-
deed, optimizing for carbon efficiency does not necessarily result in, and may even worsen, water efficiency,
which varies with the fuel mixes for electricity generation and outside weather in a unique way [5,13].
To ensure that the growth in AI does not exacerbate the global water stresses or outweigh the envi-
ronmental benefits it provides, it is critical to uncover and address AI’s hidden water footprint amid the
increasingly severe freshwater scarcity crisis, worsened extended droughts, and quickly aging public water
infrastructure. The urgency can also be reflected in part by the recent commitment to “Water Positive by
2030” from industry leaders, including Google [8] and Microsoft [10], by policy guidelines and legislative
efforts to mitigate AI’s water consumption [14,15], and by the inclusion of water consumption as a key envi-
ronmental metric into the first international standard on sustainable AI to be published by the ISO/IEC [16].
Moreover, setting targets for minimizing water consumption is included as part of the recent U.S. executive
order for advancing AI data center infrastructures [17].
In this paper, we advocate for a holistic approach to sustainable AI that extends beyond the carbon foot-
print to also address the water footprint. Specifically, we present a principled methodology to estimate AI’s
total water footprint, including both operational water and embodied water. By taking the GPT-3 model with
175 billion parameters as an example [18], we show that training GPT-3 in Microsoft’s U.S. data centers can
consume a total of 5.4 million liters of water, including 700,000 liters of scope-1 on-site water consumption.
Additionally, GPT-3 needs to “drink” (i.e., consume) a 500ml bottle of water for roughly 10 – 50 medium-
length responses, depending on when and where it is deployed. Note that our estimate of inference water
consumption for GPT-3 is conservative, and the actual water consumption could be several times higher.
Next, we emphasize the need for increasing transparency of AI’ water footprint, including disclosing
more information about operational data and keeping users informed of the runtime water efficiency. We
show that WUE (Water Usage Effectiveness, a measure of water efficiency) varies both spatially and tempo-
rally, suggesting that “when” and “where” to perform AI training can significantly affect the water footprint.
Finally, we highlight the necessity of holistically addressing the water footprint along with the carbon foot-
print to enable truly sustainable AI — the water footprint of AI can no longer stay under the radar.
2 Background
2.1 Water Withdrawal vs. Water Consumption
There are two related but different concepts — water withdrawal and water consumption, both of which are
important for understanding the impacts on water stress and availability [19,20].
3The scope definition of water usage [12] is in line with that of carbon emissions and is discussed in Section 2.2. Our scope-2 water
withdrawal (and consumption when applicable) is for location-based electricity generation throughout the paper. Large data centers
often adopt sustainability programs (e.g., renewable purchasing agreements) to offset their location-based electricity usage and thus
may have lower market-based carbon and water footprints.
2


•Water withdrawal: It refers to freshwater taken from the ground or surface water sources, either tem-
porarily or permanently, and then used for agricultural, industrial, or municipal uses (normally excluding
water used for hydroelectricity generation) [19]. As water is a finite shared resource, water withdrawal
indicates the level of competition as well as dependence on water resources among different sectors.
•Water consumption: It is defined as “water withdrawal minus water discharge”, and means the amount
of water “evaporated, transpired, incorporated into products or crops, or otherwise removed from the im-
mediate water environment” [20]. Water consumption reflects the impact on downstream water availability
and is crucial for assessing watershed-level scarcity [19].
These two types of water usage correspond to two different water footprints, i.e., water withdrawal foot-
print (WWF) [12,21] and water consumption footprint (WCF), respectively [22]. By default, water footprint
refers to the water consumption footprint unless otherwise specified.
2.2 How Does AI Use Water?
AI’s water usage spans three scopes: on-site water for data center cooling (scope 1), off-site water for elec-
tricity generation (scope 2), and supply-chain water for server manufacturing (scope 3).
2.2.1 Scope-1 Water Usage
Nearly all the server energy is converted into heat, which must then be removed from the data center server
room to avoid overheating. This process involves two sequential stages: server-level cooling followed by
facility-level cooling.
In the server-level cooling stage, heat is transferred from the servers to the facility or a heat exchanger,
typically using either air or liquid cooling methods (e.g., direct-to-chip cooling or immersion cooling),
which do not evaporate or consume water. In general, new data centers dedicated to AI training often
rely on liquid cooling due to the high server power densities.
In the facility-level cooling stage, heat is rejected from the data center facility to the outside environment.
While there are various cooling methods, water-intensive cooling towers and water evaporation-assisted
air cooling are two common approaches used in many data centers, including those operated by major
technology companies [5,8].
Data Center
Chilled 
WaterWarm 
WaterPumpCooling 
Tower
Server RackCRAHWater
SourceCooling
TowerHeat 
Exchanger
ChatGPT
 AlphaGO
Power 
Plant
Scope -1 Water
Scope -2 Water
Figure 1: An example of data center’s operational water us-
age: on-site scope-1 water usage for data center cooling (via
cooling towers in the example), and off-site scope-2 water
usage for electricity generation. The icons for AI models
are only for illustration purposes.Cooling tower. As illustrated in Figure 1, some
water is evaporated (i.e., “consumed”) in the cool-
ing tower to dissipate heat into the environment,
while the remaining water moves along an open
loop to the heat exchanger to further absorb the
server heat. Additionally, non-evaporated water
can be recycled only a few times (typically 3–10 cy-
cles, depending on water quality) before discharge,
requiring continuous clean freshwater replenish-
ment to prevent mineral and salt buildup. Thus, to
keep the cooling tower working, new water must be
constantly added to make up for the evaporated wa-
ter and discharged water. Importantly, clean fresh-
water (potable water in many cases [8]) is needed
to avoid pipe clogs and/or bacterial growth.
For cooling towers, water withdrawal refers to
the amount of added water, including both evapo-
rated water and discharged water, while water consumption exclusively indicates the amount of evaporated
water. With good water quality, roughly 80% of water withdrawal is evaporated and considered “consump-
tion” [8]. On average, depending on the weather conditions and operational settings, data centers can evap-
orate approximately 1 – 9 liters per kWh of server energy: 1 L/kWh for Google’s annualized global on-site
water efficiency [8] and 9 L/kWh for a large commercial data center during the summer in Arizona [23].
Air cooling with water evaporation assistance. When the climate condition is appropriate, data centers
may use “free” outside air to directly reject the heat to the outside environment. Nonetheless, water evapo-
ration is still needed when the outside air is too hot (e.g., higher than 85 degrees Fahrenheit); additionally,
3


water is also needed for humidity control when the outside air is too dry [24]. The added water is consid-
ered “withdrawal”, out of which about 70% is consumed based on Meta’s report [25]. Generally, outside air
cooling is more water-efficient than cooling towers on average. However, hot weather raises the evaporative
water demand and maximum water consumption, potentially stressing local water supplies during peak
demand on hot days. Additionally, the application of outside air cooling may have challenges in hot regions
and/or for many colocation facilities that are located in business districts.
Some data centers may opt for dry coolers, which consume no on-site water year-round [26]. However,
this approach typically increases cooling energy consumption compared to water-based cooling methods,
potentially exacerbating the overall stress on water resources due to higher scope-2 water consumption.
2.2.2 Scope-2 Water Usage
In many countries, thermoelectric power is among the top sectors in terms of water withdrawal and water
consumption [12]. Thus, similarly to scope-2 carbon emissions, data centers are accountable for off-site
scope-2 water usage associated with electricity consumption, which forms part of the “true water cost of
data centers,” as highlighted by the U.S. Department of Energy [5].
Different power plants use different amounts of water for each kWh generation, depending on the cooling
techniques. Typically, water withdrawal due to hydropower generation is excluded, but water consumption
due to increased water evaporation rates from hydropower generation is included [5]. For electricity gener-
ation, the U.S. national average water withdrawal and consumption are estimated at about 43.8 L/kWh [27]
and 3.1 L/kWh [12], respectively. Meta’s self-reported scope-2 water consumption for its global data center
fleet was 3.7 L/kWh (i.e., 55,475 megaliters divided by 14,975,435 MWh) in 2023 [25].
2.2.3 Scope-3 Water Usage
AI chip and server manufacturing uses a huge amount of water [28, 29]. For example, ultrapure water is
needed for wafer fabrication and water is also needed for keeping semiconductor plants cool. Importantly,
the discharged water may contain toxic chemicals and/or hazardous wastes. While water recycling at semi-
conductor plants can effectively reduce water withdrawal, the recycling rate in many cases remains low, e.g.,
the average recycling rate for wafer plants and semiconductor plants in Singapore are 45% and 23%, respec-
tively [29]. Although largely obscure, scope-3 water usage is likely significant [28]. For instance, Apple
reports that its supply chain accounts for 99% of its total water footprint [30].
It is important to recognize that, unlike agriculture whose water footprint is mostly green (i.e., water
stored in soil and used by plants), the majority of AI’s water footprint is blue water extracted from rivers,
lakes, or groundwater, which is directly accessible for human use but often more limited in availability.
3 Estimating AI’s Water Footprint
We present a general methodology for estimating AI’s water consumption footprint. To obtain the water
withdrawal footprint, we simply replace the WUE with water withdrawal efficiency.
3.1 Operational Water Footprint
We collectively refer to on-site scope-1 water and off-site scope-2 water as the operational water.
•On-site WUE. We denote the on-site scope-1 WUE at time tbyρs1,t, which is defined as the ratio of
the on-site water consumption to server energy consumption and varies over time depending on the outside
temperature (see [13] for an example of on-site WUE based on cooling towers). Concretely, ρs1,tincreases
significantly for cooling towers when the outside wet bulb temperature increases, and increases for outside
air cooling when the outside dry bulb temperature is too hot or the humidity is too low.
•Off-site WUE. We denote the off-site scope-2 WUE at time tasρs2,t, which is defined as the ratio of off-
site water consumption for each kWh of electricity consumption and measures the electricity water intensity
factor (EWIF). While there are different methods to estimate ρs2,t, a common one is weighted averaging:
ρs2,t=P
kbk,t×EWIF kP
kbk,twhere bk,tdenotes the amount of electricity generated from fuel type kat time tfor
the grid serving the data center under consideration, and EWIF kis the EWIF for fuel type k[31,32]. Thus,
variations in energy fuel mixes of electricity generation result in temporal variations of the off-site WUE.
Moreover, the off-site WUE also varies across regions due to different energy fuel mixes [5,12].
4


Table 1: Estimate of GPT-3’s operational water consumption footprint. “*” denotes data centers under construction
as of July 2023, whose PUE and WUE are projected by Microsoft.
Location PUEOn-site
WUE
(L/kWh)Off-site
EWIF
(L/kWh)Water for Training (million L) Water for Each Request (mL) # of Requests
for 500ml
WaterOn-site
WaterOff-site
WaterTotal
WaterOn-site
WaterOff-site
WaterTotal
Water
U.S. Average 1.170 0.550 3.142 0.708 4.731 5.439 2.200 14.704 16.904 29.6
Arizona 1.180 1.630 4.959 2.098 7.531 9.629 6.520 23.406 29.926 16.7
Georgia* 1.120 0.060 2.309 0.077 3.328 3.406 0.240 10.345 10.585 47.2
Illinois 1.350 0.740 2.233 0.952 3.880 4.833 2.960 12.060 15.020 33.3
Iowa 1.160 0.140 3.104 0.180 4.634 4.814 0.560 14.403 14.963 33.4
Texas 1.280 0.250 1.287 0.322 2.120 2.442 1.000 6.590 7.590 65.9
Virginia 1.140 0.140 2.385 0.180 3.499 3.679 0.560 10.875 11.435 43.7
Washington 1.150 0.950 9.501 1.223 14.063 15.285 3.800 43.706 47.506 10.5
Wyoming 1.110 0.130 2.574 0.167 3.677 3.845 0.520 11.429 11.949 41.8
Australia* 1.120 0.012 4.259 0.015 6.138 6.154 0.048 19.078 19.126 26.1
Denmark* 1.160 0.010 3.180 0.013 4.747 4.760 0.040 14.754 14.794 33.8
Finland* 1.120 0.010 4.542 0.013 6.548 6.561 0.040 20.350 20.390 24.5
India* 1.430 0.000 3.445 0.000 6.340 6.340 0.000 19.704 19.704 25.4
Indonesia* 1.320 1.900 2.271 2.445 3.858 6.304 7.600 11.992 19.592 25.5
Ireland 1.190 0.020 1.476 0.026 2.261 2.287 0.080 7.027 7.107 70.4
Mexico* 1.120 0.056 5.300 0.072 7.639 7.711 0.224 23.742 23.966 20.9
Netherlands 1.140 0.060 3.445 0.077 5.054 5.131 0.240 15.708 15.948 31.4
Sweden 1.160 0.090 6.019 0.116 8.986 9.101 0.360 27.927 28.287 17.7
•Operational water footprint. Consider a time-slotted model t= 1,2,···, T, where the length of each
time slot depends on how frequently we want to assess the operational water footprint. At time t, suppose
that an AI model uses energy etwhich can be measured using power meters and/or servers’ built-in tools,
and the data center hosting the AI model has a power usage effectiveness (PUE) of θtthat accounts for
the non-IT energy overhead. Then, the total operational water footprint of the AI model can be written as
WaterOperational =PT
t=1et·[ρs1,t+θt·ρs2,t].
3.2 Embodied Water Footprint
Similar to accounting for the embodied carbon footprint [33], the total scope-3 water footprint is amortized
over the lifespan of a server. Specifically, if Wrepresents the total water used to manufacture the AI servers
and the servers are expected to operate for a period of T0, then the embodied water footprint over a period
ofTis calculated as WaterEmbodied =T·W
T0By adding up the operational and embodied water footprints, we obtain the total water footprint as
WaterTotal =PT
t=1et·[ρs1,t+θt·ρs2,t] +T·W
T0. In practice, to obtain a rough estimate, we can use the
average values for the annualized WUE and the estimated AI server energy consumption.
3.3 Case Study: Estimating GPT-3’s Operational Water Consumption Footprint
The core of ChatGPT, a popular online service, is a large language model (LLM) based on subsequent ver-
sions of GPT-3. We present a case study to estimate the operational water consumption for the full GPT-3
model with 175 billion parameters [18]. We exclude embodied water footprint due to the lack of public data
for scope-3 water usage. We choose GPT-3 as Microsoft publishes its location-wise WUE and PUE [34,35].
The results are summarized in Table 1.
3.3.1 Training
GPT-3 was trained and deployed by OpenAI in Microsoft’s data centers, with an estimated training energy
of 1287 MWh [36]. In line with the practice of estimating the carbon footprint, we use the most recent
annualized average on-site PUE and WUE for each location, as reported by Microsoft [34, 35]. For power
plant water efficiency, different references may provide different estimates of EWIF. Thus, for consistency
across regions, we use the EWIF provided by [12] to estimate scope-2 water consumption, as it employs
the same methodology for calculating EWIF across a large number of regions. Moreover, a large number of
Microsoft’s data centers are located in the U.S., where the average EWIF provided by [12] is 3.14 L/kWh and
significantly lower than 4.35 L/kWh reported by the recent U.S. Department of Energy study [5]. The specific
location for training GPT-3 is not public. Thus, we consider Microsoft’s different data center locations, while
excluding Singapore and Taiwan since the EWIF data for these regions is not available in [12].
5


0.1 0.3 0.5 0.7 0.9
Carbon (kg/kWh)0481216Water (L/kWh)AKMS
HIOAMROENWPP
NYUP
AZNM(a) Carbon/water efficiency
MON TUE WED THU FRI1.51.82.12.42.73.0Water (L/kWh)
0.200.250.300.350.40
Carbon (kg/kWh) (b) Hourly carbon/water efficiency
MON TUE WED THU FRI0204060PercentageCoal
Natural Gas
NuclearOil
Wind
SolarHydro
Other (c) Hourly energy fuel mixes
Figure 2: (a) The U.S. eGRID-level scope-2 water consumption intensity factor vs. carbon emission rate [12, 39].
The dashed line represents a linear regression model, showing that the eGRID-level scope-2 carbon emission and water
consumption efficiencies are not aligned. (b)A 5-day snapshot of scope-2 carbon emission rate and water consumption
intensity in Virginia, starting from April 4, 2022. The values are calculated based on the fuel mixes, carbon emission
rate and water consumption intensity for each fuel type [12, 27, 39]. The scope-2 carbon and water efficiencies only
have a weak Pearson correlation coefficient of 0.06 in Virginia. (c)A 5-day snapshot of energy fuel mixes serving
Virginia, starting from April 4, 2022 [27].
3.3.2 Inference
As a representative usage scenario for an LLM, we consider a conversation task, which typically includes
a CPU-intensive prompt phase that processes the user’s input (a.k.a., prompt) and a memory-intensive
token phase that produces outputs [37]. More specifically, we consider a medium-sized request, each with
approximately ≤800 words of input and 150 – 300 words of output [37]. The official estimate shows that
GPT-3 consumes an order of 0.4 kWh electricity to generate 100 pages of content (e.g., roughly 0.004 kWh per
page) [18]. Thus, we consider 0.004 kWh as the per-request server energy consumption for our conversation
task. The PUE, WUE, and EWIF are the same as those used for estimating the training water consumption.
Our estimate of inference water consumption for GPT-3 is on the conservative side, and the actual wa-
ter consumption could be several times higher. Concretely, when service level objectives (SLOs) for LLM
response time are considered in real enterprise-grade Nvidia DGX H100 systems for conversation tasks,
the inference server energy consumption for a much smaller model (e.g., Llama-3-70B) to process each
medium-sized request is already ∼0.010 kWh when using a state-of-the-practice LLM inference solution
and accounting for the non-GPU server overhead [37]. When considering the Falcon-180B model with a
comparable size to GPT-3-175B, the server energy consumption will even reach ∼0.016 kWh for processing
a medium-sized request [37]. Additionally, our EWIF for the U.S. (i.e., 3.14L/kWh on average) is conserva-
tively chosen and significantly lower than 4.35L/kWh recently reported by [5].
While there is no official information on its resource consumption, the subsequent GPT-4 model is ex-
pected to consume substantially more energy and water than GPT-3 for processing the same request [38].
Nonetheless, we emphasize that the on-site WUE of Microsoft’s data centers is already among the lowest in
the industry. With continued efforts to reduce AI’s computational demand and improve the overall water
efficiency, the water consumption per request may decrease in the future, while the total water consump-
tion is likely to rise further as a result of the growing demand for AI services and the increasing scale of AI
applications [5].
4 Our Recommendations
We provide our recommendations to address AI’s water footprint from the scheduling and policy perspec-
tives, making future AI more environmentally sustainable.
4.1 More Transparency and Comprehensive Reporting
Despite its growing importance, AI’s water footprint has received relatively less attention. For example,
while AI model cards routinely include carbon emissions and serve as an important reporting framework
for understanding AI’s environmental impacts, they currently omit information on AI’s water consumption.
The lack of transparency may obstruct efforts to drive innovations that enhance water sustainability and
6


support truly sustainable AI. As an initial step to raise awareness among end users about the water resource
impacts of their AI usage, we recommend tracking and reporting AI’s water consumption in AI model cards
and/or through cloud dashboards.
Moreover, a comprehensive understanding and reporting of AI’s scope-2 water consumption associ-
ated with electricity generation remain limited. Although data centers have increasingly adopted climate-
conscious cooling system designs to minimize on-site water consumption [8,24,26], these efforts primarily
focus on scope-1 water usage while largely overlooking scope-2 impacts. Just as addressing scope-2 carbon
emissions is important for mitigating climate change, it is equally crucial to address scope-2 water consump-
tion to reduce AI’s “true water cost”, as noted by the U.S. Department of Energy study [5]. To better reflect
the true impacts of data centers on water resources, some technology companies such as Meta have begun
to include scope-2 water consumption in their sustainability reports [25]. We recommend the reporting of
scope-2 water consumption as a standard practice. This approach makes the off-site water consumption
visible to AI model developers as well as end users and can unlock new opportunities for demand-side
flexibility, thereby alleviating the overall strain on water resources.
Finally, despite the enormous scope-3 supply-chain water footprint [30], there is limited data available
for embodied water usage by chip manufacturing. We recommend further research on scope-3 water con-
sumption to achieve a comprehensive understanding of AI’s overall water footprint and to foster corporate
water stewardship.
4.2 “When” and “Where” Matter
Judiciously deciding “when” and “where” to train a large AI model can significantly affect the water foot-
print. The water efficiency exhibits a spatial-temporal diversity — on-site water efficiency changes due to
variations of outside weather conditions, and off-site water efficiency changes due to variations of the grid’s
energy fuel mixes to meet time-varying demands (Figure 2). Therefore, we can dynamically schedule AI
training and inference in a water-wise manner to cut the water footprint. For example, we may schedule
AI training at midnight and/or in a data center with better water efficiency. Likewise, if informed of the
real-time water efficiency, some water-conscious users may prefer to use AI inference during water-efficient
hours and/or in water-efficient data centers, which can reduce AI’s water footprint by enabling demand-side
flexibility.
4.3 “Follow the Sun” or “Unfollow the Sun”
To cut the carbon footprint, it is preferable to “follow the sun” when solar energy is more abundant. Nonethe-
less, to cut the water footprint, it may be more appealing to “unfollow the sun” to avoid high-temperature
hours of a day when WUE is high. This conflict can also be shown in Figure 2(a) and Figure 2(b), where we
see misalignment between the scope-2 water consumption intensity factor and carbon emission rate: mini-
mizing one footprint might increase the other footprint. This observation further corroborates the previous
finding that the environmental impacts of carbon and water footprints are not substitutable [5,13]. There-
fore, to judiciously achieve a balance between “follow the sun” for carbon efficiency and “unfollow the sun”
for water efficiency, we need to reconcile the potential water-carbon conflicts by using holistic approaches
that are both carbon-efficient and water-wise.
5 Conclusion
In this paper, we uncover AI’s water usage as a critical concern for socially responsible and environmentally
sustainable AI. We present a principled methodology to estimate AI’s water footprint. Then, using GPT-
3 as an example, we show that a large AI model can consume millions of liters of water for training. We
also discuss that the scope-1 and scope-2 water efficiencies vary spatially and temporally — judiciously
deciding “when” and “where” to run a large AI model can significantly cut the water footprint. In addition,
we recommend increased transparency and comprehensive reporting of AI’s water footprint, and highlight
the necessity of holistically addressing the water footprint along with the carbon footprint to build truly
sustainable AI.
AI’s water footprint can no longer stay under the radar and must be addressed as a priority as part of the collective
efforts to combat global water challenges.
7


References
[1] Facebook. Sustainability report. https://sustainability.fb.com/wp-content/uploads/2021/06/
2020_FB_Sustainability-Report.pdf, 2020.
[2] Google. Water commitments. https://sustainability.google/commitments/water/, 2023.
[3] UN Water Conference. How ’aquapreneurs’ are innovating to solve the water crisis. https://www.
weforum.org/agenda/2023/03/un-water-conference-aquapreneurs-innovation, 2023.
[4] The U.S. White House. White House action plan on global water security. https://www.whitehouse.
gov/wp-content/uploads/2022/06/water-action-plan_final_formatted.pdf, 2022.
[5] Arman Shehabi, Sarah J. Smith, Alex Hubbard, Alex Newkirk, Nuoa Lei, Md Abu Bakar Siddik, Billie
Holecek, Jonathan Koomey, Eric Masanet, and Dale Sartor. 2024 United States data center energy usage
report. Lawrence Berkeley National Laboratory LBNL-2001637, December 2024.
[6] Roy Schwartz, Jesse Dodge, Noah A. Smith, and Oren Etzioni. Green AI. Commun. ACM, 63(12):54–63,
nov 2020.
[7] Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy considerations for deep
learning in NLP. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,
pages 3645–3650, Florence, Italy, July 2019. Association for Computational Linguistics.
[8] Google. Environmental report. https://sustainability.google/reports/, 2024.
[9] PepsiCo. ESG - water. https://www.pepsico.com/our-impact/esg-topics-a-z/water, 2023.
[10] Microsoft. Environmental sustainability report. https://www.microsoft.com/en-us/
corporate-responsibility/sustainability/report, 2024.
[11] Alex de Vries. The growing energy footprint of artificial intelligence. Joule, October 2023.
[12] Paul Reig, Tianyi Luo, Eric Christensen, and Julie Sinistore. Guidance for calculating water use em-
bedded in purchased electricity. World Resources Institute, 2020.
[13] Mohammad A. Islam, Kishwar Ahmed, Hong Xu, Nguyen H. Tran, Gang Quan, and Shaolei Ren.
Exploiting spatio-temporal diversity for water saving in geo-distributed data centers. IEEE Transactions
on Cloud Computing, 6(3):734–746, 2018.
[14] United Nations Environment Programme. Artificial intelligence (AI) end-to-end: The environmental
impact of the full AI lifecycle needs to be comprehensively assessed. https://wedocs.unep.org/20.
500.11822/46288, September 2024.
[15] U.S. Congress. S.3732 - artificial intelligence environmental impacts act of 2024. https://www.
congress.gov/bill/118th-congress/senate-bill/3732, February 2024.
[16] ISO/IEC JTC for AI (SC42). ISO/IEC TR 20226 sustainability: Harnessing the power of AI. https:
//etech.iec.ch/issue/2023-06/sustainability-harnessing-the-power-of-ai, 2023.
[17] The U.S. White House. Executive order on advancing United States leadership in artificial intelligence
infrastructure, January 2025.
[18] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language
models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors,
Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.,
2020.
8


[19] Paul Reig. What’s the difference between water use and water consumption? World Resources Institute
Commentary, 2013.
[20] Jordan Macknick, Robin Newmark, Garvin Heath, and KC Hallett. A review of operational water con-
sumption and withdrawal factors for electricity generating technologies. NREL Tech. Report: NREL/TP-
6A20-50900, 2011.
[21] Elliot Cohen and Anu Ramaswami. The water withdrawal footprint of energy supply to cities. Journal
of Industrial Ecology, 18(1):26–39, 2014.
[22] Md Abu Bakar Siddik, Arman Shehabi, and Landon Marston. The environmental footprint of data
centers in the United States. Environmental Research Letters, 16(6):064017, 2021.
[23] Leila Karimi, Leeann Yacuel, Joseph Degraft-Johnson, Jamie Ashby, Michael Green, Matt Renner, Aryn
Bergman, Robert Norwood, and Kerri L. Hickenbottom. Water-energy tradeoffs in data centers: A case
study in hot-arid climates. Resources, Conservation and Recycling, 181:106194, 2022.
[24] Meta. Sustainability — water. https://sustainability.fb.com/water/, 2023.
[25] Meta. Sustainability report. https://sustainability.atmeta.com/2024-sustainability-report/,
2024.
[26] Steve Solomon. Sustainable by design: Next-generation datacenters consume zero wa-
ter for cooling. https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/12/09/
sustainable-by-design-next-generation-datacenters-consume-zero-water-for-cooling/,
2024.
[27] U.S. Energy Information Administration. Open data. https://www.eia.gov/opendata/.
[28] Kali Frost and Inez Hua. Quantifying spatiotemporal impacts of the interaction of water scarcity
and water use by the global semiconductor manufacturing industry. Water Resources and Industry,
22:100115, 2019.
[29] Singapore Public Utilities Board. Wafer fabrication and semiconductor plants benchmarks. https:
//www.pub.gov.sg/Documents/WaterEfficiencyBenchmark_WaferFab.pdf.
[30] Apple. Environmental responsibility report. https://www.apple.com/environment/, 2024.
[31] Kishwar Ahmed, Mohammad A. Islam, Shaolei Ren, and Gang Quan. Exploiting temporal diversity
of water efficiency to make data center less “thirsty”. In ICAC, 2014.
[32] Peter Xiang Gao, Andrew R. Curtis, Bernard Wong, and Srinivasan Keshav. It’s not easy being green.
SIGCOMM Comput. Commun. Rev., 2012.
[33] Alexandra Sasha Luccioni, Sylvain Viguier, and Anne-Laure Ligozat. Estimating the carbon footprint
of BLOOM, a 176B parameter language model. J. Mach. Learn. Res., 24(1), mar 2024.
[34] Microsoft. Microsoft in your community. https://local.microsoft.com/.
[35] Microsoft. Microsoft’s sustainability targets. https://datacenters.microsoft.com/
sustainability/efficiency/, 2023.
[36] David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild,
David So, Maud Texier, and Jeff Dean. Carbon emissions and large neural network training, 2021.
[37] Jovan Stojkovic, Chaojie Zhang, Inigo Goiri, Josep Torrellas, and Esha Choukse. DynamoLLM: Design-
ing LLM inference clusters for performance and energy efficiency. In IEEE International Symposium on
High-Performance Computer Architecture (HPCA), 2025.
[38] Noah Shumba, Opelo Tshekiso, Pengfei Li, Giulia Fanti, and Shaolei Ren. A water efficiency dataset
for african data centers. In NeurIPS Workshop on Tackling Climate Change with Machine Learning, 2024.
9


[39] U.S. EPA. eGRID data explorer. https://www.epa.gov/egrid/data-explorer.
[40] Equinix. Sustainability report. https://sustainability.equinix.com/wp-content/uploads/2024/
07/Equinix-Inc_2023-Sustainability-Report.pdf, 2024.
[41] U.S. Energy Information Administration. U.S. electric power sector continues water efficiency gains.
https://www.eia.gov/todayinenergy/detail.php?id=56820, 2022.
[42] U.S. Central Intelligence Agency. The world fact book — total water withdrawal. https://www.cia.
gov/the-world-factbook/field/total-water-withdrawal/, 2020.
10


Appendix: Operational Water for Global AI in 2027
A recent study suggests that the global AI could consume 85 – 134 TWh of electricity in 2027 based on the
GPU shipment [11], whereas a more aggressive projection by the U.S. Department of Energy predicts that
AI servers’ electricity consumption in the U.S. alone will surpass 150 – 300 TWh in 2028 [5]. Based on the
former and more conservative projection, we estimate the potential water usage for global AI in 2027, while
noting that our global estimates will be exceeded by the water usage attributed to AI in the U.S. alone in
2028 if the U.S. Department of Energy’s projection comes to fruition.
Scope-1 water usage. The scope-1 water efficiency depends on a variety of factors, including the cooling
system designs, climate conditions, and operational settings. To set the global scope-1 water efficiency, we
utilize the annualized water efficiencies reported by two leading data center operators, Google and Equinix,
in their latest sustainability reports [8, 40]. Specifically, for on-site scope-1 water withdrawal, we assume
1.2 L/kWh, which results in a total scope-1 water withdrawal of 0.11 – 0.16 billion cubic meters. Similarly,
assuming 1.0 L/kWh for the global scope-1 water consumption efficiency, we obtain a total on-site scope-
1 water consumption of 0.09 – 0.14 billion cubic meters. Note that Google and Equinix both operate data
centers globally, but represent two distinct categories of data centers: hyperscale data centers (Google) and
multi-tenant colocation data centers (Equinix). According to the U.S. Department of Energy [5], these two
types of data centers collectively account for the vast majority of data center energy consumption in the U.S.,
with colocation data centers consuming slightly more energy than hyperscalers.
Scope-2 water usage. As noted by the U.S. Department of Energy [5], scope-2 water usage is part of
the true water cost of data centers. The U.S. average electricity water withdrawal and consumption inten-
sity factors are both lower than the global averages [12]. Thus, in our estimate, we use the U.S. average
electricity water withdrawal intensity factor 43.83 L/kWh [41], and electricity water consumption intensity
factor 3.14 L/kWh [12], respectively. Note that, since [12] includes hydropower in the calculation, it has
a higher electricity water withdrawal factor than the U.S. Energy Information Administration’s calculation
(i.e., 386.07 L/kWh vs. 43.83 L/kWh for the U.S.). Moreover, our value of 3.14 L/kWh for the U.S. average
water consumption factor is lower than 4.35 L/kWh reported by the U.S. Department of Energy [5], as well
as lower than Meta’s global electricity water consumption intensity factor of 3.70 L/kWh in 2024 (i.e., 55,475
megaliters divided by 14,975,435 MWh) [25]. Therefore, our choices of 43.83 L/kWh and 3.14 L/kWh for
electricity water withdrawal and consumption intensity factors are both on the conservative side, which can
partly absorb potential over-estimates of global AI’s energy demand in 2027 provided by [11].
To account for the data center non-IT energy overheads, we conservatively assume a power usage effec-
tiveness (PUE) of 1.1, which is a fairly low value even for state-of-the-art data center facilities [8]. Thus,
AI’s total electricity consumption becomes 93.5 – 147.4 TWh. Thus, after multiplying 43.83 L/kWh and 3.14
L/kWh by 93.5 – 147.4 TWh, we obtain the total scope-2 water withdrawal of 4.10 – 6.46 billion cubic meters
and water consumption of 0.29 – 0.46 billion cubic meters, respectively.
Total water usage. By adding up scope-1 and scope-2 water usage together, the total water withdrawal
and water consumption of global AI may reach 4.2 – 6.6 billion cubic meters and 0.38 – 0.60 billion cubic
meters, respectively. According to the U.S. Central Intelligence Agency [42], the estimated U.S. annual water
withdrawals in Denmark and the United Kingdom in 2020 (the latest year available as of January, 2025) were
0.98 billion cubic meters and 8.42 billion cubic meters, respectively. Thus, assuming that the 2027 water
withdrawals in these two countries remain similar to their 2020 levels, the total water withdrawal attributed
to global AI in 2027 is projected to surpass the equivalent of the total annual water withdrawal of 4 – 6
Denmark or approximately half of the United Kingdom. The U.S. Central Intelligence Agency [42] does not
provide the country-wide annual water consumption information, and hence we do not contextualize the
total water consumption of global AI in 2027.
The estimates of global AI’s water usage in 2027 are naturally subject to uncertainties, e.g., the future
water efficiency may differ from the current value we use. Nonetheless, we emphasize that our estimates
are on the conservative side. For example, considering a higher estimate, the U.S. Department of Energy’s
scope-1 water consumption attributed to AI in the U.S. alone could exceed 0.2 billion cubic meters in 2028 [5].
Moreover, based on the reported scope-2 water consumption efficiency, the combined scope-1 and scope-2
water consumption attributed to AI in the U.S. alone is projected to reach up to about 2 billion cubic meters
in 2028 [5], which is significantly higher than our estimate of global AI’s total water consumption in 2027.
11


T EC H ·C L I M AT E  C H A N G E
California wildﬁres raise alarm on water-guzzling AI like
ChatGPT
BY  A N D  
January 9, 2025 at 11:15 AM EST
In order to shoot off one email per week for a year, ChatGPT would use up 27 liters of water, or about one-and-a-half jugs.
JAS M I N  M E R DA D  -  G E T T Y  I M AG E SHOME NEWS TECH FINANCE LEADERSHIP WELL EDUCATION FORTUNE 500
J A N E  T H I E R F O R T U N E  E D I TO R S
Get unlimited access for $29  $1/month. Cancel
anytime.
START MY TRIALCalifornia wildfires raise alarm on water-guzzling AI like ChatGPT | Fortune https://fortune.com/article/how-mu -use/
1 of 19 3/14/2025, 2:24 AM


If there weren’t enough of an argument against AI from an environmental standpoint , a
new waterfall of data might push even the most ambivalent consumer over the edge. 
Per the International Energy Agency , energy consumption by global data centers could
more than double by 2026, “reaching levels that exceed large nations.” Ironically, “while
we’re using AI to solve some of the world’s biggest challenges—from climate modeling to
health-care breakthroughs—we’re also contributing to an environmental crisis of a
different kind,” Chris Gladwin, a tech founder and CEO, wrote for Fortune recently. 
Related Video
How much water does AI use?
Now, reporting finds that OpenAI’s ChatGPT—which uses the GPT-4 language model—consumes 519 milliliters or just over one bottle of water, to write a 100-word email. That’sListen to the article now
1.0x
00:00 05:00
10
10
Powered by: Trinity AudioCalifornia wildfires raise alarm on water-guzzling AI like ChatGPT | Fortune https://fortune.com/article/how-mu -use/
2 of 19 3/14/2025, 2:24 AM


according to the Washington Post in a research collaboration with the University of
California, Riverside. 
In order to shoot off one email per week for a year, ChatGPT would use up 27 liters of
water, or about one-and-a-half jugs. Zooming out, WaPo wrote, that means if one in 10
U.S. residents—16 million people—asked ChatGPT to write an email a week, it’d cost more
than 435 million liters of water. 
While much has been made about the power usage each ChatGPT prompt immediately
necessitates, the water conversation has gained additional steam in recent months. 
As WaPo explained, every prompt a user enters into ChatGPT is quickly turned into code,
and “flows through a server that runs thousands of calculations to determine the best
words to use in a response.” All those calculations go through real, physical servers whichare housed in enormous data centers around the world. Spitting out an answer—oranswering a command—makes the servers heat up, like an under-duress old laptop. 
Why does AI use water?
This is where water comes in; to keep those ever-important servers from overheating andbreaking down, the data centers rely on cooling mechanisms, often via “cooling towers”that themselves require water. Each facility, depending on the climate where it’s based,uses a different amount of water and electricity. West Des Moines, Iowa, is quickly
becoming a popular destination , o
wing to a temperate climate that calls for fewer cooling
interventions. 
“We  haven’t come to the point yet where AI has tangibly taken away our most essentialCalifornia wildfires raise alarm on water-guzzling AI like ChatGPT | Fortune https://fortune.com/article/how-mu -use/
3 of 19 3/14/2025, 2:24 AM


natural water resources,”  wrote  Shaolei Ren, an associate professor of engineering at UC
Riverside who has been trying for years to quantify AI’s climate impact. Nonetheless, Ren
called AI’s increasing water usage “definitely concerning.” 
Amid rapid population growth and a changing climate, “depleting water resources andaging water infrastructures” are some of the most preeminent challenges, he wrote inNovember. “The concern is not only about the absolute amount of AI models’ water usage,but also about how AI model developers respond to the shared global challenge of watershortage.” 
How are AI companies addressing water and energy
use?
Droughts, he noted, are among the most immediate consequences of climate change, and
it’s incumbent upon businesses to address water usage in their operations—and tech firmsusing generative AI top that list. “We already see heated tensions over water usage betweenAI data centers and local communities,” Ren wrote. “If AI models keep on guzzling water,these tensions will become more frequent and could lead to social turbulence.”
Google  and Microsoft  report rising water
consumption
In Microsoft’s sustainability report  last year, the company said its global water
consumption had spiked 34% between 2021 and 2022. Over the same period, Google’swat
er usage rose 20% , it wrote in its own report. “It’s fair to say” that the majority of that
growth at both companies “is due to AI,” Ren told the AP at the time. (Microsoft’s data
center used up 700,000 liters of water in training GPT-3, WaP o reported.)
Holly Alpine, who was once Microsoft’s senior program manager of Datacenter CommunityEnvironmental Sustainability, resigned from the company earlier this year on principle,she wrote for Fortune , due to the company’s ecologically irresponsible AI development. 
“Analyst reports suggest that advanced technologies—such as AI or machine learning—hav
e the potential to increase fossil fuel yield by 15% , contributing to a resurgence of oil
and potentially delaying the global transition to renewable energy,” Alpine wrote. “Therea
l-world impacts are staggering: A single such deal between Microsoft and ExxonMobil
could generate emissions that exceed Microsoft’s 2020 annual carbon removalcommitments by over 600%.”
Whe
n she was a Microsoft employee, she wrote, she witnessed “dozens” of such deals.California wildfires raise alarm on water-guzzling AI like ChatGPT | Fortune https://fortune.com/article/how-mu -use/
4 of 19 3/14/2025, 2:24 AM


An earlier version of this story published on Fortune.com  on Sept. 23, 2024.
Did your workplace make our list of the World's Most Admired Companies?
Explore this year's list.
Latest in TechCalifornia wildfires raise alarm on water-guzzling AI like ChatGPT | Fortune https://fortune.com/article/how-mu -use/
5 of 19 3/14/2025, 2:24 AM


Data centers are booming in Texas. What
does that mean for the grid?
As energy demand surges, largely due to crypto mining facilities, data centers
and industrial electriﬁcation, Texas oﬃcials are looking at how to increase supplyand shore up the grid.
BY KAYLA GUO JAN. 24, 2025 5 AM CENTRAL SHARE
Sign up for The Brief , The Texas Tribune’s daily newsletter that keeps readers up to speed on the
most essential Texas news.
The rise of artiﬁcial intelligence, the digitization of the economy and everyday life’s
growing computing needs have turbocharged the expansion of data centers, driving up a
surge in electricity demand in Texas and across the country.
Texas’ main grid operator predicts power demand will nearly double by 2030, in part due to
more requests to plug into the grid from large users like data centers, crypto mining
facilities, hydrogen production plants and oil and gas companies.
On Tuesday, President Donald Trump announced Stargate, a joint venture between OpenAI,
SoftBank and Oracle that will invest up to $500 billion in AI-related infrastructure.
Texas will serve as ground zero, with 10 data centers by the venture already under
construction in the state, 10 more on the way and the ﬁrst project based in Abilene, Oracle
CEO Larry Ellison said . Each building will occupy half a million square feet.
The announcement reﬂected the hunger for data centers across industries and a yearslong
push to increase data capacity. Ellison noted that the partnership had been in the works for
years. He said the new data centers could offer services like maintaining electronic health
care records and helping hospitals share medical knowledge.
“The demand for digital services continues to increase and continues to be necessary to
build out our capabilities for the 21st century economy,” Dan Diorio, senior director of state
policy at the Data Center Coalition, an industry trade group, said in an interview. “Texas is
uniquely poised to beneﬁt from that.”What the data center boom in Texas means for the grid | The Texas Tribune https://www.texastribune.org/2025/01/24/texas-d grid/
1 of 5 3/14/2025, 2:16 AM


That expansion — in addition to other large energy users and factors such as population
growth and extreme weather — will stretch the grid over the next decade, raising questions
about how Texas can meet the skyrocketing demand for power while ensuring affordability
and reliability for everyday consumers.
Data centers in Texas
Data centers — which house servers that provide computing power and the fans and cooling
units needed to keep the equipment from overheating — are energy-intensive facilities that
operate 24/7.
Large data centers can require 100 MW or more each, consuming the same amount of power
per year as 350,000 to 400,000 electric cars, according to the International Energy Agency.
Put another way, a larger facility can use as much electricity as a medium-sized power
plant, the U.S. Energy Information Administration estimates.
Texas has seen a rapid increase in data capacity thanks to the state’s relatively cheap energy
prices, the ease with which facilities can connect to the grid and its overall business-
friendly tax and regulatory environment.
Companies generally employ around 50 to 150 or more employees in each data center, in
addition to an array of building and maintenance contractors, according to the Data Center
Coalition, which estimates that each job in a data center supported six jobs elsewhere in the
economy.
The state had 279 data centers as of September, according to the Texas Comptroller. The
Dallas-Fort Worth area has about 141 of those.
That translated to 591 MW of power leased by data centers in Dallas and Fort Worth last
year — the second most in the country — and nearly 190 MW in Austin and San Antonio,
according to a CBRE report.
The Electric Reliability Council of Texas, the state’s primary grid operator, estimates that 1
MW of electricity can power roughly 200 homes.
What do more data centers mean for the grid?
In Texas, the U.S. Energy Information Administration predicted that demand from large
users — including but not limited to data centers — would grow by 60% this year, making up
around 10% of the total forecast demand on the state’s main grid.What the data center boom in Texas means for the grid | The Texas Tribune https://www.texastribune.org/2025/01/24/texas-d grid/
2 of 5 3/14/2025, 2:16 AM


Large users requiring 5,496 MW of power have been approved by ERCOT to connect to the
grid, according to a September report. The EIA expects that by the end of this year, ERCOT
will have approved 9,500 MW in total large-user demand — a 73% increase.
That includes data centers and other large users like crypto mining facilities, which
represent the biggest share of large users looking to connect to the grid, according to
ERCOT.
Several other large-load projects — which would use up to 56,458 MW a year — were
awaiting ERCOT consideration as of September.
Some large users, primarily crypto mining facilities, have committed to temporarily
lowering their energy usage in periods of grid strain — an agreement that earned some
crypto mining companies millions of dollars  while many Texans’ saw their power bills surge.
Data centers, on the other hand, generally require an uninterrupted supply of power and
typically do not participate in ERCOT’s high-demand response programs, according to a
recent report from the Texas Senate Business and Commerce Committee.
Nationally, data centers are expected to consume between 11% and 12% of total U.S. power
demand by 2030 — up from around 3% and 4% of demand today, according to an analysis by
McKinsey .
Is the grid prepared?
How to meet soaring power demand is set to drive the discussion around the grid during
this year’s legislative session.
Texas lawmakers have sought to boost the state’s supply of natural gas through the Texas
Energy Fund, which will offer companies up to $10 billion in low-interest loans to build gas-
fueled power plants. State regulators are currently vetting loan applications, but new plants
will not be operational for years.
“Data centers are going to provide a very essential product for consumers that underpins
the functions of our life,” Mark Bell, president of the Association of Electric Companies of
Texas, said. “ As an industry, we are ready to step up to the challenges that we face with this
type of large load.”
Bell added that the projected demand “provides forward signals in the market” that
encourage companies to invest in new power generation.What the data center boom in Texas means for the grid | The Texas Tribune https://www.texastribune.org/2025/01/24/texas-d grid/
3 of 5 3/14/2025, 2:16 AM


ERCOT’s demand forecast, which reﬂected a sharp increase from previous years, also raised
questions among lawmakers about whether large users needed more state oversight.
“I think we need to rise to the challenge of getting the needed generation onto the grid,”
state Sen. Charles Schwertner, chair of the Business and Commerce Committee, told The
Texas Tribune in June. “But there is eventually a prioritization that could be discussed, and
obviously Texans — their families, their homes, their businesses — are the most important
individuals, the most important clients for electricity.”
On social media, Lt. Gov. Dan Patrick said in June that the Legislature needed to “take a
close look” at data centers and crypto mining facilities. “We want data centers, but it can’t
be the Wild Wild West of data centers and crypto miners crashing our grid and turning the
lights off,” he wrote.
Patrick said in a Thursday statement to The Texas Tribune that he supported Stargate and
believed Texas should be the “world leader in AI, data center and crypto. The key is to
ensure they have the power they need without a major impact to our electrical grid. The
industries understand that and they are working on solutions.”
Some companies are building generation locally or on site  to help lessen their impact on the
grid and lock in their own power supply. Building their facilities near existing generation
sites can also help alleviate grid congestion. Lawmakers this session will likely consider
whether companies should be forced to do so, with the Texas Senate Business and
Commerce Committee recommending that large loads be required to “offset their impact on
the grid by adding on-site power systems or participating in programs to curtail electricity
usage during peak demand periods.”
Judging whether data centers and other large projects might actually build in Texas after
requesting ERCOT consideration remains difﬁcult, experts testiﬁed to lawmakers last year,
making ERCOT’s demand prediction less certain. Companies looking to build data centers
may submit requests in multiple prospective locations.
In order to help ﬁrm up that forecast, the Texas Senate Business and Commerce Committee
recommended that  the state ensure regulators have enough information about how large
users might operate, such as by asking companies to submit more detailed information
about their proposed projects.
The Public Utility Commission approved a rule in November requiring crypto mining
facilities connected to the ERCOT grid to register their power usage with regulators.What the data center boom in Texas means for the grid | The Texas Tribune https://www.texastribune.org/2025/01/24/texas-d grid/
4 of 5 3/14/2025, 2:16 AM


The projected growth in usage also means the grid will need more transmission lines,
ERCOT CEO Pablo Vegas said in April.
“The forecasted pace of load growth could exceed the pace at which transmission capacity
can be built to support it,” Vegas’ presentation said. “ A new era of transmission system
planning is necessary to manage the large amount of prospective load.”
Typically, the costs of building out transmission and distribution infrastructure are spread
across a utility’s customers. But the major investments needed to support demand driven by
large industrial users raised the question of who should foot the bill.
Lawmakers have signaled interest in limiting the costs passed onto small energy consumers
“by ensuring that industries with signiﬁcant electricity demands bear a fair portion of their
actual costs.”
Diorio, of the Data Center Coalition, emphasized that the industry was “fully committed to
paying our full cost of service.”
“We do not want residential customers subsidizing data centers,” he said. “We have a strong
stake in helping Texas build out appropriately, and we’re leaning in to do that.”
Disclosure: Association of Electric Companies of Texas (AECT) has been a ﬁnancial supporter of
The Texas Tribune, a nonproﬁt, nonpartisan news organization that is funded in part by
donations from members, foundations and corporate sponsors. Financial supporters play no role
in the Tribune's journalism. Find a complete list of them here.
Learn about The Texas Tribune’s policies, including our partnership with
The Trust Project to increase transparency in news.What the data center boom in Texas means for the grid | The Texas Tribune https://www.texastribune.org/2025/01/24/texas-d grid/
5 of 5 3/14/2025, 2:16 AM


ON-PREM
How datacenters use water – and why kicking
the habit is nearly impossible
If they're not consuming H O directly, the power plant almost certainlyis
Tobias Mann Sat 4 Jan 2025 // 18:30 UTC2
FEATURE The explosive growth of datacenters that followed ChatGPT's debut in 2022 has
shone a spotlight on the environmental impact of these power-hungry facilities.
But it's not just power we have to worry about. These facilities are capable of sucking down
prodigious quantities of water .
In the US, datacenters can consume anywhere between 300,000 and four million gallons ofwater a day to keep the compute housed within them cool, Austin Shelnutt of Texas-basedStrategic Thermal Labs explained in a presentation at SC24 in Atlanta this fall.
We'll get to why some datacenters use more water than others in a bit, but in some regions
rates of consumption are as high as 
25 percent of the municipality's water supply.
This level of water consumption, understandably, has led to concerns over water scarcityand desertification, which were already problematic due to climate change, and have onlybeen exacerbated by the proliferation of generative AI. Today, the AI datacenters built totrain these models often require tens of thousands of GPUs, each capable of generating1,200 watts of power and heat.
However, over the next few years, hyperscalers, cloud providers, and model builders plan to
deploy millions of GPUs and other AI accelerators requiring gigawatts of energy, and thatmeans even higher rates of water consumption.
According to researchers at UC Riverside and the University of Texas Arlington, by 2027
global AI demand could 
account for  the withdrawal of 4.2-6.6 billion cubic meters of water
annually. That's roughly the equivalent of half the UK's water withdrawal over the course of ayear.
However, mitigating datacenter water consumption isn't as simple as ditching evaporative
cooling towers for waterless alternatives.Kicking datacenters' drinking habit is nearly impossible • The Register https://www.theregister.com/2025/01/04/how_d ater/
1 of 6 3/14/2025, 2:18 AM


The datacenter water cycle
Datacenters consume water in a couple of ways. The first, and the area we'll focus most of
our attention on, is direct water consumption. This is water that's pulled from local sourcesincluding water and wastewater treatment plants.
This water is pumped into cooling towers, where it evaporates, transferring heat to the air. If
you've ever used a swamp cooler to chill your home or apartment, cooling towers work in asimilar manner.
Evaporative cooling has become popular among datacenter operators for a couple of
reasons, but the big one is they're really good at getting rid of heat and don't require a ton ofelectricity to do it.
According to Shelnutt, evaporating ten gallons a minute is enough to cool roughly 1.5
megawatts of compute.
When we talk about "consumption," we're referring to water that's been evaporated. It isn't
actually consumed so much as it's removed from the local watershed by the prevailingwinds. This can be problematic given evaporative coolers are most effective in arid climateswhere water scarcity is commonly a problem.
According to researchers, about 70-80 percent of the water that enters a cooling tower is
actually 
consumed  [PDF], the rest is used to flush out mineral deposits similar to those found
when cleaning a humidifier. The brine that's left behind is recycled through the system until itexceeds a certain concentration, at which point it's flushed away to a holding pond ortreatment plant run onsite or by the local mu
nicipality before it's returned to the local
watershed.
For this to work, the wastewater treatment plant needs to be sized correctly to handle the
volume and concentration of brine generated by datacenters in the region. Things can getcomplicated pretty quickly when this isn't done, as was the case for Microsoft's 
campus in
Goodyear, Arizona.
Why datacenters' drinking habit is so hard to quit
One of the reasons that datacenter operators have gravitated toward evaporative coolers isbecause they're so cheap to operate compared to alternative technologies.
"It is always of a higher coefficient of performance (COP), meaning less energy required, to
evaporate water, regardless of what cooling medium is being utilized," Shelnutt said.Kicking datacenters' drinking habit is nearly impossible • The Register https://www.theregister.com/2025/01/04/how_d ater/
2 of 6 3/14/2025, 2:18 AM


In fact, COP, which refers to the amount of heat removed for a given amount of power, for
evaporative cooling comes in at 1,230 while dry coolers and chillers manage a COP of about12 and 4, respectively, he explained.
In terms of energy consumption, this makes an evaporatively cooled datacenter far more
energy efficient than one that doesn't consume water, and that translates to a loweroperating cost.
The challenge is that not every location and climate is well suited to evaporative cooling. In
hotter climates where water is either scarce or places with high humidity where evaporativecoolers are ineffective, chillers, which function similar to your AC unit, may be used instead.
In cooler climates such as the Nordic regions, datacenters often make use of free cooling
and dry coolers, which take advantage of the lower ambient air temperature to eject heat intothe atmosphere without consuming any water.
Whether or not evaporating cooling is used is highly dependent on location and climate,
Digital Realty CTO Chris Sharp told 
The Register .
"You have to understand water is a scarce resource. Everybody has to start at that basepoint," he explained. "You have to be good stewards of that resource just to ensure thatyou're utilizing it effectively."
The colocation giant operates more than 300 bit barns around the globe, and uses a variety
of designs based on predicted capacity requirements and environmental factors. Thecompany's standard datacenter design, Sharp says, doesn't consume any water at all,instead relying on chillers to pull energy from the facility. However, in some locations,evaporative cooling and dry coolers are employed instead.
Most datacenter water isn't consumed onsite
While dry coolers and chillers may not consume water onsite, they aren't withoutcompromise. These technologies consume substantially more power from the local grid andpotentially result in higher indirect water consumption.
According to the US Energy Information Administration, the US 
sources roughly 89 percent
of its power from natural gas, nuclear, and coal plants. Many of these plants employ steam
turbines to generate power, which consumes a lot of water in the process.
Ironically, while evaporative coolers are why datacenters consume so much water onsite, the
same technology is commonly employed to reduce the amount of water lost to steam. EvenKicking datacenters' drinking habit is nearly impossible • The Register https://www.theregister.com/2025/01/04/how_d ater/
3 of 6 3/14/2025, 2:18 AM


still the amount of water consumed through energy generation far exceeds that of modern
datacenters.
A 2016 study [PDF] by Lawrence Berkeley National Lab (LBL) found that roughly 83 percent
of water consumption attributable to datacenters could be attributed to power generation. As
a result, reducing onsite water consumption at the expense of higher power draw could leadto an increase in the amount of water consumed.
However, just because power plants may pull more water than datacenters, that doesn't
mean they're pulling the same water, Shaolei Ren, associate professor of electrical andcomputer engineering at UC Riverside, told 
The Register , adding that many power plants get
their water from sources like rivers and lakes that may not be suitable for datacenters.
Ren and his team have been studying the datacenter's environmental impact on water
consumption and air quality.
This, again, is highly dependent on location and the grid mix. For example, datacenterslocated in regions with an abundance of hydroelectric, solar, or wind power will have lowerindirect water consumption than one powered by fossil fuels or combustion.
What can be done to curb datacenter water consumption?
Understanding that datacenters are, with few exceptions, always going to use some amountof water, there are still plenty of ways operators are looking to reduce direct and indirectconsumption.
One of the most obvious is matching water flow rates to facility load and utilizing free cooling
wherever possible. Using a combination of sensors and software automation to monitorpumps and filters at facilities utilizing evaporative cooling, Sharp says Digital Realty hasobserved a 15 percent reduction in overall water usage.
"That equates to about 126 million gallons of avoided withdrawal from the system because
we're just running it more efficiently," he said.
We're also seeing datacenters built in colder climates that can take advantage of free cooling
most of the year. Better yet, in many Nordic countries, large quantities of hydroelectric powermean that even if auxiliary dry coolers or chillers are required, indirect water consumptionisn't as much of an issue.
We've also seen heat generated by datacenters used to warm local offices, support district
heating grids, or even greenhouses to grow produce year round.Kicking datacenters' drinking habit is nearly impossible • The Register https://www.theregister.com/2025/01/04/how_d ater/
4 of 6 3/14/2025, 2:18 AM


In locations where free cooling and heat reuse aren't practical, shifting to direct-to-chip and
immersion liquid cooling (DLC) for AI clusters, which, by the way, is a closed loop thatdoesn't really consume water, can facilitate the use of dry coolers. While dry coolers are stillmore energy-intensive than evaporative coolers, the substantially lower and therefore betterpower use effectiveness (PUE) of liquid cooling could make up the difference.
If you're not familiar, PUE describes how much power consumed by datacenters goes
toward compute, storage, or networking equipment – stuff that makes money – versus thingslike facility cooling, which don't. The closer the PUE is to 1.0, the more efficient the facility.
This is possible because a sizable chunk, upward of 20 percent, of the energy used by
air-cooled AI systems goes to chassis fans. On top of that, water is a much better conductorof heat. Shifting to DLC, something that's already happening with Nvidia's top-speccedBlackwell parts, has the potential to drop PUE from 
1.69-1.44 to around 1.1 or lower.
However, as Shelnutt noted in his SC24 presentation, this balancing act depends heavily onthe power saved by DLC not being reallocated to support additional compute.
Water-aware computing
While many of these water-saving technologies require changes to facility infrastructure toimplement, another approach might be to change the way workloads are distributed acrossdatacenters.
The idea here isn't that different from carbon-aware computing, where workloads are routed
to different locations based on the time and carbon-intensity of the grid, Ren explained."They can do something similar based on the water stress level and real-time waterefficiency, because this water evaporation rate does change over time - an hourly noon timeversus the night time."
This, he admits, isn't something that the cloud providers and hyperscalers will have an easier
time achieving as they maintain a tight grip on the orchestration of their infrastructure."Colocation providers have more challenges due to limited control over the servers andworkloads."
This approach may also not be appropriate for latency-sensitive workloads, like AI
inferencing, where proximity to users is imperative for real-time data processing. However,workloads like AI training don't have these same limitations. One can imagine an AI trainingworkload, which might run for weeks or months, could be queued up to run in a far-flungdatacenter located in the polar regions that can take advantage of free cooling.Kicking datacenters' drinking habit is nearly impossible • The Register https://www.theregister.com/2025/01/04/how_d ater/
5 of 6 3/14/2025, 2:18 AM


Fine-tuning workloads, which involve changing the behavior of a pre-trained model, are far
less computationally intensive. Depending on the size of the base model and the datasetused, a fine-tuning job may only require a few hours to complete. In this case, the job couldbe scheduled to run at night when temperatures are lower and less water is lost toevaporation.
Is water the new oil?
While datacenter water consumption remains a topic of concern, particularly indrought-prone areas, Shelnutt argues the bigger issue is where the water used by thesefacilities is coming from.
"Planet Earth has no shortage of water. What planet Earth has a shortage of, in some cases,
is regional drinkable water, and there is a water distribution scarcity issue in certain parts ofthe world," he said.
To address these concerns, Shelnutt suggests datacenter operators should be investing in
desalination plants, water distribution networks, on-premises wastewater treatment facilities,and non-potable storage to support broader adoption of evaporative coolers.
While the idea of first desalinating and then shipping water by pipeline or train might sound
cost-prohibitive, many hyperscalers have already committed hundreds of millions of dollarsto securing onsite nuclear power over the next few years. As such, investing in waterdesalination and transportation may not be so far fetched.
More importantly, Shelnutt claims that desalinating and shipping water from the coasts is still
more efficient than using dry coolers or refrigerant-based cooling tech.
"Desalinate ocean water right now at three kilowatt [hours] per cubic meter – that's an
average over the last ten years; there are many installations of desalination plants that aredown below one kilowatt hour per cubic meter – that's a COP of 222," he said.
Ship that 1,000 miles by pipeline and Shelnutt says the COP drops to 132. Shipped by train,
the COP falls yet further to 38, far less than evaporating water sourced from a municipaltreatment plant, but still far more efficient than using dry coolers. ®Kicking datacenters' drinking habit is nearly impossible • The Register https://www.theregister.com/2025/01/04/how_d ater/
6 of 6 3/14/2025, 2:18 AM


Home > Data center design and facilities
TechTarget and Informa Tech’s Digital Businesses Combine.
PUTILOV_DENIS - STOCK.ADOBE.COMPUTILOV_DENIS - STOCK.ADOBE.COM
3 OF 4 Part of: The future of AI hardware in the data
center
How the rise in AI impacts data centers
and the environment
AI's impact on data centers raises environmental concerns as rising energy
demands from technologies such as ChatGPT strain resources and challengesustainability.FEATURE AA
ByJacob Roundy Published: 25 Nov 2024
Since OpenAI launched ChatGPT in late 2022, there has been an AI boom across
all tech industries that has greatly increased data center electricity consumption anddemand.
Generative AI (GenAI) chatbots, like ChatGPT, use 
natural language processing
technology to interpret prompts conversationally, which greatly lowers the user
adoption barrier. This led to ChatGPT becoming an instant viral sensation, and inonly two months, the software gained more than 
100 million users .9Search
Data Center g
+ 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
1 of 8 3/14/2025, 2:10 AM


This rapid growth is often credited as the acceleration point for public-facing AI
projects. Since ChatGPT's launch, other tech giants, including Google, Microsoft andMeta, have launched their own 
large language model  chatbots, garnering even more
users on a global scale. The electricity consumption of these technologies isextremely high, raising concerns about the environmental impact of AI and theoverall energy use in data centers.
Take a deeper look at how the AI boom affects the environment, including how it
uses energy, real-world impacts on the world and potential ways da
ta centers can
balance AI workloads while mitigating climate impact .
The International Energy Agency  (IEA) found that data centers and data
transmission networks each account for 1% to 1.5% of global electricity consumptionand 1% of energy-related greenhouse gas emissions. The energy demand strainselectricity grids in many regions, and the resulting emissions 
harm the environment
in various ways.
According to a report published in May 2024 by the Electric Power Research
Institute  (EPRI), electricity consumption by large data centers more than doubled
between 2017 and 2021 -- before the AI boom. Much of this growth was driven by
commercially available digital services, like video streaming and communicationsapplications. Now, the proliferation of AI is further fueling data center load growth.
AI workloads are more energy-intensive than other digital technologies. For
example, the EPRI report estimated that traditional Google queries only use abo
ut
0.3 watt-hours  each, while ChatGPT requests consume around 2.9 watt-hours each.
That's nearly 10 times the amount of electricity consumption. GenAI models thatcreate images, audio and videos consume even more electricity per request.
According to EPRI estimates, AI workloads
use 10% to 20% of data center electricity.These statistics raise concerns as AI rapidlygrows and expands in business and
commercial sectors. EPRI industr
y analystsHow AI uses so much power within the data center
AI must process vast
volumes of data andconduct complexcomputationalworkloads, which is
+ 3 of 4AAzHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
2 of 8 3/14/2025, 2:10 AM


developed future scenarios for data center
load growth with this in mind. They projectedthat data centers may consume 4.6% to9.1% of U.S. electricity generation annuallyby 2030 versus an estimated 4% as of 2024.
To put this into perspective, developers are
currently building new data centers with capacities reaching up to 1,000 megawatts,enough to power 800,000 homes, according to the EPRI report. EPRI identifiedthree main factors that contribute to the high energy consumption of AI workloads:
1. Model development.  AI models must be developed and fine-tuned before
training. This process uses approximately 10% of their energy footprint,according to EPRI.
2. Model training.  An AI algorithm must process large amounts of data to train a
model. This process requires "substantial computation efforts and high energyexpenditure for extended periods," using about 30% of the energy footprint,according to EPRI.
3. Utilization.  Deploying and using a fully developed and trained AI model in real-
world applications requires intensive computations, which, according to EPRI,accounts for around 60% of their energy footprint.
AI must process vast volumes of data and conduct complex computationalworkloads, which is why it consumes so much more electricity than other digitaltechnologies. As these technologies mature and proliferate, they'll likely grow morecomplex and demand more energy.why it consumes so
much more electricitythan other digitaltechnologies. Up Next
A10 top AI hardware and chip-making A primer on AI chip design
+ 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
3 of 8 3/14/2025, 2:10 AM


IEA created the Net Zero Emissions by 2050 Scenario, which details a pathway for a
global transition to clean energy that should limit global warming by 1.5 degreesCelsius.
The Intergovernmental Panel on Climate Change's "
Sixth Assessment Report "
outlines the risks. According to IPCC, these risks include frequent extreme weather
events, the loss of some entire ecosystems, exceptional heatwaves and moreintense tropical cyclones. An increase in severe weather conditions will lead toextreme droughts, increasing flood hazards, and impacts on water and resourceavailability.
Increase in carbon emissions
A study  by researchers at the University of Massachusetts Amherst estimated that
training a large AI model could produce over 626,000 pounds of carbon dioxideequivalent. According to the university's researchers, this is more than five times acar's emissions over its entire lifetime.
Use of nonrenewable resources
According to a United Nations Environment Programme report , critical minerals and
rare earth elements are used to create the microchips used to power AI. Thesematerials are potentially finite and difficult to recycle, and they are often mined inExamples of AI's impact on the environment
+ 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
4 of 8 3/14/2025, 2:10 AM


environmentally destructive ways. The electronic waste they produce may also
contain hazardous substances.
Increase in water usage
Data centers consume water to liquid-cool the hardware that runs AI applications.According to an 
article  in Yale Environment 360 , a user who engages with ChatGPT
between 10 and 50 times causes a data center to consume half a liter of water.ChatGPT has millions of users, which means total water consumption can amount tohundreds of millions of gallons of water just to cool the equipment running AI.
These are just a few examples of the strain AI is placing on the environment. A
careful approach and thoughtful strategies are required to keep 
these environmental
impacts  in check and to build toward a more sustainable future in the industry.
EPRI created scenarios that project the potential growth rate of data centerelectricity consumption.
The first scenario starts with a baseline of the average data center load in 2023,
which equates to a little more than 150,000,000 megawatt-hours (MWh). In thehighest growth rate scenario, EPRI projected an average data center load o
f more
than 400,000,000 MWh by 2030, a staggering 166% change in growth. Conversely,the lowest growth rate scenario has a projected average data center load of lessthan 200,000,000 MWh by 2030.
While the higher growth rate scenario is intimidating, these are just projections, and
much can change in the next decade. Some factors are out of our control, likeconsumer demand for AI technologies, but others can be controlled.
EPRI offers a few areas to focus on for data centers to curb their rising energy
usage, keep load levels toward the lower end of the projected growth rate scenariosand mitigate the 
environmental impacts of AI workloads .
Operational efficiency and flexibilityPotential future stats and scenarios
EPRI guidelines to mitigate AI's negative impact
+ 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
5 of 8 3/14/2025, 2:10 AM


A comprehensive strategy is necessary to meet rising energy demands and limit
emissions growth. Strategies include investing in more energy-efficient processorsand server architectures, leaning on 
virtualization  to improve resource flexibility,
adopting more effective cooling technologies, and using continuous monitoring andanalytics to ensure optimal operational efficiency and better adaptability.
Collaboration through a shared energy economy model
Electric companies must balance resources between regular customers and datacenters with accelerating and unpredictable load growth. To better handle thissituation, data centers can collaborate more closely with electric companies tocreate a 
shared energy economy . For example, electric companies can utilize data
center backup generators as a grid reliability resource, offering a more symbioticrelationship.
Load growth forecasting and modeling
With more accurate forecasting and modeling tools, data centers and electriccompanies can better collaborate to anticipate interconnection requests. This canhelp electric companies understand the full power demand that data centers requireover time. By doing so, they can avoid stressing the energy grid and introduceflexibility into operational bandwidth and resource management.
Upgrades to the data center
To address the increasing demands of AI in data centers, administrators shouldconsider adopting more flexible computational strategies and efficient servermanagement tools. It's essential to utilize advanced computational hardware, suchas tensor processing units, field-programmable gate arrays and GPUs.
Admins should implement resource-efficient algorithmic techniques, like pruning and
quantization. It is also crucial to transition to carbon-free and low-carbon electricitysources and adopt cleaner power systems.
Achieving the Net Zero Emissions by 2050 Scenario is still possible despite the
massive energy demand to fuel AI workloads. However, the path ahead is narrowand will require global cooperation to ensure data centers can limit energy usageand 
consume electricity more sustainably , while powering the evolving technological + 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
6 of 8 3/14/2025, 2:10 AM


About Us Contributors Guideslandscape.
Jacob Roundy is a freelance writer and editor with more than a decade of
experience with specializing in a variety of technology topics, such as data centers,business intelligence, AI/ML, climate change and sustainability. His writing focuseson demystifying tech, tracking trends in the industry, and providing practicalguidance to IT leaders and administrators.
6 sustainable resources to power data centersNext Stepsm
Dig Deeper on Data center design and facilitiesm
How data centers can help
balance the electrical grid
By: Jacob RoundyHow much energy do data
centers consume?
By: Jacob Roundy
IRA fate will affect U.S.
renewable energy projects
By: Makenzie HollandHow to use data center wind
turbines for sustainableenergy
By: Julia Borgini
+ 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
7 of 8 3/14/2025, 2:10 AM


Latest TechTarget
resources
WINDOWS SERVER A
CLOUD COMPUTING
STORAGE
SUSTAINABILITY AND ESGSearchWindows Server
March Patch Tuesday fixes
6 Windows zero-dayexploits
All the vulnerabilities that had been actively
exploited in the wild will get resolved quicklyby deploying the Windows ...2
How to set up Docker
containers on WindowsServer
Docker started on the Linux OS, but Windows
containers based on this technology can bringnumerous benefits to the enterprise. ...2Editorial Ethics Policy
Meet The Editors
Contact Us
Advertisers
Partner with Us
Media Kit
Corporate SiteReprints
Answers
Definitions
E-Products
Events
FeaturesOpinions
Photo Stories
Quizzes
Tips
Tutorials
Videos
All Rights Reserved, Copyright 2000 - 2025, TechTarget
Privacy Policy
Do Not Sell or Share My Personal Information
This website is owned and operated by Informa TechTarget,
part of a global network that informs, in�uences andconnects the world’s technology buyers and sellers. Allcopyright resides with them. Informa PLC’s registered o�ceis 5 Howick Place, London SW1P 1WG. Registered in Englandand Wales. TechTarget, Inc.’s registered o�ce is 275 GroveSt. Newton, MA 02466.
+ 3 of 4AAHow the rise in AI impacts data centers and the environment | TechTarget https://www.techtarget.com/searchdatacenter/feature -A...
8 of 8 3/14/2025, 2:10 AM


AI
The boom in AI has led to a boom in AI data centers. Several readers
asked us to VERIFY how these hubs use water and electricity.
The use and prevalence of generative artiﬁcial intelligence (AI) technology has ballooned over
the past few years. This includes the growth of chatbots like ChatGPT and image generators
like Midjourney.
As AI has become ubiquitous, people have raised concerns about the environmental impacts of
the technology. One of the more common criticisms is that it requires more water and power
than older technology.
Some people have drawn links between this resource use, climate change and the wildﬁres in
Los Angeles. A viral post from Instagram that has since been  reshared many times  claimed that
a single interaction with ChatGPT uses 10 times the amount of energy as a Google search.
Readers Olive and Dean also asked us to VERIFY the impact artiﬁcial intelligence has on water
and power usage. 
THE SOURCES
•International Energy Agency (IEA)
•University of Illinois Urbana-Champaign’s Center for Secure Water
•Article on AI energy crisis published by Nature
•Google’s 2024 Environmental Report
•2023 study by engineering researchers from the University of California, Riverside
•2023 study by researcher with Digiconomist , a research company focused on unintendedWhat we can VERIFY about AI and
its environmental impact
Author:  Emery Winter
Published: 2:37 PM EST January 17, 2025
Updated:  1:31 PM EST January 24, 2025
x
 00:13 /01:16  xAI uses more energy, water than a Google search without AI | wtsp.com https://www.wtsp.com/article/news/verify/ai/ai-elect cha...
1 of 4 3/14/2025, 2:05 AM


consequences of digital trends
• Sunbird , a company that makes data center management software
WHAT WE FOUND
Our current online world relies on vast amounts of computers and data centers to operate.
These centers power everything we do online, from conducting internet searches to streaming
movies.
Artiﬁcial intelligence is more sophisticated than a regular web search or movie stream. It
requires exponentially more computing power to complete what may seem like simple tasks.
The AI boom has thus led to a rise in new data centers, too. These new data centers that
support the additional computing power required are the source of AI’s outsized environmental
impact. 
H Ho ow w  A AI I  u us se es s  e el le ec ct tr ri ic ci it ty y   
An AI tool like ChatGPT relies on large amounts of data and equally large amounts of computer
processing power to provide a result. Tech companies keep computer systems to store this
data and run programs to process it in physical locations called  data centers .
When someone gives an AI program a prompt, it uses computational power to sift through and
process all of that data, Katherine Bourzac, a science writer for Nature journals,  wrote in a 2024
article . The more computational power used, the more electricity is needed. 
H Ho ow w  A AI I  u us se es s  w wa at te er r
It’s not just electricity data centers need more of when they use more computational power;
they also need more water, according to the  University of Illinois Urbana-Champaign’s Center
for Secure Water .
The more power a computer uses, the more heat it generates. If a computer gets too hot, it’ll
start running into problems. That’s why laptops and personal computers have fans inside of
them that spin faster when the computer works harder.
Many data centers use industrial-sized fans to do the same thing on a large scale. However,
traditional air cooling isn’t always enough to dissipate the amount of heat generated by all of
the computer power AI uses, according to  Sunbird, a data center management software
company. So AI data centers use liquid coolants, which absorb and transfer heat better than air
does.
When data centers use water as their liquid coolant, the water is pumped through pipes
surrounding the center’s equipment, where it absorbs excess heat and is then typically pumped
back out through a  heat exchanger to a coolant tower , where the water evaporates. That
means these data centers need a constant source of water to run through their systems.AI uses more energy, water than a Google search without AI | wtsp.com https://www.wtsp.com/article/news/verify/ai/ai-elect cha...
2 of 4 3/14/2025, 2:05 AM


A AI I  r re es so ou ur rc ce e  u us sa ag ge e  b by y  t th he e  n nu um mb be er rs s
The average electricity demand of a typical Google search without AI is 0.3 Wh (watt-hours) of
electricity, while the average electricity demand of a ChatGPT request is 2.9 Wh, according to
the International Energy Agency (IEA) .
In 2023, John Hennessy, chairman of Google parent company Alphabet,  told Reuters  that he
predicted an exchange with an AI chatbot would likely be 10 times more energy intensive than
a standard Google search without AI.
While 0.3 to 2.9 Wh might not seem like much ( a toaster typically uses 10 to 160 Wh per use ),
those numbers add up. In 2021, before Google began integrating AI overviews into its search
engine, Google consumed more than 18 trillion watt-hours of electricity, according to  a study by
a researcher with Digiconomist . At that time, AI accounted for 10-15% of the total electricity
Google used.
Various estimates within that study estimated that Google search integrated with AI could use
between 6.9 and 8.9 Wh per search. Google didn’t include the total amount of electricity it
consumed in its  most recent environmental report , but Google did say that in 2023 it released
37% more emissions from using electricity than it did in 2022.
Google said the increase in emissions was primarily because its increasing demand for
electricity for its data centers outpaced its ability to bring more carbon-free energy projects
online.
In its most recent environmental report, Google reported it consumed 14% more water in 2023
than it did in 2022. This is “primarily due to water cooling needs” at Google’s data centers,
“which experienced increased electricity consumption year-over-year.”
The exact amount of water used to cool the machines in a data center can depend on the data
center’s design and location; data centers in hotter locations need more water for cooling.
On average, data centers can consume approximately 1-9 liters of water per kWh of server
energy, according to an estimate from engineering researchers at the University of California,
Riverside .
Related Articles
No, the Biden administration is not banning all natural gas water heaters
Images of the Hollywood sign on ﬁre are fake
Fact-checking viral ‘lone survivor’ house images from California ﬁresAI uses more energy, water than a Google search without AI | wtsp.com https://www.wtsp.com/article/news/verify/ai/ai-elect cha...
3 of 4 3/14/2025, 2:05 AM


The VERIFY  team works to separate fact from ﬁction so
that you can understand what is true and false. Please
consider subscribing to our daily newsletter , text alerts
and our YouTube channel . You can also follow us on
Snapchat , Instagram , Facebook and TikTok . Learn More
»Follow Us
Want something VERIFIED?
Text: 
LOADING NEXT ARTICLE...AI uses more energy, water than a Google search without AI | wtsp.com https://www.wtsp.com/article/news/verify/ai/ai-elect cha...
4 of 4 3/14/2025, 2:05 AM


TY ale Environment 360
As Use of A.I. Soars, So Does the Energy and Water It
Requires
Generative artiﬁcial intelligence uses massive amounts of energy for computation and data
storage and millions of gallons of water to cool the equipment at data centers. Now,
legislators and regulators — in the U.S. and the EU — are starting to demand accountability.
BY  DAV I D B E R R E BY •F E B RUA RY  6, 2024
wo months after its release in November 2022, OpenAI’s ChatGPT had
100 million active users, and suddenly tech corporations were racing to
oﬀer the public more “generative A.I.” Pundits compared the new
technology’s impact to the Internet, or electriﬁcation, or the Industrial Revolution— or 
the discovery of ﬁre.
Time will sort hype from reality, but one consequence of the explosion of artiﬁcialintelligence is clear: this technology’s environmental footprint is large and growing.
A.I. use is directly responsible for carbon emissions from non-renewable electricity
and for the consumption of millions of gallons of fresh water, and it indirectlyboosts impacts from building and maintaining the power-hungry equipment onwhich A.I. runs. As tech companies seek to embed high-intensity A.I. intoeverything from resume-writing to kidney transplant medicine and from choosingdog food to climate modeling, they cite many ways A.I. could help reducehumanity’s environmental footprint. But legislators, regulators, activists, andInside the Guian Dat � Center of Chin � Unicom, which uses artificial intelligence in its operations. TAO LIANG / XINHUA VIA GETTY IMAGESAs Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
1 of 7 3/14/2025, 2:03 AM


NEVER MISS AN ARTICLE
Subscribe to the E360 Newsletter for
weekly updates delivered to yourinbox. 
Sign Up.international organizations now want to make sure the beneﬁ ts aren’t outweighed
by A.I.’s mounting hazards.
Right now, it’s not possible to tell how your A.I.
request for homework help will aﬀect carbon
emissions or freshwater stocks.
“�e development of the next generation of A.I. tools cannot come at the expense
of the health of our planet,” Massachusetts Senator Edward Markey (D) said last
week in Washington, after he and other senators and representatives introduced a
bill that would require the federal government to assess A.I.’s currentenvironmental footprint and develop a standardized system for reporting futureimpacts. Similarly, the European Union’s “ A.I. Act,” 
approved by member states last
week, will require “high-risk A.I. systems” (which include the powerful “foundation
models” that power ChatGPT and similar A.I.s) to report their energy consumption,resource use, and other impacts throughout their systems’ lifecycle. �e EU lawtakes eﬀect next year.
Meanwhile, the International Organization for Standardization, a
global network that develops standards for manufacturers, regulators,and others, says it will issue 
criteria for “sustainable A.I.” later this
year. �ose will include standards for measuring energy eﬃciency,raw material use, transportation, and water consumption, as well as practices forreducing A.I. impacts throughout its life cycle, from the process of mining materialsand making computer components to the electricity consumed by its calculations.�e ISO wants to enable A.I. users to make informed decisions about their A.I.consumption.
As Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
2 of 7 3/14/2025, 2:03 AM


Right now, it’s not possible to tell how your A.I. request for homework help or a
picture of an astronaut riding a horse will aﬀect carbon emissions or freshwaterstocks. �is is why 2024’s crop of “sustainable A.I.” proposals describe ways to getmore information about A.I. impacts.
In the absence of standards and regulations, tech companies have been reporting
whatever they choose, however they choose, about their A.I. impact, says ShaoleiRen, an associate professor of electrical and computer engineering at UC Riverside,who has been studying the water costs of computation for the past decade. Workingfrom calculations of annual use of water for cooling systems by Microsoft, Renestimates that a person who engages in a session of questions and answers withGPT-3 (roughly 10 t0 50 responses) drives the consumption of a half-liter of freshwater. “It will vary by region, and with a bigger A.I., it could be more.” But a greatdeal remains unrevealed about the millions of gallons of water used to coolcomputers running A.I., he says.
�e same is true of carbon.“Data scientists today do not have easy or reliable access to measurements of
[greenhouse gas impacts from A.I.], which precludes development of actionabletactics,” a group of 10 prominent researchers on A.I. impacts wrote in a 2022conference 
paper. Since they presented their article, A.I. applications and users have
proliferated, but the public is still in the dark about those data, says Jesse Dodge, aresearch scientist at the Allen Institute for Artiﬁcial Intelligence in Seattle, who wasone of the paper’s coauthors.
Data centers’ electricity consumption in 2026 is
projected to reach 1,000 terawatts, roughly Japan’s
total consumption.
A.I. can run on many devices — the simple A.I. that autocorrects text messages willrun on a smartphone. But the kind of A.I. people most want to use is too big formost personal devices, Dodge says. “ �e models that are able to write a poem for
you, or draft an email, those are very large,” he says. “Size is vital for them to havethose capabilities.”
Big A.I.s need to run immense numbers of calculations very quickly, usually on
specialized Graphical Processing Units — processors originally designed for intensecomputation to render graphics on computer screens. Compared to other chips,An Amazon dat � center in � Northern Virgini � suburb. JAHI CHIKWENDIU / THE WASHINGTON POST VIA
GETTY IMAGESAs Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
3 of 7 3/14/2025, 2:03 AM


ALSO ON YALE E360
Bitcoin’s intensive energy demands
are sparking � crypto backlash. Read
more.GPUs are more energy-eﬃcient for A.I., and they’re most e ﬃcient when they’re run
in large “cloud data centers” — specialized buildings full of computers equipped
with those chips. �e larger the data center, the more energy eﬃcient it can be.Improvements in A.I.’s energy eﬃciency in recent years are partly due to the
construction of more “hyperscale data centers,” which contain many morecomputers and can quickly scale up. Where a typical cloud data center occupiesabout 100,000 square feet, a hyperscale center can be 1 or even 2 million square feet.
Estimates of the number of cloud data centers worldwide range from around 
9,000
to nearly 11,000. More are under construction. �e International Energy Agency
(IEA) projects that data centers’ electricity consumption in 2026 will be double that
of 2022 — 1,000 terawatts, roughly equivalent to Japan’s current total consumption.
However, as an illustration of one problem with the way A.I. impacts are measured,
that IEA estimate includes all data center activity, which extends beyond A.I. tomany aspects of modern life. Running Amazon’s store interface, serving up AppleTV’s videos, storing millions of people’s emails on Gmail, and “mining” Bitcoin arealso performed by data centers. (Other IEA 
reports exclude crypto operations, but
still lump all other data-center activity together.)
Most tech ﬁrms that run data centers don’t reveal what percentage of
their energy use processes A.I. �e exception is Google, which says“machine learning” — the basis for humanlike A.I. — accounts forsomewhat less than 
15 percent of its data centers’ energy use.
Another complication is the fact that A.I., unlike Bitcoin mining orA QTS dat � center under construction in Litchfield Park, Arizon � last month. ASH PONDERS / BLOOMBERG
VIA GETTY IMAGESAs Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
4 of 7 3/14/2025, 2:03 AM


online shopping, can be used to reduce humanity’s impacts. A.I. can improve
climate models, ﬁnd more eﬃcient ways to make digital tech, reduce waste intransport, and otherwise cut carbon and water use. One estimate, for example,found that A.I. -run smart homes could reduce households’ CO₂ consumption by upto 
40 percent. And a recent Google project found that an A.I. fast-crunching
atmospheric data can guide airline pilots to ﬂight paths that will leave the fewestcontrails.
Google’s data centers used 20 percent more water in
2022 than in 2021, while Microsoft’s water use rose
by 34 percent.
Because contrails create more than a third of commercial aviation’s contribution toglobal warming, “if the whole aviation industry took advantage of this single A.I.breakthrough,” says Dave Patterson, a computer-science professor emeritus at UCBerkeley and a Google researcher, “this single discovery would save more CO₂e(CO₂ and other greenhouse gases) than the CO₂e from all A.I. in 2020.”
Patterson’s analysis predicts that A.I.’s carbon footprint will soon plateau and then
begin to shrink, thanks to improvements in the e ﬃciency with which A.I. software
and hardware use energy. One reﬂection of that eﬃciency improvement: as A.I.usage has increased since 2019, its percentage of Google data-center energy use hasheld at less than 15 percent. And while global internet traﬃc has increased morethan twentyfold since 2010, the share of the world’s electricity used by data centersand networks increased 
far less, according to the IEA.
However, data about improving eﬃciency doesn’t convince some skeptics, who citea social phenomenon called “Jevons paradox”: Making a resource less costlysometimes increases its consumption in the long run. “It’s a rebound eﬀect,” Rensays. “You make the freeway wider, people use less fuel because traﬃc moves faster,but then you get more cars coming in. You get more fuel consumption than before.”If home heating is 40 percent more eﬃcient due to A.I., one critic 
recently wrote,
people could end up keeping their homes warmer for more hours of the day.
As Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
5 of 7 3/14/2025, 2:03 AM


“ A.I. is an accelerant for everything,” Dodge says. “It makes whatever you’re
developing go faster.” At the Allen Institute, A.I. has helped develop betterprograms to model the climate, track endangered species, and curb over ﬁshing, he
says. But globally A.I. could also support “a lot of applications that could accelerateclimate change. �is is where you get into ethical questions about what kind of A.I.you want.”
If global electricity use can feel a bit abstract, data centers’ water use is a more local
and tangible issue — particularly in drought-aﬄicted areas. To cool delicateelectronics in the clean interiors of the data centers, water has to be free of bacteriaand impurities that could gunk up the works. In other words, data centers oftencompete “for the same water people drink, cook, and wash with,” says Ren.
In 2022, Ren says, Google’s data centers consumed about 
5 billion gallons (nearly 20
billion liters) of fresh water for cooling. (“Consumptive use” does not include water
that’s run through a building and then returned to its source.) According to a recentstudy by Ren, Google’s data centers used 20 percent more water in 2022 than theydid in 2021, and Microsoft’s water use rose by 34 percent in the same period.(Google data centers host its Bard chatbot and other generative A.I.s; Microsoftservers host ChatGPT as well as its bigger siblings GPT-3 and GPT-4. All three areproduced by OpenAI, in which Microsoft is a large investor.)
In Chile and Uruguay, protests have erupted over
planned data centers that would tap drinking water
reservoirs.
As more data centers are built or expanded, their neighbors have been troubled toﬁnd out how much water they take. For example, in �e Dalles, Oregon, whereGoogle runs three data centers and plans two more, the city government ﬁled alawsuit in 2022 to keep Google’s water use a secret from farmers, environmentalists,and Native American tribes who were concerned about its eﬀects on agricultureand on the region’s animals and plants. �e city withdrew its suit early last year. �e
records it then made public showed that Google’s three extant data centers useAi-D� Robot, an AI-powered robot artist, addressing the British House of Lords, October 11, 2022. ROB PINNEY /
GETTY IMAGESAs Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
6 of 7 3/14/2025, 2:03 AM


MORE ON YALE E360
Faced with heavier rains, cities
scramble to control polluted runoff.
Read more.more than a quarter of the city’s water supply. And in Chile and Uruguay, protests
have erupted over planned Google data centers that would tap into the samereservoirs that supply drinking water.
Most of all, researchers say, what’s needed is a change of culture within the rareﬁed
world of A.I. development. Generative A.I.’s creators need to focus beyond thetechnical leaps and bounds of their newest creations and be less guarded about thedetails of the data, software, and hardware they use to create it.
Some day in the future, Dodge says, an A.I. might be able — or be
legally obligated — to inform a user about the water and carbonimpact of each distinct request she makes. “ �at would be a fantastic
tool that would help the environment,” he says. For now, though,individual users don’t have much information or power to know theirA.I. footprint, much less make decisions about it.
“�ere’s not much individuals can do, unfortunately,” Ren says. Right
now, you can “try to use the service judiciously,” he says.Correction, February 21, 2024: An earlier version of this article incorrectly quoted
researcher Dave Patterson as referring to CO₂ emissions from global aviation.Patterson was actually referring to CO₂e (“carbon dioxide equivalent”) emissions, ameasurement that includes both CO₂ and other greenhouse gases.
David Berreby writes the Robots for the Rest of Us newsletter. His work about AI and robotics has
appeared in �e New York Times, National Geographic, Slate, and other publications. His other sciencewriting includes 
Us and �em: �e Science of Identity and work in �e New Yorker, Nature, and many
other publications. MORE →As Use of A.I. Soars, So Does the Energy and Water It Requires - Yale E360 https://e360.yale.edu/features/artificial-intelligence- mi...
7 of 7 3/14/2025, 2:03 AM


