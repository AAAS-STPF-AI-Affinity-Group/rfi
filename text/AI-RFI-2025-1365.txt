PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 88-z5wk-cutb
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1365
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Convergence Analysis
General Comment
Convergence Analysis is a US 501(c)(3) non-profit research organization focused on frontier AI governance. 
We respectfully subm it this response to the Request for Inform ation on the Developm ent of an AI Action Plan, focusing on inform ation
relevant for securing Am erican leadership across 4 high-priority areas: 
(1) US Policy Leadership in the AI Econom y;
(2) National Security and AI Innovation in the USA;
(3) AI Diplom acy and Am erican Control;
(4) Strategic Inform ation on Powerful Dual-Use Models.
Please see the attached file for our full com m ent. 
Attachments
Response by Convergence Analysis to the Request for Inform ation on the Developm ent of an Artificial Intelligence (AI) Action Plan


1 
Response by Convergence Analysis to the Request for Information on the 
Development of an Artificial Intelligence (AI) Action Plan 
March 15, 2025 
AI Action Plan   
Attn: Faisal D'Souza   
NCO, 2415 Eisenhower Avenue   
Alexandria, V A 22314   
This document is approved for public dissemination. The document contains no 
business-pr oprietary or confidential information. Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without 
attribution. 
Introduction 
Convergence Analysis is a US 501(c)(3) non-profit research organization focused on frontier AI 
governance. We respectfully submit this response to the Request for Information on the 
Development of an AI Action Plan, focusing on information relevant for securing American 
leadership across 4 high-priority areas: (1) US Policy Leadership in the AI Economy; (2) 
National Security and AI Innovation in the USA; (3) AI Diplomacy and American Control; 
(4) Strategic Information on Powerful Dual-Use Models.
(1) US Policy Leadership in the AI Economy
The economic impacts of near-future AI systems are highly uncertain, and understudied, and yet 
there is a strong consensus among experts that they will be transformational. The economic 
policy frameworks of this administration’ s term will lay the foundations for Americans and the 
world for generations  into the future.  
In this section we highlight findings from our recent expert conference Threshold 20301 on AI’ s 
near-term economic impacts, convening specialists  from cutting-edge organizations including 
Google, DeepMind, Stanford, MIT , Metaculus and OpenAI. The conference developed practical 
AI impact forecasting methods and mapped areas of expert consensus and disagreement. Below 
we list 7 key findings:  
1.Within 5 years AI developments may lead to a sharp increase in unemployment.
1 Conference Summary: Threshold 2030 - Modeling AI Economic Futures - Convergence Analysis  


2 
The impact of AI on unemployment by 2030 will be highly sector-specific, with transport and 
tech-heavy fields facing rapid automation, while skilled physical work, such as surgery and 
dentistry, and high-prestige roles seeing more AI augmentation than replacement. Expert 
predictions for 2030 ranged from modest unemployment with wage depression in creative 
industries, to 40% unemployment rates and significant government intervention. 
2.Within 5 years AI developments are likely to lead to increasing wealth inequality.
AI advancement will likely concentrate wealth among capital owners, tech companies, and 
skilled professionals, while automation-driven unemployment increases financial pressure on 
others, leading to rising strain on government welfare.  
3.AI will disrupt wage and labor share.
AI-driven automation is expected to decrease labor's share of national income as capital owners 
capture a greater portion of economic output, although some high-skill and service-based 
professions may command rising wages. Slow AI progress in the next 5 years may only slightly 
alter wage structures, while in scenarios where AI progress continues to advance quickly, AI 
systems could lead to a near-complete displacement of human labor in cognitive fields. 
4.The rate of diffusion for AI Systems will likely be uneven across industries and
regions.
Experts predicted infrastructure and institutional inertia will limit widespread deployment of AI, 
even in scenarios with advanced AI. While some economies may integrate AI rapidly, the global 
distribution of benefits is expected to be highly unequal, potentially leading to geopolitical 
tensions. Several experts predicted limited global AI diffusion by 2030, indicating that they 
expect significant infrastructural and implementation barriers. 
5.Public Responses to AI-Driven Economies will be significant.
Experts predicted possible increased demands for wealth redistribution, shifts towards local 
labor, and growing political pressure for AI regulation. Alternative economic models such as 
universal basic income or cooperative labor structures may gain traction if conventional 
employment declines. In scenarios with high unemployment, there may be widespread crises 
around finding purpose as traditional work-based identities collapse.  
6. There is an immediate need for new economic metrics.
There are significant gaps in our ability to measure and track AI's economic impacts. 
Conventional measures fail to capture the full scope of AI-driven economic transformation. The 
development of such metrics would be crucial for tracking AI's impact on both economic 
productivity and broader social outcomes. 
7. There is a glaring lack of research on concrete AI economic policies.


3 
A notable gap emerged in the discussions around policy interventions to address AI's economic 
impacts. While attendees discussed significant existing research describing potential economic 
impacts from AI systems, there was limited research referenced or discussion regarding concrete 
policy ideas to address these impacts.  
Specific neglected topics of research include:  
●Tax & revenue policy (corporate profit taxation, robot taxes, tax base distortions),
●Social safety nets (UBI, job transition funds, AI reskilling, negative income taxes),
●Predistributive policies & market incentives (public benefit corporations, insurance
policies, procurement policies, due diligence), and
●Public / private coordination (AI as a public utility, government management /
integration).
More details on these expert discussions, models of the near-future, and conclusions can be 
found in the Threshold 2030 Conference Report.  
(2) National Security and AI Innovation in the USA
While economic opportunity drives AI innovation, experts forecast that advanced AI will enable 
capabilities with significant implications for national security, such as cyberwarfare capabilities 
and autonomous weapons systems. 
Private US labs are currently the leading organizations pushing the frontier of AI development, 
and substantial evidence2 points towards the current and continued dominance of private US AI 
labs. As AI system capabilities  are demonstrated to threaten US national security, we expect the 
US government to increase its involvement in AI technologies in order to maintain American 
superiority globally. 
Some experts have predicted, or advocated for a ‘Manhattan Project for AI’, to consolidate and 
nationalize all existing frontier AI research in the interest of national security. However, such a 
project  and other similar descriptions3 of nationalization represent only a narrow subset of 
possible scenarios of US government involvement, and are not likely to align with the objectives 
of this Action Plan of solidifying both US AI leadership and national security for three reasons:  
1) Nationalization may be seen as a threat to innovation driven by private sector competition
and diversity of approaches. The American innovation model, built on free-market
competition, is arguably why the US leads the AI race today.
2) Nationalization of frontier AI labs would face unprecedented practical, legal, and
political  challenges. Companies like Microsoft, Google, and Meta have market
3 AI and Geopolitics: How might AI affect the rise and fall of nations? | RAND  2 AI Index | Stanford HAI  


4 
capitalizations exceeding $1 trillion each. Similarly, Nvidia—controlling 80% of the AI 
chip market with a $3 trillion valuation—would require government ownership in many 
nationalization scenarios, making this financially and legally implausible. 
3) Less intrusive alternatives exist: combinations of targeted policy levers could address
national security concerns while allowing private AI development to continue.
We identify 13 sets of these policy levers that can meet both national security and 
innovation needs, as an alternative to nationalization projects. Each set of levers offers a series 
of options that afford the government increasingly more influence, on a spectrum ranging from 
standard regulations to more comprehensive government control.  
The comprehensive overview of these levers can be found in Section 2 of our report Soft 
Nationalization. 
We do not advocate or recommend for the application of any of these policy levers. This section 
is informative in nature – it is intended solely to describe the space of plausible policy levers that 
may occur.  
(3) AI Diplomacy and American Control
Securing America's AI advantage requires not only domestic policy frameworks but also 
strategic international engagement. The competitive dynamics between the US and China 
generate a range of threats to American control of powerful AI systems, their creation and their 
production. Without strong diplomatic action, rapid progress may create new, undue challenges. 
In this section we discuss two of these challenges, and make recommendations for each.  
1. Diplomacy to prevent pre-emptive attacks on the US
A national US project to develop Artificial Superintelligence4 (ASI) would incentivize 
pre-emptive strikes against the US and its AI infrastructure, as US adversaries will recognize that 
superintelligent AI threatens their ability to retaliate in nuclear or conventional warfare5. 
Adversaries would also be incentivized to exfiltrate model weights to equal or surpass America’s 
AI capabilities. The most extreme security measures are not guaranteed to prevent this, and come 
with a new set of associated challenges; for example, extreme centralization that such security 
measures likely entail would make a state’s AI development more vulnerable to a single military 
attack by an adversary6. 
6 The Manhattan Trap | Convergence Analysis 12  5 Artificial Intelligence and Nuclear Stability | CNAS  4 We define Artificial Superintelligence as an AI system that vastly exceeds human performance across nearly all 
cognitive tasks. 


5 
A cheap and effective way to reduce these risks is to open diplomatic channels to competing 
states to defuse competitive dynamics in the short term. We believe it is in the interest of the US 
government to:  
● Develop metrics for distinguishing between mainstream AI development that generates 
no strategic risk, and developments that may generate degrees of strategic risk, such as a 
national ASI project.  
● Initiate high-level dialogue with competitors, particularly China, focused specifically on 
superintelligent AI development.  
● Establish secure communication channels to prevent misperception of regular AI 
development as national ASI projects. 
 
2. Verification to maintain American Control 
Hypercompetitive acceleration of AI development and deployment also increases vulnerability to 
bad actors, and threatens American control over deployed systems, both military and civilian. As 
AI becomes more advanced, it will by definition operate with less human oversight, doing more 
with more autonomy. This increases the surface area for control failures from technical errors, 
terrorist groups or other bad actors. Given the growing autonomy of these systems, the impact of 
control failures for widely deployed military systems or of civilian infrastructure (such as 
self-driving cars) would be devastating.  
 
Maintaining American control of the most powerful AI systems requires a controlled scaling 
approach. To support this strategy, mechanisms for verifying the AI progress of competing states 
are essential. Visibility into adversaries' progress towards superintelligence would inform the 
speed of US development, allowing for US-led controlled scaling of AI systems while ensuring 
that adversaries do not race ahead. Unlike general AI development, an ASI project would likely 
require distinctive infrastructure, methods, and resources that creates detection opportunities7. 
These characteristics make verification mechanisms both strategic and feasible. We recommend 
that the USG:  ● Research methods to distinguish between general AI development and ASI-specific 
development.  
● Develop technical capabilities to monitor indicators of ASI development activities 
(4) Strategic Information on Powerful Dual-Use Models 
Effective diplomacy and national security both depend on a foundation of accurate information 
about AI capabilities. To maintain American leadership while addressing the dual-use nature of 
frontier AI, the United States Government must establish mechanisms for strategic visibility into 
the most powerful models being developed.  
 
7 The Manhattan Trap | Convergence Analysis 22 
 


6 
Powerful dual-purpose AI models have emerged as a critical technological frontier with serious 
implications for national security and global strategic capabilities, including, but not limited to:  
●Biosecurity, Terrorism, and Weapons Proliferation - AI could be used to develop
biological  or chemical weapons or even radiological or nuclear weapons8.
●Cybersecurity Threats - AI could lower the barrier to entry for sophisticated
cyberattacks from state and non-state adversaries9.
●Control failures - Advanced AI systems or autonomous weapons systems may become
extremely dangerous if they behave in unexpected ways, through technical failure or
misuse by bad actors.
The US government currently has limited visibility into the development and capabilities of 
frontier dual-use models. This lack of information  creates severe limitations on any efforts to 
detect,  anticipate, and respond to potential opportunities and threats10.To meet these challenges, 
the Bureau of Industry and Security (BIS) has proposed a rule11 establishing reporting 
requirements for the development of advanced AI models and computing clusters under the 
authority of the Defense Production Act. To add to the work being done by the US Government, 
Convergence Analysis has prepared the following proposal on lightweight registration of the 
most powerful dual-use models.  
1. The Proposal for an Advanced Dual-Use AI Registry
A registry would serve as a central repository of information on national dual-use AI capabilities
and vulnerabilities. It would:
A.Inform the creation of national strategies, with accurate information about existing
models, their capabilities  and vulnerabilities.
B.Support implementation of national strategies, ensuring that safety-critical
interventions  are carefully targeted so that all and only the relevant models are affected.
C.Build capacity in government by providing structured information on AI for
policymakers and encouraging the development of the technical knowledge required to
manage AI systems.
To capitalize on these advantages, we propose that the USG implement a registry for the most 
powerful dual-use AI models under the appropriate  authority.  
2. Avoiding Excessive Burdens on AI Labs
11 Federal Register :: Establishment of Reporting Requirements for the Development of Advanced Artificial 
Intelligence Models and Computing Clusters  10 AI Model Registries: | Convergence Analysis  9 Russia will not intimidate us with cyberthreats | Reuters  8 Skating to Where the Puck Is Going | CSET  


7 
A model registry should serve as a foundation for more robust policy development without 
imposing excessive burdens that could impede technological advancement or create unnecessary 
resistance from industry stakeholders. To ensure the proposed registry fosters AI innovation, we 
highlight several key design principles, including: (1) Minimal Reporting requirements that 
capture only essential information linked to governance goals, and (2) No Mandatory Standards 
or Licensing, as AI safety evaluations and standards remain immature. The registry should 
function as a lightweight information-gathering mechanism rather than an enforcement tool.  
3. Defining the Most Powerful Models
Our proposal includes a holistic definition of model capabilities that engages with the latest
findings in scaling laws and capitalizes on all readily available information about a given
model’s potential. This definition ensures that only the most powerful models are included in a
registry, meeting national security objectives without placing burdens on innovation. This
includes a combination of simple information on model training compute, as is already captured
by BIS’ work, but also model architecture, size and training data, in addition to findings from
capability evaluations.
4. Optimized Reporting Mechanism
We propose a reporting schedule that builds on BIS’ suggested quarterly update requirements.
Rather than enforcing quarterly reports from labs, our proposed mechanism requires new reports
from labs only when a registered model is meaningfully improved beyond a defined capability
threshold. Complementing this capability-based reporting, a bi-annual update can keep
information on model security and evaluation metrics up to date, since model security or other
features may be changed and have national security implications without improving the model
capability.
5. Information to be Reported
We recommend that 12 categories  of information are reported upon registration. These
categories of information have been chosen to optimize USG knowledge and capacity building
while creating  negligible additional overhead on AI labs and AI innovation. Our full proposal
details what specific information should be required within each category.
1.Basic Information 5.Training Data 9.Functions of the Model
2.Open-Source Status 6.Model Architecture 10. Post-Deployment
Monitoring
3.Model Size & Parameters 7.Hardware Information 11. Model Physical Security
4.Training Compute 8.Model Evaluations 12. Model Cybersecurity


8 
6.Enforcement
A registry can be effectively enforced through market mechanisms that encourage compliance.
By making model registration a prerequisite for commercial operations in the US, developers of
the most powerful dual-use models would have strong economic incentives to register. Similar
examples in other industries include:
●Know-Your-Customer12 (KYC) standards in banking protect  financial institutions against
fraud, money laundering, and terrorist financing;
●Worker registration systems such as the E-Verify system13 that requires employers to
verify the eligibility  of their employees to work in the United States. Employers face
penalties for knowingly hiring or continuing to employ unauthorized workers.
See the full report here for the comprehensive proposal: AI Model Registries: A Foundational 
Tool for AI Governance  
In Conclusion 
The rapid advancement of artificial intelligence presents a strategic imperative for American 
leadership.  The United States has an opportunity to act decisively to secure its technological 
edge while managing competitive dynamics with strategic rivals. 
In this document, we have submitted information on four high-priority areas: 
1.US Policy Leadership in the AI Economy: AI will transform the global economy with
sector -specific disruptions. The U.S. must implement forward-looking policies to address
potential unemployment, inequality, and uneven technology diffusion to capture benefits,
maintain competitive advantage and become a future leader in AI Economic policy.
2.National Security and Innovation: Frontier AI technologies will redefine defense
capabilities.  Rather than nationalizing innovation, which threatens market competition
and faces financial and legal hurdles, targeted policy levers can effectively harness
private sector innovation while securing critical national interests.
3.AI Diplomacy and American Control: Establishing high-level communication channels
with competitors  will prevent misperception and reduce the risk of pre-emptive actions
against U.S. AI infrastructure, preserving America's technological lead.
4.Strategic Information on Powerful Dual-Use Models: The proposed Advanced
Dual-Use AI Model Registry will provide American  leadership with foundational
information on the most powerful AI models while supporting America's innovation
ecosystem.
13 E-Verify | USG 12 Know Your Customer (KYC) | Swift  


9 
For more information on any of the above, please contact 
Convergence Analysis stands ready to provide our continued support and additional insights and 
clarification  on any aspects of this submission as the government develops the AI Action Plan.  
Respectfully submitted, 
Convergence Analysis 


