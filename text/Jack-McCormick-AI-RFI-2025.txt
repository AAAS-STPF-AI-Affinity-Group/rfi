From: Jack McCormick
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Saturday, March 15, 2025 5:26:10 PM
CAUTION: This email originated from outside your organization. Exercise caution when opening
attachments or clicking links, especially from unknown senders.
This is a fundamentally bad idea. The "guard rails" that this plan seeks to remove are the legal
rights of the American citizenry, and the citizenry of the rest of the world, to own what theyproduce. The plan proposed would allow tech giants to pick the pocket of every man, womanand child in this country of their labor without a cent to compensate them. And this is just ifthey are trained on publicly available information. What if they are allowed to train onprivately held information? These machines have no true intelligence to them. If trained onsecret information, it can be made to reveal secret information. This has already beendemonstrated.
Beyond the violation of our rights, an issue that should be a primary concern, there is also the
fact that
 Large Language models are, by their very nature, will be incapable of reaching the
goals promised. The models do not think, and truly do not process information. For all of theirtechnical impressiveness, they are ultimately very similar to markov chains, chaining togethera series of words that it predicts should go together. These models cannot, truly, analyze orsynthesize
 information. They can only summarize - and even on that they are failing. The
terminology for this phenomena in the AI industry is "hallucinating" but it's not ahallucination. It is a failure. And large language models fail often and regularly. Questions andstatements can be phrased, either intentionally or by accident, to state that things that are wellknown to be dangerous to be safe. Things that are not a matter of opinion. Phrased correctly,you can get these models to tell you that mixing bleach and ammonia
 is safe. But a basic
knowledge of chemistry will tell you that this is highly unsafe - that this is how you producemustard gas. If the machines were capable of analyzing data, they would recognize that this isan error and correct. They do not. They cannot. Because the machine does not learn to think. Itlearns to repeat.
And this is the final thing to mention. Beyond the fact that these ideas would violate the rights
of American citizens. Beyond the fact that these machines are incapable of thinking like we'vebeen promised and assured. There is a simple factor to consider: garbage in, garbage out. Ifthese machines are allowed to widely scrape everything for their data set, they will be filledwith garbage data. Information that is wrong because it's outdated. Information that is wrongbecause of errors. Information that is wrong because it's being offered sarcastically.Information that is wrong because someone wrote it wrong on purpose. The machine cannotanalyze. The machine cannot sort truth from falsehood from jest.
 
What happens when the answer given in jest is provided by the AI, and causes someone todie? Who is held responsible? Not legally, but morally: who is to blame? The machine? Themachine cannot be held accountable for its actions. The user? The user treated a machine thatthey were told was a reliable source of information as a reliable
 source of information. Are we
to blame them for not knowing things without being told them? What about the company thatowns the machine? They can say "but our data says that's true. We only collected it, we didnot create it." The original posters of this information? This information was a clear joke,made decades before the thought of a LLM scraping that information could even be imagined?


You, perhaps. After all, you removed the guard rails. Don't you have some responsibility in
this matter?  
But let's talk about that metaphor. Guard rails. Guard rails are there for a reason. They stop
people from falling to their deaths. There are rarely, if ever, situations where guard rails  prove
to be a hindrance. Guard rails save lives. The only reason to remove guard rails is because youdo not care about other people's safety.
Nothing good can come of removing the guard rails. It can only cause harm.
All e-mails to and from this account are for NITRD official use only and subject to certain disclosure
requirements.If you have received this e-mail in error, we ask that you notify the sender and delete it immediately.


