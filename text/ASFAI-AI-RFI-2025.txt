American Society for AI ASFAI.org Page 1 of 14First, we assess policy areas of defense , licensing , transparency , fraud
detection , accountability , export controls , and consumer protection .
Next, we provide an overview of state-level initiatives , with the hope that
federal AI policies will gain from state-level efforts.
Finally, we discuss approaches to achieving ethical & beneficial AI . 
Rei Llazani
President, American Society for AIAmerican Society for AI
Rei Llazani
President
American Society for AI
Office of Science and Technology Policy (OSTP)
Executive Office of the President
Faisal D'Souza, NCO
2415 Eisenhower Avenue
Alexandria, Virginia 22314
Response to RFI on the “Development of an AI Action Plan”
Dear OSTP Team,
On behalf of the American Society for Artificial Intelligence (ASFAI), I appreciate 
the opportunity to provide input on the development of the AI Action Plan (Federal 
Register Document No. 2025-02305). ASFAI is a private, non-profit organization 
dedicated to bringing together top AI leaders, executives, and researchers. Since 
launching in 2023, we have emerged as the most prominent AI association in the 
United States. Our mission is to make the world a better place with AI, ensuring 
the United States remains competitive and the leader in AI. Wholly non-partisan & 
unbiased, uniquely operating as unpaid volunteers, accepting zero donations & zero 
sponsorships.
Given our highly esteemed & distinguished membership of only senior leaders; 
including Fortune 100 C-Suite executives, U.S. Congressmen, and leading AI 
pioneers, researchers, and entrepreneurs, we offer unique insights into both the 
opportunities and challenges AI presents across industries. This response focuses 
on areas where U.S. leadership in AI can be strengthened while maintaining 
American-led ethics & global competitiveness.
Our submission addresses three areas in developing a national AI policy:


American Society for AI ASFAI.org Page 2 of 14AI Policy Areas
ASFAI members represent a wide variety of interests in numerous fields
including distinguished representatives of the business, legal, militaryand academic communities. Our membership holds diverse views, butwe are united in believing that AI can be used for good , and that the
United States should be the global leader in AI . We believe that the
US can take the lead both in developing cutting edge AI technologyand in establishing regulatory and legal principles to ensure the ethicaland beneficial use of AI. 
While our European allies have taken a cautious approach to the
development of AI, the regulatory framework they have establishedappears to have limited the pace of innovation in those countries. Due to the key role that the US plays in pushing the frontiers of AItechnology, we cannot afford to create regulatory barriers toinnovation.  
However, in accordance with our core principles, the members of ASFAIgenerally believe it is possible to approach the regulation of AI in a
way that will not limit the growth of this technology  or cede
leadership to another country. 
A recent survey proposed a number of potential areas for government
involvement that could be implemented consistent with this approach.
The results, as shown in the following pages, give insight into which
areas should be prioritized.
This report is submitted through ASFAI’s Policy Committee.
AMERICAN SOCIETY FOR AI (POLICY COMMITTEE)
MICHAEL CAREY, RUSS WILCOX, SHIVANKU MISRA, SIWEI LYU, TERRY
VIRTS, JAMES TODARO, HUGO DANTE, SAMO BURJA, JACKSON TUFTS
REI LLAZANI, AARON POYNTON, PARITOSH AMBEKARAmerican Society for AI
This document is approved for public dissemination. The document contains no business-
proprietary or confidential information. Document contents may be reused by the
government in developing the AI Action Plan and associated documents without attribution.


American Society for AI
Defense and Law Enforcement
Policy Consideration
“The government must prohibit autonomous AI agents from engagingin lethal activities without a human in the loop to ensure accountability,ethical decision-making, and adherence to international humanitarianlaws. Lethal decisions require complex judgment, moral reasoning, andsituational awareness that AI systems cannot fully replicate or validateindependently.”
Survey Result
Remarks
The majority of the ASFAI membership supports the policy that the USgovernment should prohibit autonomous AI agents from engaging inlethal activities autonomously. Current AI agents simply do not have therequisite degree of moral reasoning to make life-and-death decisionsalone.
However, our members also noted that if implemented poorly, such a
policy could put the US at a disadvantage against an adversary thatdoes not adhere to such restrictions. Therefore, limitations on the use ofAI should differ transparently based on rules of engagement for specificareas of operation.
American Society for AI ASFAI.org Page 3 of 14


American Society for AI
Export Controls
Policy Consideration
“Implement export controls, sanctions, and other legal restrictions toprevent the transfer of advanced AI models, hardware, and relatedtechnologies to adversary nations and countries engaged in severehuman rights abuses.”
Survey Result
Remarks
The majority of our membership supports limiting the export of AItechnology to potential adversaries and countries suspected of using AIto enable human rights abuses. AI is a key strategic asset, and weshould vigorously protect American leadership in this area. Exportcontrols can be one means that the US retains our leading positionwhile reducing the risk that our adversaries will abuse the technology. 
Our members also expressed concerns that improperly implemented
export controls would be ineffective at slowing the spread of AItechnology to our enemies. Furthermore, poorly designed traderestrictions could harm innovation by making it harder for US firms toprofit from their innovations.
American Society for AI ASFAI.org Page 4 of 14


American Society for AI
Consumer Protection
Policy Consideration
“Require companies to apply safety measures for AI in high-riskapplications, including notifying users when AI impacts them adverselyand offering options for human review. Regulations would ensureconsumer control over personal data usage in AI and impose limits onAI applications involving children.”
Survey Result
Remarks
ASFAI membership supports efforts to protect consumers, such asregulations regarding the use of private data, and the development ofAI targeting medical patients and children. Such measures couldimprove trust and limit the exploitation of vulnerable people.
However, our members also suggested that consumer protection
regulations should focus on AI applications rather than the coretechnologies. In many cases, existing laws and regulations can addresspotential issues without creating new regulations aimed specifically atAI. By focusing specifically on high-risk applications, a balance can beachieved between enabling innovation in core AI technologies whileprotecting the most vulnerable members of society from exploitation.For example, with respect to medical AI, it is desirable to ensure patientprivacy protection while leveraging AI to improve clinical outcomes.
An important subset of US consumers are patients, and we suggest
ensuring patient privacy protection, while leveraging AI to enablesignificant acceleration in advanced solutions that improve clinicaloutcomes.
American Society for AI ASFAI.org Page 5 of 14


American Society for AI ASFAI.org Page 6 of 14American Society for AI
Deepfake/Fraud Detection
Policy Consideration
“To combat the misuse of AI-generated content, generative AI toolsshould include watermarking mechanisms that embed detectablemarkers into all generative outputs. These watermarks should be robustagainst tampering and universally recognizable using standardizeddetection tools. Developers of generative AI models ensure complianceby incorporating this feature at the model design stage and providingpublic access to tools for watermark verification.”
Survey Result
Remarks
ASFAI members also support efforts aimed at encouraging generativeAI systems to include watermarks to indicate the origins of AI-generated output. This could aid in preventing fraud and abuse ofgenerative AI systems by making users more accountable for thecontent they create.
However, watermarking is not a silver bullet. Bad actors are likely to
bypass such requirements. Furthermore, overly restrictive requirementscould stifle innovation. For example, it may contribute to a regulatorymoat that serves as a barrier to competition and favors largecompanies. 


American Society for AI ASFAI.org Page 7 of 14American Society for AI
Legal Accountability
Policy Consideration
“Ensure AI companies are legally accountable for breaches of privacy,civil rights, or other harms caused by their technologies. This includesallowing enforcement by an oversight body, private rights of action, andclarifying that Section 230 protections don’t automatically apply to AI.”
Survey Result
Remarks
Our membership supports holding companies that develop AI legallyaccountable for breaches of privacy, civil rights, or other harms causedby their technologies. This ensures that the developers of AI areencouraged to balance the risks and opportunities that come with AI. 
In many cases, these protections fall within the scope of current law
and do not require additional regulation. Several members suggestedthat applying common law accountability for specific harms could bemore effective than preventative regulation. Additionally, membersexpressed the view that developers should not be held accountable forthe abuse of general use tools if safety measures are taken to preventsuch harms.


American Society for AI ASFAI.org Page 8 of 14American Society for AI
Licensing & Oversight
Policy Consideration
“Establish an independent oversight body for AI, requiring companiesdeveloping high-risk AI (such as general-purpose models or facialrecognition) to register. This licensing may include risk management,pre-deployment testing, data governance, and adverse incidentreporting. The oversight body may also have authority for audits andcoordination with the state Attorneys General.”
Survey Result
Remarks
Support for a general licensing regime was less robust among ASFAImembers than for other policy proposals. While a majority of membersfavored establishing an oversight body, some members expressedconcerns that a licensing regime could severely hamper innovation. Inthe best case scenario, a federal oversight body could seek to alignindividual state requirements that might otherwise hinder thedevelopment of AI across state lines.


American Society for AI ASFAI.org Page 9 of 14American Society for AI
Transparency
Policy Consideration
“Companies developing and deploying AI systems above a thresholdsize should provide transparency regarding the training data,limitations, accuracy, and safety of their models. Furthermore, thefederal government should maintain a public database of significantadverse incidents to offer accessible information on AI systems forconsumers and researchers.”
Survey Result
Remarks
As with the licensing body, ASFAI members expressed limited supportfor regulations requiring companies to disclose data regarding thetraining and specifications of the AI systems they develop. Whiletransparency is often desirable, a mandatory reporting regime couldharm US competitiveness and make it more difficult for small firms tocompete (e.g., by requiring excessive compliance and paperwork).
However, systems other than mandatory transparency for private
companies may enable increased transparency without stiflinginnovation. For example, voluntary reporting, and government adoptionof AI to increase transparency could balance the desire for transparencywith the need to retain a competitive business environment.


American Society for AI
American Society for AI ASFAI.org Page 10 of 14Learning from State Intiatives
Another area of concern is whether AI should be regulated primarily at
the state or federal level. ASFAI research has shown that the vastmajority of states (40/50) have already completed, or are in the processof implementing a government-supported AI task force. However, theemergence of different regulatory regimes in different states couldmake it more difficult for AI companies to operate and threaten thecompetitiveness of the US as a whole.
Understanding these state-level initiatives can provide insights to
shape federal policy. While a patchwork approach to regulation couldbe harmful, state governments can also serve as vital laboratories for
policy innovation , offering real-world evidence of how different
governance approaches succeed or fail in practice. Thus, it may beappropriate for federal policymakers to observe state initiatives before
implementing a regulatory approach for the whole country . 
States with dedicated AI committees, working groups, or tasks forces


American Society for AI ASFAI.org Page 11 of 14American Society for AI
State-Level Implementation Models
Dedicated Task Forces
Several states (e.g., Maryland) have established dedicated task forceswith specific mandates and sunset provisions. This model typicallyinvolves a discrete group of experts working within a defined timeframeto produce specific deliverables, such as policy recommendations orimplementation frameworks. This can result in a more focused mission,but the fixed duration can limit long-term oversight capability.
Integrated Agency
Other states have integrated AI governance into existing governmentalstructures, such as Georgia’s effort spearheaded by the GeorgiaTechnology Authority. This model can be more efficient, but it lacks thefocus of a dedicated task force. 
Legislative Committees
States such as Colorado have established legislative committees withongoing AI oversight responsibilities. This model emphasizescontinuous legislative engagement and  oversight. However, legislativecommittees may not have the same expertise available compared to adedicated task force or a technology-specific government agency.
Hybrid Approaches
Some states have developed hybrid models that combine elements ofmultiple approaches. For example, Oregon has combined a legislativeTask Force with an executive Advisory Council. Hybrid approaches canbalance the advantages of various other approaches.


American Society for AI ASFAI.org Page 12 of 14American Society for AI
State-Level AI Policies
By observing the effects of policies implemented at the state level,
federal lawmakers can gain insight before imposing restrictiveregulations. However, the era of state experimentation is justbeginning, so it is critical to document and observe the effects of statepolicies as these effects emerge. Example areas of focus include:
Adoption and Preparation
States have recognized that AI policy should not be solely focused onregulation and limiting risk. Governments can also encourage increaseddevelopment and adoption of AI. For example, Iowa's executive taskforce specifically targets cost reduction and automation opportunities,while Arkansas emphasizes practical applications in unemploymentinsurance fraud detection and recidivism reduction.Other states have focused on preparing for the rise of AI. For example,Wisconsin's task force is tasked with assessing labor marketimplications, while New Jersey combines workforce preparation withbroader economic development goals. 
Deepfake/Fraud Detection
Numerous states have taken steps to prevent fraud and deepfakes. Forexample, California recently passed a law compelling companies toremove deepfakes when identified by users, and allowing courts toissue injunctions blocking the distribution of deceptive political contentduring elections. Tennessee passed legislation targeting unauthorizedAI-generated replication of people’s voices and likenesses to preventunwanted AI impersonation.
Consumer Protection
Colorado recently enacted legislation requiring developers of high-riskAI systems to exercise reasonable care to prevent algorithmicdiscrimination and mandating disclosures to consumers. Similarly, Utahpassed a law establishing liability for undisclosed AI use that violatesconsumer protection laws and requiring disclosures in regulatedprofessions such as healthcare. Other states have focused onprevention of bias and discrimination. For example, a recent New Yorklaw mandates bias audits for automated employment decision tools.Arizona's judicial steering committee is tasked with addressing biasmitigation in sensitive government functions.


American Society for AI ASFAI.org Page 13 of 14American Society for AI
Alternatives for Achieving Ethical AI
To achieve beneficial AI while continuing to advance US leadership,
alternatives to regulation should be explored that enable ethics to serveas a foundational pillar without becoming a constraint on innovation.Ethical AI ensures that AI adoption is sustainable, enforceable, andaligned with democratic values. To effectively integrate ethics into AIpolicy without constraining growth, the following principles shouldguide U.S. AI strategy:
Investing in the Development of Ethical AI 
The US should pursue ethical governance frameworks that accelerate AIadoption, rather than becoming a regulatory burden. This includesincentivizing ethical AI innovation. For example, the federalgovernment could provide tax incentives, R&D grants, and governmentcontracts for companies that integrate responsible AI practices. 
Government policy can also include facilitating the development of
private Ethical AI Certification Standards. These standards could includevoluntary programs that encourage companies to build trust throughtransparency. Voluntary programs enable companies to balance thecosts and benefits of participation and are less likely to hinderinnovation for companies that find it too costly to comply.
Assessing AI Risk
The ethical deployment of AI must balance innovation, security, andeconomic development. But in order to do this we must firstunderstand the risks and benefits of AI. Accordingly, the US could worktoward developing standardized risk assessments.These assessmentscould be based on the work of state and academic initiatives.
The risks of AI will vary greatly across sectors. Therefore, it will be
essential to establish sector-specific AI risk mitigation frameworks toensure safety in critical infrastructure, financial services, defenseapplications, consumer products, etc. Determining the impact on theworkforce in these sectors is of particular importance. Once the risksand opportunities are better understood, mitigation programs such asAI skills training could be implemented across industries to enhancesystem reliability, reduce unintended risks, and strengthen human-AIcollaboration.


American Society for AI ASFAI.org Page 14 of 14American Society for AI
Alternatives for Achieving Ethical AI (continued)
Enhancing Transparency and Public Trust
Sustained AI leadership requires public trust and transparency to drivebroad adoption across industries. One method for doing this is for thegovernment to become a leader in using AI systems to enhance thelevel of transparency in government. When people see AI being used tokeep the government accountable, it could encourage thedevelopment of AI models to achieve transparency in other high-stakessystems such as finance, healthcare, and public services. Data that wasonce inaccessible to the public can be made available and explainablethrough AI. 
Additionally, the US could invest in a national AI literacy campaign to
ensure that the public is equipped to take advantage of newopportunities that become available as AI systems become morecapable. By understanding AI, people are more likely to employ AIsystems for their own personal benefit.
Conclusion
The US is the global leader in AI, and we should do everything in ourpower to retain that position. In some cases , such as the use of AI for
military and law enforcement, careful consideration should be given
to establish clear standards . However, the establishment of European-
style regulation stifles innovation and creates an opening for othernations to overtake the US at the technological frontier.
Accordingly, the federal government should carefully observe and
learn from state-level AI regulatory experiments  before enacting
broad federal policies. Most states have already launched diverse AIinitiatives and governance models, ranging from dedicated task forcesto legislative oversight committees. In some instances, federalregulations could streamline state-level rules to avoid the US becominga patchwork jurisdiction that impedes technological development.Finally, approaches other than regulation should be considered to
achieve ethical development  and deployment of AI systems. From
incentive programs to educational campaigns, it is important that theUS take a broad-based approach to accelerating ethical AI in a way thatdoes not threaten our position as the world leader in this crucialtechnology.


