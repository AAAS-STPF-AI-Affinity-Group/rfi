PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-38a1-oqxa
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-8923
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Erin Joyce  
General Comment
Developm ent of an Artificial Intelligence Action Plan
Public Com m ent on AI:
Topic area: Privacy
The nature of Machine Learning m odels is that it relies on personal data, and it can be leaked during the m erging of datasets to analyze
and create learning m odels to be used in program m ing. 
These transfers are occurring everywhere now – especially as new versions of “chatbots” com e on the m arket, with little to no oversight.
It’s fueling a kind of gold rush for datasets – and a sense that “anything goes” am id an arm s race around the globe for dom inance in AI
system s. 
The United States technology industry has a history of ignoring data privacy. 
Indeed, the free m odel of usage that Facebook, Google, and other m ajor tech players rely upon reflects this “data m ust be free” m odel.
Only in the past few years have data privacy standards been ram ping up, such as Europe’s GDRP, and California’s Consum er Privacy
Act (CCPA), which strives to give consum ers m ore power over the data about them  – which is the fuel for AI and specifically, the “m eta-
learning” phase that we are m oving into as a society.
These “m eta-learners” are already turning ML system s in on them selves to learn how to learn m ore quickly. Com panies are scooping up
data about how we use software in m ore invasive ways. At som e point, I should be given a prom pt asking m e how m uch of this
data/creation/asset, or otherwise thing of value can be exploited by the “m eta-learner.” 
So a whole new thinking about the “EULA” – the End User License Agreem ent m ay be in order in the software and application industry. 
Trust Agents Must be Em powered -- with Prom pts to the End-User
We need to re-think the uses of encryption to ensure data privacy is preserved for consum ers during the transit of data to and fro on its
way to whatever data lake or ocean a "m eta-learner" will be diving into. Am azon is am ong the m ajor cloud providers (AWS) to deploy
so-called "hom om orphic encryption", to protect each hop datasets are taking in order to em power analysis or predictive m odels based on
the type of data being joined, etc. 
A kind of "decoy" encryption needs to becom e industry standard -- with governm ent's help -- to block the “not so fast” m eta learners
from  som e leakage along the way – or even diverting datasets as web services (another form  of m achine learning) grow m ore advanced.
Machines are talking to each other -- and can get kind of sloppy if they are not program m ed for explicit form s of data protection, such as
encryption m ethods that ensure "dum b" system s don't leak. 


Many com panies are offering free versions of their “build your own learning system ” m odels. The only way the user can protect their
privacy is via paid version, which m eans personal data is being put to use without the end user's consent. Com panies are under no
obligation to disclose how they are using the custom er’s data -- even with paid version of these services that claim  privacy is enhanced.
AI governance m ust balance the benefits of these “services” with privacy standards. 
Adding param eters to these learning system s is all the rage am ong the “discrete” program m ing m odels that hold sway in the race to build a
faster “m eta-learner.” The United States governm ent needs to add som e param eters to the software industry and technology providers as
well that ensures we are prom pted with updates about how our datasets are being used and whether that data is allowed to be ingested
into a “learning” m odel. 
Thank you for the opportunity to add som e thoughts to the RFI. 
Erin Marie Joyce
Alexandria, Virginia


