1 
 Paul F. Uhlir  
______________________________________________________________________________  
 
         March 13 , 2025  
 
To Whom It May Concern:  
 
I am writing in response to a “Request for Information (RFI) on the Development of an Artificial 
Intelligence (AI) Action Plan ”, issued by the National Science Foundation (NSF) on February 6, 
2025. Until 2015, I was employed by the National Academy of Sciences for 30 years in 
Washington, DC with my last position  there  as founding director of the Board on Research Data 
and Information (2008 -2015) . I am now retired and a part -time data and information policy 
consultant  to international organizations, governments, and universities . My complete 
professional profile is available on my website at: www.paulfuhlir.com .   
 
In accordance with the request for a n RFI posted in the Federal Register, “this document is 
approved for public dissemination. The document contains no business -proprietary or 
confidential information . Document contents may be reused by the government in developing 
the AI action plan and associated documents without attribution. ” 
 
Because my background and experience focused on the policy and management of research 
data and not the technical aspects of AI ( for the sake of simplicity, I include Generative Artificial 
Intelligence and Artificial General Intelligence in that term), I will focus my remarks on the 
policy issues and not the technical ones. I also concentrate on the processes that need to be 
involved rather than on the substan ce of the issues , primarily because this is a very fast -moving 
and shifting area. The establishment of a flexible and quick ly responsive process is essential to 
successfully implementing any AI Action Plan.  And lastly, my remarks focus on the threats or 
concerns of the rapid ly emerging tec hnology, since the positive aspects  and opportunities are 
better known  and require less consideration . 
 
With regard to the process, it is clear that the Trump Administration does not wish to burden 
industry with onerous regulations or requirements or to hamper the progress in developing AI.  I 
share that concern, but  we live in an interdependent global environment —whether we like it or 
not—so we need to  cooperate with the international community  for our own security and the 
world’s . It is not an overstatement to say that we are fundamentally at the dawn of a new era —
another  true paradigm shift —building on, but completely transformative of, the digital 
networks and  the WorldWideWeb that began 30 years ago, and which constituted a paradigm 
shift in their own right.  
 
I am not a technical expert, but I do know that AI requires massive amounts of factually 
accurate data and information to succeed. The data -intensive sciences to which we have 
become accustomed will be the fuel that drives AI and its limitless applications . What is 
especially important is that all fields of science, whether in the life sciences, physical sciences, 


2 
 social sciences, engineering, the humanities —indeed, all areas of human endeavor —are poised 
to welcome the benefits.  
 
Many countries already have huge, factually accurate, and georeferenced databases that will be 
exploited by AI. We can use them to make incredible advances, but if the advances we are 
about to make are unlimited and profound, so are the dangers posed by the technology that 
world leaders —especially in the development of AI technology itself —are warning us about. In 
many ways, the technical advances and their unl imited applications will be the easy part, 
although their successful implementation will require a great deal of effort and expense.  
 
What concerns me as an information lawyer are the human systems that are used to control 
the technology and to avoid the worst pitfalls.  The pace of technological progress will always 
outrun the capability of human systems to adequately control them. Moreover, the rapidity of 
technological advances is accelerating, making our ability to control them increasingly difficult. 
With AI we very well may  be entering into an era of runaway technology, in which we are 
predicted to end up being the spectators and ult imately perhaps the victims of our own 
success. It is the vision called Singularity, which may only be two decades from now.  
 
It therefore is not too early —and perhaps in many ways it is too late —to think seriously and to 
devote adequate resources for that control. We need to devise human systems to safely 
harness that technology. For that, AI systems  themselves  may be the answer, at least in part. 
Indeed, if asking the right question has been a hallmark of scientific advances in the past, that is 
now one of the most important skills for an AI -enabled approach to problem -solving and 
perhaps control.  
 
As someone  involved in science and innovation  throughout my career , and in the data activities 
that have been both the spark and the fire, my first instinct would be to break the perceived 
problems into manageable pieces and to address the most important parts first. It is time -
consuming and difficult enough to get national, much less global agreeme nt on even the most 
mundane and simplest concerns. However, we must now facilitate a process that involves many 
different types of people, including political and business leaders, cyber -engineering experts, 
domain scientists, and the ethicists and lawyers from all countries, to work together in a 
sustained effort. We need to mute the worst potential effects of AI and to make progress on 
well-defined baskets of issues that are of near -term and longer -term focus.  
 
Such attention should be concentrated, simultaneously, at the national and international levels. 
Separate, yet interrelated agreements though formal treaties and protocols should  be devised, 
if possible, although some would say that it is a fool’s errand if that is to be accomplished 
rapidly. The dismal state of international law in confronting data and other technological 
challenges is not inspiring.  
 
We should endeavor to establish processes —now —that address a well -curated and 
continuously updated list of the most important problems. We need to devise methods to 
maintain control over the growing super -intelligences we are unleashing. The same or similar 


3 
 processes should be set up in major domains of technical activity, such as biotechnology, 
nanotechnology, robotics, and so on. Together, these domains of our existence need to be 
coordinated in a manner that puts a premium on the safest results.  
 
Some of the likely potential problems in the not -too-distant future are familiar while others 
may be less so. In fact, there are a number of well -known examples that have already occurred, 
even without the assistance of AI technologies. Well -publicized one s affect all areas of human 
endeavor, such as : 
 
First, the massive dislocation of workforces in a broad range of sectors. This is not just manual 
labor in the service and manufacturing industries, but includes professional service sectors such 
as accounting , law, and medicine;  
 
Second, the potentially damaging impacts on privacy protections by finding and processing 
personal data, or by using sensitive information for social surveillance. The EU has already 
enacted the GDPR on a regional basis and that may be a treaty that could be expanded more 
globall y; 
 
Third, greatly enabl ed criminal activities and capa cities, especially cybercrimes, through various 
software attacks, data theft, malicious code development, or fabricated information. Many 
examples of that have already occurred, not just in the United States, but all over the world ; 
 
Fourth, an expansion of human -induced disasters and infrastructure attacks, such as shutting 
down electrical grids, incapacitating computer systems and networks, or breaching large -scale 
energy sources ; 
 
Fifth, the automation and enhancement of weaponry in warfare, and their hijacking by non -
state actors in terrorism ; 
 
Sixth, the growth of inequality and the concentration of power. This is already happening  in the 
US and throughout the world ;  
 
Seventh, and related to my previous point, the adverse effects from a growing gap between the 
highly developed economies and the poorer nations in AI capacities on a global basis. This too 
has been taking place for several decades , known  as the digital divide , and  
 
Eighth, extreme financial manipulation of markets and the propagation of economic 
instabilities . 
 
The list goes on.  
 
In the somewhat longer term, however, we are likely to see not only a n expansion of many of 
these impacts, but also to experience entirely new threats that humanity must realistically be 
able to confront. Such global problems could be generated by the technological advances 


4 
 themselves, or they could be geopolitical in nature, that is, a byproduct of the advancing 
technology.  
 
In the arena of the technology itself, we could experience losing control to a self -aware super -
intelligence that some well -informed experts have said might even lead to human extinction. 
Recent public statements of cyber -technology leaders, again in the US, have been alarming 
(Sam Altman, Geoffrey Hinton, Elon Musk, and many more ).  
 
How do we deal with such an existential crisis that may be confronting us? Humanity must 
develop and implement fail -safe mechanisms for that potential threat. The development of this 
AI Action Plan  should have a role to play in that.  
 
On the geopolitical front, we could easily exceed the boundaries of individual nations, leading 
to large -scale conflicts that may be very difficult to manage. What will be the processes that can 
be instituted, that can confront such eventualities and build  trust?  
 
In either case, experts in government, industry, and academia  should become involved and 
work for our collective future. More specifically, we need to take some actions, such as:  
 
- be proactive for safety and propose adequate mechanisms and potential solutions in the AI 
technology sector , sooner rather than later ; 
 
- increase  research in safety mechanisms and improve prediction  capabilitie s; 
 
- work on standards in the appropriate organizations that promote common and effective 
approaches to technical and management issues ; 
 
- train employees in all sectors to use AI responsibly and promote transparency in its 
development and implementation ; 
 
- collaborate on ethical guidelines and insist on incorporating them in institutional and national 
policies, and international instruments , and last but not least ;  
 
- help ensure that humans always maintain supremacy over AI technology.  
 
Best wishes,  
 
Paul F. Uhlir  


