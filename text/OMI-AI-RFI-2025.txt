1 
Submission to the Office of Science and Technology Policy’s  
Request for Information on the Development of an  
Artificial Intelligence (AI) Action Plan  
This document is approved for public dissemination. The document contains no business-
proprietary or confidential information. Document contents may be reused by the government in 
developing the AI Action Plan and associated documents without attribution.  
March 15,  2025 
The Open Markets Institute welcomes the opportunity to respond to the Office of Science and 
Technology Policy’s (OSTP) Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan . Through this response, we propose an alternative approach to 
the proposed AI Action Plan and associated AI policy . We set forth our proposals for 
building an innovative and competitive AI ecosystem that  leads the world and secures US 
national security by creating a more level playing field and fairer market for the benefit of 
the public interest rather than corporate profit.  
The Open Markets Institute (OMI) is a non -profit organization based in Washington, D.C. and 
Brussels, Belgium dedicated to promoting fair and competitive markets and promoting and 
defending free speech. Our mission is to safeguard our political economy from concentrations of 
private power that undermine  a fair competition and threaten liberty, democracy, and prosperity. 
Open Markets  and its Center for Journalism and Liberty  regularly provides expertise on policies 
related to competition, emerging technology, and freedom of speech to Federal and state 
governments, lawmakers, competition authorities, courts, and journalists.    
Background 
The global AI ecosystem is highly concentrated , which undermines innovation, security, and 
resiliency and thus any AI Action Plan should include a focus on redressing these 
anticompetitive dynamics to ensure a flourishing, pluralistic , rights-based market for this 
transformative technology . Just three companies  — Google, Amazon, and Microsoft — 
collectively hold two-thirds of the global market share  in cloud computing,1 the method by 
which most AI companies access computing resources for model training and inference. Nvidia 
holds 90% of the market for graphics processing units (GPUs) , the chips that allow data centers 
to be optimized for AI.2 And Big Tech has acquired or engaged in “acqui -hires” of some of the 
1 “Cloud is a Global Market - Apart from China,” SRG Research, August 21, 2024, 
https://www.srgresearch.com/articles/cloud -is-a-global-market-apart-from-china.  
2 Nauman Khan, “NVIDIA Crushes Rivals: Secures Unprecedented 90% of GPU Market in Q3 2024 ,” Yahoo 
Finance, December 12, 2024, https://finance.yahoo.com/news/nvidia -crushes-rivals-secures-unprecedented -
102235255.html .  


2most promising AI startups, leading to a consolidation of talent3 in a few firms , replicating the 
same dynamics that we saw in the first two decades of the internet, which resulted in highly 
concentrated markets for search, social media, and the like . 
A concentrated AI market controlled by a few powerful players presents challenges beyond mere 
market competition. It stifles innovation by reducing incentives for established players to 
develop new solutions. It leaves consumers with fewer options for AI products, including safe AI 
models or small models that are less harmful to the environment. It also impacts the secur ity and 
resilience of a society as more and more services and critical infrastructure, from government 
services to healthcare to financial systems, are dependent on a handful of actors , leaving entire 
societies vulnerable to foreign attacks . And it undermines free speech , as companies such as X 
and Meta deploy their own AI models  to automate control over their social media platforms, 
identifying political dissidents and banning social media accounts .4 This consolidation of power 
threatens not only market dynamics and consumer outcomes but also innovation, the 
environment, and the foundations of democracy itself.  
We challenge the U.S. government’s current framing of priorities in AI, which focuses largely on 
ensuring American dominance in the global AI market , as evidenced by the E xecutive Order on  
Removing Barriers to American Leadership in Artificial Intelligence . As a transatlantic 
organization, we strongly believe in the power of  international cooperation on key issues related 
to AI, a transformational technology that transcends borders. We welcome actions taken by 
competition authorities to align and cooperate  with each other, such as the EU and the UK 
Competition and Markets Authority (CMA)’s agreement of joint cooperation5 and the joint 
statement  by the U.S. Federal Trade Commission (FTC), Department of Justice (DOJ), UK 
CMA, and European Commission on the importance of antitrust enforcement in AI.6 This 
alignment is essential when it comes to governing global technolog ies involved in AI 
development and deployment.  
The proposed AI Action Plan equates innovation with protection of US monopolistic technology 
companies , namely Google, Amazon, Microsoft, Meta, and Apple.  Empirical research shows that 
these massive, dominant  companies are less innovative than startups and SMEs  due to 
bureaucratic and organizational barriers to taking risks  and deters external innovation . For 
example, these companies are  actively undermin e innovation with “killer acquisitions,” “acqui -
hires,” and entering into “partnerships” (which act as de facto mergers) , leading to fewer firms, 
less competition and greater concentration that can create single points of failure . 
3 AI eating software, ACCEL (2024) at 32, https://cdn.prod.website -
files.com/6643a08d305ab77f8c7566b6/670f22a19ea69a94f9710c1a_16%20October%20 -
%20Accel%202024%20Euroscape.pdf .  
4 Mickey Carroll, “Elon Musk accused of censoring right -wing X accounts who disagree with him on immigration,” 
Sky News , December 28, 2024, https://news.sky.com/story/elon -musk-accused-of-censoring -right-wing-x-accounts-
who-disagree-with-him-on-immigration -13280740?dcmp=snt -sf-twitter.  
5 “EU and Britain agree on cooperation in antitrust investigations,” Reuters, October 29, 2024, 
https://www.reuters.com/markets/eu -britain-agree-cooperation -antitrust-investigations -2024-10-29/.  
6 “FTC, DOJ, and International Enforcers Issue Joint Statement on AI Competition Issues ,” Federal Trade 
Commission, press release, July 23, 2024, https://www.ftc.gov/news -events/news/press -releases/2024/07/ftc -doj-
international -enforcers-issue-joint-statement -ai-competition -issues.


3Lastly, we take issue with the administration’s de -regulatory stance and its argument that 
regulation hampers innovation. Rather, regulation of the market can ensure that we obtain the 
outcomes we seek, those that are beneficial to humanity, uphold democracy, and ensure robust 
competition among a variety o f options. The importance of the AI industry should not exempt 
corporations from abiding by existing competition, labor, environmental, privacy, copyright, and 
transparency laws, as is currently the case . The government must not allow law -breaking to 
become a competitive advantage. Doing so constitutes a “race to the bottom,” leaving Americans 
exploited for their personal data and labor, left with a dearth of options for AI products, 
deprioritized in terms of energy access, and overall worse off.  
The current oligopolization of the AI market  hurts innovation far more than regulation does, a 
lesson that should again be evident from previous eras of technological innovation . To correct 
this market failure, we propose that the AI Action Plan should emphasize the use of antitrust 
enforcement, strengthened copyright protections  for AI inputs , and pro-competitive policy  to 
check Big Tech’s monopoly power and enable fair competition for all.   
Our Vision for an AI Action Plan  
We imagine an alternative policy framework focused on competition, infrastructure and access, 
supporting democratic and responsible AI development, and protecting creators and publishers. 
Competition and Anti -Monopoly Measures 
Competition authorities — the FTC and the DOJ — should use e xisting merger control rules, 
including Section 7 of the Clayton Act , to scrutinize, and if necessary, block mergers and 
partnerships. They should also use existing antitrust laws, such as the Sherman Act and the 
Federal Trade Commission Act, to investigate and prohibit dominant platforms from engaging in 
anticompetitive practices.  
When monopolistic behavior is found to have occurred, enforcers should quickly impose 
remedies designed not only to prevent abusive conduct but also to open up markets  and foster 
innovation. Such remedies should include the divestment or sale of parts of a corporation , 
especially business lines that cause a substantial conflict of interest such as cloud . Other 
remedies could include interoperability and data portability between different foundation models  
as well as restrictions on how data can be leverage d across different business lines  (as the DOJ 
recommended in its proposed remedies7). 
7 See Courtney C. Radsch, “Letter to the U.S. Department of Justice Antitrust Division on the Google search 
monopoly case,”  Open Markets Institute and Center for Journalism & Liberty, November 19, 2024, 
https://www.openmarketsinstitute.org/publications/cjl -omi-urges-doj-to-break-googles-search-monopoly ; Karina 
Montoya and Courtney C. Radsch, “Beyond court remedies in the Google Search case: A competition reform for the 
search ecosystem,” Concurrences , no. 1 (January 2025), 
https://static1.squarespace.com/static/5efcb64b1cf16e4c487b2f61/t/67aa2433158bfc091e597712/1739203635721/C
oncurrences_Radsch+%26+Montoya.pdf .  


4 
 The FTC should continue its critical investigations and enforcement actions of dominant 
technology corporations , as it is poised to do with the upcoming lawsuit against Meta Platforms 
seeking the breakup of Facebook, WhatsApp, and Instagram.  
Leveraging Current Legal Frameworks to Regulate AI Companies  
Relevant enforcement authorities should hold AI platforms accountable to existing privacy, 
copyright, contract, and consumer protection laws, environmental and labor standards, and 
horizontal AI laws. Ensuring compliance with the letter and spirit of exist ing laws, regulations 
and commitments could curb dominant players' power and their ability to exploit or abuse those 
dependent on their services.  
For example, applicable contract laws and consumer protection laws, including the FTC Act and 
the CCPA, should be used to the greatest extent possible to hold AI companies accountable for 
violating their terms of service or amending terms of service and pr ivacy policies secretly or 
retroactively. This includes instances where companies surreptitiously adopt more permissive 
data practices to train AI models on user data or share user data with third parties for AI training.  
In some cases, remedies could and should include the deletion of both data and resulting 
algorithms, as this can be a more effective remedy for redressing  the anticompetitive  behavior 
and advantages gained, than a fine.  
Lastly, given the enormous financial opportunity presented by federal contracts and the potential 
to affect markets, public procurement policy should be reformed to limit Big Tech capture of 
federal contracts , especially where critical measures of national security or safety are concerned.  
Infrastructure and Access   
Given its centrality in the AI ecosystem and the digital economy more generally, cloud 
computing should be treated as a public utility and regulated accordingly, with an emphasis on 
fair, transparent, and non -discriminatory access and pricing. This would e nsure that Big Tech 
firms are no longer able to leverage their control of computing power to benefit their own 
services, pick winners and steer the broader trajectory of AI innovation.  
In addition, regulators should ensure antidiscrimination and neutrality principles for cloud 
services. In the absence of those, they should investigate the  potential for censorship at the cloud 
infrastructure level, given the lack of net neutrality protections. They have been criticized for 
privileging certain customers, functions, geographies, and sectors over others in terms of access, 
speed, and security .8 And they have the power to censor specific users, such as journalists or 
political dissidents or anyone else they want , with impunity . This is not a hypothetical threat, as 
was demonstrated by Amazon’s move to suspend Parler, a right -wing social media platform, 
from AWS in the wake of the January 6 Capitol attack ;9 Amazon’s termination of  WikiLeaks’ 
 
8 Courtney C. Radsch, “Trump V. Tech: What Is Censorship and Who Gets To Do It?”  Medium. 
https://medium.com/center -for-media-data-and-society/trump -v-tech-what-is-censorship -and-who-gets-to-do-it-
a567b6a341df .  
9 Alex Fitzpatrick, “Why Amazon’s Move to Drop Parler Is a Big Deal for the Future of the Internet,” TIME, January 
21, 2021, https://time.com/5929888/amazon -parler-aws/. 


5AWS service under political pressure from U.S. Senator Joseph Lieberman on the grounds of 
national security ;10 and Google and Amazon’s blocking of the practice of “domain fronting ,”11 a 
practice used by Signal  — a secure messaging platform relied upon by dissidents and journalists  
— to evade censorship in countries like Egypt, Iran, Qatar, and the UAE.12  
Market concentration amplifies these dangers to free speech, as organizations banned from Big 
Tech’s infrastructure have few alternatives for reaching users. Treating the cloud as a public 
utility and regulating it as such would bring the cloud further under public control and decreasing 
the likelihood that Big Tech can arbitrarily cut off or deprioritize service to users for various 
reasons. 
Supporting Democratic and Responsible AI Development  
In the realm of industrial policy, t he government should invest in building public computing 
capacity. In order to undermine Big Tech’s power in the cloud computing space, viable 
alternatives must be available, and given the tech corporations’ anticompetitive behavior, the 
government must step in and provide investment for the development of alternatives.  
The government can build up p ublic compute capacity in many ways , including the  direct 
provision  of compute — such as the US Department of Energy’s supercomputers  and the 
National AI Research Resource (NAIRR) — and decentralized provision, which would create 
distributed networks of smaller facilities.13 Any programs for the provision of public compute 
should prioritize accessibility and affordability for smaller actors, including startups, SMEs, 
researchers, and academic institutions.  
The AI Action Plan should also ensure that the government invest s in open-source AI 
development and adoption. Open-source AI that is fully transparent about model weights and 
training data14 can be a vital check to Big Tech’s power  in that they offer accessible and 
democrati c alternatives to models owned by or partnered with Big Tech.   
Enforce Exis ting IP laws and Protect Creators  
The U.S government and relevant authorities must also enforce existing intellectual property (IP) 
laws, including copyright laws, in order to create a more balanced and fairer  marketplace in 
which all play by the same rules and ensure that the AI industry is not able to develop its wealth 
and power by stripping value from the intellectual property of creators and publishers.  
10 John Naughton, “WikiLeaks Row: Why Amazon’s Desertion Has Ominous Implications for Democracy,” The 
Guardian , December 11, 2010, sec. Technology, https://www.theguardian.com/technology/2010/dec/11/wikileaks -
amazon-denial-democracy -lieberman . 
11 Bruce Schneier, “Censorship in the Age of Large Cloud Providers,” Lawfare, June 7, 2018, 
https://www.lawfaremedia.org/article/censorship -age-large-cloud-providers .  
12 “A letter from Amazon,” Signal, May 1, 2018, https://signal.org/blog/looking -back-on-the-front/.  
13 Matt Davies and Jai Vipra, “Computing Commons,” Ada Lovelace Institute, February 7, 2025, 
https://www.adalovelaceinstitute.org/report/computing -commons/ .  
14 “The Open Source AI Definition – 1.0,” Open source Initiative , https://opensource.org/ai/open -source-ai-
definition .  


6Leading AI corporations plan to invest approximately $1 trillion in AI development over the next 
five years.15 This massive investment relies heavily on training and grounding data that often 
includes creative and information works collected from creators and publishers without 
permission , compensation or credit . These companies have strategically ignored copyright law 
around the world while resting on a flimsy fair use argument in the US  and, in many cases, 
willingly broken copyright ,16 to gain commercial advantage before regulatory frameworks can 
adapt.   
The government should establish an opt-in protocol for AI training data collection that honors 
copyright principles, protects creators’ and publisher  rights, and ensures technology companies 
operate with proper authorization  while abiding by the law .17 A consent -based approach is 
essential to protect the sustainability and competitiveness of America's creative industries against 
unauthorized exploitation. The decisions we make now regarding data usage rights will 
significantly impact the integrity of ou r information ecosystem and, by extension, our democratic 
values. 
While technology corporations speculate about  potential transformative benefits  of AI systems , 
the safety and effectiveness of generative AI relies heavily on access to high -quality training 
data.18 Therefore, establishing regulatory frameworks to ensure fair compensation for creators is 
not just about protecting their rights – it is also about preserving the very source of innovation 
that AI companies depend upon for advancement and ensuring creator s are still incentivized to 
create.  
Conclusion  
The rapid spread of AI presents an inflection point for American society and our economic 
system. The policy decisions made by the U.S. government today will determine whether AI 
serves concentrated corporate interests or functions as a democratic  technology that benefits the 
public interest  and promotes US leadership and national security . We urge the administration to 
pivot away from its current approach of prioritizing Big Tech dominance and instead embrace a 
framework that promotes genuine competition, prevents dangerous consolidation of power that 
undermines security and resiliency  and ensures equitable access to AI infrastructure  — all of 
which will allow innovation to thrive.  
The measures we have outlined — continued antitrust enforcement, regulation of cloud 
computing as a public utility, investment in public compute resources, support for open -source 
15 Erum Manzoor, “Comparing Major Companies’ AI Spending in 2024 and the Challenge of Productionizing AI 
Solutions,” AIM Councils,  6 November 2024,  https://council.aimresearch.co/comparing -major-companies -ai-
spending-in-2024-and-the-challenge -of-productionizing -ai-solutions/ .  
16 See Suchir Balaji, “When does generative AI qualify for fair use?”, 23 October 2024, 
https://suchir.net/fair_use.html , and Kate Knibbs, “Meta Secretly Trained Its AI on a Notorious Piracy Database, 
Newly Unredacted Court Docs Reveal,” WIRED, January 9, 2025, https://www.wired.com/story/new -documents -
unredacted -meta-copyright -ai-lawsuit/.  
17 Courtney C. Radsch, “The case for consent in the AI data gold rush,” Brookings , January 16, 2025, 
https://www.brookings.edu/articles/the -case-for-consent-in-the-ai-data-gold-rush/.  
18 Courtney C. Radsch, “AI Needs Us More Than We Need It,” Washington Monthly , October 29, 2024, 
http://washingtonmonthly.com/2024/10/29/ai -needs-us-more-than-we-need-it/. 


7 
 alternatives, and protection of copyright — represent a comprehensive strategy to create a more 
fair, innovative, and competitive AI ecosystem. By adopting these recommendations, the 
government can help ensure that AI development and deployment serves the public interest 
rather than further entrenching the power of dominant technology corporations at the expense of 
the government and the public.  
Additional OMI background and expertise:  
 
The Open Markets Institute  has authored policy briefs and original reports on the topics of 
technology and market concentration. In November 2023, we released our flagship report on 
corporate power and AI, “ AI in the Public Interest: Confronting the Monopoly Threat .” We 
followed up this work with a report in partnership with the Mozilla Foundation, “ Stopping Big 
Tech from Becoming Big AI ”  and an Expert Brief on AI and Market Concentration . In addition, 
OMI’s Center for Journalism and Liberty has authored multiple pieces on the harms of 
concentration in the AI value chain to journalism and free speech through proprietary policy 
papers such as  “What is the Value of Journalism to AI?”  and publishing commentary in 
Brookings , Tech Policy Press , and Washington Monthly . 
 
In addition, OMI has supported numerous public authorities in the U.S., UK, and EU with 
technology policy advice and enforcement actions. We have submitted recommendations to U.S. 
Department of Justice Antitrust Division  in support of its proposed final judgement in the case 
that found Google held an illegal monopoly over search and text advertising and to the UK 
Competition and Markets Authority (CMA)  to consider structural separation in its Google 
general search services investigation. We have also supported  the European Commission’s DG 
Competition’s case on Google’s monopolistic practices in online advertising technology 
(‘adtech’). We have provided strategic policy advice to the UK CMA  and the French competition 
authority. Lastly, we have provided comments  to the UK in response to its consultation on 
artificial intelligence and copyright, urging the Intellectual Property Office to adopt an opt -in 
approach to copyright to protect the creative industries.  
 


