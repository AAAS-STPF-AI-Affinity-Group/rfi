PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-1ot2-t5vh
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7642
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Grayson Sch ultz 
General Comment
I am  writing in response to the National Science Foundation’s request for inform ation on the developm ent of an Artificial Intelligence (AI)
Action Plan. As a professional writer who m akes a living through m y creative and intellectual work, I recognize AI’s potential to enhance
various industries, including writing, research, and healthcare. However, I am  deeply concerned about the risks AI poses to copyright
protections, data ownership, health equity, and overall accountability. Without proper safeguards, AI can be used in ways that exploit
individuals, violate privacy, and in healthcare settings, even cost lives.
While AI can serve as a valuable tool, its use m ust be governed by strong protections to ensure that copyrighted m aterial is not exploited
without consent or com pensation. Many AI m odels are trained on m assive datasets that include copyrighted content, often without the
knowledge or perm ission of creators. This practice threatens the livelihoods of writers, artists, and other professionals whose work is their
prim ary source of incom e. The AI Action Plan m ust explicitly address how AI com panies will be held responsible for respecting copyright
laws and ensuring fair com pensation for those whose work is used in training m odels.
Beyond the im pact on creative professionals, I am  particularly concerned about the role of AI in healthcare and health-related data. AI-
driven decision-m aking in m edical settings has already led to serious, som etim es deadly, consequences when not properly tested, ethically
designed, or effectively regulated. Biases em bedded in AI m odels—due to incom plete, non-representative, or discrim inatory data—can
lead to m isdiagnoses, denial of critical treatm ents, and the reinforcem ent of existing health inequities. If AI is used to determ ine who
receives care or how m edical resources are allocated, unchecked bias can quite literally be a m atter of life and death.
Additionally, the handling of sensitive health data raises m ajor ethical concerns. AI tools are increasingly used to process patient records,
insurance claim s, and even predictive health analytics. However, without robust protections, this data can be m isused, leading to breaches
of privacy, discrim ination, and exploitation. Patients m ust have full control over their own health data, and AI com panies m ust be held to
strict ethical and legal standards to ensure data security and responsible use.
Finally, AI developers and corporations m ust be held accountable for harm  caused by their technologies. Whether through bias in AI
m odels, m isinform ation, or econom ic disruptions, the consequences of AI m isuse can be severe. There m ust be clear legal m echanism s
that allow individuals and organizations to challenge AI-driven decisions and seek redress when harm  occurs. Com panies profiting from
AI should bear responsibility for m itigating risks and addressing negative outcom es.
I urge the National Science Foundation to develop an AI Action Plan that prioritizes ethical guidelines, strong regulatory fram eworks, and
accountability m echanism s. AI should be designed to support hum an creativity, health, and innovation—not to underm ine the rights and
livelihoods of those who create original content or to endanger lives through unchecked autom ation. I appreciate the opportunity to
provide input on this critical issue and look forward to policies that balance AI’s potential benefits with essential protections.


