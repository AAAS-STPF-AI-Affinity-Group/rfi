PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 88-6wbs-tkuk
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1289
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Holly Elmore 
General Comment
To the NITRD NCO and OSTP,
I am  relieved to see the United States governm ent treating frontier AI as the absolute force that it will be. The potential benefits are
enorm ous, but our top priority at this critical juncture m ust be ensuring the loyalty and reliability of these frontier AI system s. The United
States m ust take the reins while we have the lead to ensure that no country develops out-of-control superhum an AI. We m ust m ake an AI
Deal to prevent superhum an AI developm ent by all nations while we still have the lead. 
I did m y PhD work in bioinform atics. I still rem em ber when GPUs for scientific applications were novelties in the com pute cluster at
Harvard only seven years ago. How far we have com e. Five years after I graduated, frontier AI could have com pleted m y PhD work in a
fraction of the tim e. I m arvel at the potential of this am azing technology to im prove our lives. I becam e a scientist to im prove our lives
through knowledge and innovation. But now I fear that, without wise leadership, frontier AI will becom e a threat to hum anity instead of the
boon that it can be.
The first thing we need to steer frontier AI and keep it aligned with Am erican interests is m ore tim e. Over the past few years, AI has gone
from  barely being able to write coherent sentences to rivaling physicists and m athem aticians at elite-level problem s. AI experts believe that
truly hum an-level AI could be around the corner, and I agree. Without creating m ore tim e to steer and innovate in the direction we want,
we will lose the ability to control the technology at all.
Superhum an AI could exploit cybersecurity vulnerabilities, cripple our infrastructure, work with our adversaries to induce arm ed conflict,
or m ake synthetic superpathogens. We m ay be able to elim inate som e of these risks by hardening our security– for instance, by m andating
better biosecurity practices– but not all. By definition, any AI system  with greater-than-hum an intelligence will be able to think up new
ways to threaten our security that we ourselves had failed to consider. Even if we are lucky enough to avoid widespread loss of life,
superhum an AI that escapes our control could nonetheless threaten our national interests, destabilize the econom y, and plunge our
country– and our world– into chaos. The world needs strong leadership to steer frontier AI away from  catastrophe and into a better
future.
The United States can provide that leadership, for ourselves and the world. Am erica should have a great AI Plan that ensures that we
build beneficial AI and lead the rest of the world in keeping it beneficial. Other nations are developing their own frontier AI, but the United
States is ahead. This puts us in a position to lead the rest of the world in avoiding potentially fatal m istakes with this powerful technology.
An AI Deal that lim its how m uch any nation can experim ent with AI over a certain level of power (achieved perhaps through lim its on
training com pute) would allow the US to ensure the beneficial developm ent of future AI and m aintain its lead.
Thank you, 
Holly Elm ore, PhD


