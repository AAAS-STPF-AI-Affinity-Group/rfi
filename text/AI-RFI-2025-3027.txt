PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-ron8-fz9e
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-3027
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Moss M Jacques
General Comment
"U.S. AI Leadership and Global Governance: Balancing Innovation and Strict Oversight"
See attached file(s)
Attachments
White paper AI Action plan


 Moss M.Jacques


“AI is likely to be either the best or worst thing to happen to humanity.”
 Stephen 
Hawking


U.S. AI Leadership and Global 
Governance: Balancing Innovation and 
Strict Oversight
Strategic Investments in AI Research and 
Development
On his second day in office, President Trump announced the Stargate Project, marking the 
beginning of a renewed global race for AI dominance. To maintain leadership in this rapidly 
evolving field, the U.S. must prioritize substantial investments in AI research, infrastructure, and 
talent. A strong commitment from both the government and private sector is essential to driving 
innovation while ensuring responsible governance. There’s no doubt that robust investment is the 
foundation of AI leadership. The U.S. government and private sector must significantly fund AI 
research, infrastructure, and talent to stay ahead. 
Public funding for AI R&D has grown in recent years – for example, the National Science 
Foundation launched seven new AI Research Institutes with a $140  million investment focused 
on trustworthy AI, climate, cybersecurity, and health applications  (1).Overall federal AI R&D 
spending more than doubled from about $1.3  billion in 2017 to $3.2  billion in 2022  (2), reflecting 
a recognition of AI’s strategic importance. Private-sector investment dwarfs public funding and 
is a key U.S. strength. American tech companies and startups are pouring capital into AI at 
unprecedented levels. In FY2025, Microsoft alone plans to invest roughly $80  billion in AI-
enabled data centers (over half of it in the U.S.) to power advanced AI models and applications  
(3).Other industry leaders like Google and Amazon are also “investing heavily” in AI, alongside 
a wave of new startups, and more private capital is flowing into the AI sector (4). Thanks to this 
combination of venture capital, corporate R&D, and government support, the United States 
currently “leads the global AI race” driven by innovations from companies of all sizes (5). To 
maintain this edge, experts recommend increasing federal support for fundamental AI research 
(e.g. through NSF, DARPA, and DOE programs) and expanding public-private partnerships. 
Strategic initiatives like the CHIPS and Science Act authorize tens of billions for science 
(including AI), and a proposed AI R&D roadmap in the Senate calls for $32  billion of federal 
investment (6). Sustained funding growth, matched with incentives for commercialization, will 
drive the next wave of AI breakthroughs. The U.S. should also support critical AI infrastructure 
(such as a National AI Research Resource for computing power) and continue to “double down 


on its strengths ” – world-class universities, vibrant startups, and leading tech firms – to cement 
its leadership (7). By jointly investing in innovation, government and industry can ensure America 
stays at the cutting edge of AI advancement while others race to catch up.
Smart and Adaptive Regulatory Frameworks
Shaping AI with thoughtful regulation is essential to ensure ethical use and public trust, but it 
must be done without smothering innovation. U.S. policymakers are grappling with how to 
oversee AI in a balanced way. A Senate hearing in May 2023 emphasized that how the U.S. sets 
AI rules will “help set the tone globally for AI regulation and how to address AI risks without 
stifling innovation” (8). There is broad agreement that certain AI applications need guardrails – all 
witnesses at the hearing (including OpenAI’s CEO and IBM’s AI ethics lead) agreed on the need 
for some form of AI regulation  (9). For instance, AI leaders have proposed safety requirements 
and even licensing highly advanced AI models, along with rigorous testing/auditing before and 
after deployment  (10). IBM’s representative argued for a risk-based, use-specific approach: rather 
than regulating AI technology itself, focus regulations on high-risk use cases (much like the EU’s 
draft AI Act, which imposes stricter rules on sensitive uses such as AI in hiring or loan decisions) 
(11).Lower-risk applications would face lighter touch oversight, preserving space for 
experimentation. This kind of tiered framework can protect the public from harmful AI outcomes 
(bias, unsafe systems, etc.) while avoiding one-size-fits-all rules that could impede benign 
innovations.
The U.S. has begun developing guidance and standards instead of broad AI laws. Agencies are 
applying existing laws (e.g. the FTC policing deceptive AI practices, EEOC addressing biased 
hiring algorithms)  (12). The National Institute of Standards and Technology released an AI Risk 
Management Framework to guide organizations in designing trustworthy AI, and the White 
House published a Blueprint for an AI Bill of Rights  outlining principles like data privacy, 
algorithmic discrimination protections, and human oversight (13). However, experts note that 
more is needed – the lack of a comprehensive national AI law means the U.S. is often reacting  to 
other countries’ approaches (like Europe’s AI Act) rather than setting the agenda  (14). To lead, 
the U.S. may need to craft its own flexible but enforceable AI rules – for example, requiring 
transparency for AI systems that affect consumers, mandating bias audits for high-impact 
algorithms, and ensuring accountability when AI causes harm. Narrowly targeted legislation can 
address urgent risks (for example, a proposed bill to ban malicious deepfakes used in non-
consensual pornography) without overburdening the broader AI ecosystem  (15).Crucially, any 
regulatory framework should be updated continuously in step with AI’s rapid evolution and 
involve industry input. A heavy-handed approach could “discourage investment, deter start-ups, 
and compromise American leadership”  Industry voices caution that the U.S. “cannot afford 
to slow its own private sector with heavy-handed regulations” and should instead adopt 
a common-sense approach that keeps the “wind at its back”  Industry voices caution that 
the U.S. “cannot afford to slow its own private sector with heavy-handed regulations” 


and should instead adopt a common-sense approach that keeps the “wind at its back” .
(16). Sandboxing and pilot programs can help test AI oversight mechanisms in a controlled way. 
In sum, the U.S. should pursue agile, risk-proportionate regulations that ensure AI systems are 
safe, fair, and transparent, while still enabling innovators to thrive. By getting this balance right, 
America can both protect its values and foster an environment where responsible AI innovation 
flourishes – setting an example for other nations.
International Collaborations for Global AI 
Governance
No country can shape global AI norms alone – the U.S. must work closely with allies and 
multilateral organizations to develop consistent international AI governance. This collaboration 
is both strategic and value-driven: democracies want to promote AI that respects human rights 
and security worldwide, especially as authoritarian models of AI deployment gain ground. There 
are already several forums where the U.S. engages partners on AI policy. For example, the U.S.–
EU Trade and Technology Council has a working group devoted to AI, aiming to align standards 
and develop a joint code of conduct for AI. The Global Partnership on AI (GP AI)  – a multi-
stakeholder initiative launched by U.S. allies like France and Canada – is another venue for 
sharing research and best practices on responsible AI. (Notably, the U.S. joined GPAI and 
recently supported integrating it into the OECD to give it a more stable structure (17).The 
Organisation for Economic Co-operation and Development itself has been instrumental in 
convening like-minded nations – the OECD’s AI Principles (endorsed by 40+ countries including 
the U.S.) outline common commitments to safety, fairness, and accountability in AI. Building on 
that, the OECD’s AI Policy Observatory helps coordinate policy approaches.
High-level diplomatic coordination is also picking up. G7 leaders, in their 2023 Hiroshima 
summit communiqué, underscored the need for cooperation on AI, specifically calling for joint 
efforts to address the impacts of advanced AI models like ChatGPT  (18).They launched the 
“Hiroshima AI Process” to have inclusive discussions (with the OECD and GPAI) on topics such 
as generative AI governance (19). Likewise, the United States participated in the UK’s Global AI 
Safety Summit (November 2023 at Bletchley Park) which brought together dozens of countries 
to begin coordinating on AI safety research and international monitoring of frontier AI systems. 
Moving forward, the U.S. can lead by advocating for interoperability between different nations’ 
AI regulations – essentially a common baseline of standards. The G7 has highlighted the 
“necessity of interoperability ” among AI governance frameworks so that trustworthy AI can be 
fostered across borders (20). Concretely, this could mean aligning on definitions of high-risk AI, 
sharing assessment tools and best practices, and avoiding conflicting requirements on companies.
Working with allies also extends to joint R&D and talent development. The U.S. can expand 
scientific cooperation with partner nations (e.g. joint AI research centers or scholarship 
programs) to pool expertise. Furthermore, it should coordinate export controls and security 


measures with allies to prevent dangerous AI tech from proliferating to hostile actors, while 
ensuring democracies maintain access to the best AI innovations. The U.S. State Department has 
even launched the Partnership for Global Inclusivity on AI , bringing together government and 
industry to ensure AI benefits are shared globally and aligned with democratic values  (20) (21) . 
Through such initiatives, the U.S. and like-minded nations can present a united front in 
establishing AI norms – from banning AI-enabled human rights abuses (like mass surveillance 
and social credit scoring) to setting guidelines for military AI use. International standards bodies 
and treaties will likely play a role; the U.S. should actively participate in drafting any global AI 
accord to ensure it reflects openness, human rights, and innovation. In summary, by deepening 
alliances – with Europe, G7 partners, and emerging AI hubs – and by strengthening multilateral 
efforts (OECD, United Nations, GPAI), the U.S. can shape a global governance model where AI 
is developed and used responsibly. This collaborative leadership not only addresses transnational 
challenges (like AI-driven cyber threats or autonomous weapons) but also reinforces U.S. 
credibility as the world’s AI leader committed to the common good.
Ethical and Security Considerations in AI 
Development
Advancing AI technology comes with serious ethical responsibilities and security risks that must 
be proactively managed. On the ethical front, AI systems can profoundly impact people’s lives, 
so issues of bias, fairness, transparency, and privacy are paramount. Scholars note that AI 
presents three major areas of ethical concern for society: (1) privacy and surveillance, (2) bias 
and discrimination, and (3) the role of human judgment in decisions made by algorithms  (22). In 
practice, AI algorithms have sometimes replicated or even amplified societal biases – for 
example, machine-learning models used in criminal sentencing or hiring have been found to 
reflect racial and gender biases present in their training data  (23). Without careful oversight, AI 
could unintentionally entrench inequality (e.g. “redlining” in lending might re-emerge if credit 
AI models learn from historical discriminatory data  (24). Ensuring algorithmic fairness is thus a 
key governance challenge. The U.S. can lead by establishing standards for testing AI systems for 
bias before deployment, mandating diverse and representative training data where possible, and 
requiring explanations for important automated decisions. Efforts like the White House’s AI Bill 
of Rights blueprint and NIST’s guidance encourage practices to mitigate bias and protect civil 
rights in AI  (25) . Some cities and states have begun to require algorithmic audits (New York City 
now mandates bias audits for AI hiring tools, for instance). Federally, strengthening anti-
discrimination enforcement to cover AI-driven decisions is an important step to ensure ethics are 
not sacrificed for expedience.
Another ethical imperative is transparency and human oversight. Critical decisions – such as 
medical diagnoses or loan approvals – should not be left to “black box” algorithms without 
recourse. Policies can require that AI is used to assist, not replace, human decision-makers in 
high-stakes domains, preserving a “human-in-the-loop” for judgment (26). Additionally, people 


should be informed when AI is impacting them (for example, chatbots or deepfakes should be 
clearly labeled to distinguish them from human content (27). The U.S. should encourage 
development of explainable AI  and set guidelines for transparency so that AI-driven processes 
can be inspected for errors or biases. This will build public trust in AI systems as they become 
more prevalent.
On the security side, AI’s dual-use nature raises concerns for both national security and public 
safety. Malicious actors – from cybercriminals to foreign adversaries – can misuse AI tools in 
novel ways. Indeed, officials warn that “malicious actors may use AI tools to defraud the public” 
and conduct sophisticated scams or disinformation campaigns (27),
One emerging threat is AI-generated content (deepfakes and AI voice clones) being used to 
spread misinformation or impersonate people for fraud. Such exploits can undermine democratic 
processes (e.g. fake videos of candidates) and erode trust in information. The U.S. needs to 
harden its defenses against AI-enabled threats by investing in detection of deepfakes, imposing 
penalties on AI-assisted fraud, and educating the public about verifying content. In 2023, the 
Biden administration required major AI firms to red-team their models for security flaws and 
share the results with the government  (28), an approach that should continue to ensure AI models 
don’t have hidden dangerous capabilities or vulnerabilities.
AI is also becoming a battlefield technology, which introduces security and ethical challenges in 
warfare. The Department of Defense has recognized this by adopting ethical principles for AI in 
defense, pledging that even as it accelerates AI adoption for national security, it will maintain 
America’s “steadfast commitment to responsible and lawful behavior” in the use of AI  (29). This 
means U.S. military AI (e.g. autonomous systems or decision aids) should be governed by rules 
of engagement and human control to prevent unintended escalation or violations of international 
law. The U.S. can lead global discussions on norms for military AI (such as banning fully 
autonomous weapons that operate without meaningful human oversight). More broadly, 
safeguarding AI safety is vital – advanced AI systems should be designed with fail-safes and 
tested for reliability, so they do not behave unpredictably in critical applications (whether in 
power grids, healthcare, or defense systems).
In summary, the U.S. must embed ethics and security into the AI lifecycle. This involves rigorous 
testing and validation of AI for biases and flaws, continuous monitoring of AI outcomes, and the 
ability to hold systems and developers accountable for harm. By developing strong ethical 
guidelines (for industry and government use alike) and investing in AI safety research, the U.S. 
can ensure that technological progress does not come at the expense of fundamental rights or 
security. Maintaining this balance is not only a moral responsibility but also key to sustaining 
public support for AI innovations.
Preparing the Economy and Workforce for the AI Era


AI has the potential to boost productivity and create new industries, but it will undoubtedly 
disrupt labor markets. To harness AI’s benefits while minimizing job displacement, the U.S. 
needs a comprehensive economic and workforce development strategy. This starts with 
education and training: workers at all levels must be equipped with the skills to work alongside 
AI. The private sector and government can collaborate on large-scale upskilling and reskilling 
programs to help current workers adapt. As Microsoft’s leadership has noted, America should 
“champion skilling programs that will enable widespread AI adoption and enhanced career 
opportunities across the economy” (30) .Concretely, this could mean tech companies partnering 
with community colleges to teach AI-related skills, federal incentives for apprenticeship 
programs in tech, and online training initiatives to reach workers in industries from 
manufacturing to healthcare. Investing in human capital is as important as investing in R&D – a 
workforce fluent in using AI tools will amplify productivity rather than be replaced.
At the same time, we must acknowledge that AI will change the nature of many jobs. Recent 
analyses suggest that over 30% of U.S. workers could see at least half of their typical tasks 
impacted or automated by generative AI in the coming years (31). Unlike past automation which 
mainly affected routine factory jobs, this AI wave could disrupt white-collar and “nonroutine” 
roles – from office administration to legal drafting (32). This doesn’t automatically imply mass 
unemployment; rather, many jobs will evolve, with AI handling certain tasks and employees 
focusing on those requiring human judgment, creativity, or interpersonal skills. Still, there will 
be displacement in some areas, and new job roles will emerge in others (such as AI model 
trainers, explainability experts, or maintenance of AI systems). To manage this transition, 
proactive policies are needed. The government can strengthen safety nets and adjustment 
assistance for workers who do lose jobs to AI – for example, extending unemployment benefits 
tied to retraining programs, or providing wage insurance that cushions income loss during a 
career shift. Mobility and lifelong learning should be encouraged so that workers can 
continuously update their skills as job requirements change.
Moreover, preparing the economy means supporting sectors and communities to benefit from AI. 
Small businesses, for instance, could increase their competitiveness by adopting AI tools – but 
they need access to affordable AI solutions and training on how to use them. Public programs 
that provide grants or technical assistance for AI adoption in smaller firms (say, an AI extension 
service akin to agricultural extensions) could spread productivity gains more evenly. STEM 
education at the K-12 and college levels also requires an upgrade: integrating AI literacy, data 
science, and critical thinking about technology into curricula will ensure the next generation is 
ready for AI-driven workplaces. Universities and vocational schools should expand programs in 
AI, machine learning, and related fields, not just for developers but for domain experts who can 
apply AI in areas like medicine, law, or finance.
Finally, fostering new industries and entrepreneurship in AI will create jobs to offset those lost. 
The U.S. can provide innovation-friendly environments through startup incubators, R&D tax 
credits, and regional tech hubs (some of which are funded by recent legislation). By driving AI 


innovation across sectors – including entirely new fields we can’t yet imagine – the economy can 
generate roles that leverage uniquely human skills. Historically, technological revolutions (from 
the industrial age to the computer era) ultimately created more jobs than they destroyed, though 
not without painful adjustments. With smart planning, the U.S. can maximize AI’s upside for 
economic growth while easing the workforce through the transition. In short, human capital 
investment, education reform, and supportive labor policies are critical to ensure American 
workers thrive in the AI era rather than being left behind (33). This will also help maintain public 
support for the advancement of AI, as people see tangible benefits in their work and daily lives.
AI and The Preservation of Human Rights
While AI has the potential to drive progress and innovation, its development and deployment 
also pose serious risks to fundamental human rights, particularly freedom of expression, freedom 
of movement, and freedom of assembly. The increasing use of AI in surveillance, content 
moderation, predictive policing, and social control has sparked debates on its potential to stifle 
democracy, suppress dissent, and infringe on personal liberties. To ensure AI serves humanity 
rather than oppresses it, a comprehensive AI action plan must be developed, one that safeguards 
these fundamental freedoms while maintaining technological progress (34).
Freedom of Expression and AI: Protecting the Right 
to Speak and Be Heard
Freedom of expression is a cornerstone of democratic societies, enabling individuals to voice 
opinions, exchange ideas, and hold those in power accountable. However, AI-powered 
technologies such as automated content moderation, misinformation detection, and algorithm-
driven censorship have raised concerns about the potential suppression of free speech.
Social media platforms, news aggregators, and online forums increasingly rely on AI algorithms 
to filter, rank, and remove content. While these systems are designed to combat hate speech, 
misinformation, and illegal content, they often lack the nuance to distinguish between harmful 
speech and legitimate expression. Automated moderation tools can disproportionately silence 
marginalized voices, misinterpret satire, and remove politically sensitive content under vague or 
biased policies. In authoritarian regimes, AI-driven censorship has been weaponized to suppress 
dissent, limit press freedom, and manipulate public discourse .(35)
To protect freedom of expression, an AI action plan must include:1)Transparent content 
moderation policies that are clearly communicated to users and subject to public scrutiny.2) 
Human oversight in AI-driven censorship to prevent wrongful suppression of speech.3) Appeal 
mechanisms for content removal that allow users to challenge AI decisions. 4) Protection of 
whistleblowers and independent journalists from AI-enabled surveillance and retaliation.


By ensuring that AI respects the right to express opinions freely, societies can maintain open and 
democratic discourse while minimizing the harms of misinformation and online abuse.
Freedom of Movement and AI: Preventing Unjust 
Surveillance and Control
Freedom of movement, the ability to travel and move without unjust restrictions, is a 
fundamental right enshrined in international human rights law. However, AI-powered 
surveillance, facial recognition, and predictive policing have introduced significant threats to this 
freedom.
Governments and private entities increasingly use AI-driven surveillance tools to monitor public 
spaces, track individuals, and control migration. While these technologies can enhance security, 
they also raise concerns about mass surveillance, racial profiling, and the restriction of mobility 
based on algorithmic assessments. In some regions, AI is used to create digital border control 
systems, using machine learning to determine who can enter a country based on opaque and 
often discriminatory criteria. Additionally, smart cities and AI-powered transportation systems 
have been criticized for disproportionately tracking and restricting certain populations, 
particularly minorities and activists.
To ensure AI does not infringe on freedom of movement, an AI action plan should include:1) 
Strict regulations on AI-powered surveillance to prevent excessive monitoring and tracking.2) 
Bans or limitations on real-time facial recognition in public spaces to protect individuals' 
privacy.3) Transparent use of AI in border control and immigration decisions to prevent 
discrimination and ensure due process.4) Oversight mechanisms for predictive policing systems 
to prevent racial profiling and unjust travel restrictions.
By safeguarding freedom of movement, societies can ensure that AI does not become a tool of 
control and discrimination but rather supports secure and equitable mobility.
Freedom of Assembly and AI: Defending the Right to 
Protest and Organize
Freedom of assembly—the right to gather, protest, and collectively express opinions—is 
fundamental to democratic participation. However, AI-driven surveillance, social media 
monitoring, and predictive analytics have increasingly been used to suppress activism and 
dissent.
Governments and law enforcement agencies worldwide have deployed AI tools to track protest 
organizers, monitor online discussions, and predict demonstrations before they occur. AI-
powered drones, facial recognition cameras, and social media scraping tools allow authorities to 
identify individuals attending protests, leading to preemptive arrests or retaliation (36). In some 


cases, AI-driven sentiment analysis has been used to label certain groups as "threats" simply 
based on their political beliefs or affiliations.
To prevent AI from undermining the right to peaceful assembly, an AI action plan must 
include:1) Restrictions on AI surveillance during protests to prevent the targeting of 
demonstrators.2) Legal protections against AI-driven profiling of activists and political groups.3) 
Bans on AI-powered predictive policing targeting protest movements. 4) Transparency in 
government use of AI for public security to prevent the misuse of technology against peaceful 
demonstrators.
By ensuring AI does not erode the right to assemble, societies can protect civic engagement and 
the democratic process, preventing technology from becoming a tool of oppression.
A Human-Centered AI Future: Balancing Innovation 
and Rights
While AI offers many advantages, its development and deployment must be carefully managed 
to ensure that fundamental rights are not compromised. The risks associated with AI-driven 
censorship, surveillance, and social control are real, and without proper safeguards, they can 
threaten democracy and personal freedoms.
As AI becomes increasingly embedded in society, its impact on fundamental freedoms cannot be 
ignored. While AI has the potential to improve communication, security, and mobility, it also 
presents significant risks to freedom of expression, freedom of movement, and freedom of 
assembly. If left unchecked, AI could become a tool for censorship, mass surveillance, and social 
control, restricting individuals’ ability to speak, travel, and protest without fear.
To prevent this, a comprehensive AI action plan is essential—one that establishes clear ethical 
guidelines, legal protections, and oversight mechanisms to ensure that AI serves humanity rather 
than oppresses it. Transparency, accountability, and human oversight must be at the core of AI 
governance, ensuring that technology aligns with democratic principles and human rights (37).
Ultimately, AI should be a force for empowerment, not restriction. By taking proactive measures 
to safeguard fundamental freedoms, societies can harness AI’s potential while ensuring that 
technology remains a tool for progress rather than oppression. As AI continues to evolve, 
governments, businesses, and civil society must work together to create policies that uphold 
justice, protect human dignity, and preserve the fundamental rights that define free and 
democratic societies.


To balance technological innovation with human rights, an AI action plan should be built on the 
principles of transparency, accountability, and human oversight. It should prioritize the 
protection of free speech, mobility, and assembly while fostering the ethical use of AI. 
International cooperation and regulatory frameworks must also play a crucial role in establishing 
global AI governance standards that prevent the misuse of AI by governments and corporations.
Ultimately, AI should be a force for empowerment, not control. By ensuring that AI serves 
humanity rather than restricting its freedoms, societies can build a future where technology 
enhances, rather than undermines, the principles of democracy, justice, and human dignity.
Geopolitical Implications and Global Leadership
AI is not just a technology – it’s a strategic asset that will influence the global balance of power. 
The U.S. faces stiff competition from other AI powerhouses, particularly China, and also must 
coordinate with allies like the EU who are setting their own AI agendas. Navigating this 
landscape requires a deft geopolitical strategy: winning the technological race while promoting 
responsible AI use worldwide.
Competition with China is a defining feature of the AI era. China has declared its ambition to be 
the world leader in AI by 2030 and is investing heavily to get there – from massive government 
funding for research to national programs nurturing AI talent. In some metrics, China is already 
ahead (for instance, it leads in the number of AI research publications and has a large domestic 
AI market). A recent analysis cautioned that China may hold a lead over the U.S. in certain AI 
activities (38).,galvanizing a U.S. response. The U.S. approach to this rivalry has been twofold: 
out-innovate and out-invest in key AI areas, and restrict China’s access to the most critical AI-
enabling technologies. On the innovation front, maintaining U.S. leadership means continuing 
the R&D investments and talent attraction discussed earlier, so the best minds and companies do 
their work in America. On the defensive front, the U.S. has implemented export controls on 
advanced semiconductors and AI chips to slow China’s progress in cutting-edge AI (given that 
high-end GPUs are crucial for training AI models). It’s a delicate balance – these controls protect 
national security, but the U.S. must also avoid isolating itself or overly fragmenting the global 
tech ecosystem.
The U.S. can leverage its strengths against China by emphasizing qualities that make its AI 
offerings more attractive globally. American AI products and platforms are generally seen as 
more trustworthy  than Chinese counterparts by many countries, partly due to concerns over 
authoritarian misuse of tech by Beijing  (39). The U.S. should capitalize on this trust advantage: 
for example, by providing AI solutions (in healthcare, education, agriculture, etc.) to developing 
regions, the U.S. and its companies can undercut China’s influence and ensure international AI 
infrastructure isn’t dominated by one regime’s standards. Microsoft’s partnership to build AI 
centers in Africa and an international fund for AI infrastructure is one private-sector example of 
extending U.S. AI leadership outward  (40). U.S. foreign assistance and development finance 


could similarly support adoption of American-led AI in partner countries, emphasizing 
transparency, privacy, and security. As one tech leader put it, the U.S. is “in a strong position to 
win the essential race with China by advancing international adoption of American AI” and 
leveraging its unmatched private sector investments  (41).While competing, the U.S. also needs to 
manage risks of an AI arms race. Unchecked rivalry could spur rapid deployment of unsafe AI or 
even military AI escalation. Thus, dialogue with China is important to set some guardrails  – 
much like nuclear arms control during the Cold War. The U.S. and China (along with other 
powers) might find mutual interest in agreements on AI safety in military systems or norms 
against using AI for destabilizing cyberattacks, etc. Keeping channels open (through academic 
collaborations or joint workshops on AI safety) could help reduce misperceptions. However, 
given the broader strategic tensions, the U.S. will likely rely more on its network of allies to 
promote its vision of AI governance.
In contrast to the competitive stance with China, the European Union is a partner in values, 
though it presents a different challenge: the EU is asserting leadership in AI regulation. The EU’s 
upcoming AI Act is slated to be the world’s first comprehensive AI law, and it reflects a more 
precautionary approach. This could impact U.S. companies operating in Europe and potentially 
set de facto global standards (the way Europe’s GDPR did for privacy). The U.S. must 
diplomatically engage with the EU to find common ground so that innovation isn’t stifled, and 
transatlantic digital trade remains open. Through forums like the U.S.-EU Trade Council, 
American and European officials are already trying to align AI governance approaches. They 
won’t agree on everything – the EU favors stricter rules, whereas the U.S. often prefers 
innovation-friendly guidelines  (42). – but a degree of coordination is crucial. For example, the 
two sides have discussed a voluntary AI Code of Conduct  for industry as an interim step until 
regulation comes. The goal should be to minimize conflicting requirements and emphasize 
shared principles (like transparency, accountability, and the protection of fundamental rights). By 
partnering with the EU and other democracies on AI standards, the U.S. strengthens a coalition 
of responsible AI developers that can present an alternative to authoritarian tech governance.
Lastly, promoting responsible AI globally means leading by example. The U.S. should 
demonstrate that AI can be developed in line with democratic values and used to benefit society. 
This involves continuing to champion initiatives like using AI for good (e.g. AI for climate 
resilience, disaster response, improving healthcare in poorer countries). When the U.S. deploys 
AI tools abroad or assists other nations, it should adhere to high standards of ethics and respect 
for local laws, setting a positive precedent. Additionally, U.S. leadership in global bodies (like 
urging the UN to take on AI issues or creating an international panel for AI akin to the IPCC for 
climate) can help ensure a rules-based order for AI. The State Department has explicitly tied AI 
advancement to democratic principles, arguing that the U.S. and allies can further scientific 
progress and “promote democracy and human rights” by shaping AI norms  (43).In conclusion, 
the United States can navigate the geopolitics of AI by staying true to its core values while 
pushing the frontiers of innovation. By fostering innovation at home and with allies, establishing 


sensible oversight, and engaging abroad with both competitors and friends, the U.S. can remain 
the global leader in AI. Striking this balance is critical – poorly crafted policies or a failure to 
cooperate internationally could undermine U.S. advantages. But with a forward-looking strategy, 
the U.S. can “remain at the forefront of the global AI race while ensuring accountability and 
ethical development .”(44).In doing so, America will not only out-compete rivals, but also steer 
the evolution of AI in a direction that is safe, equitable, and beneficial for the world.
Sources:
1-US Congress Joint Economic Committee- September 2023  “Maintaining American
Leadership in Artificial Intelligence Through Public Investment and Workforce
Development”
https://www.jec.senate.gov/public/_cache/files/8b10c63b-d93c-45c5-8f26-
900fb23154d1/maintaining-american-leadership-in-artificial-intelligence.pdf
2-US Congress Joint Economic Committee- September 2023  “Maintaining American
Leadership in Artificial Intelligence Through Public Investment and Workforce
Development”
https://www.jec.senate.gov/public/_cache/files/8b10c63b-d93c-45c5-8f26-
900fb23154d1/maintaining-american-leadership-in-artificial-intelligence.pdf
3-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
4-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
5-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
6-Boast- May 16,2024 “U.S. pitches AI R&D funding roadmap as business adoption
soars”
U.S. AI R&D Funding Roadmap as Adoption Soars - Boast
7-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues


8-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
9-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
10-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
11-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
12-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
13-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
14-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
15-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead   on
international AI governance”
             The US government should regulate AI if it wants to lead on international AI   governance
16- Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
17-A new institution for governing AI? Lessons from GPAI


          A new institution for governing AI? Lessons from GPAI
18-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
 The US government should regulate AI if it wants to lead on international AI governance
19- Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
 The US government should regulate AI if it wants to lead on international AI governance
20- Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
 The US government should regulate AI if it wants to lead on international AI governance
21- Partnership for Global Inclusivity on AI (PGIAI)
Advancing Sustainable Development through Safe, Secure, and Trustworthy AI - United  
States Department of State
22-United States and Eight Companies Launch the Partnership for Global Inclusivity on AI
United States and Eight Companies Launch the Partnership for Global Inclusivity on AI -  
United States Department of State
23-Ethical concerns mount as AI takes bigger decision-making role in more industries
United States and Eight Companies Launch the Partnership for Global Inclusivity on AI -  
United States Department of State
24- Ethical concerns mount as AI takes bigger decision-making role in more industries
United States and Eight Companies Launch the Partnership for Global Inclusivity on AI -  
United States Department of State


25-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
26-Brookings- May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
27-Brookings - May 22,2023 “The US government should regulate AI if it wants to lead on
international AI governance”
The US government should regulate AI if it wants to lead on international AI governance
28-Brookings- December 6, 2024 “ The global AI race: Will US innovation lead or lag?”
The global AI race: Will US innovation lead or lag?
29-DOD Adopts Ethical Principles for Artificial Intelligence
DOD Adopts Ethical Principles for Artificial Intelligence > U.S. Department of Defense >  
Release  
30-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
31-Brookings- October 10, 2024 “ Generative AI, the American worker, and the future of
work”
Generative AI, the American worker, and the future of work
32-Brookings- October 10, 2024 “ Generative AI, the American worker, and the future of
work”
Generative AI, the American worker, and the future of work


33-Brookings- October 10, 2024 “ Generative AI, the American worker, and the future of
work”
Generative AI, the American worker, and the future of work
34-Moss M.Jacques Feb 11, 2025 “Advocating for Global Ethical AI Governance”
 mossmjacques.com/newsletter
35-Moss M.Jacques Feb 11, 2025 “Advocating for Global Ethical AI Governance”
 mossmjacques.com/newsletter
36- Moss M.Jacques Feb 11, 2025 “Advocating for Global Ethical AI Governance”
 mossmjacques.com/newsletter
37- Moss M.Jacques Feb 11, 2025 “Advocating for Global Ethical AI Governance”
   mossmjacques.com/newsletter  
38-Brookings  March 26, 2024  -The evolution of artificial intelligence (AI) spending by the
U.S. government
The evolution of artificial intelligence (AI) spending by the U.S. government
39-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
40-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
41-Microsoft -January 2025 “The Golden Opportunity for American AI”
The Golden Opportunity for American AI - Microsoft On the Issues
42-CSIS.gov  June 6, 2023- The Path to Trustworthy AI: G7 Outcomes and Implications for
Global AI Governance


 The Path to Trustworthy AI: G7 Outcomes and Implications for Global AI Governance  
43-U.S Department of State -Partnership for Global Inclusivity on AI (PGIAI)
              Advancing Sustainable Development through Safe, Secure, and Trustworthy AI -  
44-Brookings December 6, 2024- The global AI race: Will US innovation lead or lag?
The global AI race: Will US innovation lead or lag?


