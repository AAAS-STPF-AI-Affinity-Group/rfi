3/13/2025 via FDM S 
Steven Zuber, 
I am writi ng in response to the White House’s Request for Information on the development 
of an Arti ﬁcial Intelligence Action Plan. As AI systems become increasingly capable, it is 
imperative that their development is guided by careful, deliberate planning  to ensure 
alignment with human values and long -term safety. The potential beneﬁts of AI are 
immense, but so are the risks. One of the most pressing concerns is the possibility of 
misaligned superintelligence —AI systems that, due to insufficient oversight or ﬂawed 
design, could act in ways that are dangerous to humanity. Researchers at institutions such as the Machine Intelligence Research Institute (MIRI) (intelligence.org), Center for AI Policy (CAIS) (safe.ai), and Control AI (controlai.com) have outlined scenarios in which advanced 
AI, if not properly controlled, could lead to catastrophic outcomes. A robust AI Action Plan 
must prioritize technical research into AI alignment, as well as policies that ensure AI systems remain interpretable and corrigibl e. Additionally, the economic impact of AI -driven 
automation must not be overlooked. Large-scale job displacement could lead to signiﬁcant economic instability and social unrest. While automation has historically created new 
types of employment, the speed at which AI is progressing may outpace our ability to 
adapt. Policymakers must explore strategies such as retraining programs, adjustments to 
labor laws, and, potentially, new economic models to support displaced workers. I urge the administration to approach AI development with a strong commitment to long -term safety 
and societal well -being. This means supporting rigorous research into AI alignment, 
creating regulatory frameworks that prevent reckless AI deployment, and preparing for the economic shifts t hat AI will bring. By taking these concerns seriously now, we can help 
ensure that AI remains a tool for human progress rather than an existential risk. Thank you for your attention to this critical issue. I appreciate your leadership in shaping a responsi ble 
AI future and your solicitation for thoughts from your fellow Americans. I'm sure I'm not 
alone when I say I welcome further discussion on these concerns. Sincerely, Steven Zuber  


