PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 88-3tai-uigv
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1280
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Paul DeStefano 
DeStefano  
General Comment
Re: AI Action Plan
Dear Office of Science and Technology Policy and Faisal D'Souza,
I have 15 years experience teaching undergraduate physics students, and m y research is focused on how to achieve better outcom es for
students through optim al learning techniques. In addition, I am  a m em ber of the PauseAI m ovem ent that opposes the developm ent of
super-hum an or sm arter-than-hum an AI until we are highly confident we can ensure it serves the interest of Am erican citizens. While I am
concerned about m any dim ensions of AI, I am  contacting you about a few key aspects of security: the risk to worker capabilities, the risk
to the dom estic consum er econom y, and the risks to national security.
As an educator, I care deeply about *how* m y students learn, not m erely what they learn. I've also written a lot of code, and I received
m y Certified Inform ation System s Security Professional certification in 2003. While m y colleagues are actively working to create best
practice for using AI to im prove student learning of physics and other sciences, this work and advancem ents in education will not prevent
AI developers from  building dangerous system s that are *treated* as m uch m ore reliable than they truly are. We know that AI capabilities
are over estim ated by experts, professionals, and lay people. Most people struggle to use AI safely, unable to detect "hallucinations",
errors, and lies presented as truth. Even these early LLMs are falsely viewed by the public as "neutral" agents with access to perfect
knowledge. This conception, alone, is dangerous, even for those who never interact with AI, them selves. Our work force need to be well
educated. AI m ay, but is not guaranteed, to im prove worker capabilities and productivity. AI is NOT a tool, like the com puter that
brought large productivity gains to workers in m any industries. AI is an agent, and workers and students interact with it in a com pletely
different way than they do with tools. No one knows how this will turn out.
While som e people are excited about new technology and prefer to support the cutting edge for no other reason that it is new and
exciting, our econom y relies on stable and sm ooth execution. Right now, the econom y is becom ing paralyzed by the anticipated disruption
of AI. Businesses need to know that, whatever they im agine is possible through AI, the policy of the U.S. toward AI will deliver robust
com petition, safety, security, and fairness. And consum ers need the sam e! The federal governm ent should not purchase AI tools that have
not been reviewed for safety and security by experts. To that end, it should work to establish an independent body that establishes
guidelines and requirem ents for the industry.
Finally, AI poses a serious threat to our national security. Maintaining global dom inance in artificial intelligence technology will be difficult,
and we should hedge our bets by earnestly participating in the global effort to govern AI technology. Experts have repeatedly expressed
genuine concern over the threat to all hum an life that we face with AI. Personally, I am  *not* afraid of this eventuality; I don't think this is
likely. But, this outcom e is so catastrophic that we m ust invest deeply in preventing it, no m atter how unlikely. This is an inherent risk for
this technology. We have to take it seriously. Does that investm ent m ean greatly increasing the current cost of AI, and therefore forgoing
future benefits of AI advancem ents? Yes. But that doesn't change the calculation.
Recom m endations
Many good ideas have been proposed to ensure AI is developed responsibly. Here are som e of m y favorites:


- We need an international body of experts to track and verify the AI capabilities, worldwide. Much like nuclear weapons, which are not
available to just anyone with the knowledge, powerful AI rem ains far beyond consum er access and control. The U.S. can benefit from
being a strong m em ber of such an effort.
- We need legislation that places the full burden of all types of cost on developers.
- Extrem ely strong whistleblower protections.
Sincerely,


