PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 11, 2025
Status: 
Tracking No. m 84-onse-vbdz
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1138
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Governm ent Agency Type:  Foreign
Governm ent Agency:  Noem a Research
General Comment
Please find our com m ent attached.
Attachments
Response to White House's RFI on AI Action


This document is approved for public dissemination. The document contains no business-proprietary or con ﬁdential 
information. Document contents may be reused by the government in developing the AI Action Plan and associated 
documents without attribution. 
Strengthen State Capacity to Wield AI as a 
Geopolitical Resour ce 
By Noema Research 
In this response, we articulate policy objectiv es that w e argue to be of strategic 
relevance to the US, and indeed to any global AI power that is determined to lead in 
the development of this remarkably powerful technology. This resource is structured as 
follows: 
●New Resource Emerging. In this section, we describe AI as one of many
geopolitically relevant resources, such as steel or energy.
●Strengthen State Capacity. In this section, we introduce two straightforward
policy objectives concerning this new resource.
●Leverage, Credibility, Security. In this section, we re ﬂect on the geopolitical
impacts of the suggested initiatives.
●Barriers Versus Setbacks. Finally, we advance an intuitive framing for weighing
the upsides and downsides of speciﬁc AI policies.
We conclude with pointers to further resources related to the arguments advanced in 
the rest of the document. 
New Resource Emerging 
An effective way of conceiving of AI development is as the creation of a qualitatively 
novel resource based on certain raw materials and manufacturing processes. Just as 
steel production requires iron ores and specialized furnaces, and energy generation 
demands fossil fuels and combustion equipment, AI development necessitates 
computational power and learning algorithms. Feed in larger quantities of raw 
materials and more efficient manufacturing processes, and you predictably obtain 
more "virtual labor" that can be used to extend what humans can achieve. 
Perhaps more than any other resource that has preceded it, AI can be applied in an 
incredibly wide range of contexts. The intellectual faculties of these virtual entities may 
be harnessed to augment the productivity of the human workforce, may be directed 1 


towards strengthening the cybersecurity of critical infrastructure, and may be recruited 
towards furthering the development of effective healthcare interventions. 
Naturally, the remarkable generality of this intellectual labor forged out of computing 
power and learning algorithms may also be applied in ways detrimental to national 
interests. These virtual capabilities may disrupt the labor market in ways that cause 
societal unrest, may enable foreign adversaries to identify vulnerabilities in domestic 
infrastructure, and may empower rogue actors to interfere with public health in 
increasingly sophisticated ways. 
Like steel, energy, and countless other resources being manufactured on an industrial 
scale, AI is a highly geopolitically relevant resource due to its dual-use nature. The 
unusual origin of this new asset — largely, the private sector — has led governments 
from around the world to scramble towards achieving adequate state capacity with 
varying degrees of success. However , we argue that bringing governments "in the loop" 
is a critical step for effectively wielding this emerging resource on the world stage, 
navigating domestic developments wisely, and enabling meaningful leadership in the 
development of this historical technology. 
Strengthen State Capacity 
T o enact this critical step, we suggest two policy objectives: ●Measure capability consumption domestically. In order to credibly and
effectively wield this technology to further national interests, governments need
to ﬁrst and foremost become aware of the quantity of these newly
manufactured resources. Governments may especially bene ﬁt from gaining
insight into types of virtual labor that are of high geopolitical relevance, such as
automated hacking or automated research, among others. Governments should
have knowledge of, for instance, how much autonomous hacking is being minted
domestically, and how much of this capability gets exported to foreign
adversaries. They may also beneﬁt from, for instance, being aware of the
consumption of economically valuable capabilities, in order to gain a deeper
understanding of the impacts on the labor market.
●Pursue associated domestic and international opportunities. With this
enhanced awareness of the synthesis of these resources domestically,
governments may beneﬁt from building capacity for actively investigating the
strategic opportunities enabled by this understanding. We hint at particular
directions in the following section, yet here stress the policy objective of building
the capacity to investigate such interventions in the ﬁrst place. This may be
easiest to achieve as part of existing organizations with expertise in related
2 


domains, such as relevant public bodies (e.g., US AISI), and think tanks with a 
history of navigating the game theory of emerging technologies to advance 
national interests (e.g., RAND ). 
Leverage, Credibility, Security 
As governments gain awareness of the quantity of these resources and actively pursue 
strategies informed by this understanding, we expect the following beneﬁts to 
materialize: 
●Leverage. This awareness may help highlight the scope and scale of this virtual
workforce as a resource to be used in bargaining across the world stage. As
nations boast extensive natural resources, advanced military equipment, or
thriving consumer economies, so may the intellectual horsepower of these
virtual entities constitute an additional negotiation token to be used in securing
strategic deals. When composed with established policy practices, such as for
instance through tariffs on imported quantities of virtual labor , these resources
may provide a net increase in the range of available foreign policy actions.●Credibility. Demonstrating awareness of domestic AI development through
measures of capability consumption may help boost credibility both
internationally, as well as among citizens impacted by the synthesis of this
resource. Deploying mechanisms for proving the correctness and validity of
these measurements can further provide the foundation of credibility needed to
pursue landmark bilateral or multilateral initiatives on AI, analogous to howmany nuclear security agreements have been predicated on literal warhead
counts or tons of dual-use materials.
●Security. Similar to managing the proliferation of chemical precursors or
radioactive materials for national security reasons, monitoring the quantities of
dual-use AI capabilities being consumed by domestic organizations may help
governments effectively address emerging threats. Beyond the domestic setting,
surgical international initiatives may help extend existing non-proliferation
efforts in the domain of dual-use AI capabilities, such as autonomous hacking.Barriers Versus Setbacks 
This extensive optionality may be achievable at little cost to companies developing AI. 
Consider that computational resources used in AI development are estimated to 
increase by ~5x per year, and the learning algorithms are estimated to become ~3x 
more efficient in the same period, for a total increase of ~15x per year in the amount of 
virtual labor that can effectively be "minted." Assume that metering capability 
3 


consumption time incurs a 5% overhead relative to the baseline computational power 
of serving frontier models. This would be equivalent to a one-time setback of less than 
a week for the development of AI capabilities. That said, AI companies based in the US 
are estimated to be much farther ahead, potentially making it palatable to invest in the 
powerful geopolitical instruments detailed above, in order to be able to collect their 
future dividends. 
T o conclude, strengthening state capacity in AI by equipping governments with this 
enhanced awareness would allow them to wield these emerging resources more 
effectively in their dealings. By pursuing these policy objectives, governments can 
maintain leadership and ensure these powerful technologies serve national interests. 
We lay out a more concrete vision for how these remote measurement capabilities may 
be developed and applied in a dedicated resource on "virtual diplomacy." Noema Research is an R&D lab working on techniques for remotely measuring AI 
capabilities with a view towards averting Great Power con ﬂict. Based in the EU, we 
work with frontier labs and institutions from around the world to understand and 
manage the capability surface of AI systems. T o enshrine this mission, leadership has 
formally pledged to donate 100% of proceeds on liquidity to charity. 
4 


1201 Wilson Blvd, Floor 27 
Arlington, V A 22209 
March 15, 2025 
Trustible Comments on the Request for Information (RFI) on the Development of an Arti ﬁcial 
Intelligence (AI) Action Plan 
To the O ﬃce of Science and Technology Policy:  
On behalf of Trustible, a leading technology company based in Virginia that helps build trust through AI 
governance software, we appreciate the opportunity to submit comments in response to the O ﬃce of 
Science and Technology Policy’s RFI on developing an AI Action Plan.1  
Trustible provides a Software as a Service platform that leverages AI to help large and medium size 
organizations implement internal processes to manage and oversee their use of AI. Trustible supports the 
Administration's goal to sustain and enhance America’s global AI competitiveness and innovation. In 
order for the U.S. to maintain and build upon its AI leadership, we should encourage an AI ecosystem that 
leverages our world-class technology infrastructure and build trust amongst innovative AI tools. 
Innovation and trust ﬂourish when there are common sense, industry-driven standards available for 
technology companies to adopt at scale. 
I. The Second Trump Administration Can Continue Its Work from the First Trump
Administration by Promoting Common Sense, Pragmatic Standards.
We encourage the Trump Administration to convene pragmatic stakeholders from across industry, 
academia, and other faucets of civil society to create technical standards that build trust in AI 
technologies. Establishing a practical set of AI standards helps grow the AI ecosystem and economy 
because companies that adopt those standards can demonstrate a basic level of reliability for their AI tools 
– enhancing the marketability and procurement of these systems. As part of our work, we gain valuable
insights from the private sector about its development and adoption of AI tools. We consistently hear from
companies that they want certain assurances about AI technology before they adopt it.President Trump understood the importance that standards have in building trust and grow ing economic 
opportunity when he signed the Executive Order on Maintaining American Leadership in AI in February 
2019. We encourage the Administration to build upon the success it achieved with regards to issuing 
technical standards. The current standards landscape is more saturated with guidance for foundational 
model creators than companies that integrate or deploy these models for their own products and services. 
However, foundation model creators are vastly outnumbered by organizations that are not developing their 
own models. While these organizations may have strong subject matter expertise, they may lack the 
requisite talent to demonstrate trustworthiness in their systems that is found in frontier model labs. 1 Our comments are approved for public dissemination and contain no business-proprietary or con ﬁdential 
information. We understand that the contents of these comments may be reused by the government in developing the 
AI Action Plan and associated documents without attribution. 
1 


Therefore, standards can be extremely valuable for non-frontier model companies because it provides 
them with a baseline of scalable best practices. 
II. The Trump Administration Can Learn from the Cybersecurity Ecosystem to Develop
Scalable AI Standards.
The Administration should reference the success with cybersecurity standards as a roadmap for 
continuing its work on developing AI standards. Standards, such as the Service Organization Control 2 
(SOC-2), Payment Card Industry Data Security Standard, and HITRUST, set attainable goals for 
companies to achieve while also helping them set a strong foundation for cybersecurity practices. These 
standards are particularly helpful for small and medium enterprises (SMEs) because they are market 
driven eﬀorts that lower entry barriers for companies who may otherwise not have been able to 
demonstrate a baseline level of cybersecurity practices for their customers. In fact, SOC-2’s scalability 
helped us build trust with potential and existing customers. An auditable standard tailored towards AI can 
make recommendations for companies, particularly SMEs, that deploy AI systems but not develop them. 
We should avoid the pitfalls of critics who assert that standards simply serve as “check the box exercise,” 
when in practice these standards assist smaller enterprises like ourselves with understanding the types of 
cybersecurity controls to implement. Instead, the Administration should view AI standards as a means to 
help entrepreneurs and new SMEs incorporate best practices from rational industry AI experts. III. The Trump Administration Should Lead on AI Standards to Promote American Values in
the AI Ecosystem.
In the absence of continued U.S. leadership on AI standards, there is a heightened risk for other countries 
and international bodies to dictate heavy-handed protocols that are the anthesis of U.S. freedom, 
competitiveness, and innovation. There are many emerging standards that either impose unattainable 
requirements for SMEs or prevent operationalization due to overbroad and convoluted language. As a 
fast-growing startup company, we understand the unique challenges that entrepreneurs and SMEs face 
when trying to demonstrate trust in their products to prospective customers. The Administration can help 
avoid these barriers by encouraging the development of guidance or standards that are scalable for early 
AI startups or tools to increase the market adoption of these technologies. Trustible appreciates and supports the Trump Administration's e ﬀorts to meaningfully engage 
stakeholders on how best to position the U.S. as a global leader in AI. Being the leader in AI standards 
will help achieve that goal, while also unlocking America’s technological innovation and economic 
prosperity. Trustible looks forward to building a meaningful partnership with the Administration as it 
continues to pursue a robust AI policy agenda.   
Respectfully, 
Gerald Kierce   Andrew Gamino-Cheong 
Co-Founder and CEO  Co-Founder and CTO 
Trustible  Trustible 
2 


