PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-1ngq-d3v7
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7615
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Owen Biesel  
Email: 
General Comment
This docum ent is approved for public dissem ination. The docum ent contains no business-proprietary or confidential inform ation.
Docum ent contents m ay be reused by the governm ent in developing the AI Action Plan and associated docum ents without attribution.
I am  a m athem atician, university professor, and U.S. citizen. I absolutely object to the idea that the U.S. should rem ove barriers to
"sustaining and enhancing Am erica's AI dom inance." The U.S. has an opportunity to im prove quality of life for its citizens by tightening
regulations on AI, not by loosening them . We need stricter controls around energy usage, training data selection, m odel transparency, and
consum er pricing m odels.
In looking to the future of our nation's relationship with AI, one of the biggest factors we should be considering is how m uch it is
worsening our im pact on clim ate change. Training and running larger and larger m odels consum es vast quantities of energy -- so vast, that
AI datacenters are bidding up the cost of renewable energy, m aking it less affordable for Am erican households and leading coal and other
fossil fuel plants to stay open past their originally scheduled shutdowns. Restrictions on energy usage per user request (including training
costs am ortized over the period between m odel updates) would help ensure that U.S. AI com panies don't m ake needlessly energy-
inefficient m odels with hidden environm ental costs for Am erican people.
Another area where lack of regulation is currently ham pering AI's progress is in the lack of transparency around data sets. There is no
reliable benchm ark to com pare m odel perform ance on various tasks, because the overwhelm ing m ajority of AI products have no reason
to disclose their training sets. We would have a m uch better sense of which m odels are true im provem ents, and which m ethods yield
better updates, if we were able to com pare m odels while sure that they were not trained on the question-answer pairs that we are also
using to evaluate them . (This is a fundam ental principle of m achine learning: that the data sets used to train, fine-tune, and ultim ately test the
perform ance of com puter m odels m ust be kept separate or the m odels will underperform  in new situations. It is also a principle that AI
com panies have no interest in following, as secretly testing on their training data inflates their test scores.) Being m ore open about training
sets would also encourage AI com panies to use sm aller, higher-quality data sets, rather than using too-broad training sets and then having
to hope that the lower-quality outputs can be (expensively) fine-tuned away, with no guarantees.
Generative AI com panies would also better benefit the U.S. by being forced to have their outputs point to the original sources that m ost
contributed to them . This is a m ajor technical difficulty for current m odels: they are prim arily trained on hum an creative work that is then
"forgotten" except in how they update the m odel weights. (Large language m odels only retain on the order of a single bit of inform ation per
sam ple text, but only on average: m any sim ilar texts m ay m ake no difference at all to the m odel, but a highly unique passage m ay be
retained alm ost word-for-word and appear in output as if it is generated on the fly.) However, if the U.S. develops AI m odels that can
reliably point users toward the original inform ation that inform s their output, it would be beneficial in two ways: first, users would be better
able to evaluate the context and trustworthiness of the inform ation; and second, to avoid "m odel collapse," updates to AI m odels depend
on the continued existence of hum an creative work that serves as training data, and pointing back to that original hum an work helps to
show the im portance of continuing to em ploy hum an creators.
We also need to step up enforcem ent of regulation around AI corporations' predatory pricing activities. OpenAI loses billions of dollars
on ChatGPT every year, even as it advertises that its productivity gains will save em ployers m oney (presum ably by laying off their staff or
reducing wages for less-skilled work). But the only way these facts can be reconciled is if OpenAI plans to dram atically raise prices after


subscribing com panies no longer have access to the skilled labor they have let go. The result will be m ore expensive products for
consum ers with reduced wages: not a recipe for Am erican flourishing. 
AI spokespeople will tell you that they need regulations rem oved in order to allow for innovation and progress. In fact, regulations are not
im peding progress; they m ake it possible, and m ore regulation would let Am erica lead the way on the world AI stage.


