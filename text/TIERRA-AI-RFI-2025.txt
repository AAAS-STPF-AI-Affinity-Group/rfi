March 15, 2025 
Faisal D’Souza 
Networking and Information Technology Research and Development (NITRD) 
National Coordination Office (NCO), National Science Foundation 
2415 Eisenhower Avenue 
Alexandria, VA 22314 
Re: AI Action Plan  
Dear Mr. Faisal D’Souza, 
The Trust, Innovation, and Ethics Research for Responsible AI (TIERRA), at the 
University of Michigan Medical School is a program dedicated  to promoting policies and 
best practices on the responsible development and application of artificial intelligence in 
healthcare. Utilizing knowledge and expertise from academia, industry, and the public, 
TIERRA leads research at the intersections of public trust, health information 
technologies, and healthcare systems. We are writing this letter to share our policy 
ideas regarding the future of AI in the U.S. healthcare system based on the research 
that we have conducted around AI use in healthcare both locally and nationally. 
Specifically, we recommend the new AI Action Plan: 
1.Ensure privacy and security of data and communicate these measures to
patients
AI tools in healthcare access and process sensitive patient data with varying levels of 
human oversight. Our nationally representative survey on perceptions of AI in 
healthcare shows that privacy concerns  reduce trust and perceived health benefits from 
AI tools.1 Additionally, preliminary findings from our recent public deliberations 
representing participants from 30 Michigan counties identified both privacy and data 
security as key concerns regarding the use of AI tools in healthcare. Protecting patient 
data privacy is crucial to ensuring patient safety and maintaining trust in healthcare 
providers and health systems. The AI Action Plan should require federal agencies to 
enforce strict data governance standards throughout development and application of AI, 
particularly when patients and patient data are involved. Additionally, the AI Action Plan 
should advise federal agencies like the U.S. Department of Health and Human Services 
(HHS) to develop guidelines to assist healthcare practitioners on proper patient 
disclosures and informed consent models when using AI tools in clinical settings. These 


guidelines can assist health systems develop and implement protocols that protect and 
preserve patient autonomy as AI tools become more integrated in healthcare delivery . 
2.Establish technical and safety standards for AI tools, and especially for
Software as a Medical Device
Establishing national AI safety and performance benchmarks is crucial for standardizing 
AI applications in healthcare. The AI Action Plan should advise federal  agencies like the 
Food and Drug Administration (FDA) to develop benchmarks that provide clear 
guidelines for all health AI developers and companies regarding model training, 
validation, and real-world implementation to ensure consistency across healthcare 
systems. These should apply to tools that can currently be classified as Software as a 
Medical Device (SaMD), as well as other applications that fall outside this purview. The 
AI Action Plan should also advise federal agencies to develop guidelines like the FDA 
that promote system trust measures when evaluating AI models that are intended to be 
or are used in healthcare settings.  
3.Incentivize transparency, explainability, and assurance to ensure
trustworthy AI
As health systems adopt AI tools in new and potentially high-risk ways, black-box AI 
models impose ethical uncertainties in clinical-decision making  and can negatively 
influence patient trust in their provider or their therapeutic recommendations. Policies 
should incentivize transparency in AI development, ensuring that models provide 
interpretable and clinically meaningful outputs while also balancing ethical 
considerations such as ensuring that the health AI tool does not pose a risk or harm to 
subpopulations. In addition, the AI Action Plan should advise the FDA and HHS to track 
the use of AI tools in healthcare settings and examine its effectiveness in improving not 
only inefficiencies in healthcare delivery but also against patient health outcomes. 
The integration of artificial intelligence in healthcare delivery presents significant 
opportunities and challenges for health systems, providers and their patients. Artificial 
intelligence has the potential  to help providers and clinical researchers unlock 
healthcare innovations that can effectively improve patient and population health 
outcomes. However, our research shows that public trust in health systems to use AI 
responsibly and to ensure that AI tools would not cause harm to them is low.2 Trust is a 
foundational element to successful patient-provider relationships, and trust in the 
healthcare system has been demonstrated as a predictor of patient engagement.3 
Irresponsible use of AI in healthcare can sow mistrust in providers and health systems 
and potentially result in negative patient and health outcomes.  


At a time when trust in health institutions is at a decline, ensuring that policies promote 
patient-centered care such as attention to patient safety, autonomy, and access to care 
is at the core of the AI Action Plan and is essential to AI’s responsible  deployment in 
healthcare as well as sustainable growth and continued innovation. 
A clear regulatory framework is essential to ensuring AI applications in healthcare align 
with patient-centered care while encouraging innovation. By prioritizing  privacy, 
standards, and explainability, the AI Action Plan can promote responsible AI integration 
and improve population health outcomes in the United States. 
We appreciate your consideration of our recommendations and look forward to the 
development of the AI Action Plan. 
Sincerely, 
Dr. Jodyn Platt, PhD, MPH 
Director | Trust, Innovation, and Ethics Research for Responsible AI 
TIERRA | University of Michigan Medicine 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by 
the government  in developing the AI Action Plan and associated documents without 
attribution. 
References 
1.Nong P and Platt J. Patient’s trust in health systems to use artificial intelligence.
JAMA Network Open. 2025;8(2):e2460628.
2.Nong P and Platt J. 2025.
3.Platt J, Nong P, Smiddy R, Hamasha R, Carmona Clavijo G, Richardson J, and
Kardia SLR. Public Comfort with the use of ChatGPT and expectations for
healthcare. JAMIA. 2024; 1976-1982. https://doi.org/10.1093/jamia/ocae164. 
 Verified by signNow
35607124f6534727a6b403/14/2025 21:14:17 UTC


