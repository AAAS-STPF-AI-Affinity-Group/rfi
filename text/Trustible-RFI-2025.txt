1201 Wilson Blvd, Floor 27 
Arlington, V A 22209 
March 15, 2025 
Trustible Comments on the Request for Information (RFI) on the Development of an Arti ﬁcial 
Intelligence (AI) Action Plan 
To the O ﬃce of Science and Technology Policy: 
On behalf of Trustible, a leading technology company based in Virginia that helps build trust through AI 
governance software, we appreciate the opportunity to submit comments in response to the O ﬃce of 
Science and Technology Policy’s RFI on developing an AI Action Plan.1  
Trustible provides a Software as a Service platform that leverages AI to help large and medium size 
organizations implement internal processes to manage and oversee their use of AI. Trustible supports the 
Administration's goal to sustain and enhance America’s global AI competitiveness and innovation. In 
order for the U.S. to maintain and build upon its AI leadership, we should encourage an AI ecosystem that 
leverages our world-class technology infrastructure and build trust amongst innovative AI tools. 
Innovation and trust ﬂourish when there are common sense, industry-driven standards available for 
technology companies to adopt at scale. 
I. The Second Trump Administration Can Continue Its Work from the First Trump
Administration by Promoting Common Sense, Pragmatic Standards.
We encourage the Trump Administration to convene pragmatic stakeholders from across industry, 
academia, and other faucets of civil society to create technical standards that build trust in AI 
technologies. Establishing a practical set of AI standards helps grow the AI ecosystem and economy 
because companies that adopt those standards can demonstrate a basic level of reliability for their AI tools 
– enhancing the marketability and procurement of these systems. As part of our work, we gain valuable
insights from the private sector about its development and adoption of AI tools. We consistently hear from
companies that they want certain assurances about AI technology before they adopt it.President Trump understood the importance that standards have in building trust and growing economic 
opportunity when he signed the Executive Order on Maintaining American Leadership in AI in February 
2019. We encourage the Administration to build upon the success it achieved with regards to issuing 
technical standards. The current standards landscape is more saturated with guidance for foundational 
model creators than companies that integrate or deploy these models for their own products and services. 
However, foundation model creators are vastly outnumbered by organizations that are not developing their 
own models. While these organizations may have strong subject matter expertise, they may lack the 
requisite talent to demonstrate trustworthiness in their systems that is found in frontier model labs. 1 Our comments are approved for public dissemination and contain no business-proprietary or con ﬁdential 
information. We understand that the contents of these comments may be reused by the government in developing the 
AI Action Plan and associated documents without attribution. 
1 


Therefore, standards can be extremely valuable for non-frontier model companies because it provides 
them with a baseline of scalable best practices. 
II. The Trump Administration Can Learn from the Cybersecurity Ecosystem to Develop
Scalable AI Standards.
The Administration should reference the success with cybersecurity standards as a roadmap for 
continuing its work on developing AI standards. Standards, such as the Service Organization Control 2 
(SOC-2), Payment Card Industry Data Security Standard, and HITRUST, set attainable goals for 
companies to achieve while also helping them set a strong foundation for cybersecurity practices. These 
standards are particularly helpful for small and medium enterprises (SMEs) because they are market 
driven eﬀorts that lower entry barriers for companies who may otherwise not have been able to 
demonstrate a baseline level of cybersecurity practices for their customers. In fact, SOC-2’s scalability 
helped us build trust with potential and existing customers. An auditable standard tailored towards AI can 
make recommendations for companies, particularly SMEs, that deploy AI systems but not develop them. 
We should avoid the pitfalls of critics who assert that standards simply serve as “check the box exercise,” 
when in practice these standards assist smaller enterprises like ourselves with understanding the types of 
cybersecurity controls to implement. Instead, the Administration should view AI standards as a means to 
help entrepreneurs and new SMEs incorporate best practices from rational industry AI experts. III. The Trump Administration Should Lead on AI Standards to Promote American Values in
the AI Ecosystem.
In the absence of continued U.S. leadership on AI standards, there is a heightened risk for other countries 
and international bodies to dictate heavy-handed protocols that are the anthesis of U.S. freedom, 
competitiveness, and innovation. There are many emerging standards that either impose unattainable 
requirements for SMEs or prevent operationalization due to overbroad and convoluted language. As a 
fast-growing startup company, we understand the unique challenges that entrepreneurs and SMEs face 
when trying to demonstrate trust in their products to prospective customers. The Administration can help 
avoid these barriers by encouraging the development of guidance or standards that are scalable for early 
AI startups or tools to increase the market adoption of these technologies. Trustible appreciates and supports the Trump Administration's e ﬀorts to meaningfully engage 
stakeholders on how best to position the U.S. as a global leader in AI. Being the leader in AI standards 
will help achieve that goal, while also unlocking America’s technological innovation and economic 
prosperity. Trustible looks forward to building a meaningful partnership with the Administration as it 
continues to pursue a robust AI policy agenda.   
Respectfully, 
Gerald Kierce   Andrew Gamino-Cheong 
Co-Founder and CEO  Co-Founder and CTO 
Trustible Trustible 
2 


