PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-jb6h-2xpr
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-2271
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Kudzu Technologies, Inc.
General Comment
Public Com m ent on Artificial Intelligence Action Plan
Subm itted to: Networking and Inform ation Technology Research and Developm ent (NITRD) National Coordination Office (NCO),
National Science Foundation
Date: March 15, 2025
To Whom  It May Concern,
Am erica faces a pivotal m om ent in Artificial Intelligence. With sm art policies Am erica will lead in AI while continuing to uphold free
m arkets, fair com petition, and strong national security.
The AI Action Plan is a key opportunity to drive innovation by elim inating unnecessary governm ent constraints and enhancing U.S.
leadership. Policym akers m ust act decisively and avoid burdensom e regulations that favor large tech incum bents and instead foster an
industry-driven ecosystem  that establishes a global standard that prom otes Am erican innovation. 
Am erica should focus on preventing ideological bias, adding security standards to AI, protecting data rights, and establishing clear
standards without stifling the free-m arket forces that drive innovation breakthroughs. 
Key Policy Recom m endations:
1. Preventing Ideological Bias in AI Training
AI system s should be ideologically neutral, ensuring that liberty, free-m arket principles, and open inquiry rem ain core to their design.
Training datasets m ust not em bed partisan, anti-Am erican biases that distort historical facts or suppress legitim ate viewpoints. An
independent industry standard for ideological neutrality should be developed. If this is not achieved, then it should be accom plished by
legislation. Preventing bias will preserve public trust in AI m odels while preventing distortions that can adversely im pact society.
2. AI Filtering and Free Expression
AI m odels should rem ain largely unfiltered, except in extrem e cases where content poses im m inent harm . Allowing filtered m odels to
becom e the norm  risks enabling censorship creep, shifting from  m inor distortions to the suppression of historical facts and political realities
– as seen through China’s DeepSeek. Likewise, the question of whether open-source m odels should allow user-controlled filtering is
crucial and deserves further exploration.
3. Protecting AI Model Architecture for National Security
Com m unist China’s brute-force reverse-engineering of Am erican innovators to create DeepSeek underscores the need to secure m odel
weights and proprietary architectures. Am erica m ust take proactive steps to prevent adversarial state actors from  exfiltrating sensitive AI
innovations while m aintaining an open, com petitive ecosystem  for dom estic research and developm ent. Policym akers should engage with
industry leaders to create robust security fram eworks that balance IP protection with continued innovation.
4. Data Governance, Privacy and Security Standards


Strong data governance and security standards are essential to protecting individual privacy, preventing leaks, and safeguarding sensitive
AI com ponents. Policies should avoid regulatory overreach while prom oting industry-led protections for consum er data and national
security-sensitive datasets. Additionally, AI workflows should be segm ented to m itigate risks, with clear industry standards preventing
unauthorized m odel distillation and knowledge transfer. Rather than im posing rigid m andates, the governm ent should encourage private-
sector adoption of security m easures, ensuring AI system s rem ain both secure and innovative.
5. AI Accuracy, Error Rates, and Hallucinations
The potential for harm  is too great if LLMs provide inaccurate answers once AI has achieved greater adoption throughout the econom y,
m aking it essential for the industry to establish self-regulating m echanism s that ensure AI reliability. LLMs should have built-in checks and
balances, using agentic workflows to vet whether they have hallucinated or lied, and inform  users of such errors. Standards around error
rates and hallucinations should be considered, but they should be m arket-driven, not overseen by the governm ent.
These recom m endations uphold the Executive Order’s intent of rem oving barriers to AI leadership, preventing ideological capture, and
fostering innovation through free m arkets while protecting our national security interests. 
Conclusion
Free m arkets, fair com petition, and robust national security continue to help keep Am erica great. By resisting regulatory overreach,
creating security standards for AI, and enforcing ideological neutrality, the U.S. will dom inate AI and continue leading in this wave of
innovation.
I urge policym akers to prioritize innovation-driven solutions while ensuring AI rem ains secure, unbiased, and aggressively aligned with
Am erican values. Thank you for your tim e and consideration.
Sincerely,
Alec S. Jones
Kudzu Technologies, Inc.
Attachments
Artificial Intelligence Action Plan Public Com m ent


P a g e  1 | 2 Public Comment on Artificial Intelligence Action Plan 
Submitted to:  Networking and Information Technology Research and Development (NITRD) 
National Coordination Office (NCO), National Science Foundation 
Date: March 15, 2025 
To Whom It May Concern, 
America faces a pivotal moment in Artificial Intelligence. With smart policies America will lead in AI 
while continuing to uphold free markets, fair competition, and strong national security. 
The AI Action Plan is a key opportunity to drive innovation by eliminating unnecessary government 
constraints and enhancing U.S. leadership. Policymakers must act decisively and avoid burdensome 
regulations that favor large tech incumbents and instead foster an industry-driven ecosystem that 
establishes a global standard that promotes American innovation.  
America should focus on preventing ideological bias, adding security standards to AI, protecting data 
rights, and establishing clear standards without stifling the free-market forces that drive innovation 
breakthroughs.  
Key Policy Recommendations: 
1. Preventing Ideological Bias in AI Training
AI systems should be ideologically neutral, ensuring that liberty, free-market principles, and 
open inquiry remain core to their design. Training datasets must not embed partisan, anti-
American biases that distort historical facts or suppress legitimate viewpoints. An independent 
industry standard for ideological neutrality should be developed. If this is not achieved, then it 
should be accomplished by legislation. Preventing bias will preserve public trust in AI models 
while preventing distortions that can adversely impact society. 
2. AI Filtering and Free Expression
AI models should remain largely unfiltered, except in extreme cases where content poses 
imminent harm. Allowing filtered models to become the norm risks enabling censorship creep, 
shifting from minor distortions to the suppression of historical facts and political realities – as 
seen through China’s DeepSeek. Likewise, the question of whether open-source models should 
allow user-controlled filtering is crucial and deserves further exploration. 
3. Protecting AI Model Architecture for National Security
Communist China’s brute-force reverse-engineering of American innovators to create 
DeepSeek underscores the need to secure model weights and proprietary architectures. 
America must take proactive steps to prevent adversarial state actors from exfiltrating 
sensitive AI innovations while maintaining an open, competitive ecosystem for domestic 
research and development. Policymakers should engage with industry leaders to create robust 
security frameworks that balance IP protection with continued innovation. 


P a g e  2 | 2 4. Data Governance, Privacy and Security Standards
Strong data governance and security standards are essential to protecting individual privacy, 
preventing leaks, and safeguarding sensitive AI components. Policies should avoid regulatory 
overreach while promoting industry-led protections for consumer data and national security-
sensitive datasets. Additionally, AI workflows should be segmented to mitigate risks, with clear 
industry standards preventing unauthorized model distillation and knowledge transfer. Rather 
than imposing rigid mandates, the government should encourage private-sector adoption of 
security measures, ensuring AI systems remain both secure and innovative. 
5. AI Accuracy, Error Rates, and Hallucinations
The potential for harm is too great if LLMs provide inaccurate answers once AI has achieved 
greater adoption throughout the economy, making it essential for the industry to establish 
self-regulating mechanisms that ensure AI reliability. LLMs should have built-in checks and 
balances, using agentic workflows to vet whether they have hallucinated or lied, and inform 
users of such errors. Standards around error rates and hallucinations should be considered, 
but they should be market-driven, not overseen by the government. 
These recommendations uphold the Executive Order’s intent of removing barriers to AI leadership, 
preventing ideological capture, and fostering innovation through free markets while protecting our 
national security interests.  
Conclusion  
Free markets, fair competition, and robust national security continue to help keep America great. By 
resisting regulatory overreach, creating security standards for AI, and enforcing ideological neutrality, 
the U.S. will dominate AI and continue leading in this wave of innovation. 
I urge policymakers to prioritize innovation-driven solutions while ensuring AI remains secure, 
unbiased, and aggressively aligned with American values. Thank you for your time and consideration. 
Sincerely, 
Alec S. Jones 
Kudzu Technologies, Inc.  


