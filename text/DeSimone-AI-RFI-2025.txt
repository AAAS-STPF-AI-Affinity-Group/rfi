3/13/2025  via FDMS  
Felix De Simone,  
With thanks to the NITRD NCO and the OSTP: I am a policy advocate with an academic 
backgr ound covering political science and international relations, and I have spent much of the 
last few years learning about AI and watching on in horror as we came closer to building systems that can outthink us. The US Government has a responsibility to keep Americans safe; therefore, responding to the emerging threat of smarter-than- human AI must be front and center of the 
administration’s new AI Action Plan. As an Americ an, and a human being, I am deeply alarmed 
by the threat that superhuman artificial intelligence may soon pose to our nation and even our species. Although the vast majority of AI systems are safe and beneficial, efforts to build smarter -than-human AI could be cataclysmic. Thousands of scientists and industry experts– 
including figures like David Sacks and Elon Musk– have warned that we don’t know how to control smarter-than-human AI, and that efforts to build these systems could cause global catastrophe. T o quote a 2024 paper coauthored by several of the world’s leading computer 
scientists: “once autonomous AI systems pursue undesirable goals, we may be unable to keep them in check [...] in open conflict, AI systems could autonomously deploy a variety of weapons, including biological ones [...] this unchecked AI advancement could culminate in a large- scale 
loss of life and the biosphere, and the marginalization and extinction of humanity.” (Bengio, Hinton et al, "Managing Extreme AI Risks Amid Rapid Progress," Science, 2024). By all means, we should lead in cutting-edge specialized AI innovation– with benefits in medicine, science, productivity, and more. But efforts to build smarter-than-human AI risk culminating in what Trump’s AI Czar David Sacks termed a “potential successor species.” We control the world because of our intelligence – if we build something smarter than us, losing control is a likely result. An “arms race” to build smarter -than-human AI is a race with no winners – the US will 
not benefit fr om being the first to build rogue AI that destroys us. Instead, America must lead in 
negotiating an AI Deal: an international agreement to prohibit developing smarter -than-human 
AI, until we know how to control it, while encouraging specialized AI innovation. History has much to teach us about this approach. President Reagan demanded that the Soviets negotiate on nuclear weapons, because he realized that a nuclear war has no winners – a few years later, the 
US and USSR signed a treaty prohibiting intermedia te-range ballistic missiles. The President 
should adopt a similar approach when it comes to superhuman AI, demanding that China agree to negotiate to prevent its development. If we act now, and decisively, we can secure the American – and human– future for generations to come. Thank you for your consideration, Felix 
De Simone Concerned citizen and AI policy advocate 
 


