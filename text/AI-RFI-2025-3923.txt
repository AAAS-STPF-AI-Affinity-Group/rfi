PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-wj4g-dot0
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-3923
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Michael Bono 
General Comment
Generative Artificial Intelligence (AI), including large language m odels (LLMs), are unnecessary for Am erican technical or econom ic
dom inance, and as currently im plem ented are largely based on large-scale theft of hum an beings' intellectual property. Generative AI
m odels are frequently trained on hum an-created content without the consent of content creators, allowing for replication of creators'
intellectual property. This non-consensual usage allows AI firm s and their custom ers to steal jobs from  Am erican workers. Moreover,
text-based generative AI m odels such as LLMs frequently output factually inaccurate inform ation that can deceive Am ericans and even
put them  at risk through unsafe advice regarding food preparation or m edical care. Finally, generative AI requires large quantities of
energy and clean water, wasting valuable resources and driving up energy prices for Am erican citizens. The large-scale evangelization of
generative AI is frequently based on exaggerations of generative AI's abilities. Any AI action plan should prioritize 1) protecting Am erican
workers from  having their work stolen for nonconsensual AI training, 2) protecting Am ericans' safety by ensuring that unreliable generative
AI m odels are never used for any decision that affects Am ericans' safety (e.g. air traffic control, m edical claim s, food safety advice,
m edical advice), and 3) prioritizing the use of Am erica's energy and water resources for hum an beings over wasteful generative AI data
centers.


