1 
 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution.  
ZealStrat’s Input to the 
Development of an AI Action 
Plan by OSTP as Directed by 
Presidential Executive Order  
 
 
Submitted by:  
ZealStrat LLC 
Dr. Ganesan Keerthivasan, M.D., CEO 
Dr. Thomas M. Tirpak, Ph.D., Head of AI Ethics 
 
Submitted to:  
AI Action Plan  
Attn: Faisal D’Souza 
NITRD NCO, 2415 Eisenhower Avenue, 
Alexandria, VA 22314 
Via Email:  
 
Date: March 15, 2025 
  


2 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. Table of Contents  
Introduction .................................................................................................................................... 3 
1. Creating Economic Value Through AI ..................................................................................... 3 
A. Incentivize AI Adoption Across Diverse Sectors  ............................................................................................ 3  
B. Foster Robust Infrastructure and Research Capacity  ....................................................................................... 4  
C. Upskill and Retain the Workforce  ................................................................................................................... 4  
D. Promote Responsible Corporate Behavior  ...................................................................................................... 4  
E. Measure and Track Economic Impact  ............................................................................................................. 5  
2. Regulation and Governance ...................................................................................................... 5 
A. Establish a Standards -Based AI Governance Framework  ............................................................................... 6  
B. Incentivize Ethical and Responsible AI Deployment  ...................................................................................... 6  
C. Proactive Risk Management and Liability Clarity  .......................................................................................... 7  
D. Cultivating a Culture of Ethical AI .................................................................................................................. 7  
E. Looking Ahead: Adaptability and Future -Proofing ......................................................................................... 7  
3. Model Development and Assurance (Explainability) ............................................................... 8 
Key Recommendations  ......................................................................................................................................... 8  
4. Cybersecurity and Data Privacy ................................................................................................ 9 
A. Risk -Based Cybersecurity Strategies  ............................................................................................................... 9  
B. Privacy -by-Default and Data Protection .......................................................................................................... 9  
C. Collaborative Governance for Cybersecurity and Data Privacy .................................................................... 10 
5. International Collaboration Framework and Competition .................................................... 10 
Overview ............................................................................................................................................................ 10 
Actionable Recommendations  ............................................................................................................................ 11 
Conclusion .................................................................................................................................... 12 


3 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. Introduction  
ZealStrat is pleased to submit these comments in response to the National Coordination Office 
(NCO) and Office of Science and Technology Policy (OSTP) Request for Information regarding 
the development of an AI Action Plan. ZealStrat is a strategic advisory organization with 
expertise in artificial intelligence (AI) governance, risk assessment, and innovation policies. 
ZeaalStrat’s mission is to help public and private organizations responsibly harness the power of 
emerging technologies, especially AI, for sustainable growth. 
We commend the Administration’s efforts to identify priority actions that will foster a robust and 
dynamic AI ecosystem across the United States, while addressing safety, security, and ethical 
considerations. Below, we provide our perspective on eight focus areas, which we believe are 
crucial to ensuring that U.S. leadership in AI is sustained and enhanced. 
1. Creating Economic Value Through AI
Overview  
AI technologies present significant opportunities for job creation, productivity gains, and overall 
economic advancement across industries. By strategically integrating AI into sectors such as 
manufacturing, healthcare, and logistics, policymakers can help businesses of all sizes become 
more resilient and globally competitive. However, realizing these benefits requires targeted 
incentives, robust infrastructure development, and a clear framework for measuring AI’s 
economic impact. AI’s immense computational power also holds the promise of accelerating 
scientific discoveries—ranging from identifying new energy sources to uncovering previously 
unknown physical and chemical properties of matter, ultimately propelling humanity’s progress 
in fields like biology, sub-atomic physics, and space exploration. 
While these transformative possibilities should be at the heart of our AI strategy, many 
organizations currently focus on using AI primarily to achieve operational efficiencies and trim 
costs, with the likely side-effect of leaving large numbers of people unemployed. This short-
sighted approach threatens not only the long-term sustainability of AI development but also the consumer base that businesses rely upon. Instead, companies should use AI to not only boost 
productivity but empower employees through upskilling and adaptation, ensuring that economic 
gains and opportunities are broadly shared. By fostering a balanced approach —investing in 
people as well as technology—AI can truly serve the collective good, fueling innovation and 
prosperity for all. 
A. Incentivize AI Adoption Across Diverse Sectors
●Targeted Sector Grants and Tax Incentives
oProvide grants, subsidies, or R&D tax credits for AI projects in key sectors (e.g.,
manufacturing, healthcare, logistics, energy) that demonstrate potential for job
creation and productivity gains.
oEncourage AI applications that unlock new scientific frontiers (e.g., energy
sources, novel materials, biotech breakthroughs) with the potential to transform
entire industries.


4 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. ●Industry-Specific AI Pilots
oEstablish pilot programs within federal agencies (e.g., Departments of Energy,
Agriculture, Defense) to test advanced AI solutions.
oShowcase successful pilots to accelerate adoption across the public and private
sectors, ensuring small and medium enterprises also benefit from these insights.
B. Foster Robust Infrastructure and Research Capacity
●High-Performance Computing (HPC) and Data Centers
oExpand funding for national HPC centers to support AI research—especially
projects exploring new energy discoveries, physics, and space research. The goal
should be to challenge the norm, advance the technology and foundational
science, and re-imagine their applications with the help of AI.
oOffer cost-sharing or low-interest loan programs for companies building AI-focused data centers, particularly in economically distressed regions.
●Public-Private Research Collaboration
oCreate federal “AI Science Challenge Funds” to co-invest in large-scale research
with private partners, focusing on areas like sub-atomic physics, medical
research, and advanced materials.
C. Upskill and Retain the Workforce
●National AI Upskilling Initiative
oLaunch a coordinated federal program offering short-course certifications,apprenticeships, and training stipends to retool workers for AI-intensive roles.
oCollaborate with community colleges, vocational schools, and industryassociations to ensure affordable, accessible AI and digital training.
●Workforce Retention Incentives
oOffer tax benefits or matching grants to companies that expand their AI
operations while retaining or retraining current employees, rather than opting
for layoffs.
oRecognize and reward organizations that demonstrate a people-first approach—
innovating through AI without undermining the broader consumer base.
D. Promote Responsible Corporate Behavior
●Adaptive Corporate Governance
oEncourage larger firms to adopt responsible AI charters, committing to reinvest
a portion of AI-driven productivity gains into workforce development, new
product lines, or public R&D partnerships.
oEstablish voluntary recognition programs—public “Responsible AI” badges—forcompanies that exemplify a balanced approach to AI-driven transformation and
workforce retention.
●Stakeholder Engagement and Reporting
oRequire AI-driven companies of a certain size to publish annual disclosures
detailing how AI adoption has impacted their employment levels, salaries, andinvestments in training.


5 
 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. o Mandate transparent communication on Company’s long-term workforce 
strategy, ensuring that employees, investors, and the public understand the 
company’s commitment to shared prosperity. 
E. Measure and Track Economic Impact  
● Standardized Metrics & Dashboards 
o Develop a unified set of AI impact indicators (e.g., GDP contribution, jobs 
created, productivity growth, R&D output) and display them on a public-facing 
federal dashboard. 
o Use these metrics to periodically review, adjust, or sunset  incentives and 
regulations as the market evolves. 
● Periodic Policy Reviews  
o Convene an AI Economic Advisory Council—comprising policymakers, 
industry leaders, and academic experts—to evaluate the effectiveness of 
incentives, workforce programs, and research initiatives every year. 
o Update policies promptly based on data-driven insights, keeping pace with new 
technologies and global competition. 
Summary 
By adopting these focused strategies—ranging from targeted sector incentives and robust 
infrastructure funding, to workforce upskilling and responsible corporate governance—the 
Administration can capitalize on AI’s transformative potential. This balanced approach ensures 
that productivity gains do not come at the expense of widespread job loss or weakened consumer 
demand. Instead, it fosters inclusive economic growth, fuels scientific discovery, and 
strengthens the United States as a global leader in AI-driven innovation. 
2. Regulation and Governance  
Overview 
Effective AI governance is a cornerstone of building and maintaining public trust in AI -driven 
systems. It requires a flexible, risk-based approach that protects civil liberties, national security, 
and public welfare—while also fostering innovation and economic growth. Drawing on our 
Ethical AI expertise, ZealStrat recommends leveraging recognized frameworks and standards 
(e.g., IEEE CertifAIEdTM) to align government oversight with private-sector best practices and 
ensure that AI deployments remain transparent, accountable, fair and robust, while maintaining the expected level of privacy. A harmonized, risk-based governance framework should 
emphasize flexibility to accommodate evolving technologies and include clear mechanisms for 
transparency and accountability. 
Importantly, the Federal Government should not serve as a vast regulatory entity —akin to the 
FDA (Food and Drug Administration)—managing millions of AI applications and certifications, 
as this would introduce significant inefficiencies and waste taxpayer d ollars. Instead, we propose 
the use of accredited third-party assessors who can objectively evaluate AI systems under the guidance of globally recognized standards bodies, such as IEEE. These organizations would be 
responsible for updating and maintaining the relevant frameworks, as well as training enough 


6 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. assessors to meet demand. The Federal Government’s role could then be more efficiently 
focused on approving and monitoring these ethical AI and AI risk frameworks, maintaining a 
publicly accessible list of endorsed standards. This streamlined approach protects consumers and promotes national interests without unnecessarily slowing innovation in the AI space. 
A. Establish a Standards -Based AI Governance Framework
i.Adopt Globally Recognized Standards:
oIEEE CertifAIEd™: Provides a structured ethics and risk assessment frameworkthat integrates societal values, covering a comprehensive set of Ethical
Foundational Requirements for privacy, transparency, algorithmic bias, and
accountability—offering a way to earn a globally recognized trustmark for
ethical AI systems that satisfy these requirements.
oNIST AI RMF: Encourages organizations to identify, measure, manage, andmonitor AI risks across the lifecycle of AI system design, development, and
deployment, supporting them with practical insights from better practices across
multiple industries and applications..
ii.Drive Consistency and Comparability:
oUsing common terminology and reporting structures for AI risk management
facilitates consistent regulation and cross-sector benchmarking.
oSimplifying regulatory compliance for organizations that operate both nationallyand internationally supports broader U.S. competitiveness in AI.
iii.Encourage Continuous Monitoring, Improvement, Compliance and FeedbackLoops:
oMandate periodic reviews or audits to ensure that AI systems adapt to rapidlychanging technologies and regulatory requirements.
oReward organizations that go beyond baseline compliance by adopting morerigorous certifications, and earn trustmarks such as IEEE CertifAIEd™.
oImplement post-deployment monitoring and user-feedback mechanisms to catch
emerging issues and support agile model updates.
B. Incentivize Ethical and Responsible AI Deployment
i.Public-Private Partnerships:
oCollaborate with industry leaders, academia, and standards bodies (e.g., IEEE) to
develop practical guidelines that strike the right balance between oversight and
innovation.
oOffer innovation grants or tax incentives for organizations investing in human-
centric AI, explainable models, and robust safety testing.
ii.Certification and Trustmarks:
oEncourage agencies and private organizations to seek trusted certifications. For
example, IEEE CertifAIEd™ can add a tangible seal of approval,
demonstrating that an AI system meets rigorous ethical and safety standards.
oPublic communication of applicable standards and assessment organizations thatwould sufficiently fulfill the AI safety and risk regulations. This will help end-


7 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. users and government buyers identify vendors committed to responsible, secure 
AI, and foster transparency in the selection of such vendors. 
C. Proactive Risk Management and Liability Clarity
i.Contextual Risk-Based Controls:
oImplement tiered oversight based on an AI system’s potential for harm. High-impact domains (e.g., healthcare, finance, Insurance, public safety) may require
more stringent safeguards and advanced system explainability.
oEncourage organizations to map, measure, and manage AI-related riskscontinuously, aligning with recognized frameworks like IEEE and NIST to stay
ahead of emerging threats and liabilities.
ii.Legal and Regulatory Certainty:
oClearly define developer vs. deployer responsibilities to provide clarity onliability in cases of erroneous or biased outputs (e.g., AI used in hiring decisions
or critical resource allocations). Emerging AI legislation, such as Colorado’s AI
Consumer Protection Act, have pointed to the need for stakeholders across the
entire AI system lifecycle to be appropriately held accountable.
oStandards organizations like IEEE should continuously incorporate insights fromrecent legal precedents (such as lawsuits alleging AI-based discrimination) to
refine risk assessment and compliance guidelines. This approach ensures the
U.S. AI ecosystem remains both globally competitive and legally resilient.
D. Cultivating a Culture of Ethical AI
i.Organizational AI Ethics Committees:
oEncourage the formation of intra-organizational AI ethics boards or
committees that align R&D teams, legal departments, and C-suite executives on
AI governance decisions and accountability structures.
oEducate and Train employees: Incorporate a culture of risk awareness where
employees at all levels understand the ethical dimensions of AI development and
deployment.
ii.Public Education and Stakeholder Engagement:
oSponsor public outreach programs to demystify AI technologies, highlightingboth their capabilities and their limitations.
oEngage with non-profit organizations like IEEE Standards Association, consumeradvocates, and community stakeholders to co-design or refine AI policies,
ensuring broader input on societal and ethical implications.
E. Looking Ahead: Adaptability and Future -Proofing
i.Periodic Policy Updates:
oGiven the rapid evolution of AI, regulatory agencies should evaluate and update
relevant regulations and advisory guidance on a regular cycle (e.g., every 12 –18
months) to keep pace with technological advancements and evolving societalexpectations.


8 
 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. o Encourage agencies, industries, and standards bodies to convene in joint forums 
to share lessons learned and emerging best practices. 
ii. Forward-Looking Governance: 
o Promote research into next-generation AI technologies (e.g., neuromorphic 
computing, quantum-assisted AI, advanced generative systems) to anticipate new 
ethical, legal, and economic considerations. 
o Develop contingency plans and policy frameworks that account for breakthroughs and disruptive AI applications—ensuring the AI Action Plan 
remains relevant and resilient over time. 
Conclusion 
A modern, standards-driven approach to AI regulation and governance—bolstered by the IEEE 
CertifAIEd™ and NIST AI RMF—will equip U.S. policymakers and stakeholders with the 
tools they need to drive innovation and ensure safety. By combining clear oversight structures, 
incentivizing ethical practices, and committing to periodic framework updates, the U.S. can 
cement its leadership in AI while safeguarding the public interest and reinforcing long-term 
trust in emerging technologies. 
3. Model Development and Assurance (Explainability)  
Overview  Explainability and transparency of AI models are critical for building public trust and ensuring responsible deployment, particularly in high-risk, and potentially high-reward domains such as 
healthcare, finance, and public safety. Clear, interpretable outputs can help stakeholders identify 
and mitigate issues like algorithmic bias, model drift, and unintended consequences.  
Key Recommendations  
i. Tailored Explainability  
o Require context-specific explainability protocols: detailed explanations in 
sensitive uses (e.g., medical diagnoses) and lighter-touch approaches for lower-
risk scenarios. 
ii. Verification & Validation Frameworks  
o Adopt standardized testing methods (e.g., stress tests, red-teaming) to detect 
potential failure modes or biases before wide-scale deployment. 
o Encourage or mandate external audits of critical AI systems, leveraging 
recognized standards (e.g., IEEE CertifAIEd™) to evaluate transparency, bias 
risks, and overall model fitness 
iii. Continuous Monitoring and Feedback Loops  
o Implement post-deployment monitoring and user-feedback mechanisms to catch emerging issues and support agile model updates. 


9 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. 4. Cybersecurity and Data Privacy
Overview 
With AI systems increasingly relied upon to process vast quantities of sensitive information, 
cybersecurity and data privacy have become foundational to maintaining trust and ensuring safe 
outcomes. Robust safeguards must be embedded throughout the AI lifecycle—from data 
collection and preprocessing to model training, inference, and ongoing maintenance. By adopting secure-by-design (https://www.cisa.gov/securebydesign) and privacy-by-default principles, 
organizations can protect against malicious attacks, minimize data exposure risks, and preserve individual rights. 
A. Risk- Based Cybersecurity Strategies
i.Promote Secure-by-Design Development
oMandate a systematic review of potential attack vectors (e.g., data poisoning,
model inversion, adversarial inputs) to guide security measures.
oLayer multiple security controls—such as encryption, intrusion detection, andcontinuous monitoring—throughout the AI workflow.
ii.Lifecycle Monitoring and Incident Response
oOngoing Assessments: Periodically audit AI systems to detect vulnerabilities
early and address them promptly.
oStandardized Protocols: Promote consistent incident response proceduresaligned with NIST Cybersecurity Framework guidelines, ensuring timely
containment and mitigation.
iii.Third-Party Validation
oSimilar to the Regulation and Governance recommendation, leverage
accredited assessors that specialize in cybersecurity evaluations. These assessors
can ensure AI models and infrastructure meet recognized technical standards
(e.g., ISO/IEC 27001, IEEE CertifAIEd™ security benchmarks) withoutimposing excessive federal oversight.
B. Privacy -by-Default and Data Protection
i.Data Minimization and Purpose Limitation
oCollect Only What’s Needed: Government and industry stakeholders shouldadopt policies that limit data gathering to what is necessary for the model to
reliably serve its intended application - no more, not less.
oPurpose Clarity: Clearly define how data will be used, shared, and retained, withtransparent consent mechanisms for end-users.
ii.Technical Privacy Approaches
oDifferential Privacy and Encryption: Encourage advanced techniques (e.g.,
homomorphic encryption, secure multiparty computation) to protect sensitive data
in training or inference.
oSecure Data Storage: Mandate robust security practices for data at rest and intransit (e.g., encryption, secure enclaves), ensuring consistent safeguards across
the supply chain.
iii.Certification of Privacy Frameworks


10 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. oCreate a federal registry of approved privacy standards (e.g., IEEE
CertifAIEd™, ISO 27701) that public agencies and private companies can adopt.
oFederal oversight can be limited to reviewing and endorsing these frameworks—
rather than becoming a large regulatory apparatus—thereby reducing
administrative burden and accelerating compliance.
C. Collaborative Governance for Cybersecurity and Data Privacy
i.Public-Private Partnerships
oInformation Sharing: Encourage sector-wide intelligence exchanges on
emerging threats and best practices.
oJoint Incident Exercises: Promote simulation drills across agencies andindustries to test readiness and resilience against AI-specific cyber threats.
ii.Continuous Standards Evolution
oWork closely with recognized standards bodies (NIST, IEEE) to update
cybersecurity and privacy guidelines in response to new AI capabilities and
emerging vulnerabilities.
oEnsure standards remain flexible, avoiding one-size-fits-all mandates that may
stifle AI innovation and progress with novel applications.
iii.Transparency and Accountability
oAudit Trails and Logging: Require that AI systems maintain logs of critical data
processing events, enabling traceability for security investigations.
oPublic Reporting: Incentivize voluntary disclosure of data breaches or system
vulnerabilities, reinforcing public trust and improving collective defenses.
Conclusion 
By combining risk-based cybersecurity strategies with privacy-by-default principles and 
leveraging third-party certification, the Federal Government can help ensure that AI systems 
remain both innovative and secure . A federated approach—where official agencies endorse 
robust standards bodies and maintain a curated list of approved frameworks —avoids the 
inefficiency of direct government involvement in every stage. This model protects the public 
interest while fostering a competitive, responsible AI ecosystem that upholds user trust at all times.  
5. International Collaboration Framework and
Competition
Overview 
Issue 1: Protecting U.S. Innovations 
The United States invests heavily in advanced research and development, striving to create 
game-changing AI technologies. Yet certain foreign adversaries—sometimes referred to as 
“rogue states”—exploit hacking, industrial espionage, or illicit financial incentives to access U.S. 
technology at minimal cost. This poses an unfair threat to U.S. firms and workers, undermines 
incentives for legitimate innovation, and compromises American competitiveness. A more robust 


11 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. strategy is needed to protect American intellectual property (IP) and deter unauthorized 
technology transfers. 
Issue 2: Upholding Ethical Standards Amid Global Competition 
Ethical values—derived from humanitarian, cultural, or religious principles—are core to the U.S. 
identity and serve as a guiding force in AI development. Nevertheless, countries that do not 
prioritize such ethical considerations can deploy AI without safeg uards, moving at a faster but 
riskier pace. While this might create short-term competitive disadvantages for American enterprises, resorting to unethical methods in response is neither morally acceptable nor 
strategically sustainable. Over time, AI solutions that harm or exploit people tend to lose public 
trust. Therefore, the United States must maintain a high ethical bar in AI while preventing 
rogue or unethical AI solutions from undercutting American standards in both domestic and allied markets. 
Actionable Recommendations  
1.Strengthen IP Protections and Deterrence Measures
oFederal Technology Security Office: Establish or empower an existing federal
body to coordinate AI-related IP protections across agencies (e.g., Commerce,
State, Defense) and to respond swiftly to cyber intrusions or industrial espionage
attempts. Continue ongoing initiatives for the United States Patent and trademark
Office (USPTO) to better identify and protect innovations, with a statutory right
for such protection, protecting IPR-owners’ right, and thereby promoting
innovation of AI-enabled systems that benefit society.
oEnhanced Legal Frameworks: Strengthen penalties for individuals and entitiesinvolved in corporate espionage or unauthorized technology transfers, ensuring
the legal deterrents match the severity of the offense.
oExport Controls and Screening: Bolster current export control mechanisms tocover critical AI software, hardware, and data assets, thereby preventing
adversarial entities from siphoning U.S. technology.
2.Require U.S. Certification for Foreign AI Solutions
oStandards-Based Entry: Mandate that any AI technology imported or used in
the U.S. meet certification requirements set by approved organizations such as
IEEE, focusing on data privacy, security, and ethical considerations. Much like
the regulatory approach in the medical, pharmaceutical, and food industries, this
ensures that only AI solutions meeting rigorous safety and ethical standards gain
market access.
oAllied Reciprocity: Coordinate with international allies to recognize shared AI
certification frameworks, collectively refusing market access to AI solutions that
fail to meet these frameworks’ rigorous ethical and security standards.
oPeriodic Reassessment: Require periodic compliance audits to ensure continuousadherence to evolving U.S. guidelines and ethical benchmarks.
3.Promote a Unified Ethical AI Strategy with Allies
oAllied Task Force: Form a multinational task force comprising key partners (e.g.,
NATO members, G7 countries, or other allies) to discuss AI ethics, share threat
intelligence, and develop joint strategies for preventing the spread of malicious AI
tools.


12 
This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. oCross-Border R&D: Encourage co-funded research programs that allow allied
nations to pool AI expertise, emphasizing shared values like transparency and
human rights. This collaboration fosters technological parity and mutual
economic benefits.
4.Accelerate America’s Ethical AI Ecosystem
oTalent Retention and Growth: Increase specialized visa slots and incentives for
top AI talent from around the world to remain in the U.S., helping to bolster
America’s leadership in cutting-edge research.
oSupport for Ethical AI Incubators: Fund incubators and accelerators focusingon AI solutions that meet rigorous ethical standards—especially those that serve
national security, healthcare, energy, or other high-priority sectors.
oPublic Awareness Campaigns: Launch educational programs and publicoutreach initiatives highlighting the importance of ethical AI, helping U.S.citizens understand why certain foreign AI solutions may be restricted.
Conclusion By deploying robust IP protection measures, requiring all AI solutions including domestic and 
foreign AI solutions, to adhere to the ethical standards recognized by the U nited States. And 
collaborating with allies on this unified approach, the United States can safeguard its technological edge, uphold ethical principles, and maintain global leadership in AI innovation. 
This balanced strategy reflects American values, secures national interests, and ensures that AI’s 
long-term benefits are both sustainable and equitable. Moreover, this approach will level the 
playfield for all competitors and global players to have healthy competition.  
Conclusion  
ZealStrat appreciates the opportunity to provide input for this AI Action Plan. We encourage the 
Administration to adopt policies that support responsible AI innovation, sustainable economic 
growth, as well as efficient and effective governance. By balancing regulatory prudence with 
flexibility for emerging technologies, the United States can maintain its global leadership in AI while safeguarding public trust and national interests. 
If you have any questions about the perspectives we have shared on behalf of ZealStrat, please 
contact:  
Dr. Ganesan Keerthivasan  
email:  or phone: (650) 
Thank you for your consideration. 
Respectfully Submitted, 
Dr. Ganesan Keerthivasan 
Chief Executive Officer, ZealStrat LLC 
March 15, 2025. 


