To: 
From: The Center for AI Risk Management and Alignment  
Subject: AI Action Plan RFI Submission  
The Center for AI Risk Management & Alignment (CARMA) is a research and policy think tank dedicated to 
more securely and safely mapping the progression and effects of emergent abilities in artificial intelligence. 
Through progressing the sciences of AI risk and creating frameworks for AI management, we work toward 
unlocking more of AI’s benefits for Americans.
In order to achieve the AI Action Plan’s stated goal, to maintain U.S. leadership in AI, and for 
the nation to properly reap the benefits of technological innovation  while minimizing unwanted 
types of disruptions to civil life and security, CARMA proposes that the AI Action Plan include a 
strategy for the US national security apparatus to update and enhance its orientation toward 
emerging technology risks with national security consequences.  
The federal government has developed a variety of tools to understand AI capabilities for 
innovation and risk. However, given the nascent nature of AI governance, the AI research 
community, governments, and developers have indicated potential negative side effects for the 
rapid development and proliferation of AI systems.1 As the administration seeks to develop its 
own governance priorities, we advocate for the below policy recommendations within the current 
regulatory landscape:  
Recommendation 1: Monitoring and Engagement 
A.Ensure that NSA, DHS, Commerce, and relevant agencies are tracking AGI
developments and potential threats that stem from their proliferation. The
government should continue to engage with AI developers to share information
on  novel threats with immediate and distant timeframes.
1 “Governing AI for Humanity”, United Nations, Sept. 2024. https://news.un.org/en/story/2024/09/1154541 


B.CISA’ s Joint Cyber Defense Collaborative, NIST, OSTP, and NSA all have
separate engagement remits with industry- the AI Action Plan should illustrate
these Lines of Effort as appropriate as a part of a larger framework for
understanding AI dual use capabilities.C.The White House should convene industry leaders and civil society groups to
discuss maintaining AI leadership through prioritizing governance, security, and
investment.
Recommendation 2: Assess AI technology for Risk 
A.Ensure the AI Safety Institute’s Testing Risks of AI for National Security Task
Force is properly resourced and authorized to study the national security risks of
AI models across all relevant domains. Specifically, how AI non-programmed
behavior, including deceptive scheming, self-preservation, self-replication, and
recursive self-improvement could lead to national security risks. The findings of
the task force should regularly update the National Security Council and relevant
national security agencies to inform response planning and regulatory efforts.B.Engage with industry and civil society to develop national security Risk
Assessments specifically focused on general-purpose AI systems.
C.Direct agencies within the federal research community (DARPA, NIST, OSTP,
and the National Laboratories) to develop a historical report on the development
of innovative technology and emergent national security risks.
Recommendation 3: Risk Reduction and Response 
A.The nature of AI threats are varied and can come in a multitude of vectors,
resulting in a threat environment that will prove difficult to respond to without
properly prepared emergency response mechanisms. Therefore, we recommend
that the federal government establish a framework for emergency preparedness  to
respond to and deter AI-related threats of national significance. This framework
should include: ■Threat monitoring within the intelligence community and
homeland security enterprises. Relevant agencies should ensure
that cyber vulnerabilities databases are updated with relevant threat
vector information as novel AI threats arise.
■Red team and table top exercises with teams of emergency
response and germane Sector Risk Management Agencies (e.g.
CISA, FEMA , HHS,  and a relevant Intelligence Community
partner for health-related AI threats) for knowledge management
and response plan development.


 
■ Early warning detection mechanisms 
■ Communications and coordination plans. Presidential Policy 
Directive 41, the National Cyber Incident Response Plan and other 
relevant national security documents have established coordinating 
mechanisms that centralize command, control and communication 
for cyber emergencies - these structures should be tested and 
updated as appropriate for the types of threats that experts think 
plausible from advanced general-purpose agentic AI. ■ FEMA, in its 2050 Strategic Foresight Report, recognized that 
developments in AI could lead to emergent behaviors that are hard 
to predict or interpret. AI-enhanced bad actors may also introduce 
chemical or geoengineering threats to public health. Cyberattacks 
involving AI that could interrupt critical government functions or 
sow mistrust of the government present significant national 
security risk to the emergency preparedness function. FEMA, as 
the federal emergency response agency, should play an integral 
role in developing response plans from AI threats.  ■ The White House, State, CISA, NIST and the IC should engage in 
international efforts for minimizing risk from nation state actors, 
transnational AI threats to US critical infrastructure. These 
multilateral efforts should include engaging with allies to share 
information and coordinate response planning as appropriate, and 
lead on AI governance in multilateral fora including NATO, the 
UN, and the G7. ■ The Plan should instruct the Bureau of Industry and Security to 
mandate that companies develop and install geolocation and 
geofencing capabilities so that AI chips, and their systems, are 
used in pre-approved areas and do not fall into the hands of 
malevolent foreign actors. As a failsafe, BIS should assess the 
feasibility of mandating targeted deactivation capabilities within 
powerful AI chips as the national security landscape evolves to 
necessitate the action.  ■ The White House should implement distinct yet coordinated 
bioassessment (monitoring and detection) and bioremediation 
(mitigation and response) capabilities to respond to novel AI/bio 
threats: 
a. Bioassessment: Designate a responsible entity, such as the 
Biosecurity, Assessments, and Materials group within 
Lawrence Livermore National Laboratory's Physical and 
Life Sciences Directorate, to develop advanced methods for 


detecting and characterizing AI-enhanced bio-threats. This 
designation should be accompanied by an institutional gap 
analysis to determine required capabilities and funding. 
b.Bioremediation : Clearly define coordination mechanisms
among emergency response agencies, including the
Department of Homeland Security (DHS), Centers for
Disease Control and Prevention (CDC), and relevant state
and local entities, ensuring rapid containment, mitigation,
and public communication in response to detected threats.The White House should also establish formal collaboration 
mechanisms between government, private sector biotechnology 
firms, academic research institutions, and international partners to 
facilitate information sharing, joint preparedness exercises, and 
timely response to novel AI bio threats.  
Conclusion 
The above recommendations outline a multi-layered governmental approach to tracking, 
assessing, and mitigating potential AI-driven national security risks. The framework emphasizes 
proactive monitoring through interagency and external collaboration, rigorous technological risk 
assessment, and establishing robust emergency response preparedness. The policy proposals  
advocate for a flexible, anticipatory governance structure that can rapidly adapt to the complex 
and evolving landscape of AI-related national security challenges while maintaining AI 
leadership in the global landscape. 


