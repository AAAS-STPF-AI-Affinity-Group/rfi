March 14, 2025 
National Coordination Office  
Networking and Information Technology Research and Development Program 
2415 Eisenhower Avenue, Alexandria, VA 22314  
Attention: Faisal D'Souza  
Re: AI AcƟon Plan Request for InformaƟon 
To Whom It May Concern: 
JPMorganChase appreciates the opportunity to respond to the NaƟonal Science FoundaƟon 
(NSF) and Networking and InformaƟon Technology Research and Development (NITRD) NaƟonal 
CoordinaƟon Oﬃce’s (NCO) Request for InformaƟon (RFI) on the Development of an ArƟﬁcial 
Intelligence AcƟon Plan (“AI AcƟon Plan”). As a leader in the ﬁnancial services sector, we 
recognize the transformaƟve potenƟal of arƟﬁcial intelligence (AI) and the importance of a 
cohesive naƟonal strategy to harness its beneﬁts while addressing associated risks. 
JPMorganChase is a U.S.-based company that serves millions of customers, clients, and 
communiƟes in over 100 global markets. Our company Purpose is to Make Dreams Possible for 
everyone, everywhere, every day—undergirded by our Principles, which guide how we work, 
and include ExcepƟonal Client Service; OperaƟonal Excellence; A Commitment to Integrity, 
Fairness and Responsibility; and A Great Team and Winning Culture.  
We are encouraged by the government’s prioriƟzaƟon of a strategy that advances the interests 
of the United States as global leader in AI, ensuring that we and other democraƟc naƟons 
remain at the forefront of AI innovaƟon and leadership. Below, we oﬀer our perspecƟves on 
how the naƟon can opƟmize such a strategy to promote innovaƟon, ensure security, and 
broadly extend the beneﬁts of AI capabiliƟes. 
I. AI and JPMorganChase
JPMorganChase is a leader in the ﬁnancial services industry with a history of leveraging 
technology to enhance operaƟons, improve customer experiences, and manage risks: like many 
ﬁnancial service ﬁrms, we have been using AI for the beƩer part of a decade. AI technologies 
will conƟnue to be a business enabler as the ﬁnancial services ecosystem evolves. Consequently, 
we are invested in leveraging their recently-accelerated commercial development to support 
relevant aspects of the work that we do. Last year, our Chairman and CEO Jamie Dimon wrote in 
our Annual Shareholder LeƩer, “While we do not know the full eﬀect or the precise rate at 
which AI will change our business — or how it will aﬀect society at large — we are completely 
convinced the consequences will be extraordinary and possibly as transformaƟonal as some of 
the major technological invenƟons of the past several hundred years.” 
We do not treat AI as an isolated project or program. As with all broadly-enabling technologies, 
it is a core component of how we think about invesƟng in our people, our infrastructure, our 


2 operaƟons, and our product oﬀerings. With over 500 AI and ML use cases in producƟon, we are 
at the forefront of applied AI innovaƟon and deployment in ﬁnancial services globally.1 We view 
these technologies as a business imperaƟve that can help us serve our clients and communiƟes 
beƩer and become more eﬃcient in many of our day-to-day acƟviƟes. Our experience with AI 
spans various domains, including such use cases as fraud detecƟon, risk, and personalized 
ﬁnancial services. We have also invested in developing internal AI capabiliƟes, such as our LLM 
Suite, to enhance producƟvity and innovaƟon across the ﬁrm. 
We also see robust, thoughƞul risk management as a criƟcal aspect of eﬀecƟve AI 
deployment—for our ﬁrm, and at the scale of the American and global economies. Our 
commitment to AI as an enabler of our business is reﬂected across the breadth of our 
operaƟons, robust governance frameworks, and investment in talent and technology. We 
employ a comprehensive approach to AI that integrates security imperaƟves, a strong 
prioriƟzaƟon of risk management, compliance with our regulatory obligaƟons, and business and 
strategic objecƟves, ensuring that our AI iniƟaƟves align with our broader mission to serve our 
clients and communiƟes eﬀecƟvely and responsibly. Clearly, AI comes with risks, which need to 
be rigorously managed; fortunately, the majority of these risks are not unique to AI 
technologies. JPMC has a thorough, well-established risk and control framework that helps us 
proacƟvely stay in front of AI-related risks. The governance and risk management of AI is 
integrated into our exisƟng ﬁrmwide risk management and control frameworks relaƟng to 
model risk, data governance, technology controls, and operaƟonal risk. These frameworks are 
based on exisƟng bank laws, regulaƟons, and guidance that have historically been, and remain, 
applicable to the use of AI.  
Through our extensive experiences in responsibly governing and deploying AI systems, 
JPMorganChase has acquired unique insights into the pracƟcal applicaƟons and challenges of AI 
in the ﬁnancial sector. By sharing our experƟse and collaboraƟng with policymakers, we hope to 
contribute to the development of a naƟonal AI strategy for the U.S. that supports sustainable 
growth and innovaƟon in the ﬁnancial services industry, ulƟmately reinforcing the United States' 
leadership in AI. 
II. AI RegulaƟon in Financial Services
ExisƟng regulaƟons and risk guidance for banks are robust, and have provided a durable and 
adaptable architecture for AI risk management. These frameworks play an instrumental role in 
informing and enabling our sector’s adopƟon and deployment of AI systems. By building on 
these established pracƟces, regulators can create a supporƟve environment for AI innovaƟon 1 JPMorganChase has, for mulƟple years running, scored atop the Evident AI Index, which provides a benchmark of 
AI adopƟon and maturity throughout the banking sector. The Index evaluates 50 of the largest banks in North 
America, Europe, and Asia against 90 individual indicators drawn from millions of publicly available data points. A 
link to the full 2024 results is available at hƩps://evidenƟnsights.com/ai-index/ .  


3 while safeguarding the stability and integrity of the ﬁnancial system, thereby enhancing the 
United States' compeƟƟve advantage in the global ﬁnancial landscape.  
A. UƟlity of ExisƟng Frameworks
Across the ﬁnancial sector, the use of AI is generally subject to the safety and soundness 
requirements of our prudenƟal regulators (the FRB, OCC and FDIC); guidance on model and 
third party risk management; requirements relaƟng to the management, governance, and use 
of data including privacy, cybersecurity, and other informaƟon security requirements; and 
addiƟonal policies. Depending on the use case, the use of AI by ﬁnancial insƟtuƟons is also 
subject to acƟvity-speciﬁc requirements such as the regulaƟons of market regulators, including 
the SEC and CFTC, that have robust regulatory frameworks around risk management and anƟ-
market manipulaƟon that apply to various markets acƟviƟes regardless of the technology used, 
or consumer protecƟon laws and regulaƟons such as those relaƟng to anƟ-discriminaƟon, fair 
lending, and unfair or decepƟve acts and pracƟces. 
Where AI may amplify exisƟng risks or presents new risks, and as the technology evolves, banks 
conƟnue to adapt their frameworks accordingly, and are leveraging AI governance principles as 
well as guidance by policymakers on speciﬁc AI risks. As such, we believe the exisƟng regulatory 
landscape as it relates to banks is ﬁt for purpose and adequately addresses the risks of AI. It also 
provides a ﬂexible, risk-based framework for banks to address new or elevated risks as they 
arise—a useful model, we think, for other sectors which may currently face less structure in AI 
risk management. 
Rather than re-invenƟng these frameworks, government agencies should conﬁrm and clarify the 
applicability of exisƟng rules to AI and provide addiƟonal guidance where necessary, and 
potenƟally consider how to harmonize such rules with emerging state and local regulaƟon. This 
approach ensures that AI innovaƟons are integrated into exisƟng regulatory structures without 
unnecessary disrupƟon. By leveraging exisƟng frameworks, regulators can provide clear and 
consistent guidance to ﬁnancial insƟtuƟons, facilitaƟng the responsible adopƟon of AI 
technologies and reinforcing the United States' posiƟon as a leader in ﬁnancial innovaƟon.  
B. Value of a Sectoral Approach
A sectoral approach allows regulators to tailor their oversight to the speciﬁc characterisƟcs and 
needs of each industry, ensuring that AI regulaƟons are both eﬀecƟve and proporƟonate. In the 
ﬁnancial services sector, a sectoral approach is parƟcularly important given the global 
complexity and interconnectedness of ﬁnancial markets. ExisƟng agencies—such as the OCC 
and Federal Reserve—are best suited to oversee AI implementaƟon within the ﬁnancial services 
sector, where regulatory regimes are well-established, and where interoperability of the global 
ﬁnancial system is an important consideraƟon. These agencies have the experƟse and 
infrastructure to eﬀecƟvely monitor and respond to AI-related risks and ensure compliance with 
exisƟng laws.  


4 By leveraging their deep understanding of the industry, ﬁnancial regulators can develop 
targeted policies that address the unique risks and opportuniƟes associated with AI. This 
includes fostering innovaƟon in areas such as credit underwriƟng and fraud prevenƟon, while 
ensuring that AI applicaƟons do not compromise consumer protecƟon or ﬁnancial stability.  
Financial regulators should verify the adequacy and applicability of exisƟng requirements, and 
where relevant provide clarity on how to apply those rules in the context of AI. For example, 
regulators may consider updates to model risk management guidance to be more reﬂecƟve of 
bank operaƟons. While the exisƟng model risk management guidance has risk-based 
components, it contains a number of absolutes like the requirement for validaƟon. As such, the 
language should be clearer on the requirements (or lack thereof) for validaƟon for the lowest 
risk acƟviƟes. Further guidance could help banks diﬀerenƟate between high- and medium-risk 
AI use cases and issues and idenƟfy appropriate safeguards to use AI responsibly within the 
exisƟng risk framework. However, overly prescripƟve safeguards or prohibiƟons on the use of AI 
could become a barrier to valuable use cases if banks do not have appropriate ﬂexibility to test 
and adapt new AI tools. 
We have prioriƟzed engagement with our regulators on AI issues, especially recently as AI 
capabiliƟes have advanced. By working closely with industry stakeholders, regulators can foster 
an environment that supports the responsible development and deployment of AI technologies, 
thereby strengthening the United States' leadership in the global ﬁnancial sector. 
C. Importance of a Uniﬁed Federal Framework
Diﬀerences in regulatory approaches across jurisdicƟons result in increased complexity and 
compliance costs for banks and pose concerns for management of AI-related risks. While this is 
not unique to AI, the rapid evoluƟon of state-level legislaƟon, which ranges from 
comprehensive AI bills to a variety of regulaƟons addressing related topics, creates a 
signiﬁcantly more fragmented landscape for compliance with respect to AI. The expansion of 
the number of regulaƟons and regulators regulaƟng or seeking to regulate AI pose an addiƟonal 
layer of uncertainty and compliance costs for banks. In addiƟon, many banks operate customer 
branches across jurisdicƟons in the U.S., or globally, with addiƟonal customers beyond such 
physical footprint, which subjects banks to diﬀering legislaƟve and regulatory requirements, 
creaƟng compliance challenges. The need to determine how to comply with varying laws, and 
to understand their diﬀerences and impacts to banks’ businesses, results in heightened 
compliance and legal risks and increased compliance costs – in some instances, without 
corresponding risk management beneﬁts.  
As a result, diﬀerences in jurisdicƟonal approaches sƟﬂe innovaƟon and impede the successful 
rollout of safe and secure AI products and services in the ﬁnancial services sector, creaƟng 
cascading eﬀects for consumers who are unable to enjoy the beneﬁts that could be provided 
from the use of AI or the reducƟon of costs that could be passed on to consumers. In addiƟon, 
diﬀerent regulatory approaches may result in varying product and service availability across 


5 jurisdicƟons, resulƟng in consumer confusion as to what products and services are available to 
them, especially for those consumers who operate or live in mulƟple locaƟons. As such, 
consistency and certainty around AI and related data requirements across jurisdicƟons is 
imperaƟve to give banks the conﬁdence that they can build new products and services that 
meet the needs of consumers while not running afoul of a patchwork of domesƟc and 
internaƟonal requirements. To avoid the creaƟon of a patchwork of potenƟally inconsistent 
and/or contradictory state, local and sector-speciﬁc AI regulaƟons, U.S. lawmakers and federal 
regulators should clearly express their intent to exclusively occupy the ﬁeld in issuing AI-related 
standards and regulaƟon for banks. Any new laws, whether enacted at the federal, state or local 
level, that cover industries outside of banks should acknowledge the regulatory framework 
covering banks and provide enƟty-level exempƟons for banks that are already subject to 
supervision and exisƟng ﬁnancial law.  
D. Necessity of a Level Playing Field
The regulaƟon of AI in the ﬁnancial services sector should apply to any enƟty that uses AI to 
provide ﬁnancial services, not only banking organizaƟons. RegulaƟon that is consistent and 
comparable across enƟƟes that provide ﬁnancial services – banks and non-banks, new ﬁrms and 
incumbents, and large and small ﬁrms – will best protect consumers. Currently, only banks are 
subject to model risk management guidance from regulators, leaving non-banks that provide 
ﬁnancial services outside of such regulatory perimeters. Further, non-banks are not regularly or 
consistently supervised by federal regulators. For example, while non-bank lenders are subject 
to fair lending laws, these enƟƟes have no obligaƟon to follow model risk management in their 
use of AI for credit underwriƟng. A lack of consistent standards between banks and non-banks 
that provide ﬁnancial services puts consumers at risk by not aﬀording equal protecƟons to all 
consumers. 
To miƟgate such risks, non-banks that provide ﬁnancial services should be subject to similar 
requirements and oversight as banks with respect to their use of AI. This could be accomplished 
by the expansion of banking regulators’ ability to supervise these enƟƟes or through separate 
legislaƟon or regulaƟon. As noted by the OCC, “the prospect of banking being re-bundled by 
nonbank enƟƟes outside of the bank regulatory perimeter bears careful monitoring because of 
the ﬁnancial stability implicaƟons.” IrrespecƟve of the approach that is adopted, regulators 
should recognize and leverage exisƟng risk management frameworks and regulaƟons to which 
banks are subject to ensure appropriate and safe implementaƟon of AI across the ﬁnancial 
services industry. 
Third-party vendors must be integral partners in strengthening controls for a resilient AI 
ecosystem. This includes ensuring that third-party AI models and tools meet the same standards 
of safety, security, and accountability as those developed in-house. By establishing consistent 
standards across the industry, regulators can promote fair compeƟƟon and prevent regulatory 
arbitrage. 


6 A level playing ﬁeld is essenƟal for fostering innovaƟon and ensuring that consumers have 
access to high-quality ﬁnancial services. By promoƟng consistency and ensuring that non-bank 
enƟƟes, such as ﬁntech companies, are subject to the same regulatory requirements as 
tradiƟonal ﬁnancial insƟtuƟons, the government can enable the growth of a diverse and 
dynamic ﬁnancial services ecosystem, reinforcing the United States' posiƟon as a global leader 
in ﬁnancial innovaƟon and a leader in securing the safety and soundness of the global ﬁnancial 
system. 
III. General Tenets of OpƟmal AI Policies
As the U.S. government contemplates its approach to harnessing AI’s potenƟal, there are 
general policy principles that we believe promote posiƟve outcomes for businesses and 
innovaƟon across emerging technology issues.  
In parƟcular, we advocate for observing the following key tenets: 
Balancing Risk ReducƟon with InnovaƟon: RegulaƟons should not impose obstacles to
the cauƟous, risk-conscious adopƟon of AI. A risk-based approach allows for innovaƟon
while managing potenƟal risks. This includes encouraging the development of AI
soluƟons that enhance ﬁnancial inclusion and consumer protecƟon. By focusing on
outcomes rather than prescripƟve rules, regulators can create a ﬂexible framework that
supports the responsible use of AI technologies. Balancing risk reducƟon with innovaƟon
requires a nuanced understanding of the potenƟal beneﬁts and challenges of AI. By
adopƟng a risk-based approach, regulators can tailor their oversight to the speciﬁc risks
associated with diﬀerent AI applicaƟons. This includes considering factors such as the
complexity of the AI model, the sensiƟvity of the data being used, and the potenƟal
impact on consumers. By taking a proporƟonal approach, regulators can ensure that AI
regulaƟons are both eﬀecƟve and supporƟve of innovaƟon, thereby enhancing the
United States' compeƟƟve advantage in the global AI landscape.
Enabling Public-Private Partnership : Partnerships between regulators and private
insƟtuƟons is crucial for proacƟve issue resoluƟon. For example, we advocate for
partnerships that address AI-enabled fraud and cybersecurity threats, leveraging the
experƟse and resources of both sectors to develop eﬀecƟve soluƟons. Together,
regulators and industry stakeholders can work to idenƟfy emerging risks and develop
strategies to miƟgate them before they become systemic issues. By working with
industry stakeholders, regulators can gain insights into the pracƟcal challenges and
opportuniƟes associated with AI. This includes sharing best pracƟces, developing joint
iniƟaƟves, and creaƟng forums for dialogue. By building strong partnerships, regulators,
and industry stakeholders can work together to create a regulatory environment that
supports the responsible development and deployment of AI technologies, reinforcing
the United States' leadership in AI innovaƟon.


 
7 
  Pursuing Technology-Neutral, Performance-Based Approaches : Rather than regulaƟng 
speciﬁc technologies, governments should focus on the outcomes produced by AI or 
other algorithmic models to ensure they comply with applicable laws and other policy. 
This approach encourages innovaƟon and adaptability, allowing ﬁrms to choose the best 
tools and methods to achieve regulatory objecƟves. By focusing on performance rather 
than process, regulators can create a ﬂexible framework that supports the responsible 
use of AI technologies and enhance the United States' compeƟƟve advantage in the 
global AI landscape.  
 Ensuring a Risk-Based, ProporƟonal Approach: Government or regulatory requirements 
should align with the speciﬁc risks of each use case, ensuring that regulaƟons are not 
overly burdensome. This includes tailoring compliance obligaƟons to the size and 
complexity of the insƟtuƟon and the potenƟal impact of the AI applicaƟon. By taking a 
proporƟonal approach, regulators can ensure that AI regulaƟons are both eﬀecƟve and 
supporƟve of innovaƟon.  
 
IV. Recommended Features of a NaƟonal AI AcƟon Plan 
From our vantage as a proponent of innovaƟon, and as an industry-leading business with global 
reach, we have idenƟﬁed several components of the AI ecosystem that we believe will play an 
important role in advancing and sustaining U.S. leadership in the technology’s development, 
governance, and adopƟon.  These components would, in our view, be addiƟve to the 
government’s AI AcƟon Plan.  
A. Assert American Leadership to Promote HarmonizaƟon of InternaƟonal Regulatory 
Approaches to AI 
InternaƟonal regulatory harmonizaƟon is essenƟal for fostering innovaƟon and ensuring that 
U.S. businesses that deploy AI can operate globally. By contribuƟng to and collaboraƟng in 
internaƟonal and mulƟlateral seƫngs, the U.S. can support the development of adaptable 
standards and frameworks that promote consistency and interoperability across jurisdicƟons.  
The United States is uniquely posiƟoned to lead internaƟonal iniƟaƟves to develop consistent 
global standards, which can facilitate cross-border AI governance, reduce unnecessary 
compliance burdens for mulƟnaƟonal ﬁrms, and reinforce a global governance system for AI 
aligned to democraƟc values, in line with the prioriƟes of the last several U.S. presidenƟal 
administraƟons. This includes establishing or parƟcipaƟng in appropriate mulƟlateral forums, 
championing best pracƟces, and establishing joint iniƟaƟves with other governments. By 
facilitaƟng internaƟonal cooperaƟon, the U.S. can help create a cohesive regulatory 
environment that supports global businesses and reinforces the United States' leadership in the 
global AI landscape. As reﬂected in our last Annual Shareholder LeƩer, these same prioriƟes 
ensure that companies like JPMorganChase, a company that historically has worked across 


8 borders and boundaries, can do our part to ensure that the global economy is safe and secure—
and can conƟnue to play a forceful and essenƟal role in advancing economic growth.  
B. Fostering MulƟstakeholder Standards Development
MulƟstakeholder standards development is essenƟal for fostering innovaƟon and ensuring that 
AI technologies are used responsibly. By establishing world-leading collaboraƟve forums, the 
U.S. can drive and support the global development of technical standards and frameworks that 
shape the trajectory of these technologies for decades to come. 
As home to the world’s greatest and most innovaƟve technology companies, the United States 
is the intuiƟve home for such collaboraƟve eﬀorts. We are supporƟve, for example, of NIST's 
eﬀorts in developing AI standards and encouraging parƟcipaƟon from a diverse range of 
stakeholders, including industry, academia, and civil society. Through the development of a 
naƟonal AI AcƟon Plan, the government has an opportunity build on these eﬀorts and ensure 
this work remains anchored within the United States and informed by our leading AI innovators 
and our naƟonal interests and values.  
C. Maintaining American Leadership in Science and Technology Research and
Development
American scienƟﬁc research and development (R&D) is an investment in the endurance of our 
country’s global leadership in technology and AI.  By invesƟng in R&D, the U.S. can sustain the 
innovaƟon environment that has powered economic growth, expanded access to digital 
technology, and contributed to scienƟﬁc breakthroughs. JPMorganChase has beneﬁted from the 
fruits of mulƟdisciplinary, government-funded R&D investments, including through partnerships 
with leading research centers and the deployment of resulƟng innovaƟons.  
The AI AcƟon plan ideally will reﬂect the important role that R&D plays in securing American 
technological leadership—in a holisƟc investment strategy that supports not just foundaƟonal 
AI investment, but scienƟﬁc research and development across a range of related and necessary 
ﬁelds which will increasingly be impacted by AI (and necessary in shaping it). We are heartened 
by biparƟsan proposals to further these investments, including through eﬀorts to provide access 
to compute resources and datasets for researchers and startups, supporƟng the development of 
new AI technologies and applicaƟons, and promoƟng collaboraƟon and cooperaƟon among 
stakeholders. We believe such commitments will drive innovaƟon and maintain the U.S.'s 
compeƟƟve edge, ensuring that American ﬁrms remain at the forefront of AI development and 
that the U.S. remains a global leader in science and engineering.  
D. Securing NaƟonal AI Infrastructure
Securing naƟonal AI infrastructure will promote trust in AI systems, ensuring businesses and 
ciƟzens can leverage AI systems with conﬁdence, while miƟgaƟng threats to U.S. naƟonal 
security.  


9 The United States should extend its leadership in global cybersecurity standards to the 
emerging ﬁeld of arƟﬁcial intelligence. By aligning voluntary standards with exisƟng NIST 
frameworks like the Cybersecurity, Privacy, and AI Risk Management Frameworks (RMF), AI 
systems can be designed with strong safeguards against cyber threats and adversarial 
manipulaƟon. Enhanced collaboraƟon between government, industry, and internaƟonal 
standard-seƫng bodies will promote consistency across jurisdicƟons, prevenƟng regulatory 
fragmentaƟon and acceleraƟng the adopƟon of best pracƟces for AI security and reliability, 
parƟcularly in the ﬁnancial sector. AddiƟonally, supporƟng the industry-driven ﬁnancial sector 
proﬁle of the AI RMF can enable criƟcal infrastructure enƟƟes to eﬀecƟvely manage risk while 
deploying new technologies. 
As adversaries increasingly use AI to bolster cyberaƩacks and fraud, which threatens ﬁnancial 
stability, it is crucial to improve the sharing of threat intelligence related to AI-enabled aƩacks. 
This can be achieved with industry-speciﬁc informaƟon-sharing hubs and Sector Risk 
Management Agencies (SRMAs). In the ﬁnancial sector, regulators and security agencies should 
conƟnue exchanging Ɵmely insights on emerging AI-driven threats, such as AI-generated 
phishing scams and deepfake fraud. Strengthening cross-sector communicaƟons, facilitated by 
enƟƟes like the Department of Homeland Security (DHS), to share threat intelligence, aƩack 
paƩerns, and miƟgaƟon strategies will further help the ﬁnancial sector defend against AI-
enabled threats and enhance the resilience of criƟcal infrastructure.   
While advanced AI models have the potenƟal to reinforce American technological leadership, 
we recognize that in the wrong hands, advanced AI capabiliƟes can pose risks to U.S. naƟonal 
security. AI models can enable advanced military, intelligence, and oﬀensive cyber applicaƟons, 
lower the barriers to entry to develop weapons of mass destrucƟon (WMD), and assist in 
human rights violaƟons. To miƟgate these risks, a clear, consistent, and transparent export 
control framework is necessary to ensure that malicious overseas actors lack access to advanced 
hardware and closed-weight dual-use models. At the same Ɵme, export control policy must 
ensure that U.S. ﬁrms retain access to global markets and are able to reinvest in research and 
development to push the technological fronƟer forward.   
To support the growing demand for data centers, the AI AcƟon Plan should account for the 
importance of expanding America’s energy capabiliƟes. This may include biparƟsan eﬀorts to 
increase America's electrical capacity, expedite permiƫng processes, and promote a range of 
viable energy sources, including enhanced access to alternaƟve energy.  
E. Combaƫng the Threat of AI-Enabled Fraud and Scams
Advances in generaƟve AI and syntheƟc media have introduced new threats to customers 
outside of their tradiƟonal banking experience, and represent new threats to broad-scale 
consumer trust in the ﬁnancial system. These developments have moƟvated our signiﬁcant 
investment in mulƟstakeholder work addressing AI-enabled decepƟve content, and fraud and 
scams, including with relevant U.S. public and private sector partners. JPMorganChase is 


10 supporƟve of federal proposals to empower civil enforcement agencies to combat AI-enabled 
fraud, and our teams are working closely with lawmakers and law enforcement agencies to 
ensure bad actors can be held to account.  
Public-private partnerships are especially valuable in addressing risks to consumers that may 
stem from such fraudulent and abusive uses of AI. By working with private sector stakeholders, 
the U.S. can parƟcipate in the development of strategies to combat AI-enabled fraud and scams, 
leveraging the experƟse and resources of both sectors to develop eﬀecƟve soluƟons. In this 
context, we emphasize the importance of working with industry to establish robust training 
pracƟces for recognizing and miƟgaƟng AI-based fraud tacƟcs. AddiƟonally, it is vital to idenƟfy 
acƟons for U.S. and state governments to bridge the gap between physical and digital 
government credenƟals. This includes enabling the validaƟon of idenƟty informaƟon against 
government records and repositories to ensure safe, secure, and reliable transacƟons. 
Moreover, enhancing ﬁnancial insƟtuƟons' ability to trust and digitally validate government ID 
documents and other digital aƩributes during enrollment and authenƟcaƟon processes is 
essenƟal for strengthening security and trust in digital transacƟons. 
F. SupporƟng a Future-Ready American Workforce
SupporƟng a future-ready American workforce is criƟcal to the long-term success of our naƟon’s 
AI leadership. To ensure a skilled workforce, it is crucial to aƩract and retain top talent in AI and 
related ﬁelds, ensuring that the United States remains a global leader in technological 
innovaƟon. As AI shiŌs the nature and the rate at which job tasks transform, many workers will 
have to embrace lifelong learning to build skills to be resilient in the face of AI and other 
technological changes.  
In recogniƟon of these shiŌs, JPMC provides youth and adult apprenƟceships in areas including 
technology, business operaƟons, and ﬁnance, and our $350 million global workforce investment 
has enabled us to pilot new educaƟon and training programs and improve connecƟvity between 
among employers and educaƟonal insƟtuƟons. Leveraging insights from these investments, the 
ﬁrm is commiƩed to advancing a broad policy agenda  to promote lifelong learning and build worker digital resiliency.  This includes supporƟng the Workforce InnovaƟon and Opportunity 
Act (WIOA) reauthorizaƟon to strengthen the public workforce and Workforce Pell, which would 
allow Federal Pell Grants to be used for high-quality, short-term programs important for 
reskilling.  We look forward to working with policymakers to build upon the impact of these 
investments and develop addiƟonal strategies for maintaining a skilled and producƟve 
workforce.  
By developing training programs and partnering with educaƟonal insƟtuƟons, the U.S. can build 
a robust and adaptable workforce that is capable of meeƟng the challenges and opportuniƟes 
presented by AI. In addiƟon to invesƟng in workforce resilience, we urge the U.S. government to 
more broadly consider the potenƟal labor market and economic impacts of AI as it is scaled 
across the economy, including by invesƟng in foundaƟonal research to beƩer understand the 


11 current and potenƟal future implicaƟons of such transiƟons in support of informing supporƟve, 
evidenced-based policies.  
Strategic investments in human capital, workforce resilience, and overall health of the U.S. 
workforce and economy will not only drive economic growth but also ensure that the beneﬁts 
of AI are broadly shared across society. 
Concluding Statement  
JPMorganChase is commiƩed to supporƟng the development of a naƟonal AI strategy that 
fosters innovaƟon and ensures America’s conƟnued leadership in shaping these 
transformaƟonal technology systems.  
We are grateful for the opportunity to share our reﬂecƟons on ways that the AI AcƟon plan can 
advance the strategic interests of the United States, and promote regulatory frameworks that 
are adaptable, risk-based, and provide a level playing ﬁeld for innovaƟon and invenƟon. In 
addiƟon, by promoƟng internaƟonal cooperaƟon, invesƟng in research and development, and 
fostering public-private partnerships, the US can establish an environment that is favorable to 
businesses and organizaƟons deploying AI technologies in risk-conscious ways. 
We stand ready to work with the federal government and other stakeholders to ensure that the 
future of AI is one that enriches the communiƟes and customers we serve. Together, we can 
chart a path forward that secures American leadership in AI and drives sustainable growth and 
innovaƟon for years to come. 
We look forward to conƟnued engagement on these criƟcal issues. 
Sincerely, 
JPMorganChase & Co. 


