PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-yp6n-zq8d
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-5488
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: John Sweet  
General Comment
I am  subm itting this response to RFI 7555-01-P, which seeks input on the developm ent of an AI Action Plan for the United States. My
full com m ents are provided in the attached docum ent, where I offer inform ed perspectives on AI research infrastructure, workforce
developm ent, and innovation policy, drawing on m y experience in AI strategy, technology transfer, and innovation. I appreciate the
opportunity to contribute to this im portant national discussion.
Attachments
John Sweet - AI Action Plan Response (RFI 7555-01-P)


1 This document is approved for public dissemination. The document contains no business-
proprietary or confidential information. Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without 
attribution. 
Response to RFI 7555-01-P: 
Perspectives from an AI Strategist at Oregon State University 
I. IntroductionMy name is John Sweet, and I am writing in my individual capacity. I currently serve as 
Director of AI Administrative Strategy and Implementation at Oregon State University 
(OSU), but the views expressed in this response are my own and do not necessarily 
reflect the views of Oregon State University. 
By writing today, I hope to bring practical insights to these proceedings. The advice 
presented below arises through a long professional career dedicated to innovation 
strategy and technology commercialization with a special expertise in artificial 
intelligence and software innovation. With over two decades of experience in university-
based technology transfer, industry partnerships, and economic development, I have 
helped translate university research into real-world impact through intellectual property 
formation, startup creation, and industry collaboration. As Director of AI Administrative 
Strategy and Implementation at Oregon State University, I lead AI-driven initiatives in 
research administration, policy strategy, and workforce development, ensuring that 
university innovations contribute to national competitiveness. This experience informs 
my perspective on policies that strengthen United States AI leadership by expanding key 
research infrastructure, supporting industry commercialization pathways, and ensuring 
that federally funded research fuels economic and societal progress for our nation. 
As an R1 research-intensive institution, Oregon State University is one of only three 
universities in the United States to hold all four federal grant designations as a land, sea, 
space, and sun grant institution. These designations recognize OSU’s extensive research 
capabilities, deep commitment to education and public service, and global leadership in 
advancing scientific knowledge. OSU is among the top 1.4% of universities worldwide 
[1] and leads the State of Oregon in research funding.
OSU also serves as a model for how federal investment in research universities 
strengthens U.S. AI leadership. By advancing AI infrastructure, workforce development, 
and commercialization, OSU demonstrates the essential role of research institutions in 
securing America’s economic and national security future. 
With this response to RFI 7555-01-P, I aim to highlight the essential role that research-
intensive universities play in securing U.S. leadership in AI. The AI Action Plan should 
prioritize: 


2 •Expanding United States AI research infrastructure to ensure American
institutions remain globally competitive.
•Strengthening AI workforce development to secure a pipeline of top talent.
•Removing regulatory barriers to accelerate AI research, commercialization, and
startup growth.
II. Background
AI will reshape global power structures, influencing economic growth, military 
capabilities, and intelligence operations. But are we moving fast enough to stay ahead? 
The rapid adoption of AI by adversaries, particularly China and Russia, threatens U.S. technological superiority and national security. We believe that American research 
universities serve a critical role in countering these challenges, ensuring U.S. 
preeminence in AI by: 
•Driving foundational AI research that keeps the U.S. at the cutting edge of
technological breakthroughs.
•Educating and training the next generation of AI leaders, equipping them withthe skills to advance U.S. capabilities in both civilian and defense applications.
•Developing AI-powered defense and cybersecurity innovations, protectingU.S. infrastructure, intelligence operations, and national security interests.
•Partnering with industry and government agencies to translate research intoreal-world applications, accelerating AI deployment for strategic advantage.
Without sustained federal investment in university-based AI research infrastructure, 
workforce development, and commercialization, the U.S. risks falling behind in this 
critical race. A strong National AI Action Plan must recognize the indispensable role of 
universities in ensuring that America—not its adversaries—leads the next era of AI 
innovation. 
III. AI Research Infrastructure: Building a Foundation for U.S. AI Leadership
AI Policy Recommendations: 
•Expand NSF, DOE, and DoD funding for AI supercomputing and research
infrastructure at leading universities.
•Support the National AI Research Resource (NAIRR) to ensure universities andstartups have shared access to AI computing power and datasets needed for the
development of new models and applications using AI.
•Prioritize federal funding for research that leverages AI-driven innovation,enabling AI to augment, automate, and accelerate scientific discovery across
disciplines.


3 Reasoning: 
High-performance computing and AI research facilities are critical national assets. The 
United States should promote its AI research capacity to remain competitive. 
The Jen -Hsun Huang and Lori Mills Huang Collaborative Innovation Complex 
(HCIC) at OSU will house one of the nation’s most advanced AI-optimized 
supercomputers. This facility serves as a model for AI research infrastructure. Like all 
research infrastructure, it will depend on a vibrant and well-funded research system to 
maximally drive scientific discovery, support breakthrough AI innovations, and ensure 
that U.S. universities remain the epicenter of global AI leadership. Federal investment in 
AI research facilities and long-term funding commitments will be critical to sustaining 
this leadership and accelerating America’s AI competitiveness. 
The A-Lab at Lawrence Berkeley National Laboratory has demonstrated how 
autonomous AI labs can accelerate materials discovery [2]. The SAMPLE platform at the 
University of Wisconsin-Madison has demonstrated how autonomous AI-driven 
laboratories can accelerate protein engineering by independently exploring and 
optimizing protein properties [3]. The Virtual Lab project at Stanford University 
demonstrated that AI agents can autonomously design and optimize SARS-CoV-2 
nanobodies [4]. Google’s AlphaFold demonstrated the value of AI-driven innovation to 
accelerate protein discovery, leading the Royal Swedish Academy of Sciences in 2024 to 
award to David Baker, Demis Hassabis, and John Jumper the Nobel Prize in Chemistry 
[5]. OSU has posited an Autonomous Protein Discovery and Synthesis (AutoPDS) Lab 
envisioning increasing automation in scientific discovery leveraging the HCIC and other 
resources at OSU for protein research. Federal support for such initiatives will ensure AI-
driven research remains U.S.-led. 
China's aggressive support for AI research through its universities is evident in its 
national strategies, increases in funding, expansion of educational programs, talent 
recruitment programs, establishment of specialized research institutions, and integration 
of technology into large-scale national projects. These efforts collectively enhance 
China's position in the global AI landscape. The U.S. should plan to match and exceed 
China’s commitment to AI research and education, ensuring that American universities 
remain at the global epicenter for AI innovation. 
IV. AI Workforce Development: Strengthening America’s Talent Pipeline
AI Policy Recommendations: 
•STEM Immigration Reform.  America has long been the destination for the
world's brightest minds, attracting top talent in AI and STEM fields to our
universities. However, to maintain U.S. leadership in artificial intelligence and
critical technologies, we must ensure that these highly skilled PhD graduates stay


4 in America to contribute to our economy, innovation ecosystem, and national 
security. Currently, too many foreign-born AI PhD graduates-trained in U.S. 
universities with American resources and taxpayer funding-are forced to leave 
due to outdated immigration policies. Meanwhile, China and other strategic 
competitors aggressively recruit AI talent, offering immediate residency and 
incentives to return home. The U.S. cannot afford to train the next generation of 
AI pioneers only to lose them to global rivals. 
•Fellowships for AI-Focused PhD Training.  We should establish new federally
funded initiatives aimed at increasing the number of AI-trained PhDs in key
technical fields to ensure U.S. leadership in artificial intelligence, semiconductors,
energy, and other national security-relevant domains. Initiatives centered in the
National Science Foundation (NSF) in partnership with the Department of Energy
(DOE), the Department of Defense (DoD), and the National Institute of Standards
and Technology (NIST) could provide competitive fellowships, research grants,
and AI-centric doctoral program development funds to U.S. universities to
dramatically scale AI PhD production in areas of strategic importance.
Reasoning: 
The National Security Commission on AI (NSCAI) warns that “for the first time in our 
lifetime, the United States risks losing the competition for talent on the scientific 
frontiers” [6]. While U.S.-born participation in STEM doctoral programs has stagnated 
since 1990, China has consistently expanded its talent pipeline. In 2019 alone, Chinese 
universities awarded 49,498 STEM PhDs compared to 33,759 in the U.S., with trends 
suggesting an even greater gap in the coming years [7]. 
Private industry currently funds and performs close to 80% of R&D in the United States 
[8], yet the majority of the innovators conducting that research were originally trained at 
American universities—institutions largely supported by federally sponsored research 
and education programs. This makes continued federal investment in university-led AI 
research essential to maintaining U.S. technological leadership. 
Oregon State University exemplifies this pipeline. Jensen Huang, CEO of NVIDIA and 
OSU alumnus, is a prime example of how U.S. universities help to produce world-
changing technology leaders [9]. The innovations Huang has led at NVIDIA, particularly 
in GPU computing, have enabled the AI revolution as we now know it [10]. Without 
strong university-led AI education, tomorrow’s next generation of pioneers and 
innovators will not have the foundation necessary to sustain America’s global leadership 
in AI – and in whatever greater future lies beyond. 
To fully leverage AI talent, the U.S. must ensure that research-driven innovations 
transition seamlessly from universities to commercial and industrial applications. This 
requires a regulatory environment that supports AI startups, protects intellectual property, 
and fosters industry partnerships, as detailed in the following section. 


5 V. AI Commercialization: Reducing Barriers to AI Startup Growth
AI Policy Recommendations: 
•Streamline reporting and compliance regulations to remove bureaucratic obstacles
for university-developed intellectual property dedicated to university-led AI
startups, especially for projects involving software and data commercialization.
•Expand SBIR/STTR funding for AI startups emerging from university research.
•Encourage AI-industry-university partnerships to accelerate AI commercialization
and scale innovations.
•Promote, but not require, open-source AI models in dual-use systems to enhancetransparency, national security, and competitiveness.
•Establish clear liability protections for foundation model developers, similar toDMCA safe harbor provisions, to ensure AI innovation can progress without
undue copyright risk.
Reasoning: 
Universities serve as critical innovation hubs, producing high-impact AI-driven startups. 
In Oregon State University’s recent experience, OSU can point to several of its startups 
that might be viewed as “national assets” from a policy perspective, including: 
•Inpria  (Semiconductors): Developing next-generation materials for AI chip
manufacturing, enabling smaller, more efficient, and powerful AI chips.
•Agility Robotics (AI-Driven Robotics): Creating humanoid robots for industrial
automation, logistics, and human-machine collaboration.
•NuScale Power (AI-Energy Infrastructure): Pioneering modular nuclearreactors that can provide scalable energy solutions for AI-driven data centers.
To maximize the success of AI commercialization, strong university-industry 
partnerships must be fostered. These partnerships allow for the co-development of AI technologies, integration of real-world business challenges into academic research, and 
direct talent pipelines from universities to AI startups. Expanding public-private research 
consortiums will strengthen America’s competitive edge in AI innovation. 
Commercial investment in AI and emerging technologies depends critically on the 
availability of intellectual property that is free from excessive regulatory burdens, march-
in rights uncertainty, and compliance challenges. Universities must retain the ability to 
manage and commercialize federally funded research under the principles of the Bayh-
Dole Act, which has successfully driven technology transfer and innovation for over four 
decades. Any proposals to expand march-in rights should be rejected in favor of 
protecting the property rights essential for attracting investment and fostering innovation. 


6 Additionally, open-source AI should be encouraged in dual-use systems to support 
national security objectives while promoting innovation. As I noted earlier (see Section 
VI) open-source AI allows for broader inspection of model architectures, enhancing trust
and security. Public scrutiny can uncover potential vulnerabilities or embedded bias es
that might otherwise go unnoticed in proprietary systems, strengthening the reliability ofAI models deployed for defense and critical infrastructure.
Finally, regarding liability protections, the absence of clear liability protections creates 
uncertainty for AI developers, particularly in regard to training data and potential 
copyright claims. Foundation model developers require clear, predictable guidelines to 
ensure AI innovation can progress without undue copyright risk. Just as DMCA safe 
harbor provisions enabled ISPs, search engines, and streaming content providers to 
flourish, similar protections should apply to AI models trained on publicly available data. 
Without legal clarity, U.S. AI startups face greater risk and uncertainty than global 
competitors, potentially driving innovation offshore. A balanced approach in the AI 
Action Plan can support commercialization while maintaining appropriate safeguards for 
content owners, ensuring that the U.S. remains the global leader in AI. 
VI. AI for National Security and Economic Strength
AI Policy Recommendations: 
•Expand DoD and DARPA AI research grants for universities to maintain U.S. AI
leadership in robotics, defense applications, and other applications of AI.
•Invest in AI energy infrastructure, including nuclear SMRs, to sustain AI-driveneconomic growth.
•Expand resources for DARPA’s Explainable AI (XAI) program to ensure AIsystems remain transparent, controllable, and aligned with national security
objectives.
•In government procurement of AI systems, encourage the adoption of open-source foundation models (e.g., Meta’s LLaMA AI) to benefit from public
scrutiny, enhanced security, and accelerated innovation. In sensitive defense and
intelligence applications, selectively preserve proprietary controls when
transparency would pose unacceptable risks to the protection of classified
information.
•Preserve university autonomy in managing federally funded research IP byupholding the Bayh-Dole Act’s principles to support AI commercialization and
innovation.
Reasoning: 
AI is foundational to national security, supporting applications such as cybersecurity, 
autonomous defense systems, and intelligence operations. However, as AI takes on 


7 increasingly critical roles in national defense, ensuring explainability, security, and 
energy resilience must become policy priorities. 
Federal investment in DARPA and DoD AI research grants can help maintain the 
U.S. lead in AI-driven defense technologies, including autonomous military systems, 
cyber defense, and AI-powered intelligence analysis. Sustained federal investment in 
university-led AI research will ensure that the U.S. remains at the cutting edge of 
innovation. 
Energy is critical to AI infrastructure. Large-scale AI systems require massive 
computational power, and the energy demands of AI models are expected to grow 
exponentially in the coming years. Nuclear small modular reactors (SMRs) offer a 
scalable, reliable energy source that enhances national security by reducing dependence 
on foreign energy and increasing resilience. OSU’s NuScale Power, a leading SMR 
developer, can strengthen AI infrastructure by enabling decentralized, fault-tolerant 
energy distribution, minimizing systemic risks from cyber and physical attacks. By siting 
SMRs near AI data centers and critical installations, the U.S. can bolster security and 
ensure the operational continuity of AI systems essential to defense and intelligence. 
Research Into Explainability in AI Is a National Priority. Without a clear 
understanding of how AI systems make decisions, there is a risk that their vulnerabilities 
could be more acute than expected. [ See Figure 1.] Expanding DARPA’s Explainable AI 
(XAI) program will enhance the ability to inspect, verify, and understand AI decision-making processes before they are deployed in military or other high-stakes environments. 
This will ensure that AI remains a tool that serves human decision-makers, rather than 
operating autonomously beyond oversight. 
Figure 1. Why Explainability in AI is Essential: 
Image Credit: https://www.darpa.mil/research/programs/explainable-artificial-
intelligence 


8 Promotion of Openness as a Path to National Security. Openness in AI systems can 
strengthen national security by enabling greater transparency and greater external 
validation of AI systems, buttressing research into Explainability in AI. Though openness 
in AI might appear to increase vulnerability, it actually bolsters national security by 
inviting continuous public inspection, proactively revealing vulnerabilities or potential 
exploits that might otherwise remain hidden until exploited by adversaries. The risks 
associated with AI opacity – including adversarial manipulation and emergent deception 
– underscore the critical need for openness, particularly in defense and intelligence
applications.
AI vulnerabilities fall into two categories that threaten the alignment between an AI 
model’s objectives and the interests of the people it was designed to serve: 
•Intentional manipulation: Adversaries exploit system vulnerabilities using
techniques such as prompt injection [11] to override constraints and hijack
outputs.
•Emergent deception: AI systems can independently develop deceptive strategiesto optimize unseen or obscure objectives, even without explicit design. Recent
research (published in January of this year) demonstrates that, under certain
conditions, AI models may strategically manipulate resources and outputs, evade
detection, resist external controls, and even misrepresent past actions [12],
resembling principal-agent problems previously observed only in human decision-
making [13].
Unlike adversarial manipulation, which originates externally, in-context scheming arises 
internally through the AI’s learning process and environmental context. The risk of 
scheming and hiding ulterior motives – and, more generally, the challenges of achieving 
alignment – will only rise as AI systems assume greater capabilities and sophistication. 
Proprietary AI models may obscure both types of vulnerabilities, making them more 
difficult to assess and mitigate. This is why open-source AI models can enhance security 
and trustworthiness. It is also why, as I mentioned before, the AI Action Plan should 
continue to support research into Explainable AI (XAI). 
Balancing Openness with Proprietary Protections. While open-source practices 
enhance reliability and security through community oversight, certain sensitive defense 
and intelligence applications require proprietary controls. A nuanced approach—leveraging open-source foundation models for general-purpose or foundational AI 
components while preserving proprietary layers for strategically sensitive systems—can 
protect classified information and operational integrity. This balanced model maximizes 
transparency benefits without compromising national security. 
Broader Economic and Innovation Benefits of Openness. More generally, open-source 
AI promotes faster innovation, greater industry collaboration, and competitive advantage 
by enabling a broader ecosystem of researchers and developers to improve, secure, and 


9 build upon foundational AI systems. Encouraging open-source practices positions the 
U.S. AI industry as a leader. 
VII. AI as an Embedded Scientific Collaborator: The Future of AI-Driven
Discovery
Policy Recommendations 
•Prioritizing Federal Funding for AI-Integrated Research:  Federal agencies
should prioritize funding for AI-integrated research, ensuring AI is leveraged in
all fields of discovery.
•Establishing AI-Focused Federal Research Centers:  The Department of
Energy (DOE), the National Science Foundation (NSF), and the National
Institutes of Health (NIH) should establish dedicated AI-focused research centers
to accelerate breakthroughs in materials science, energy, and life sciences.
•Developing Best Practices for AI-Driven Research Integrity:  The NationalInstitute of Standards and Technology (NIST) should develop best practices andguidelines for AI-driven research for the purpose of ensuring reliability,
reproducibility, and transparency in AI-generated scientific findings.
•Advancing Autonomous Research Laboratories at Universities:  The federal
government should support the development of autonomous research laboratories
at universities, equipping them with high-performance computing and robotics
infrastructure to enable AI-driven experimentation at scale.
•Ensuring Patent Protection for AI-Generated Inventions: AI-generatedinventions should be eligible for patent protection, even in cases where a humandoes not make a direct inventive contribution. Ensuring patentability will drive
investment in AI-directed research systems that can accelerate scientific discovery
and help maintain America's lead in research.
Reasoning: 
AI as an Active Scientific Collaborator: Recent advancements have shown that AI is 
not just a tool for researchers but an active scientific collaborator capable of hypothesis 
generation, experimental design, and self-directed discovery. As I mentioned before, 
Google DeepMind’s AlphaFold has revolutionized protein structure prediction, solving a 
biological challenge that had eluded scientists for decades. Similarly, this year the Google 
AI Co-Scientist demonstrated that AI can propose, test, and refine hypotheses faster than 
traditional research methods [14]. Last year, researchers at MIT found that AI-assisted 
researchers discover 44% more materials, resulting in a 39% increase in patent filings 
[15]. These breakthroughs indicate that AI will continue to expand the frontiers of 
scientific discovery by handling repetitive research tasks, identifying unexplored 
directions, and optimizing experimental conditions in ways that human researchers 
cannot do alone. 


10 Autonomous Laboratories and AI-Driven Experimentation: The emergence of 
autonomous laboratories – where AI directs both computational modeling and physical 
experimentation – marks a paradigm shift in scientific discovery. As I indicated above, 
the A-Lab at Lawrence Berkeley National Laboratory has already synthesized novel 
materials at a fraction of the time required by traditional experimental techniques. Google 
DeepMind CEO Demis Hassabis has compared the work of AlphaFold AI to billions of 
years of PhD research, calling this effect “science at digital speed” [16]. These 
developments underscore a fundamental reality: AI-driven research is no longer 
speculative – it is already producing transformative results, and its influence will only 
grow. 
Given the sheer velocity and compounding effects of AI-powered innovation, it should be 
clear by now that federal investment in AI-powered research platforms will be vital to 
maintaining American leadership in science and technology.  Expansion of funding for 
high-performance AI experimentation facilities, as well as funding for AI-adjacent research and education, will enable researchers to unlock new scientific principles faster, 
drive innovation across multiple domains, and enhance U.S. competitiveness in emerging 
industries. 
Patentability of AI-Generated Inventions: As AI systems become increasingly capable 
of generating novel solutions with minimal human intervention, the current restrictions 
on patentability for AI-generated inventions pose a direct threat to investment in AI-
driven research. Under current U.S. Patent and Trademark Office (USPTO) guidelines, 
an invention must have at least one human inventor making an inventive contribution. 
This means that entirely AI-generated discoveries are ineligible for patent protection, 
potentially suppressing private-sector investment in AI research systems that could 
otherwise transform science and industry. 
If the U.S. fails to adapt its patent system to accommodate AI-generated inventions, 
investors and research institutions may shift or delay their focus away from AI-driven 
discovery, fearing an inability to secure intellectual property rights. This could cause the 
U.S. to fall behind other nations that adopt more flexible frameworks for AI-generated 
innovation. 
Patent protection uniquely incentivizes private-sector investment by providing a clear, 
predictable pathway for securing returns. It creates an environment of certainty for 
investors, directly encouraging the commercial investment necessary to advance AI-
driven research at scale. 
VIII. Conclusion and Call to Action
The United States stands at a pivotal moment in artificial intelligence, where federal 
policy decisions will shape the nation’s ability to maintain its leadership in AI research, 
workforce development, and commercialization. Research universities, including Oregon 


11 State University, are critical to ensuring that the U.S. remains at the forefront of AI-
driven innovation. As this response has detailed, sustaining America’s AI dominance 
requires targeted federal investments in research infrastructure, workforce expansion, and 
commercialization pathways. 
Key Priorities for the National AI Action Plan: 
•Universities as AI Innovation Hubs: The National AI Action Plan must
prioritize research universities as the foundation of American AI leadership.
Federal agencies must support cutting-edge AI research, recognizing that
university-led breakthroughs drive industry advancements and national security
capabilities.
•Investment in Infrastructure and Workforce Development: The federalgovernment must expand AI research infrastructure through sustained funding for
high-performance computing, autonomous research laboratories, and national AI
research resources. Workforce shortages in AI must be addressed through
expanded STEM education programs, AI PhD fellowships, and immigration
policies that retain top AI talent trained at U.S. institutions.
•Reducing Barriers to AI Commercialization: Regulatory clarity is essential toensure that AI startups can thrive in the U.S. market. Streamlining compliance
burdens, protecting university-managed intellectual property, and increasing
SBIR/STTR funding will foster AI commercialization, allowing research
institutions to drive economic growth.
•Ensuring AI Security and Explainability: The U.S. must take the lead in
explainable AI (XAI) research and open-source AI practices to secure national AIsystems from adversarial threats. Expanding DARPA’s XAI program and
encouraging public scrutiny of government AI models will ensure that AI remains
accountable, trustworthy, and aligned with American values.
Commitment to AI Leadership: 
Oregon State University remains committed to advancing AI research, training the next 
generation of AI leaders, and translating research innovation into societal impact. As the 
federal government crafts the National AI Action Plan, we urge policymakers to adopt 
these recommendations to ensure that the United States – not its adversaries – remains the 
global leader in artificial intelligence. 


12 __________________________ 
Selected References: 
[1] Center for World University Rankings (CWUR), "Oregon State University Ranking
(2024)," 2024. Available at: https://cwur.org/2024/oregon-state -university.php.
(Accessed: 13-Mar -2025).
[2] N. J. Szymanski et al., "An autonomous laboratory for the accelerated synthesis ofnovel materials," Nature, vol. 624, pp. 86–93, Dec. 2023, doi: 10.1038/s41586-023-
06734-w.
[3] J. T. Rapp, B. J. Bremer, and P. A. Romero, "Self-driving laboratories toautonomously navigate the protein fitness landscape," Nature Chemical Engineering, vol.
1, pp. 97–107, Jan. 2024, doi: 10.1038/s44286-023-00002-4.
[4] K. Swanson, W. Wu, N. L. Bulaong, J. E. Pak, and J. Zou, “The Virtual Lab: AIAgents Design New SARS-CoV-2 Nanobodies with Experimental Validation,”  bioRxiv,
Nov. 2024. doi: 10.1101/2024.11.11.623004.
[5] The Nobel Committee for Chemistry, " Scientific Background to the Nobel Prize in
Chemistry 2024: Computational Protein Design and Protein Structure Prediction,"
Royal Swedish Academy of Sciences, Stockholm, Sweden, Oct. 2024. Available at:
https://www.nobelprize.org/uploads/2024/10/advanced-chemistryprize2024.pdf
[6] National Security Commission on Artificial Intelligence, “Final Report (See Chapter
10: The Talent Competition, pp. 171–182),” National Security Commission on ArtificialIntelligence, 2021. Available at: https://reports.nscai.gov/final-report/chapter-10.
[7] R. Zwetsloot, J. Corrigan, E. Weinstein, D. Peterson, D. Gehlhaus, and R. Fedasiuk,
"China is fast outpacing U.S. STEM PhD growth," Center for Security and Emerging
Technology (CSET), Data Brief, Aug. 2021. Available:
https://cset.georgetown.edu/publication/china-is-fast-outpacing-u-s-stem -phd-growth/.
[8] National Science Board, " Invention, Knowledge Transfer, and Innovation," Science &
Engineering Indicators 2024 (NSB-2024-1), Feb. 29, 2024. Available at:https://ncses.nsf.gov/pubs/nsb20241.
[9] J.-H. Huang, Engineering Hall of Fame - 2013, College of Engineering, Oregon State
University, 2013. Available at: https://engineering.oregonstate.edu/alumni-
partners/oregon-stater -awards/searchable-awards-database/jen-hsun-huang-engineering-
hall.
[10] T. S. Perry, "Move Over, Moore’s Law: Make Way for Huang’s Law," IEEE
Spectrum, Apr. 2, 2018. Available at: https://spectrum.ieee.org/move-over-moores-law-
make-way -for-huangs-law.


13 [11] Z. Shao, H. Liu, J. Mu, and N. Z. Gong, “Making LLMs Vulnerable to Prompt
Injection via Poisoning Alignment,” arXiv preprint arXiv:2410.14827, Oct. 2024.
Available: https://arxiv.org/abs/2410.14827.
[12] A. Meinke, B. Schoen, J. Scheurer, M. Balesni, R. Shah, and M. Hobbhahn,
"Frontier models are capable of in-context scheming," arXiv preprint arXiv:2412.04984,
Jan. 2025. Available at: https://arxiv.org/abs/2412.04984.
[13] S. A. Ross, “The economic theory of agency: The principal’s problem,”  Amer.
Econ. Rev., vol. 63, no. 2, pp. 134–139, 1973. [Online]. Available:https://www.aeaweb.org/aer/top20/63.2.134-139.pdf.
[14] J. Gottweis, W.-H. Weng, A. Daryin, T. Tu, A. Palepu, P. Sirkovic, et al.,
“Accelerating scientific breakthroughs with an AI co-scientist,” Google Research, 2025.
Available at: https://research.google/blog/accelerating-scientific-breakthroughs-with -an-
ai-co-scientist/.
[15] A. Toner-Rodgers, "Artificial Intelligence, Scientific Discovery, and ProductInnovation," presented at the NBER Labor Studies Program Meeting, Nov. 4, 2024.
Available at: https://conference.nber.org/conf_papers/f210475.pdf
[16] L. Beliūnas, "Google DeepMind’s CEO Demis Hassabis says AlphaFold AI has
performed the equivalent of a billion years of PhD research," LinkedIn Post, Mar. 11,
2025. [Video.] Available at: https://www.linkedin.com/posts/linasbeliunas_google-
deepminds-ceo-demis-hassabis-says-ugcPost-7305182011512492032-UesN/ . Accessed:
Mar. 12, 2025. 
#eof# 


