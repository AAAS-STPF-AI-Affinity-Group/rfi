 
   3/12/2025 via FDMS  
Andrew Dorph   
To Whom It May Concern, I am submitting this comment in response to the Request for 
Information (RFI) on the development of the Artificial Intelligence (AI) Action Plan, with a 
specific focus on the use, storage, and replication of actors’ and broadcasters ’ images, likenesses, 
and biometric data. As AI technologies advance, it is imperative that the AI Action Plan 
incorporates robust protections for these individuals, drawing on existing legislative efforts to 
address the intersection of artificial intellig ence, data privacy, and intellectual property rights. 
**Actors' and Broadcasters' Image and Likeness Protection:** The rapid evolution of AI has 
made it increasingly feasible to replicate and manipulate the images, voices, and likenesses of 
actors, broadca sters, and other public figures, often without their consent. These attributes are 
not only integral to their professional identities but also critical to their livelihoods. Existing 
legislative efforts, such as California’s AB 2602 (signed into law on Sep tember 17, 2024), 
provide a strong foundation by requiring explicit consent and detailed contractual specifications 
for the use of AI -generated digital replicas of a performer’s voice or likeness. Similarly, the 
federal “Nurture Originals, Foster Art, and Keep Entertainment Safe Act” (NO FAKES Act), 
introduced in the U.S. Senate in July 2024 and the House in September 2024, aims to establish a 
property right over digital replicas, holding individuals and platforms liable for unauthorized use. 
I urge the AI Action Plan to build on these measures by mandating consent for any AI -generated 
use of likenesses —whether in entertainment, advertising, or beyond —and by implementing 
safeguards to prevent misuse, ensuring individuals retain autonomy over their image, voi ce, and 
persona. **Biometric Data Usage and Privacy:** The proliferation of AI -driven technologies, 
such as facial recognition and voice synthesis, has heightened the risks associated with biometric 
data collection, storage, and replication. This highly se nsitive data can be exploited, threatening 
individuals’ privacy, safety, and dignity. Tennessee’s Ensuring Likeness Voice and Image 
Security (ELVIS) Act, effective July 1, 2024, explicitly protects an individual’s voice as a 
property right, offering a mode l for addressing biometric data in AI contexts. Additionally, 
California’s AB 1836 (signed into law on September 17, 2024) extends posthumous protections 
by prohibiting unauthorized commercial use of deceased performers’ digital replicas without 
estate con sent. The AI Action Plan should adopt and expand upon these precedents by 
establishing stringent regulations for biometric data, including robust security measures to 
prevent unauthorized access, clear rights for individuals to access and revoke consent fo r its use, 
and mandates for data deletion when no longer needed. **Transparency and Accountability:** 
Transparency is a cornerstone of ethical AI deployment. Actors and broadcasters must be 
informed about how their biometric data, images, and likenesses ar e utilized in AI systems. The 
federal “Content Origin Protection and Integrity from Edited and Deepfaked Media Act” 
(COPIED Act), introduced in July 2024, exemplifies this principle by requiring provenance data 
to identify AI -generated content, empowering creators to track and control its use. Organizations 
leveraging such data should be held accountable through clear guidelines on AI model training 
and data sourcing, as well as regular audits to ensure compliance with privacy laws and ethical 
standards. Th e AI Action Plan should integrate these accountability mechanisms to foster trust 
and responsibility in AI development. **Conclusion:** The AI Action Plan must prioritize 
comprehensive protections for actors, broadcasters, and others whose images and biome tric data 
are implicated in AI technologies. By drawing on existing bills —such as California’s AB 2602 


 
   and AB 1836, Tennessee’s ELVIS Act, and federal proposals like the NO FAKES Act and 
COPIED Act —policymakers can craft a framework that safeguards individual rights, ensures 
privacy, and promotes ethical AI innovation. I appreciate the opportunity to contri bute to this 
vital discussion and strongly encourage the inclusion of these measures in the AI Action Plan to 
address the challenges posed by AI in a rapidly changing digital landscape.  
 


