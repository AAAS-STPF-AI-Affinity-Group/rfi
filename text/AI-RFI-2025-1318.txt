PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 88-txwe-8lkk
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1318
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Kai Mich lmayr 
General Comment
There are m any dangerous applications for AI that seem s to be being ignored for the interest of ego. What about the scam  calls that use
AI generated voices to trick people into thinking their loved ones are in trouble? What about AI generated deep fakes that could lead
people to believe an individual had done som ething when the "evidence" is a com pletely fabricated video? What about all of the artwork
that has been stolen without perm ission from  artists to train generative AI m odels? Why don't we focus on the security of the Am erican
people and our allies abroad from  the harm ful uses of AI before we rush ahead and let the people suffer until it's too late and too difficult
to place regulations and protections? The urge of progress needs to be balanced with caution, otherwise we risk great harm  to a great
m any people. Protect the people, artists, and the environm ent first before rushing head first to stroke ones ego.


involvement of universities  like Florida State, these benefits  might be foregone by innovations  in 
the venture -capital -driven  private sector.  
Substantial funding and support for AI research should be considered for research institutions 
via traditional methods such as the National Science Foundation (NSF) and the Defense 
Advanced Research Project s Agency  (DARPA) . However, in times of competing funding 
choices, universities are well situated for  private -public partnerships for AI innovation. Over the 
past few decades , universities such as Florida State have focused on relevant research that 
impacts society throughout the life cycle of product and technology development.  Universities 
have been playing an increasingly vital role in patents and other commercialization activities . 
Finally, public universities act as the training ground for tomorrow's workforce, so increased 
hands -on opportunities with the technologies of tomorrow will enable a more competitive and 
effective workforce. As examples, DARPA grant programs often use public research universities 
as ‘red teams’ to serve as reliability and robustness checks on larger, often private, innovation 
efforts. Further, many NSF programs, such as SBIR, have training and education components 
that further the impact of grant funding. Such p rograms  should continue to flourish to ensure AI 
is not only a successful technology but a useful product to drive American economic success.  
Specific Recom mendations  
Recommendation 1: Develop Clear  Vision, Objectives , and Frameworks.  
The first major step in establishing an AI Action Plan is to define the overarching goals and long-
term vision for AI in the US, recognizing the present landscape upon which to build. This 
involves setting specific, measurable, achievable, relevant, and ti me-bound (SMART) objectives 
that align with national interests. The vision should encompass scientific advancement, health and medical discoveries, economic growth, national security, societal well -being, and global 
harmony.  Additionally, a comprehensive regulatory and policy framework is necessary to govern 
AI development and deployment. This includes creating guidelines for AI use in critical sectors, establishing standards for AI safety and performance, and addressing legal and liability issues. 
The framework should be flexible to adapt to the rapidly changing AI landscape.  
Positioning AI in Human- AI Collaboration – G uardrails  and Frameworks  
In an era where artificial intelligence (AI) is rapidly transforming various sectors, developing 
comprehensive guidelines, resources, and toolkits that focus on responsible AI integration is 
crucial . These resources should include motivating and guiding questions that address where, 
how, and why AI is used and augmented. By doing so, we can ensure that AI is implemented 
thoughtfully and ethically, as described below : 
•Develop open- source frameworks and toolkit s – essential to fostering a deeper
understanding of AI and its applications . These tools can help create communities of
practice among educators and students, enabling them to harness AI's power  while also
recognizing its limitations. We can empower the next generation of AI practitioners by
promoting collaboration and knowledge sharing .


•Refram e AI as a service.  By shifting the mindset towards AI and democratizing AI
products, we can involve a wider range of users in the development and pilot testing
phases. This user -centered approach ensures that AI designs are aligned with the goals
and needs of the users, leading to more effective and accessible AI solutions.
•Prioritiz e the deve lopment of fundamental science for large AI models and the
engineering techniques required to implement them.  Understanding the
mechanisms of AI models is essential for achieving long- term dominance in the field.
While the principles of current AI models, such as gradient descent optimization, are wellunderstood, the semantics of the representation space need fu rther exploration. Gaining
insights into the structures of the representation space is crucial for many applications.
•Develop better al gorithms and new model architectures.  For instance, the published
reinforcement learning algorithm in DeepSeek models shows potential, but it does not
address many fundamental problems correctly. As demonstrated by the super -human
performance of AlphaGo algorithms in the game of Go, correctly  implemented
reinforcement learning algorithms can lead to significant improvements in various
applications.
•Shar e datasets and know -how tricks- of-the-trade to unleash the potential of
universities and research institutions. By facilitating access to valuable resources
and expertise, we can accelerate the pace of AI innovation and discovery.
Recommendation 2 : Invest  in Research and Development to Ensure Innovation  and 
Competitiveness .  
The US should encourage innovation by supporting research and development in AI while also ensuring that regulations do not stifle technological advancements . A strong commitment to 
R&D is crucial for maintaining innovation in AI. The government should allocate substantial funding to AI research, encourage public -private partnerships, and support academic institutions 
and AI programs within these institutions. Fostering a vibrant research ecosystem will drive breakthroughs in AI technologies and applications, while cultivating future users and leaders in 
the field.  
AI in Medicine to Promote Enhanced Public Health 
AI is emerging as a transformative force in the field of medicine, presenting unprecedented 
opportunities to enhance patient care, streamline clinical processes, and improve outcomes. As 
AI technologies continue to advance, their integration into healthcare sys tems across the US 
promises to advance  medical practice  and therefore improve  overall health outcomes.  Some 
areas that have seen large potential gains  are in enhancing diagnostic accuracy  with such tools 
as AI-powered imaging systems and the use of machine learning algorithms  where AI can 
analyze huge amounts  of medical data extremely fast and accurately. Personalized medicine is 
becoming an increasingly possible through AI with analyses of genetic profiles, lifestyle factors , 
and other medical history data that can assist physicians in specifically tailoring treatments to 


individual patients.  This approach yields much better health outcomes.  Beyond improving 
diagnostic s and treatment, AI is extremely useful in streamlining clinical workflows , such as 
appointment , surgery, and other  scheduling, managing patient records , and processing 
insurance claims.  With reduced time spent on administrative burdens, more care can be 
directed at  the patient.  Predictive analytics  also represents another area where AI is 
substantially impacting.  Patterns in enormous amounts of patient data can be analyzed  allowing 
AI predictions, for example, on the likelihood of certain health conditions  or identifying  patients 
or groups of patients at risk  for developing diseases.  Importantly, this capability  enables 
healthcare providers  to shift the focus from intervention to prevention and also provides the 
opportunity to intervene earlier, likely reducing the incidence and/or severity of diseases.  
Additionally, AI provides  an important tool for educating the public and presenting medical and 
health information in a variety of platforms , such as bots, chatbots , or other  ‘devices ’ that can be 
accessed , as well as AI -powered bots that can provide healthcare/therapy.  
These improvements in healthcare, although immense, have challenges and ethical 
considerations that must be addressed. Patient data and privacy  of patient data remain 
essential , as is the need  for total transparency in the AI algorithms.  Concerns about potential 
bias in AI systems  could lead to inconsistencies in the delivery of care.  These and other 
concerns  strongly suggest the need for the development of robust regulatory frameworks and 
guidelines  essential  to ensure that AI is used responsibly and safely  in healthcare.  
•Invest in research  and development  to advance AI technologies and their
applications in medicine  and healthcare.
•Provide healthca re professionals with training on AI tools and their integration
into clinical practice.
•Establish comp rehensive policies to address the ethical and regulatory
challenges associated with AI.
•Foster collabor ation between healthcare providers, technology companies, and
academic institutions to drive innovation.
•Ensure AI appl ications prioritize patient well -being and personalized care.
Design for  Human -AI Collaboration 
The need for explainable AI and human- centered AI research is becoming increasingly 
important as organizations integrate AI systems alongside human operators. This research aims 
to enhance our understanding of explainability, transparency, fairness, and interpretability, ensuring that human operators can align with AI's workings.  For example, Florida State 
University researchers have developed the LabGenie system, that leverages Gen AI as a way 
for patients to better understand medical lab results and ideate on questions they can ask thei r 
doctors.  This patient aid is an  excellent example of how an explainable AI agent can enhance 


comprehension and empower the public  with information, in this case, with their health 
information.  
•Develop dynamic AI with situational and contextual awareness to provid e
personalized experiences in collaborative settings.  For instance, an AI tool designed
to record clinical data and offer best practice guidance must adapt its responses based
on individual user needs and contextual awareness. Such tools should cater to variousstakeholders, including medical professionals, patients, and community partners, byunderstanding their unique perspectives and tailoring responses accordingly.
•Democratiz e AI development and usage . Generative AI, despite some controversy,
democratizes knowledge and empowers individuals by providing access to tools thatenhance expression and innovation.  For example, generative AI allows non- artists to
create art without years of experience, enabling richer content presentation and broaderengagement. This can lead to economic growth and support small businesses lackingtechnical expertise, offering them the necessary infrastructure to start and grow.
•Defin e intellectual property rights for AI -generated content and models to protect
creators and innovators.  The US government should establish clear policies for data
collection, storage, and AI model training, aligning with legal and ethical standards.
•Additionally , develop  frameworks for monetizing AI, such as licensing and
subscription models, to enable  fair compensation and scalable  growth in the AI
industry.  Academia and higher educational institutions are major consumers of AI -
enabled products  (such as GPT models and extensions for varied workflows in text
processing and image analysis) . Therefore, having custom licenses and academic rates
will bolster AI innovation and partnerships between academia and industry.
•Enhance profitab ility using AI as a tool for organizations.  Essential is an
understanding  of industry 's AI adoption and utilization strategies. Improved AI learning
and training methods should address inherent incentive issues in AI training, unlockingthe potential for real -time personalization and learning within AI mechanisms.
Understanding how self -interested humans verify AI training data or use its
recommendations is critical for developing the next generation of AI models .
•Ensur e a heterogeneous infrastructure to make AI reliable in safety -critical areas
like manufacturing.  Policies should focus on researching and developing ultra -reliable
infrastructure to integrate AI and applications. High- performance computing (HPC)
provides the computational power needed to train and run complex AI models, enablingthe processing of massive datasets and complex algorithms. Heterogeneous computing,utilizing different processing units optimized for specific tasks, enhances AI
computations' reliability, efficiency, and speed. Together, HPC and heterogeneous
computing accelerate AI research and development by providing the necessary
infrastructure for advanced AI models.


Integrating various processors, such as GPUs, TPUs, FPGAs, and CPUs, tailored for 
different computing environments (on devices or in the cloud), allows for optimized processing of specific AI tasks, leading to faster training times and improved performance . Both HPC and heterogeneous computing architectures can scale to meet 
AI research's growing computational demands, enabling increasingly complex AI applications.  
•Incentiviz e resear ch that supports long- term, heterogeneous computing systems
for integrating AI applications.  Public universities, like Florida State University , with
robust computing infrastructures, play a crucial role in maintaining AI dominance.
Therefore, new policies should support and incentivize research  in such  institutions.
Recommendation 3: Enhance Data Infrastructure and Access. 
Data is the lifeblood of AI. Ensuring that data is accessible, high- quality, and secure is 
fundamental  to AI development. The government should create policies that facilitate data 
sharing while respecting and ensuring privacy and mitigating security concerns.  
Frameworks  and Expansions  of Data Storage Infrastructure  
Data is the cornerstone of AI development, influencing model performance, fairness, and reliability. To foster innovation while safeguarding privacy and security, a structured approach to 
data infrastructure is essential. This approach should incorporate data injection, data 
provenance, data governance, and controlled data access.  
•Adopt  a federated architecture within  a national AI data infrastructure to support
secure data sharing across institutions while maintaining data privacy and
security.  Federated learning and differential privacy techniques can be leveraged to
ensure privacy -preserving data access  while enabling AI models to learn from distributed
datasets . Establishing federated AI data hubs for critical domains such as healthcare,
climate science, and cybersecurity is crucial. Additionally, AI models trained ondistributed  datasets should adhere to Fair Information Practices (FIP), and secure
sandbox environments should be provided for AI researchers to test models on real -
world data without direct access.
•Ensure trust in AI systems through the ability to trace the origins and
modifications of data.  Embedding data provenance mechanisms within the
infrastructure ensures transparency, reproducibility, and accountability. Mandatingmachine- readable metadata standards like the FAIR principles (Findability, Accessibility,
Interoperability, and Reusability) is essential. Implementing blockchain- based audit trails
and developing explainable AI (XAI) tools help users understand how data impacts AIdecision- making.
•Balance data access  with privacy preservation , which  is crucial for ethical AI
development.  AI governance frameworks should enforce tiered access models based


on user credentials, research purposes, and ethical review processes. Establishing data 
access policies that align with regulations, promoting synthetic data and secure multi -
party computation (SMPC) for AI model training, and developing an AI Data Commons  
for secure access to high -quality public -sector datasets are necessary actions.  
•Make n ational  investments to curat e, standardiz e, and expand  datasets; create
data annotation frameworks ; develop public -private partnerships; and incentiviz e
open- source AI datasets while enforcing responsible data -sharing practices.
Public universities can enable and engage communities for tight integrations, ensuring AI
benefits small companies and essential community members.
Recommendation 4: Creat e Public- Private  and Other  Partnerships . 
Work ing together to develop standards and practices for AI, promoting cooperation, and 
addressing national and global challenges  will undoubtedly ensure greatest achievements and 
most efficiencies . Collaboration between the government, industry, academia, and non- profit 
organizations is vital for the progress and effective implementation of AI. Establishing 
partnerships and collaborative frameworks will enable knowledge exchange, resource sharing, and coordinated efforts to address AI challenges and opportunities.  
•Build incentive structures within private contracting for collaboration with public
research universities and ensure requirements for independent testing and
validation of products.
•Require educational training and access component to private contract to allow
for training of the next generation of AI users and developers.
•Foster interdisciplinary collaborations across computing, social sciences and
humanities to develop a roadmap for smart futures.  This could also entail
establishment of collaborative partnerships/programs, scholarly exchanges and
innovation centers that connect academia, industry and government to break silos of
expertise and create a bridge to connect ideas, developing a shared purpose towardsfuture visions and goals.
•Create m ore platforms for sharing academic insights and facilitating industry-
academic partnerships . For example, Florida State University  has partnered with
Microsoft to ideate and develop novel, custom tools that can help educators build on
Gen AI powered agents to create instructional content and enrich classroom learning.
•Engage with industry in student  and faculty  discussion forums such as
conferences, campus -wide events and consorti a. For example, Florida State
Unive rsity has several centers and collaboration catalysts (such as its Innovation Hub),
where industry partners can present and discuss research -industry partnership
opportunities to better engage with students , faculty , and the public .


Recommendation 5: Ensure National  Security . 
Ensuring the security of AI systems is paramount. AI -driven national security strategies focus on 
the identification of potential problems , risks, and challenges  arising from AI advancements. 
Rather than focusing on the broad issues posed by AI, a concerted  focus should be on the most 
critical problems immediately confronting us. Four potential problems related to national security 
are identified and elaborated upon below.  
Deepfakes and Fabrication 
Florida State University  research highlights the growing misuse of deepfakes for fraud, identity 
theft, and misinformation, threatening national security and public trust. AI -generated deepfakes 
can impersonate authority figures, bypass facial recognition, and manipulate individuals.  
•Combat deepfakes t hrough robust detection methods. Examples of such methods
include AI-powered verification tools, real-time detection, and regulatory measures  such as
watermarking.
•Build public AI literacy through education and awareness campaigns. These
initiatives can help individuals recognize and resist digital manipulation.
•Integrate technol ogical, regulatory, and educational initiatives to enhance
cybersecurity, prevent fraud, and safeguard public trust in digital content.
AI-powered Deliberate Disinformation Campaigns  
Research at Florida State University  highlights that AI -powered deliberate disinformation 
campaigns pose a significant threat, especially when exploited by malicious actors or 
adversarial nations. Preventing such misuse is critical to maintaining societal trust and security. By developing resilient AI systems, we can : 
•Enhance our defense agai nst cyber threats, including misinformation campaigns
that distort reality , by developing resilient AI systems . However, biased or misused
AI algorithms can amplify these risks. Ensuring transparency and explainability in AIdecisions is vital to foster accountability and trust.
•Leverage AI to de tect and prevent misinformation, identify foreign election
interference, and develop voter fraud detection tools to protect the integrity ofdemocratic processes.
Lone Wolf Terrori sts and Rogue Nation S tates  
FSU research can inform the development of AI -powered tools to detect cyber insider threats, 
lone wolf terrorists, and rogue nation- states by analyzing interpersonal and group 
communication. Identifying these threats is critical for national security, as cyberspace has no 
borders but can be safeguarded using advanced deception detection technologies. While 
traditional polygraph solutions rely on physiological data, AI -driven communication analysis can 
infer deception and identify malicious intent in digital  environment.  


•Strengthen  national se curity  through further research to enhance AI -driven cyber
behavioral analysis, sentiment detection, and intent assessment.  These
technologies can detect emerging threats, assess online actors’ trustworthiness, and
prevent attacks.
•Integrat e AI-powered solutions into national security frameworks will improve
early threat detection and response, ultimately protecting individuals,communities, and the nation.
Traceability  of Anonymity Online  
Florida State University  research can inform strategies to enhance the traceability of online 
anonymity, a critical issue as large -scale AI initiatives like the Stargate Project that expands 
digital infrastructure in the United States. While AI -driven platforms offer significant 
advancement, they also introduce security risks by enabling anonymous bad actors to evade 
detection. Anonymity can obscure accountability, facilitating cybercrime, lo ng-wolf terrorism, and 
state -sponsored threats. Additionally, AI -generated false data and the complexity of network 
traffic make it difficult to trace digital identities, complicating law enforcement efforts.  
•Develop AI-powered so lutions for identifying and tracking malicious online
activity while balancing privacy and security concerns to mitigate these risks .
Strengthening digital forensics, enhancing VoIP traceability, and leveraging AI for real -
time anomaly detection will be critical in safeguarding national security and ensuring the
integrity of digital ecosystems.
•Develop AI pl atforms that are more trustworthy and reliable than the competition.
•Create systems  that enhance imperfect and biased human decision- making in
both commercial and military settings. Trust will be essential for widespread public
adoption of AI technology and for effective collaboration between human and robotic
troops in military operations.
Recommendation 6: Protect Data Privacy and Security . 
Speaking broadly, there need to be coalitions across the government, private and public sectors 
to protect people’s privacy rights , and to make good decisions concerning how AI is applied and 
used in surveillance and monitoring . How various  priorities and rules  would interact with  existing 
privacy laws requires additional assessment . Additionally,  infrastructure  and resources for 
seeking redressal in the case of violation of legally protected privacy needs to be created.  
For its own part, t he government should implement measures to protect AI systems from 
threats, including cyber -attacks , exploitation,  and misuse. Data privacy and robust security 
measures must be in place to protect individuals’ personal information and to prevent data breaches. Five potential vulnerabilities  related to national security are identified and elaborated 
upon below that need to be addressed  with top priority . 


Cyber -Physical C ritical Infrastructure  
Our research demonstrates that cyber -physical critical infrastructure is increasingly vulnerable 
as generative AI enables the creation of sophisticated code for programmable logic controllers 
(PLCs), which are vital for industrial systems. Hackers can exploit AI -generated code to infiltrate 
and manipulate vital infrastructure, including water treatment plants, electrical grids, and transportation networks, leading to potential equipment failure or public safety risks. Safeguarding these critical infrastructures against cyber -physical threats is a growing priority.  
•Deploy AI-enhanced sensors t o detect early failure signs in critical systems  and
combine AI predictions with human expertise to avoid false positives.
AI-Powered  Cyber- Physical Attacks 
Our work demonstrates that AI -powered cyber- physical attacks, particularly those leveraging 
adversarial machine learning, have greatly increased the sophistication of cybersecurity threats. Polymorphic malware, such as the Black Mamba ransomware, highlights how AI can predict and bypass tradit ional defense mechanisms, rendering current cybersecurity technologies 
ineffective. Hackers exploit AI techniques to evade endpoint detection and response by 
dynamically retrieving synthesized and polymorphic code from trusted AI sources, allowing 
malware to carry out harmful actions without triggering security alerts. Furthermore, generative 
AI complicates security by creating unique malware payloads, making it increasingly challenging to distinguish between benign and malicious code, ultimately exposing s ystems to undetectable 
threats.  
•Invest in  cyber -security training programs and the development of cyber -security
platforms to combat  cyber -physical attacks.
Malicious G PTs and AI Exploitation 
Florida State University  research highlights that hackers can exploit malicious and generative 
pre-trained transformers (GPTs) to undermine the accuracy and reliability of AI/ML systems 
through various attack strategies. These include poisoning attacks, where fake data is injected 
into training datasets, evasion attacks that manipulate input data, and model tampering, which 
alters AI model parameters. These tactics collectively weaken AI -driven decision- making, 
making cybersecurity defenses more vulnerable to manipulation.  
•Implement  securit y-by-design principles, conducting adversarial testing,
establishing AI security initiatives, and enhancing AI interpretability fortransparency and accountability.  Additionally, AI has significantly improved the
effectiveness of Distributed Denial- of-Service (DDoS) attacks and malware performance,
enabling attackers to execute more powerful, adaptive, and persistent cyber threats and
disruptions.
AI Manipulation 
Florida State University  institutional research demonstrates that AI manipulation has become a 
significant concern, as AI -generated output can influence/ deceive people’s perception and 
decision- making. One notable example is AI -generated phishing attacks, where AI creates 


highly convincing fake emails or websites that are difficult to distinguish from legitimate ones. 
Additionally, AI can craft personalized messages, increasing the likelihood of successful deception and potentially leading to data theft, influencing mass  perceptions , and other 
malicious activities.  
•Direct  research f unding toward AI -generated content detection tools, fostering
collaboration between cybersecurity experts, AI researchers, and policymakers tostay ahead of evolving cybercriminal tactics, and establishing stronger safeguardand legislation agai nst AI -based fraud.
Recommendation 7 : Promote Ethical AI Development . 
Establish ment  of guidelines  that evolve with the further development of AI  is essential  to ensure 
AI systems are designed and used ethically and avoid biases.   AI development and deployment 
must adhere to ethical standards that ensure fairness, accountability, and transparency.  
•Establish  a thoughtful set of ethical guidelines to prevent biases, protect privacy,
and promote the responsible and ethical use of AI technologies.  This should include
input from diverse stakeholders, including ethicists, technologists, and affectedcommunities.
Human- in-the-loop Configuration of Human -AI Interaction  
A clear  need  exists to understand the intricacies of human experience and how they shape the 
way AI is perceived, adopted and deployed. There needs to be a focus on human -in-the-loop 
frameworks for designing and developing AI technologies, so that stakeholder voices are valued 
and embedded in the AI usage pipeline.    
•Repurpose the focus of AI innovation from only technical to sociotechnical.
Increasingly, AI artifacts are finding use and extensive deployment in varied societal
contexts, increasing the need to raise awareness and consciousness towards how AI isdesigned and developed through a human -centered approach.
AI Bias  
Research at Florida State University highlights that AI bias is a significant concern, as it can 
lead to discriminatory outcomes stemming from skewed or non -representative datasets. Just as 
human’s biases are influenced by personal preferences, AI systems can inherit similar biases, which cannot be entirely eliminated. As AI systems are trained on large volumes of human data, 
privacy risks also increase. While federated learning techniques offer potential for learning from 
distributed data, they also pose challenges in ensuring unbiased data correlation.  
•Implement predevelopment bias assessments for AI systems.
•Incorporate bi as detection and auditing into AI models.
•Ensure AI syst ems use broad, representative datasets that reflect population
demographics.


•Develop human -in-the-loop syst ems for sensitive decisions.
•Establish nonpart isan oversight for election security tools.
Recommendation 8: Invest  in Workforce  Development . 
Invest ing in education and training programs is essential for  prepar ing the workforce to handle  
and optimally apply the changes brought by AI.  Building a skilled workforce is essential for 
sustaining AI growth.  
•Invest in education and training programs at all levels, from K -12 to higher
education and lifelong learning.  Emphasizing STEM (Science, Technology,
Engineering, and Mathematics) education, interdisciplinary studies, and AI -specific
curricula will prepare the next generation of AI professionals.
•Integrate AI-specifi c curricula in all post -graduate, professional educational
programs to ensure that AI tools are being used effectively in all professions.
Curriculum Development  to Embrace  and Collaborate  with AI 
Human- AI collaboration will require transforming the future AI workforce's preparedness, 
emphasizing protection against overreliance on AI. This involves balancing technical and 
societal considerations, fostering interdisciplinary training, and developing novel pedagogical approaches. Literacy initiatives drawing on humanities and social sciences are crucial for 
cultivating ethical and moral consciousness towards responsible AI use.  
•Creat e experiential educational pathways and AI -assisted learning tools to expand
capacities and enable non- programmers to build systems.
•Make AI pr oducts accessible and provide essential  guidelines for academic use.
•Ensure safety tra ining and curricula to enhance critical consciousness and
situational awareness, especially in high- risk conditions like armed forces
operations .
The following sections illustrate how AI can be  applied effectively in teaching, training, and 
learning efforts critical to a much more robust development and use of AI’s full potential. 
Teacher Training and AI Innovation 
Florida State University has led several professional development sessions associated with its 
INSPIRE Initiative  to train K -12 educators to have a deeper understanding of AI and associated 
areas  (such as generative AI, prompt engineering, data science and responsible AI) .  
•Support  teacher training initiatives to strengthen the capabilities of educators to
better equip and prepare  the future AI workforce.  Such initiatives can help create and
expand existing teacher certifications and professional development goals that are


essential for evolving teaching needs in STEM education as AI and data science skills 
become essential for the future workforce.  
K–12 AI Literacy Programs  
Foundational skills are essential for creating an AI -ready workforce pipeline.  
•Embed AI lit eracy within K -12 curricula , because early exposure to AI concepts
develops critical evaluation skills that prepare students to identify algorithmic
biases and understand ethical implications of AI technologies.  These foundational
skills are essential for creating an AI -ready workforce pipeline. Students exposed to
these programs transition from passive AI consumers to informed contributors within the
AI ecosystem.
Advanced Self -Evaluation and Skills Assessment  
Florida State University’s  “Khan Academy on Steroids” platforms provide sophisticated self -
evaluation tools that offer granular insights into learning deficiencies and strengths. These AI -
driven diagnostic tools generate real -time assessments with personalized recommendations, 
fostering self -regulated learning and autonomous intellectual growth - critical skills for workforce 
adaptability in an AI -driven economy.  
AI-Driven Car eer Navigation 
Florida State University ’s research on predictive analytics for career development demonstrates 
how AI can assess labor market trends and align professional development with emerging industry demands. Machine learning algorithms identify skill gaps and recommend tailored training modules, creating dynamic career roadmaps that help workers adapt to technological 
disruption and maintain employability.  
Immersive Training Environments  
Florida State University’s  work with AI -powered VR training modules revolutionizes vocational 
education by offering immersive, experiential learning environments. These AI -driven 
simulations model complex job- specific scenarios and dynamically adjust difficulty based on 
learner performance, providing risk -free skill acquisition particularly valuable in high- stakes 
industries such as healthcare, manufacturing, and cybersecurity.  
Higher Educati on Research Integration  
Florida State University ’s integration of AI in higher education shows how AI -powered research 
assistants streamline scholarly workflows, while AI -driven tutoring platforms provide targeted 
instructional support in STEM fields. AI -facilitated peer collaboration platforms foster 
interdisciplinary research synergies essential for breakthrough innovation in AI development.  
Personalized Lear ning Pathways  
Our research demonstrates that AI -powered adaptive learning systems significantly enhance 
educational outcomes by dynamically analyzing student performance and providing targeted 
interventions. These systems scaffold instruction based on individual progres s trajectories, 


ensuring differentiated pedagogical support that accelerates skill acquisition - a model that 
should be expanded nationwide through strategic federal investment.  
Adult Basic  Education Enhancement 
Florida State University ’s work with Adult Basic Education (ABE) programs showcases how AI 
can democratize access to high- quality education for working adults. AI- driven language models 
facilitate tailored reading comprehension passages and contextualized skill -building exercises, 
while adaptive platforms adjust content complexity based on learner progression. This approach 
is particularly effective for adults balancing employment and family obligations, who require 
flexible, personalized educational modalities. Each area should consider providing examples that address this recommendation to provide context for our perspectives on policy implications.  
Recommendation 9: Promote International Cooperation . 
AI development is a global endeavor. The US should engage in international cooperation to 
harmonize standards, share best practices, and address global challenges. Participating in 
international forums and collaborating with other nations will strengthen the global AI ecosystem and ensure that AI benefits are widely shared. International standards and best practices for AI must be developed and promoted. Global challenges can be addressed in collaboration using 
the power of AI.  
Exchange of Ideas, Innovation, and Cooperation  
•Creat e strategic alliances for innovating and piloting AI usage and deployment .
Understanding policy and future growth in the AI sector within the global economy helps
us grasp how different nations may approach AI innovation and preparedness in thecoming years.
•Develop and cultiv ate crucial  research partnerships.  For example, French
institutions and private companies have been key players in developing humanoidrobots, while Japan has long been at the forefront of humanoid robotics. It is vital to
understand the momentum, market, and ways to build partnerships with these global
giants, along with their business models and innovative visions .
•As data becomes i ncreasingly valuable to AI, protect  it just like any natural
resource. Currently, there are relatively few guardrails to protect individuals' privacy and
safety in this new digital world. While sharing the digital commons across the world is a
hallmark of the 21st century, we must recognize the new landscape and proactively
work to protect citizens while maintaining essentially 'free trade' in data.
•Increase internat ional cooperation for data security and protection from
manipulation and fraud . The international protection of intellectual property rights, such
as copyrights, patents, and trademarks, has been a significant issue in the past, and
developments in AI make these threats even more real.


Conclusion  
Maintaining the US’s position as the global leader in AI  is important  for national advancement, 
productivity, protection, and prosperity , and to ensure that AI serves human flourishing. 
Universities  provide an essential engine that drives technological innovation through leading 
multidisciplinary research programs and by training the next generation of AI developers and 
users, as well as producing advances in related fields necessary to fuel further evolution and 
innovation.  We , however,  recognize that this effort cannot be accomplished by a single group 
alone and must be a concerted collaboration between government, public, and private partners, 
all working together toward shared goals shaped by federal policies.  
We value this opportunity to provide feedback and guidance as you move forward in setting policies and establishing the necessary infrastructure that will enable the US to lead in this 
monumental opportunity to harness the power and potential of AI. We hope to contribute in a 
meaningful way in helping America stand firm as a global leader  in this area. 


