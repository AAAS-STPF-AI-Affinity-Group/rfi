PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-nolk-rofs
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-2575
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Anonymous Anonymous 
General Comment
The attached subm ission is from  Black Forest Labs.
Attachments
Black Forest Labs_OSTP response


March 2025 
blackforestlabs.ai 
Response to the Request for Information  
on the Development of an Arti ﬁcial Intelligence Action Plan 
Black Forest Labs 
Introduction  2 
Black Forest Labs is a frontier developer of visual AI technology  2 
The Action Plan should accelerate the development of a thriving visual AI ecosystem  3 
The Action Plan should address emerging risks through targeted reforms  3 
The Action Plan should support the safe deployment of visual AI technology  4 
Conclusion  5 
1 


Introduction1 
Black Forest Labs welcomes the opportunity to respond to the Office of Science and 
Technology Policy request for information on the development of an arti ﬁcial intelligence (“AI”) 
action plan (“Action Plan”). As a leading developer of visual AI models, Black Forest Labs is 
committed to the safe and responsible integration of AI technology, and we support efforts by 
the Trump Administration to nurture AI innovation in the private sector. Consistent with 
Executive Order 14179, we encourage the Administration to develop an Action Plan that 
prioritizes innovation and competition in visual AI technology—such as generative image and 
video models— to lay the foundational infrastructure for a thriving creative economy.  Black Forest Labs is a frontier developer of visual AI technology 
At Black Forest Labs, our mission is to develop frontier AI infrastructure for creators and 
innovators. Our founding team consists of pioneers in image and video generation—the 
researchers behind latent diffusion, VQGAN, and adversarial diffusion distillation—supported 
by investors including a16z and General Catalyst. With a small team of 25, we are pushing the 
boundaries of visual AI. Our models and tools support an ecosystem of enterprises, creators, 
and researchers around the world, making it possible for developers to build exciting new AI 
applications that we can scarcely imagine today. With over 15 million downloads to date, our 
open FLUX models rank among the most popular globally, ahead of open models such as 
Meta’s Llama,2 and top the most capable open image models.3  ● We are committed to creators. We focus on developing visual AI technology to unleash
human creativity. Our technology helps enterprises, developers, researchers, and
creators build new tools to realize their best work.
● We are committed to open innovation. We share research and model weights openly to
promote greater transparency, support experimentation in novel applications, and
expand global access to creative technology.
● We are committed to safety before, during, and after release. We apply layers of
safeguards to encourage the safe and lawful deployment of visual AI technology. From
training our models to hosting our services, we prioritize safety every step of the way.
3 Imgsys (2025), https://imgsys.org/rankings, accessed March 12, 2025. 2 See comparative developer engagement on the Hugging Face repository at AI World (2024), 
https://aiworld.eu/embed/model/model/treemap, accessed February 20, 2025. 1 This document is approved for public dissemination. The document contains no business-proprietary 
or con ﬁdential information. Document contents may be reused by the government in developing the AI 
Action Plan and associated documents without attribution.  
2 


The Action Plan should accelerate the development of a thriving visual AI ecosystem 
Visual AI plays a critical but overlooked role in the AI ecosystem. While U.S. policy to date has 
focused on language models, visual AI will unlock broad swaths of the economy. With visual AI 
technology, animators will explore new concepts; architects will reimagine spaces; game 
developers will build new experiences; and creators will discover new forms of expression. 
The economic implications of this technology are substantial—with the potential to generate 
signiﬁcant value for U.S. creative industries. 
For the U.S. to lead in this domain, the Action Plan must prioritize innovation in visual AI, not 
just language models. The Action Plan should identify leadership in visual AI as a national 
economic priority. In particular, the Administration should review future legislative and 
regulatory action to ensure that small and independent developers of visual AI models or 
services can compete effectively with large technology platforms. Competition will help to 
sustain rapid innovation in visual AI technology, and reduce costs for developers, deployers, 
and creators.  Crucially, the Action Plan should endorse open innovation in models. Open models—those 
with publicly-available weights or parameters—facilitate downstream experimentation by 
creators, developers, and enterprises. Open models enable third parties to study, ﬁne-tune, 
and integrate the model with other systems to build novel applications. Without a robust open 
ecosystem for visual AI models, the U.S. risks falling behind in the development and adoption 
of creative AI tools. In the past three months, labs backed by Tencent, Alibaba, and ByteDance 
have released capable open image and video models that rival those trained in the U.S., totaling 
1.8 million downloads by developers over that period.4  The Action Plan should address emerging risks through targeted reforms 
Like other modalities, visual AI technology can pose risks. Where there are gaps in our existing 
regulatory system, the Administration can take action to mitigate these risks, either through 
existing agencies or by encouraging Congressional action. Crucially, any reforms should be 
targeted and proportionate to avoid stiﬂing the bene ﬁcial applications of visual AI technology, 
or chilling legitimate research and innovation. For example, the Administration should avoid 
proposals that extend liability to AI researchers or developers for the misuse of technology by 
downstream actors, provided that reasonable safeguards were implemented. Examples of 
challenging proposals include the Federal Trade Commission’s supplemental rulemaking on 
impersonation under the Biden Administration,5 or variations of the No AI FRAUD Act in the 
5 89 FR 15072. 4 Download ﬁgures obtained from the Hugging Face platform (2025). 
3 


previous session of Congress.6 Expansive liability regimes could discourage visual AI research 
in the U.S., pushing development abroad without resolving these longstanding risks. Instead, 
reforms should focus in the ﬁrst instance on those who knowingly create or distribute harmful 
content, with appropriate safe harbors for model developers and service providers that 
implement reasonable mitigations. 
The Action Plan should support the safe deployment of visual AI technology 
The safe deployment of visual AI technology requires coordinated action across the entire 
ecosystem—from model developers to application providers to end users. The Action Plan is an 
opportunity to outline a comprehensive framework for encouraging safety in visual AI, helping 
to realize the vast beneﬁts of creative AI technology while managing emerging risks. 
First, the Administration should ensure that public safety research supports all media 
modalities, including image and video, not just language. Current safety research 
disproportionately focuses on large language models, with fewer resources dedicated to 
understanding visual AI risks. If the Action Plan endorses federal research, it should study 
visual AI safety, including evaluation methodologies, mitigations across the supply chain, 
content labeling techniques, and deepfake detection tools to identify synthetic media.  
Second, the Administration should drive US leadership in global standards for visual AI. 
Through the National Institute of Standards and Technology and the U.S. AI Safety Institute, 
the U.S. can accelerate the development of consensus-based standards for evaluation and 
mitigation in visual modalities. These standards should be practical and adaptable, 
acknowledging the variety in visual AI applications. Such efforts could build on early 
frameworks developed by organizations such as Thorn and the Partnership on AI.7  
Third, the Administration should recognize that the visual AI ecosystem includes not just 
model developers but application developers, deployers, and users—each with different roles 
and responsibilities. Rather than imposing uniform obligations across this diverse ecosystem, 
the Administration should adopt a distributed approach to safety. Different actors may have 
different expectations or obligations based on their role in the supply chain, their control over 
users or content, and their resourcing.  
Finally, the Administration should establish coordination mechanisms for ongoing 
collaboration between industry, law enforcement, the intelligence community, and 
policymakers to address new risks as they emerge. Visual AI technology is evolving rapidly, and 7 See e.g. Thorn (2024), https://www.thorn.org/blog/generative-ai-principles/ and Partnership on AI 
(2024), https://partnershiponai.org/modeldeployment/#landing, accessed March 12, 2025. 6 H.R.6943 (118th Congress, 2024).  
4 


static regulation will quickly become outdated. A more ﬂexible approach—built around 
public-private collaboration, consensus-based principles, and technical standards—will better 
advance the twin goals of innovation and safety. 
Conclusion 
Visual AI will support economic growth across major U.S. industries, from entertainment to 
professional services. By accelerating the development of a thriving visual AI ecosystem in the 
U.S., addressing risks through targeted reforms, and supporting the safe deployment of this
transformative technology, the Administration can help to realize the beneﬁts of visual AI
technology while mitigating emerging risks. Black Forest Labs stands ready to support these
efforts and would welcome the opportunity to contribute to the development of the Action
Plan.
5 


