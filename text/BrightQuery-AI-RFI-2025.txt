Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
BrightQuery (BQ) Response to the Request for Information (RFI) on the 
Development of an AI Action Plan  
EXECUTIVE SUMMARY 
The United States is at a pivotal juncture in redefining its leadership in artificial intelligence 
(AI). The federal government has recognized this imperative through the Request for 
Information (RFI) on the Development of an AI Action Plan and Executive Order 14179, which 
call for an AI-driven strategy that preserves America’s global leadership while minimizing 
regulatory barriers to innovation. A core component of this strategy is the development of a 
unified, efficient, and reliable "currency of data", which will serve as the foundation for AI -
driven solutions across public and private sectors. 
BrightQuery (BQ) is uniquely positioned to contribute to this transformation through its 
expertise in data standardization, open-source AI, and entity resolution. BQ advocates for an AI 
ecosystem built on four foundational forces: open data, open-source AI, government data 
sources, and contributor-driven datasets. These forces are essential to creating a transparent, interoperable, and scalable AI infrastructure that ensures equitable access to high-quality data. 
Key Proposals: 
1.Standardizing and Normalizing Data - The creation of a Global Directory is central to
this initiative. This directory will classify corporate organizations, legal entities, businesslocations, and individuals in leadership roles. It will also incorporate government entities,ensuring a comprehensive and open data framework. At present, no open global directoryof this nature exists. While private firms maintain proprietary databases, these remainclosed and inaccessible. BQ proposes to launch the first fully open, global entitydirectory, leveraging open-source entity resolution to establish a transparent andinteroperable data ecosystem.
2.Transforming Government Data into an AI-Ready Format - Government dataremains fragmented, inconsistent, and difficult to integrate across agencies. Manualprocesses, redundant compliance checks, and disparate standards increase costs and slow
AI adoption. BQ recommends implementing automated data transformation mechanisms
that convert raw government datasets into standardized, AI-ready formats, streamliningcompliance and enhancing interoperability.
3.Creating a Unified "Currency of Data" - A national data standardization strategy mustbe established to eliminate inefficiencies in AI adoption. By harmonizing data formats,ensuring structured metadata, and automating quality control, this approach willsignificantly reduce operational costs and improve AI performance. This standardizationwill facilitate seamless information-sharing across sectors, accelerating AI adoption inkey areas such as healthcare, defense, and economic policy.


Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
4.Regulatory Alignment and Policy Recommendations - To fully realize the potential of
open AI, government agencies must actively remove regulatory roadblocks that hinderthe collection, standardization, and dissemination of data. Overregulation risks slowingAI innovation at a critical time when global competition in AI leadership is intensifying.BQ advocates for a balanced regulatory environment that prioritizes data accessibility,security, and neutrality while preventing AI from becoming a tool for misinformation orcensorship.
5.Strengthening National Security Through AI Governance - AI-driven intelligence,defense, and cybersecurity applications require trustworthy, high-quality datasets. Theabsence of a structured data ecosystem undermines AI’s role in national security. BQrecommends an interoperable AI governance framework that aligns U.S. data
infrastructure with international best practices, ensuring that AI systems operate on
objective, bias-free data to support decision-making in critical domains.
The United States' ability to sustain its global AI leadership depends on a comprehensive, data-
centric approach. By integrating standardized datasets, open-source AI frameworks, and 
automated data transformation, the U.S. can unlock AI’s full potential while ensuring 
transparency, security, and efficiency. 
BrightQuery is uniquely positioned to contribute to this national effort. With expertise in factual 
data-driven AI, entity resolution, and global data integration, BQ is well-equipped to collaborate with federal agencies and AI initiatives to create a resilient, AI-ready data infrastructure. 
This document serves as a strategic roadmap for policymakers to align government directives 
with actionable AI solutions, reinforcing the United States’ leadership in AI-driven innovation, economic competitiveness, and national security. 
1. IntroductionThe United States now faces a pivotal moment to redefine its leadership in artificial intelligence 
through a bold, data-centric strategy. Government directives - outlined in the Request for 
Information on the Development of an AI Action Plan  and codified in Executive Order 14179 - 
mandate that American AI development must both sustain and enhance global leadership while 
ensuring that excessive regulatory burdens do not hinder private sector innovation. The 
Executive Order clearly states, “It is the policy of the United States to sustain and enhance 
America’s global AI dominance in order to promote human flourishing, economic 
competitiveness, and national security.” This establishes a clear mandate for a transformation in 
how our nation manages data for AI. 
At the 2025 Paris AI Summit and later in the Munich Security Conference, JD Vance articulated 
this vision, stating “this administration will ensure that American AI technology continues to be 
the gold standard worldwide, and we are the partner of choice for others ,” while warning that 
“excessive regulation of the AI sector could kill a transformative industry just as it’s taking off .” 
These remarks underscore the need to maximize AI’s potential rather than restrict it with 
cumbersome regulations. Central to this vision is the creation of a unified, efficient, and reliable 


Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
"currency of data" - a framework that will support AI-driven innovation across both public and 
private sectors. 
A key principle underlying this transformation is the interplay between several foundational 
forces shaping AI development: open data, open-source AI, government data sources, and 
contributor-driven datasets. Open data and open-source AI are inherently interconnected, as the 
advancement of open-source AI is contingent upon the availability of openly accessible, high -
quality data. Establishing a robust AI ecosystem necessitates the integration of structured, standardized, and anonymized data from both governmental entities and independent contributors, such as Bright Query’s Open Entity Data initiative and similar efforts. These 
diverse sources collectively form the foundation for an interoperable and transparent data 
infrastructure, essential for fostering innovation and ensuring equitable access to AI -driven 
advancements. 
Organizations like Bright Query (BQ) are uniquely positioned to contribute to this 
transformation. With deep expertise in data-centric AI, BQ is collaborating with government 
agencies and AI-driven initiatives to develop automated systems that harmonize disparate data 
standards. This effort includes opening BQ’s own datasets in partnership with organizations like the AI Alliance to create a comprehensive, open, global data infrastructure. 
2.
Establishing a Standardized, Open Data Ecosystem
The overarching objective is to develop a standardized and normalized framework for datasets 
derived from credible sources worldwide. These datasets will be systematically aggregated, anonymized, and made openly accessible, serving as the foundational infrastructure for AI 
applications at scale. 
Central to this initiative is the creation of a Global Directory that organizes economic entities 
into distinct categories: corporate organizations, legal entities - including LLCs and corporations 
- business locations, and individuals in the context of corporate structures and leadership roles.
Additionally, this framework can be expanded to incorporate government entities, ensuring thatpublic sector data is integrated within the broader open data ecosystem.
At present, a comprehensive, openly accessible global directory encompassing all businesses, 
legal entities, and economic actors does not exist. While certain private entities maintain 
proprietary directories, access is restricted, limiting their utility f or broader AI-driven 
applications. BrightQuery is positioned to introduce the first fully open, global directory, leveraging open-source entity resolution to establish a transparent and interoperable data 
repository. This initiative seeks to transform the accessibility and usability of entity data in the 
same way that major search engines revolutionized access to information on the internet. 
Achieving this vision requires active engagement from government entities to ensure that legal 
and regulatory frameworks do not obstruct the collection, standardization, and dissemination of 
essential data. A regulatory environment that fosters open data sharing will accelerate AI-driven 
innovation and reinforce the United States' leadership in global AI governance. 


Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
3. The Imperative for a Data-Centric AI Strategy
A data-centric approach to artificial intelligence is essential to maintaining the United States’ 
global leadership, driving economic innovation, and strengthening national security. AI’s performance and reliability fundamentally depend on the quality, structure, and provenance of its 
underlying data. Thus, AI initiatives must be built on authoritative, verifiable data sources - free from inefficiencies and biases. 
Addressing Inefficiencies in Current Government Data Structures 
Today, government data systems suffer from inefficiencies - including manual data preparation, 
inconsistent formats, and redundant compliance checks. These inefficiencies increase operational 
costs and delay AI development, ultimately undermining U.S. competitiveness. Addressing these 
structural issues is not just about cost reduction - it is essential for enabling timely and effective 
AI adoption. 
Transforming Data into a “Currency of Data” The solution is to automate the conversion of government data into standardized, AI-ready 
formats. A unified data framework, or "currency of data," eliminates repetitive manual processes, 
streamlines compliance, and significantly reduces costs. Moreover, standardization facilitates 
seamless data-sharing across agencies, fostering an integrated ecosystem where data flows 
efficiently between sectors. This interconnected data environment accelerates AI deployment across key areas such as healthcare, defense, and education. 
Automating Data Transformation to Enable AI Leadership
 
High-quality factual data exists across multiple federal agencies —such as the Department of 
Commerce and the Department of Health—but remains siloed and incompatible due to a lack of 
common frameworks. To address this, we propose an automated transformatio n mechanism that 
converts raw data into standardized, AI-ready formats. 
By implementing automated oversight and employing consistent processes, this approach 
reduces administrative overhead, eliminates manual inefficiencies, and minimizes human error. 
This guarantees that all AI systems operate on uniform, high-quality data - a critical requirement 
for reliable AI deployment. 
Aligning with National Strategic Priorities Transforming U.S. data infrastructure is not merely a modernization effort - it is a strategic 
necessity. A well-structured, automated data environment ensures that AI systems operate on 
accurate, high-quality inputs, yielding more transparent and effective outcomes.  
In economic terms, structured data reduces inefficiencies, enhances productivity, and fuels 
innovation - spurring new industries and job creation. Without a streamlined data infrastructure, 
AI-driven solutions in finance, logistics, and healthcare will rem ain fragmented and difficult to 
scale. Automating data curation and standardization frees businesses from excessive data 


   
 
Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
 
processing costs, allowing greater investment in next-generation AI applications, reinforcing the 
United States' leadership in AI. 
From a national security perspective, a robust data ecosystem is indispensable for intelligence 
analysis, military operations, and cybersecurity. Without a structured data framework, AI -driven 
threat detection and response mechanisms are compromised by inconsistent or outdated information. As AI increasingly integrates into defense, ensuring that decision -making is based 
on high-quality, bias-free data is of strategic importance. 
JD Vance underscored this point, stating: “The success of the sector isn’t just a matter of smart 
people sitting in front of a computer screen and coding. It depends on those who work with their 
hands… it will certainly make our healthcare providers better at treating diseases, but it will also depend on the data produced by those healthcare providers, by those doctors and nurses .”  
This reinforces the need for a structured, standardized national data strategy that ensures AI systems are built on reliable and comprehensive datasets. 
Automated Transformation to Reconcile Disparate Data Standards 
High-quality factual data exists across multiple federal agencies - such as the Department of 
Commerce and the Department of Health - but remains siloed and incompatible due to a lack of common frameworks. To address this, we propose an automated transformation mechanism that 
converts raw data into standardized, AI-ready formats. 
By implementing automated oversight and employing consistent processes, this approach 
reduces administrative overhead, eliminates manual inefficiencies, and minimizes human error. 
This guarantees that all AI systems operate on uniform, high-quality data - a critical requirement 
for reliable AI deployment. 
Leveraging Global Best Practices Internationally, frameworks such as SDMX have successfully standardized data exchange, 
providing a proven model for interoperability. While SDMX was developed by a consortium of 
international organizations, aligning U.S. data standards with these global benchmarks strengthens our leadership in AI governance. 
By adopting and refining best practices within federal agencies, the United States can establish 
itself as the global leader in AI data governance. As JD Vance stated, American AI must remain 
the "gold standard" for global innovation—a goal directly supported by this structured approach. 
Strategic Value of Interoperability Interoperability is not merely a technical necessity - it is a strategic imperative. The absence of 
common data standards across federal agencies results in duplicated efforts, higher compliance 
costs, and barriers to AI innovation. A unified data ecosystem, in which agencies operate under a 
shared AI-ready framework, would eliminate inefficiencies, streamline data -sharing, and 
accelerate AI adoption. 


Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
Beyond operational improvements, interoperability strengthens U.S. leadership in global AI 
governance. While SDMX and similar frameworks were not originally U.S. -led, integrating them 
into federal agencies positions the United States as the global authorit y on AI data governance. 
By demonstrating how structured, automated data environments enhance AI reliability, the U.S. 
can shape global AI regulations from a position of technical leadership and strategic influence.  
4. Integrating Policy Directives and Advancing National Priorities
A cohesive national AI strategy must seamlessly integrate government directives with technical 
execution to achieve real-world impact in human well-being, economic growth, and national 
security. 
JD Vance reinforced this vision, cautioning that “excessive regulation of the AI sector could kill 
a transformative industry just as it’s taking off.” He further asserted that “American AI will not 
be co-opted into a tool for authoritarian censorship” - highlighting the imperative of maintaining ideological neutrality in AI governance. 
By integrating open data, standardization, and automated transformation mechanisms, we can 
create an ecosystem where fragmented data becomes a unified "currency of data." This 
transformation will empower decision-makers with accurate, transparent, and acti onable 
information, ensuring that American leadership in AI remains unchallenged in the years ahead.  
5. Recommendations and Actionable Policy Steps
This strategic blueprint outlines a detailed set of actions designed to transform our national data 
infrastructure into an efficient, automated, and standardized ecosystem. The overall goal is to build a resilient AI framework anchored in a unified “currency of data” that supports human 
flourishing, drives economic competitiveness, and reinforces national security. Each 
recommendation is interdependent, collectively converting fragmented data processes into a 
strategic asset that delivers measurable benefit s. 
The foremost priority is to establish and prioritize authoritative data sources . AI systems must 
be built on verified, primary data that is demonstrably free from bias. To achieve this, federal 
agencies should be mandated to serve as gold-standard data providers, supported by rigorous 
protocols for data curation and continuous auditing. For instance, implementing standardized 
processes to verify data provenance ensures its integrity before being used for AI training. BQ’s 
expertise in factual, data-driven AI is critical; by developing advanced methodologies for data 
verification and curation, BQ can help guarantee that only the highest quality sources are 
employed - thereby reducing errors and increasing the trustworthiness of AI outputs.  
The next action is to adopt unified data standards across agencies. A consistent set of standards 
will harmonize the diverse datasets collected by federal bodies, reducing inconsistencies and 
lowering integration costs. This standardization is essential for seamless interoperability between 
systems, a prerequisite for efficient cross-domain data sharing. BQ, with its extensive experience 
in government collaborations and data science, is ideally positioned to advise on the design and 
implementation of these standards, ensuring that the integration process is both efficient and scalable. 


Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
AI systems must be built on objective, authoritative data sources that are free from ideological 
distortion. Establishing clear oversight mechanisms to verify data integrity is essential to prevent 
politically motivated alterations or biases from influencing AI-generated outputs. Without robust 
safeguards, AI technologies risk becoming instruments of misinformation rather than engines of 
innovation. BQ is well-positioned to assist in this endeavor by developing AI-driven validation 
mechanisms that assess the factual accuracy and neutrality of datasets. By leveraging automated 
fact-checking algorithms and metadata verification, BQ can help ensure that AI models remain free from ideological distortions, thereby reinforcing public trust in AI -driven decision-making. 
This issue is not theoretical; recent incidents highlight the consequences of biased AI systems. JD Vance pointed out at Munich, “We had AI image generators trying to tell us that George 
Washington was black or that America’s doughboys in World War One were in fact women.”  
While seemingly trivial, these distortions illustrate the dangers of unverified data shaping AI outputs. By implementing rigorous data validation measures, the United States can prevent such 
inaccuracies from undermining public confidence in AI technologies. 
A critical technological advancement in this strategy is the implementation of an automated data 
transformation mechanism. By automating the conversion and standardization of raw data, we 
eliminate manual errors, streamline integration, and drastically reduce the costs associated with 
data preparation. This technological solution ensures that data is consistently formatted and 
readily available for AI applications, thereby boosting reliability and reducing deployment 
delays. The efficiency gains from automation will also facilitate a rapid turnaround for AI projects, enhancing overall productivity across sectors. 
A successful AI strategy requires a regulatory environment that encourages innovation rather 
than stifles it. Reducing unnecessary compliance burdens and streamlining approval processes 
for AI initiatives will accelerate deployment and encourage investment in AI-driven industries. 
Vance directly addressed this issue, stating, “We’ve watched as governments, businesses, and 
nonprofit organizations have advanced unpopular and, I believe, downright ahistorical social 
agendas through AI.” Overregulation not only inhibits technical progress but also allows 
entrenched interests to shape AI governance in ways that do not align with broader national 
priorities. A pro-growth policy framework must focus on enabling rapid AI adoption while 
ensuring appropriate safeguards against misuse. 
BQ’s experience in AI data governance makes it an ideal partner in this initiative. By developing 
regulatory automation tools that simplify compliance while maintaining robust security and 
auditing standards, BQ can help federal agencies strike the right balance between oversight and 
innovation. 
Finally, strengthening national security through enhanced AI security measures is indispensable. 
Instituting rigorous cybersecurity standards and automated compliance checks will protect AI 
systems from adversarial exploitation. Additionally, implementing explainability protocols will 
ensure that AI decisions are transparent and auditable, a crucial factor for maintaining trust in AI 
applications, particularly in defense and critical infrastructure. These measures will not only 
prevent misuse but also enable swift detection and response to potential threats. 


Copyright 2025 B rightQuery, Inc. |  | www.BrightQuery.com | www.BrightQuery.ai  
200 Spectrum Center Drive, Suite 300 , Irvine, CA 9261 8 | 1- 888- BQDATA1  | The Factual AI Company™ 
Together, these actionable policy steps form an integrated strategy that interlinks authoritative 
data curation, unified standards, ideological neutrality, technological innovation, and streamlined 
regulatory frameworks. This comprehensive approach will enable the United States to build a 
resilient and transformative AI ecosystem that advances our national interests and positions AI as 
a catalyst for positive change across all sectors. 
6. ConclusionThis document presents a comprehensive blueprint that translates high-level government 
directives into practical, transformative actions. The Executive Order mandates that “ It is the 
policy of the United States to sustain and enhance America’s global AI dominance in order to 
promote human flourishing, economic competitiveness, and national security,” while JD Vance’s 
remarks emphasize the need to avoid excessive regulation and ensure ideological neutrality in 
American AI. These directives demand a unified data ecosystem that drives innovation, reduces costs, and reinforces national security. 
Our action plan leverages authoritative data sources, unified standards, and automated 
transformation mechanisms to create a “currency of data” that bridges fragmented datasets and 
powers reliable, high-quality AI applications. This robust infrastructure minimizes inefficiencies, 
lowers operational expenses, and accelerates AI deployment across critical sectors such as 
healthcare, defense, and education. Every element - from rigorous data curation protocols and 
streamlined compliance processes to proactive cybersecurity measures - is designed to reinforce 
the overall framework, ensuring that our national AI capabilities are both resilient and effective. 
BQ is uniquely positioned to contribute to this national effort. With its deep expertise in factual 
data-driven AI and a proven record of collaborating with federal agencies, BQ is exceptionally 
equipped to develop advanced methodologies for data verification, guide the implementation of 
unified standards, and maintain strict ideological neutrality. By integrating cutting-edge 
technological solutions with a clear understanding of strategic policy directives, BQ can help 
transform our national data infrastructure into a robust foundation for next-generation AI. 
We invite policymakers and key stakeholders to consider BQ’s role as a strategic partner in 
advancing American leadership in AI. This collaborative effort will not only reinforce our 
competitive edge on the global stage but will also deliver lasting benefits to society, the 
economy, and national security. 
This document is submitted in response to the RFI and is intended for public dissemination. All 
comments are provided voluntarily and are not binding. 


