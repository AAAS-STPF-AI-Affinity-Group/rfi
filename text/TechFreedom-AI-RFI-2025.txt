Comments of 
TechFreedom  
Andy Jungi & Santana Boultonii 
In the Matter of  
Request for Information on the Development of an Artificial Intelligence (AI) Action Plan  
2025 -02305  
March 15, 2025
i Andy Jung is Associate Counsel at  TechFreedom . He can be reached at 
ii Santana Boulton is a Legal Fellow at TechFreedom. She can be reached at 


TABLE OF CONTENTS  
Introduction  ................................ ................................ ................................ ................................ ............................  1 
I.The AI Action Plan Should Dispel Once and For All the Myth that AI is Unregulated
 ................................ ................................ ................................ ................................ ................................ ...............  2 
II.The AI Action Plan Should Lay Out a Light -Touch Approach to AI Regulation
Grounded in Existing Laws  ................................ ................................ ................................ ........................  2 
A.The AI Action Plan Should Consider the Feasibility of a Federal Regulatory
Sandbox for AI  ................................ ................................ ................................ ................................ ..........  3 
B.The AI Action Plan Should Call for Federal Preemption of State AI Laws  ........................  5 
III. The AI Action Plan Should Promote Open -Source AI  ................................ ................................ ....... 6 
IV. The AI Action Plan Should Uphold Free Speech Under the First Amendment .......................  7 
Conclusion ................................ ................................ ................................ ................................ ................................  9 


1 INTRODUCTION  
TechFreedom is a nonprofit, nonpartisan think tank based in Washington, D.C. It is dedicated 
to promoting technological progress that improves the human condition. It seeks to advance 
public policy that makes experimentation, entrepreneurship, and investment possible and 
thus unleashes the ultimate resourc e: human ingenuity. TechFreedom champions a light -
touch approach to artificial intelligence regulatio n1 that promotes open -source 
development,2 protects consumers from concrete harms,3 and upholds free speech under 
the First Amendment .4 
The Request for Information  lays out two laudable goals : “to sustain  and enhance  America's 
AI dominance, and  to ensur e that unnecessarily burdensome requirements do not hamper 
private sector AI innovation. ”5 In furtherance of these goals,  TechFreedom  recommends that 
the AI Action Plan pursue  the following priority policy actions : dispel the myth that AI is 
unregulated , lay out a light -touch approach to AI regulation grounded  in existing laws , 
promote open -source AI , and uphold free speech under the First Amendment . 
1 Corbin Barthold, 397: AI Policy Potpourri (Part One) , Tech Policy Podcast (Feb. 17, 2025), 
https://podcast.techfreedom.org/episodes/397 -ai-policy -potpourri -part -one; Andy Jung, Don't California My 
Texas: Stargate Edition , TECHFREEDOM  (Jan. 24, 2025), https://techfreedom.substack.com/p/dont -california -
my-texas -stargate . 
2 TechFreedom, Comment on  Managing Misuse Risk for Dual -Use Foundation Models (Sept. 9 , 2024 ), 
https://techfreedom.org/wp -content/uploads/2024/09/TechFreedom -NIST -AI-800 -1-Comments.pdf ; Andy 
Jung, California's AI Bill Threatens To Derail Open -Source Innovation , REASON  (Aug. 8, 2024), 
https://reason.com/2024/08/13/californias -ai-bill-threatens -to-derail -open -source -innovation/ ; 
TechFreedom Delivers Remarks at FTC’s August Open Commission Meeting , TECHFREEDOM  (Aug. 1, 2024), 
https://techfreedom.org/techfreedom -delivers -remarks -at-ftcs-august -open -commission -meeting/  
(Remarks of Andy Jung ). 
3 TechFreedom, Public Comment on CCPA Updates, Cyber, Risk, ADMT, and Insurance Regulations  (Feb. 19, 
2025), https://techfreedom.org/wp -content/uploads/2025/02/TF -Public -Comment -on-CCPA -Updates -
Cyber -Risk -ADMT -and-Insurance.pdf ; TechFreedom Delivers Remarks at FTC Open Commission Meeting , 
TECHFREEDOM  (May 19, 2023) , https://techfreedom.org/techfreedom -delivers -remarks -at-ftc-open -
commission -meeting -2/ (Remarks of Santana Boulton ). 
4 TechFreedom, Comment on Disclosure and Transparency of Artificial Intelligence -Generated Content in 
Political Advertisements (Sept. 19, 2024), https://techfreedom.org/wp -
content/uploads/2024/09/TechFreedom -FCC -AI-Comments.pdf ; Letter from TechFreedom to the Senate 
Committee on Rules and Administration Re: S. 2770, The Protect Elections from Deceptive AI Act  (May 14, 
2024), https://techfreedom.org/wp -content/uploads/2024/05/Coalition -Letter -S.-2770 -The-Protect -
Elections -from -Deceptive -AI-Act.pdf ; Ari Cohn, A.I. Panic is Causing First Amendment Hallucinations...in 
Humans , TECHFREEDOM  (Jan. 29, 2024), https://aricohn.substack.com/p/ai -panic -is-causing -first -amendment . 
5 Request for Information on the Development of an Artificial Intelligence (AI) Action Plan, 90 Fed. Reg. 9088 -
89 (Feb. 6, 2025) . 


  
2 I. The AI Action Plan Should Dispel Once and For All the Myth that AI is 
Unregulated  
AI is already regulated.6 Existing laws and regulations apply to AI :7 to quote the Federal 
Trade Commission, “ there is no AI exemption from the laws on the books. ”8 Discriminating 
against a potential tenant  is illegal, for example, regardless of whether the housing provider 
uses AI  to screen applicants .9 The AI Action Plan should state up -front that AI is  already  
regulated.  Next, the Plan should explain how existing laws and regulations apply to AI. 
II. The AI Action Plan Should Lay Out a Light -Touch Approach to AI Regulation  
Grounded in Existing Law s 
Rather than creating new rules for AI, the federal government should enforce existing laws , 
which already  address most policy concerns related to AI. The federal government does not 
need to create a new, complex regulatory framework for AI . Instead, the Department of 
Justice , Federal Trade Commission , and other federal agencies  should  use existing authority 
to police AI practices that harm consumers . 
On the one hand, this approach is light -touch: rather than creating a  new national regulator  
for AI, the federal government would use a sectoral approach  based on existing  authority . On 
the other hand, the federal government would continue to enforce  the laws already on the 
books to remedy AI-related harm s and punish bad actors . This approach would  allow the 
federal government to regulate the technology  while “ensur[ing] that unnecessarily 
burdensome requirements  do not hamper private sector AI innovation. ”10 
 
6 Andy Jung, ‘Unregulated AI’ is a myth , OC REGISTER  (Apr. 1, 2024), 
https://www.ocregister.com/2024/04/01/unregulated -ai-is-a-myth/ ; Alvaro M. Bedoya, Comm’r , Fed. Trade 
Comm’n , Remarks Before the International Association of Privacy Professionals : Early Thoughts on 
Generative AI  (Apr . 5, 2023) , https://www.ftc.gov/system/files/ftc_gov/pdf/Early -Thoughts -on-Generative -
AI-FINAL -WITH -IMAGES.pdf . 
7 See, e.g. , Andy Jung, Drake vs. Kendrick Lamar Proves AI Music Is Regulated , TECHDIRT  (June 5, 2024), 
https://www.techdirt.com/2024/06/05/drake -vs-kendrick -lamar -proves -ai-music -is-regulated/ . 
8 Press Release, Fed. Trade Comm’n , FTC Chair Khan and Officials from DOJ, CFPB and EEOC Release Joint 
Statement on AI  (Apr. 25, 2023) , https://www.ftc.gov/news -events/news/press -releases/2023/04/ftc -chair -
khan -officials -doj-cfpb -eeoc -release -joint -statement -ai. 
9 ROHIT CHOPRA , U.S.  CONSUMER FIN. PROT. BUREAU , KRISTEN CLARKE , U.S.  DEP’T OF JUST., CHARLOTTE A. BURROWS , U.S.  
EQUAL EMP. OPPORTUNITY  COMM ’N., & LINA KAHN, U. S. FED. TRADE COMM ’N., JOINT STATEMENT ON ENFORCEMENT 
EFFORTS AGAINST DISCRIMINATION AND BIAS IN AUTOMATED SYSTEMS  (2023 ), 
https://www.ftc.gov/system/files/ftc_gov/pdf/EEOC -CRT -FTC -CFPB -AI-Joint -Statement%28final%29.pdf . 
10 Request for Information on the Development of an Artificial Intelligence (AI) Action Plan, supra note  5, at 
9088 . 


3 The AI Action Plan should identify key areas of AI policy , such as consumer protection and 
AI in Education .11 For each key area, the Plan should enumerate  relevant  federal laws and 
regulations that apply to AI and explain how those rules  address harms caused by AI  in that 
sector . 
The Federal Trade Commission, for example, has broad authority over unfair and deceptive 
acts or practices that harm consumers.12 The Commission is already using this consumer 
protection authority successfully  to crack down on AI -powered scams and fraud.13 
Meanwhile , the National Institute of Standards and Technology and the U .S. AI Safety 
Institute manage more technical and esoteric AI concerns , such as  “developing the testing, 
evaluations, and guidelines that will help accelerate trustworthy AI innovation in the United 
States  … with a keen focus on helping to prevent misuse of this technology by those who seek 
to undermine our public safety and national security. ”14 This sectoral approach of using  
existing  laws and institutions  to regulate AI is already in-place and  working.15 The AI Action 
Plan should formalize the approach across the federal government.  
A. The AI Action Plan Should Consider the Feasibility of a Federal
Regulatory Sandbox for AI
Regulatory sandboxes are regulatory frameworks which allow qualifying companies to offer 
products and services without complying with the red tape governing that industry.  Sandbox 
companies are not exempt from all regulations : regulatory sandboxes  may explicitly provide , 
for example,  that co nsumer protection  and antidiscrimination laws still apply. Regulatory 
sandboxes may expire after a set period , and companies automatically exit the ir sandbox 
once they outgrow the applicable criteria.  
11 The AI Action Plan could borrow categories from the NAIAC Insights for the Administration of President 
Donald J. Trump  report : 1. AI and the Workforce ; 2. AI Awareness and Literacy ; 3. AI in Education ; 4. AI in 
Science ; 5. AI in Health ; 6. AI in Government ; 7. AI to Empower Small Business, Entrepreneurs & Nonprofits ; 
8.AI Governance ; 9. AI for the American People ; 10 AI in Law Enforcement . U.S.  NAT’L ARTIFICIAL INTEL . 
ADVISORY COMM ., NAIAC  INSIGHTS FOR THE ADMINISTRATION OF PRESIDENT DONALD J. TRUMP : DRAFT REPORT  (2025) ,
https://www.nist.gov/system/files/documents/noindex/2025/01/24/NAIAC_New_Administration_Report -
Draft_2025.01.22.pdf .
12 15 U.S.C. § 45(a)(1).
13 See, Press Release, Fed . Trade Comm’n , FTC Announces Crackdown on Deceptive AI Claims and Schemes
(Sept . 25, 2024), https://www.ftc.gov/news -events/news/press -releases/2024/09/ftc -announces -
crackdown -deceptive -ai-claims -schemes  (describing the FTC’s Oper ation AI Co mply which launched law
enforcement actions against companies which sell AI tools  that can be used in unfair and deceptive manners ).
14 Nat’l Ins t. of Standards and Tech. , U.S. Artificial Intel. Safety Inst. , https://www.nist.gov/aisi  (last visited
Mar. 14, 2025).
15 CHOPRA ET AL ., supra not e 9.


4 Legislatures create regulatory sandboxes to reduce legal pressure on growing industries and 
to encourage experimentation and innovation.16 Regulators then collaborate with sandbox 
companies to collect data on the industry,  and, i n turn, the sandbox data inform legislative 
changes that  better serve the industry and consumers.  
Fourteen states have created regulatory sandboxes for various industries,17 and Texas is 
considering a regulatory sandbox for AI.18 At the federal level, Senator s Mike Rounds (R-SD) 
and Martin Heinrich  (D-NM)  introduced a  bill last year to establish a sandbox for AI in 
banking.19 Representative s Frech Hill (R-AR) and Ritchie Torres (D-NY) introduced the 
House companion bill.20 
The European Union’s AI Act requires each EU member state to establish a regulatory 
sandbox  for AI ,21 and Spain recently launched the first EU AI sandbox in  partnership with the 
European Commission .22 Regulatory sandboxes , however, are not new : over 50 countries 
have experimented with using regulatory sandboxes for digital financial services .23 
The details  and logistics of a federal regulatory sandbox are outside the scope of this Request 
for Information. For now, the AI Action Plan should introduce and examine the idea of 
regulatory sandboxes for AI , using the states and E uropean Union as case studies . The AI 
Action Plan should also  initiate a new round of public comment specifically on  a federal  
regulatory sandbox for AI . 
16 Andy Jung, Shifting Sands in the Tech Sector , TECHDIRT (Apr. 7, 2022 , 3:31 PM), 
https://www.techdirt.com/2022/04/07/shifting -sands -in-the-tech -sector/ .  
17 INST. FOR REFORMING GOV’T, REMOVING BARRIERS TO INNOVATION : HOW REGULATORY SANDBOXES CAN SOLVE KITCHEN 
TABLE ISSUES  8 (2024 ), https://reforminggovernment.org/wp -
content/uploads/2024/05/IRG_SandboxReport.pdf . 
18 H.B. 1709 , 89th Leg. , (Tex . 2025) . See also , Jen Sidorova , Proposed Artificial Intelligence Legislation Would 
Drive Innovation out of Texas , REASON  (Mar . 3, 2025) , https://reason.org/commentary/artificial -intelligence -
legislation -is-going -to-drive -innovation -out-of-texas/ . 
(explaining how “Texas House Bill 1709’s exemptions for small businesses and experimental  AI sandboxes 
are well -intentioned but ultimately insufficient.”) .  
19 Unleashing AI Innovation in Financial Services Act , S.4951 , 118th Cong. (2024) . See also  Matthew J. Rogers 
& Maxwell J. Black , United States: Child’s Play: Congress Proposes Allowing Sandboxes for AI Within the 
Financial Services Industry , K & L GATES GLOB. INV. L. WATCH , 
https://www.investmentlawwatch.com/2024/08/07/childs -play -congress -proposes -allowing -sandboxes -
for-ai-within -the-financial -services -industry/  (last visited Mar. 14, 2025).  
20 Unleashing AI Innovation in Financial Services Act , H.R.  9309 , 118th Cong. (2024) . 
21 Regulation 2024 /1689 , art. 57, 2024  O.J. 88-89. 
22 First Regulatory Sandbox on Artificial Intelligence Presented, EUR. COMM’N. (June 27, 2022) , https://digital -
strategy.ec.europa.eu/en/news/first -regulatory -sandbox -artificial -intelligence -presented .  
23 Alex Engler, The AI Regulatory Toolbox: How Governments can Discover Algorithmic Harms , BROOKINGS INST. 
(Oct. 9, 2023), https://www.brookings.edu/articles/the -ai-regulatory -toolbox -how -governments -can-
discover -algorithmic -harms/ .  


5 B. The AI Action Plan Should Call for Federal Preemption  of State AI Laws
Across the country, states are considering hundreds of potential bills related to AI, and states 
like California and Colorado have already passed state AI legislation.24 While federalism 
sometimes benefits innovation, AI services are offered nationwide, so one state’s regulation 
will inevitably demand compliance by all American companies. Th e result would be  a 
patchwork of inconsistent legislation , with each  state’s laws layering on multiple sets of 
conflicting  obligations . 
Americ a needs a national  approach to AI policy “to sustain and enhance America's AI 
dominance, and to ensure that unnecessarily burdensome requirements do not hamper 
private sector AI innovation.”25 Europe and China , our principa l rivals in the AI race, both 
have national approaches, offering their companies the clarity of a single model . 
Nancy Pelosi (D-CA) explained that Congress is taking a more thorough and measured 
approach to AI regulation:  
AI has been a central policy focus of the President and the Congress for the 
past few years …In the House of Representatives and the U.S. Senate, we early 
on brought in academics, entrepreneurs and leaders from the public, private 
and non -profit sectors to express AI’s opportunities and challenges.  
The review is coming down to if and what standards and guardrails should 
Congress legislate. In addition to focusing on protections, we wanted to pursue 
improving AI. This work continues under the Bipartisan Task Force on 
Artificial Intelligence under the leadership of co -chairs Congressman Ted Lieu 
and Congressman Jay Obernolte .26 
Federal Trade Commission Chair Andrew Ferguson stated the risk of overregulating AI more 
bluntly: “Such regulation could strangle this nascent technology in its cradle, or move the 
development of the technology to foreign states hostile to our national interests.”27 Allowing 
24 Devin McCormick, State AI Policy in 2024: What Happened, What Didn’t, and Where do we go From Here? , 
LIBERTAS INST. (Jan. 7, 2025), https://libertas.institute/tech -innovation/state -ai-policy -in-2024 -what -
happened -what -didnt -and-where -do-we-go-from -here/ .  
25 Request for Information on the Development of an Artificial Intelligence (AI) Action Plan, supra note 5, at 
9088.  
26 Press Release, Nancy Pelosi, Pelosi Statement in Opposition to California Senate Bill 1047  (Aug. 16, 2024) , 
https://pelosi.house.gov/news/press -releases/pelosi -statement -opposition -california -senate -bill-1047 .  
27 Andrew N. Ferguson, Comm’r, Fed. Trade Comm’n, Concurring and Dissenting Statement of Commissioner  
Andrew N. Ferguson Joined by Commissioner  Melissa Holyoak Regarding the FTC Staff Report on AI 
Partnerships  & Investments 6(b) Study Matter P246201 (Jan. 17, 2025) , 
https://www.ftc.gov/system/files/ftc_gov/pdf/ferguson -ai-6b-statement.pdf .  


  
6 states to take charge on AI policy threatens to create a complicated patchwork of laws  that 
will burden the private sector  and harm national interests.28 
The AI Action Plan should call on Congress to preempt state AI laws. The Plan should 
describe the various types of AI laws states have enacted or considered and create a n AI law 
taxonomy .29 From there, federal law makers can have an informed conversation about the 
contours of national AI policy and decide the types of laws the federal government should 
control rather than states.30 The AI Action Plan should also initiate a new round of public 
comment specifically on federal preemption of state AI laws.  
III. The AI Action Plan Should Promote Open -Source AI  
In July  2024 , NTIA released a Report on Dual -Use Foundation Models with Widely Available 
Model Weights , finding that  “innovation and research” are likely “the main benefits of 
openness.”31 That same month, the F ederal Trade Commission  concluded that “open -
weights models have the potential to drive innovation, reduce costs, increase consumer 
choice, and generally benefit the public – as has been seen with open -source software. ”32 The 
Cybersecurity and Infrastructure Security Agency  joined in on the prais e of open -source 
models : “we see significant value in open foundation models to help strengthen 
cybersecurity, increase competition, and promote innovation .”33 In short: open -source AI 
benefits innovation , competition,  and cybersecurity.  
The AI Action Plan should promote open -source AI in several ways. First, the Plan should 
highlight research and strive to educate the public on the benefits of open -source  AI—while 
dispelling myths a bout open technologies. To that end, the Plan should implement across the 
federal government a marginal risk analysis framework for evaluating  open -source AI 
 
28 See Dean W. Ball & Alan Z. Rozenshtein, Congress Should Preempt State AI Safety Legislation , LAWFARE  (June  
17, 2024 , 2:00 PM), https://www.lawfaremedia.org/article/congress -should -preempt -state -ai-safety -
legislation  (discussing reasons Congress should preempt State AI Safety laws  to protect American 
innovation).  
29 Id. 
30 CONG. RSCH. SERV., FEDERAL PREEMPTION : A LEGAL PRIMER  1-10 (2023 ), https://www.congress.gov/crs -
product/R45825 .  
31 NAT’L TELECOMM . & INFO. ADMIN ., DUAL-USE FOUNDATION MODELS WITH WIDELY  
AVAILABLE MODEL WEIGHTS  (2024), https://www.ntia.gov/sites/default/files/publications/ntia -ai-open -
model -report.pdf.  
32 On Open -Weights Foundation Models , U.S. FED. TRADE COMM ’N OFF. OF TECH. BLOG (July 10, 2024), 
https://www.ftc.gov/policy/advocacy -research/tech -at-ftc/2024/07/open -weights -foundation -models .  
33 Jack Cable & Aeva Black , With Open Source Artificial Intelligence, Don’t Forget the Lessons of Open Source 
Software , CYBER SECURITY & INFRASTRUCTURE  SEC. AGENCY  (July 29, 2004) , https://www.cisa.gov/news -
events/news/open -source -artificial -intelligence -dont -forget -lessons -open -source -software .  


7 systems .34 For example, when assessing the overall risk of open -source models, the U.S. AI 
Safety Institute should use a “marginal risk and  benefit analysis framework” to weigh “the 
additional risks and benefits” of open models  “compared to those that come from” closed 
models or “other technologies more g enerally.”35 This approach recognizes that, because 
open -source software has unique risks and benefits, open -source developers must tailor 
their risk mitigation strategies  accordingly : 
Risks from open models and closed models should both be managed, though  
the particular mitigations required may vary. In some cases, managing the risk  
of open models may pose unique opportunities and challenges to reduce risk  
while maintaining as many of the benefits of openness as possible.36 
Overall, the Cybersecurity and Infrastructure Security Agency  has concluded : “While AI 
capabilities introduce new threats into the landscape, leading academics have proposed that 
the marginal risk from open as opposed to closed source models is low.”37 Meanwhile, open -
source AI boasts many benefits . The AI Action plan should recognize th e upside of open -
source technologies and promote open -sourcing models domestically.  
IV. The AI Action Plan Should Uphold Free Speech Under the First Amendment
The AI Action Plan should protect the free speech rights of Americans and AI-focused firms. 
Given the vast potential of AI, people are reasonably concerned about the accuracy of AI 
outputs. This concern is a reason to promote competition and to encourage firms to adopt 
clear standards, bu t it does not justify infringing on firms’ First Amendment rights . The Plan 
should not attempt to define what is or is not ideological  because such definitions are 
inherently political , content -based,  and would prescribe certain acce ptable, government -
favored outcomes . 
The Executive Order directs firms to  deve lop AI systems that “are free from ideological bias 
or engineered social agendas.”38 But l ike individual speech, a corporation’s speech is 
34 See TechFreedom , supra note 2 (supporting the use of marginal risk and benefit analysis to open -source AI 
development) .  
35 See NAT’L TELECOMM . & INFO. ADMIN ., supra note 31, at 10 .  
36 Id.  
37 Memorandum from Jen Easterly, CISA Director, to the Nat ’l Tele comm . & Info. A dmin. (June 18, 2024) , 
https://downloads.regulations.gov/NTIA -2023 -0009 -0335/attachment_1.pdf . See, e.g., Bommasani et al., 
Considerations for Governing Open Foundation Models  (2023) , https://hai -
production.s3.amazonaws.com/files/2023 -12/Governing -Open -Foundation -Models.pdf  (suggesting that 
policymakers focus on centering marginal risk) .  
38 Exec. Order No. 14179 , § 1, 90 Fed. Reg . 8741  (Jan. 23, 2025) , 
https://www.federalregister.gov/documents/2025/01/31/2025 -02172/removing -barriers -to-american -
leadership -in-artificial -intelligence .  


  
8 protected by the First Am endment ,39 and AI models are the speech of their creators.  
Companies have the First Amendment  right to create AI systems that reflect their preferred 
ideological biases and social agendas . Companies , and the individuals that make them up, 
make specific choices about what data to use to train AI models and rigorously define the 
kinds of responses models should put out. “The choices compani es … make,” write 
constitutional  scholars, “ about what sources to train  on and what results to modify using 
human feedback directly or indirectly influence the output of their A Is.”40 Training, in other 
words, is a n exercise of editorial judgment  protected by the First Amendment —like any 
other act of selection of content .41 
Firms make choices about how to train their models: whether to include books or papers, 
and how to prioritize responses, especially to topics of social concern. Training choices on 
politically charged topics constitute firms’ political speech . The government does not get to 
tell private companies what political views to have or promote , or to stop their political 
speech.42 The AI Action Plan should preserve this free speech, not attempt to mandate so -
called non -ideological speech : “[A]bove all else, the First Amendment means that 
government has no power to restrict expression because of its message, its ideas, its subject 
matter, or its content.”43 
Indeed, t he government cannot define what is non -ideological, what is biased, or what an 
“engineered social agenda” is . It is not the business of the state to say what is true, nor what 
acceptable political beliefs are. “The First Amendment reflects ,” the Supreme Court has said , 
“‘a profound national commitment to the principle that debate on public issues should be 
uninhibited, robust, and wide -open. ’”44 The state cannot establish a set of acceptable , true, 
non-ideological beliefs  because defining such speech entails privileging certain speech over 
 
39 See Citizens United v. F ed. Election  Comm’n , 558 U.S. 310, 365 (2010) (holding that the government “may 
not suppress political speech on the basis of the speaker’s corporate identity”); First Nat’l Bank v. Bellotti, 435 
U.S. 765, 79 7-98 (1978) (Burger , J., concurring ) (reasoning  that the First Amendment protects corporate 
speech).  
40 Eugene Volokh, Mark A. Lemley, & Peter Henderson, Freedom of Speech and AI Output , 3 J. FREE SPEECH L. 
651 , 652 (2023), https://www.journaloffreespeechlaw.org/volokhlemleyhenderson.pdf . 
41 Moody v. NetChoice, LLC, 603 U.S. 707, 717  (2024)  (“Traditional publishers and editors also select and 
shape other parties’ expression into their own curated speech products. And we have repeatedly held that 
laws curtailing their editorial choices must meet the First Amendment’s requirements. ”). 
42 See Citizens United , 558  U.S. at 324  (“The Government may not render a ban on political speech 
constitutional by carving out a limited exemption through an amorphous regulatory interpretation.” ). 
43 Police Dep ’t of Chicago v. Mosley, 408 U.S. 92, 95 (1972) . 
44 Snyder v. Phelps, 562 U.S. 443, 452 (2011)  (quoting New York Times Co. v. Sullivan, 376 U.S. 254, 270 
(1964) ). 


9 others —and such content -based restriction s are presumably unconstitutional.45 To respect 
the First Amendment, t he Plan should avoid defining acceptable political beliefs . 
CONCLUSIO N 
In order “to sustain  and enhance America's AI dominance, and  to ensur e that unnecessarily 
burdensome requirements do not hamper private sector AI innovation ,”46 the AI Action Plan 
should : dispel the myth that AI is unregulated, lay out a light -touch approach to AI regulation  
grounded in  existing laws , promote open -source AI , and uphold free speech under the First 
Amendment . Overall, public comment is a comprehensive and democratic method for 
developing a national AI strategy. TechFreedom celebrates the initiative and  looks forward 
to helping the administration  craft national AI policy  that fosters  innovation . 
Respectfully submitted,  
____________/s/____________  
Andy Jung  
Associate Counsel  
Santana Boulton  
Legal Fellow  
TechFreedom  
1500 K Street NW  
Floor 2  
Washington, D .C. 20005  
March 15, 2025  
45 See Mosley , 406 U.S. at 95.  
46 Request for Information on the Development of an Artificial Intelligence (AI) Action Plan , supra  note 5. 


