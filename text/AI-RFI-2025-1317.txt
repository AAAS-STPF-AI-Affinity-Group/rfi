PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 88-slqg-nepb
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1317
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Consum er Technology Association (CTA)
General Comment
See attached com m ents from  the Consum er Technology Association (CTA)
Attachments
CTA Com m ents on OSTP AI Action Plan RFI FINAL


– 1 –BEFORE THE  
NETWORKING AND INFORMATION TECHNOLOGY RESEARCH AND 
DEVELOPMENT NATIONAL COORDINATION OFFICE AND  
WHITE HOUSE OFFICE OF SCIENCE AND TECHNOLOGY POLICY 
In the Matter of  
Request for Information on the Development 
of an Artificial Intelligence Action Plan 
COMMENTS O F THE CONSUMER TECHNOLOGY ASSOCIATION 
IN RESPONSE TO THE NETWORKING AND INFORMATION TECHNOLOGY 
RESEARCH AND DEVELOPMENT NATIONAL COORDINATION OFFICE ON THE 
DEVELOPMENT OF AN ARTIFICIAL INTELLIGENCE ACTION PLAN 
The Consumer Technology Association® (“CTA”) submits this response to the 
Networking and Information Technology Research and Development (“NITRD”) National 
Coordination Office’s (“NCO”) Request for Information on behalf of the Office of Science and 
Technology Policy (“OSTP”) regarding the development of an Artificial Intelligence (“AI”) 
Action Plan (the “AI Action Plan”).1  
CTA’s membership includes over 1200 companies from every facet of the consumer 
technology industry, including manufacturers, distributors, developers, retailers, and integrators, 
with startups or small and mid-sized companies comprising 80 percent of CTA’s members. CTA 
also owns and produces CES®—the most powerful tech event in the world.  
I. INTRODUCTION
CTA applauds the Trump Administration’s (the “Administration”) early and decisive
action to reframe our nation’s AI policy to enhance competitiveness and private sector growth 
while limiting unnecessary regulation and oversight. With this action, the Administration can 1 This document is approved for public dissemination. The document contains no business-proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution. 


– 2 –seize this “‘Sputnik moment,’ and unshackle American innovation” to “help America’s tech 
leaders go toe to toe with foreign competitors.”2 
Investment in AI technology and systems continues to grow, and U.S. companies are at 
the forefront of the development and deployment of this powerful new technology that is 
positioning America’s tech industry to dominate the global competition and transform society for 
the benefit of all Americans. Indeed, CTA member companies continue to lead in the 
development and implementation of AI-enabled systems and solutions that are positively 
impacting human and societal development: promoting growth, improving the welfare and well-
being of individuals, and enhancing global innovation and productivity.3 
However, overly broad and prescriptive rules are likely to undermine the many benefits 
of AI that are available now and in the future. Notably, the National Security Commission on 
Artificial Intelligence’s Final Report declined to endorse significant new regulation for AI 
technologies due, in part, to the “speed of technology development by the private sector....”4
For these reasons, the Administration must adopt a new national policy framework that 
supports private sector investment and growth; eschews excessive regulation and oversight; 
establishes federal primacy on issues of national policy; and leverages existing public and private 
standards and norms that ensure sufficient guardrails for AI systems.   
2 CTA CEO and Vice Chair, Gary Shapiro's letter to the editor published  in The New York Times (Feb. 12, 2025). 
3 For example, Google has worked with the ALS Therapy Development Institute to use AI technologies to improve 
the lives of people with ALS. Google and ALS TDI: Working Together to Use Data to Improve the Lives of People 
with ALS, March 3, 2022, https://www.als.net/news/google-and-als-tdi/ . And Microsoft’s AI for Good Lab is 
exploring AI solutions to pressing issues such as curbing malnutrition and empowering blind and low-vision 
individuals to easily navigate their world.  See AI For Good Lab, https://www.microsoft.com/en-
us/research/group/ai-for-good-research-lab/ . 
4 See Final Report, National Security Commission on Artificial Intelligence, at 449 (Mar. 19, 2021), available at 
https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-1.pdf .  


– 3 –II. RESET AMERICAN AI POLICY TO ENSURE CONTINUED AMERICAN
COMPETITIVENESS AND EXCELLENCE
The Administration’s AI Action Plan should recognize the private sector’s essential role
in driving AI innovation and adopt affirmative policies to support continued private sector 
growth. U.S. companies, both large and small, are leading on the development and deployment 
of leading AI models, systems and technology. The Stanford Institute for Human-Centered 
Artificial Intelligence analyzed data on key indicators including research, private investment, and 
patents from 36 countries and ranked the U.S. first in AI development.5 
The National Institute of Standard and Technology (“NIST”) has recognized that “new 
AI-enabled systems are revolutionizing and benefitting nearly all aspects of our society and 
economy – everything from commerce and healthcare to transportation and cybersecurity.”6 The 
economic and societal effects of AI are already having a beneficial impact on the way we work, 
live and play. For example, AI agents are reportedly able to create detailed research summaries 
in minutes that would take humans hours to draft,7 and a 2023 study led by Harvard Business 
School found that consultants who worked with A.I. produced 40 percent higher quality results 
on 18 different work tasks.8 Similarly, using AI hardware and high-performance computing 
systems are improving medical imaging quality, supporting improved scientific modeling and 
5 Stanford HAI Staff, Global AI Power Rankings: Stanford HAI Tool Ranks 36 Countries in AI, November 21, 2024, 
available at: https://hai.stanford.edu/news/global-ai-power-rankings-stanford-hai-tool-ranks-36-countries-ai   
6 Artificial Intelligence , NIST, https://www.nist.gov/artificial-intelligence .  
7 Rhiannon Williams, OpenAI’s New Agent Can Compile Detailed Reports on Practically Any Topic , February 3, 
2025, MIT Technology Review, available at: https://www.technologyreview.com/2025/02/03/1110826/openais-new-
agent-can-compile-detailed-reports-on-practically-any-topic/   
8 Fabrizio Dell’Acqua, Edward McFowland III, Ethan Mollick, Hila Lifshitz-Assaf, Katherine C. Kellogg, Saran 
Rajendran, Lisa Krayer, François Candelon, and Karim R. Lakhani, Navigating the Jagged Technological Frontier: 
Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality , September 22, 
2023, Harvard Business School Technology & Operations Mgt. Unit Working Paper No. 24-013; available at: 
https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf   


– 4 – 
 helping simulate critical infrastructure and services such as weather simulations and biological 
modeling. 
To ensure American companies’ continued leadership in AI innovation, the AI Action 
Plan should avoid heavy handed regulations and unnecessary oversight, like those proposed in 
the prior administration. Instead, AI policies should ensure responsible development while 
maintaining U.S. global leadership and competitiveness. The AI Action Plan should also be 
principles-based and focused on outcomes rather than on the technical inputs of AI systems. 
Further, the AI Action Plan should adopt a risk-based perspective that focuses potential 
mitigation on specific, concrete potential harms without imposing unnecessary compliance 
burdens on the thousands of applications and use cases that present no risks. 
President Biden’s Executive Order on AI reflected a misguided approach to AI 
policymaking, favoring the development of complex and costly regulations in certain areas, at 
the risk of slowing innovation and growth. For example, the prior administration’s reliance on 
the Defense Production Act to mandate complex “know your customer” data collection and 
disclosure rules reflects the type of regulation that this Administration must avoid. A more 
balanced federal policy for AI would encourage the continued development of accurate, ethical, 
and trustworthy AI without imposing burdensome government mandates and reporting 
requirements of the past that slowed innovation and growth.   
In line with this approach, the Administration should prioritize policies that endorse self-
regulation or reliance on established industry standards to ensure sufficient guardrails are in 
place. Where possible, the new AI Action Plan should also embrace the use of regulatory 
sandboxes or other tools to explore measures to manage risks without imposing arbitrary, heavy-
handed regulations. 


– 5 –Only when regulations are deemed to be absolutely necessary should they be considered, 
and then only after a vigorous cost-benefit analysis based on a robust public record. This 
approach was used in the previous Trump Administration policies on AI and should be adopted 
again in this context.9 Further, any new regulations should focus on specific use cases based on 
risk, rather than attempting to apply new rules broadly to AI systems or models. Finally, the 
Administration should articulate a policy that opposes foreign government attempts to impose 
excessive restrictions on the development of AI models or on US AI innovation, such as 
requiring pre-deployment testing of AI models. These efforts should focus, initially, on 
counterparts in Europe to warn against overreaching regulations implementing components of 
the EU AI Act. 
III. AI POLICY SHOULD BE SET AT THE FEDERAL LEVEL
The AI Action Plan should set a clear national AI policy which obviates the need for
states and localities to attempt to govern in this area. Guardrails set at the national level will 
increase consumer trust and allow American innovation in AI to safely flourish. In the absence of 
a clear federal framework for AI, state legislatures will likely continue to attempt to regulate the 
development and deployment of AI via a patchwork of state and local obligations. Several states 
9 See Executive Order 13859, Maintaining American Leadership in Artificial Intelligence , February 11, 2019, 
available here: https://www.federalregister.gov/documents/2019/02/14/2019-02544/maintaining-american-
leadership-in-artificial-intelligence  (directing agencies to develop appropriate technical standards for AI 
technologies in consultation with the privacy sector, academia, non-governmental entities, and other appropriate 
stakeholders); Memorandum for the Heads of Executive Departments and Agencies: Guidance for Regulation of 
Artificial Intelligence Applications , Office of Management and Budget, November 17, 2020, available here: 
https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf  (directing agencies to avoid precautionary 
approach to AI regulation that holds AI systems to an impossibly high standard). 


– 6 –have already adopted such laws, and in the first 66 days of 2025, 781 bills involving AI have 
already been introduced in 47 state legislatures.10
If left unchecked, state and local regulation of AI will create a particularly challenging 
compliance environment by creating inconsistent and sometimes conflicting state laws that will 
increase compliance and litigation costs, which in turn will hamper innovation and growth. CTA 
recognizes that startups and small to medium-sized businesses are the engine of the American 
economy. Unlike larger companies, these firms lack the resources to navigate a fragmented 
regulatory landscape. Burdening them with complex, state-by-state compliance will divert their 
focus from groundbreaking advancements, suppressing AI innovation and ceding a competitive 
edge to our global adversaries. AI developers and deployers are already facing a complex 
regulatory environment that includes requirements based on sectoral and state-specific 
requirements. For example, state privacy laws already create obligations related to the use of 
automated decision-making technologies, and a number of states have passed laws specifically 
targeting the development and deployment of AI tools.  
To prevent further spread of burdensome state AI laws, the AI Action Plan should 
articulate clear principles and federal action to ensure American competitiveness continues. 
Ideally, the AI Action Plan would be enacted through statute to emphasize the primacy of federal 
law and preempt conflicting or inconsistent state laws and policies. Further, the Administration 
should direct federal agencies to clarify the applicability of existing law to AI technology, 
thereby reducing the need for duplicative and cumbersome new regulations or laws. In addition, 10 See, e.g., Utah Artificial Intelligence Policy Act , Utah Code Ann. § 13-2-12 et seq.; Colorado Artificial 
Intelligence Act , Colo. Rev. Stat. § 6-1-1701 et seq.; California AI Transparency Act , Cal. Bus. & Prof. Code § 
22757.1; California Generative Artificial Intelligence: Training Data Transparency Act , Cal. Civ. Code § 3111; 
Artificial Intelligence (AI) Legislation, MultiState, available here: https://www.multistate.ai/artificial-intelligence-ai-
legislation; Virginia proposed High-Risk Artificial Intelligence Developer and Deployer Act , HB2094 (passed in 
both houses of the legislature and currently pending before Virginia Governor Youngkin). 


– 7 –building on the previous Trump Administration’s work under the National Artificial Intelligence 
Initiative, the AI Action Plan should reestablish a center for technical expertise to advance 
government understanding of AI and to support federal agencies with authority over critical 
sectors of our economy.11 
IV. ENSURE THAT THE AI ACTION PLAN RECOGNIZES WIDELY ACCEPTED
VOLUNTARY PRINCIPLES, STANDARDS AND FRAMEWORKS
The AI Action Plan should reflect the principles articulated in established, consensus-
based frameworks developed by industry groups and public-private collaborations. Specifically, 
the AI Action Plan should incorporate principles of CTA’s National AI Policy and Regulatory Framework , which, if adopted, would ensure that businesses have the flexibility to adopt AI risk 
management measures that focus on high-risk systems and are tailored to the specific risk profile 
of the AI systems they develop, deploy, and/or implement. In line with CTA’s framework, the AI 
Action Plan should recognize the unique roles of developers and deployers in the AI ecosystem 
system, and should consider the size, revenue, time in operation, and size of the user base when 
developing potential new obligations or system guardrails. It is important that the roles of 
developers and deployers be clearly defined, as some companies, such as retailers, may fall 
somewhere in between, depending on the use case.  
Other industry groups have also been actively developing standards for the development 
of safe AI systems. These consensus-based industry standards have established critical norms 
and standards to ensure the adoption of accurate, ethical, and trustworthy AI. In addition to CTA, 
11 Executive Order 13859, Maintaining American Leadership in Artificial Intelligence , February 11, 2019, available 
here: https://www.federalregister.gov/documents/2019/02/14/2019-02544/maintaining-american-leadership-in-
artificial-intelligence  (establishing a process for coordination with the private sector, academia, non-governmental 
entities, and other stakeholders). 


– 8 – 
 ISO and many other industry standards bodies have developed comprehensive and detailed 
standards governing the use and development of AI in various domains, including:  
 ANSI/CTA-2096: Guidelines for Developing Trustworthy Artificial Intelligence 
Systems. 
 ANSI/CTA-2125: Best Practices and Recommendations for Information Disclosure. 
 ISO/IEC 23894: AI Risk Management standard. 
 ISO/IEC 42001:2023: Information Technology - Artificial Intelligence – Management 
System. 
 IEEE P2863 – Recommended Practice for Organizational Governance of Artificial 
Intelligence. 
 
The AI Action Plan should also leverage and build upon existing efforts at public-private 
collaboration to establish flexible and evolving guardrails, such as the NIST AI Risk 
Management Framework (“RMF”). The RMF was developed at the direction of President 
Trump’s Executive Order 13859 of February 11, 2019, Maintaining American Leadership in 
Artificial Intelligence and NIST’s August 9, 2019, report “U.S. Leadership in AI: A Plan for 
Federal Engagement in Developing Technical Standards and Related Tools” and continues to be 
a leading voluntary standard for measuring, mapping and managing potential risks.  
CTA supports the development of frameworks such as the RMF because they offer a 
flexible and voluntary approach to AI governance that helps identify and address risks in the 
design, development, use, and evaluation of AI products and services across a wide spectrum of 
types, applications, and use cases throughout the AI lifecycle. The RMF is widely accepted as a 
critically important framework for AI governance, risk management and operations. 
Significantly, because the RMF is not binding it provides necessary flexibility for organizations 
of all sizes to implement key elements of the framework to suit their specific operational needs.  
This flexibility ensures that small and medium-sized enterprises can operationalize risk 
management protocols without facing the burden of complex and costly government mandates. 


– 9 –To address any potential risks posed by the most advanced, “frontier” AI models, the AI 
Action Plan should focus on research to improve the measurement of frontier model capabilities 
in national security-related areas. In line with a risk-based approach, the Administration should 
develop narrowly tailored requirements for models that achieve these capabilities, and should 
engage with standards organizations and international bodies to develop consensus around 
security protocols that are aligned with the U.S. approach.    
The AI Action Plan should provide safe harbor protections for entities that have self-
certified or obtained a third-party certification of compliance with an accepted AI risk 
management or governance standard, such as the NIST AI RMF or ISO 42001.12  
The Administration’s new plan should also recognize that certain entities are already 
subject to federal and state sector-specific regulations, and that additional overarching rules are 
unnecessary. Businesses in highly regulated industries such as healthcare, financial services, and 
automobile manufacturing are subject to regulations that govern their use of AI, and existing 
laws may apply to businesses’ use of AI in the hiring and employment context. The AI Action 
Plan should exempt businesses that are subject to sector-specific obligations from any new 
proposed obligations to avoid creating overly complex compliance obligations.    
V. INCENTIVIZE PRIVATE SECTOR INVESTMENT IN AI INFRASTRUCTURE
AND ADOPT POLICIES THAT WILL ENSURE THE U.S. CONTINUES TO
LEAD IN AI
The Administration should adopt policies that encourage and facilitate the development
of necessary infrastructure to support the development and training of large models, such as 12 See also Colorado Artificial Intelligence Act , Colo. Rev. Stat. Ann. § 6-1-1706(3)(b) (establishing compliance 
with the RMF as an affirmative defense to alleged violations of the Colorado Artificial Intelligence Act), Virginia 
proposed High-Risk Artificial Intelligence Developer and Deployer Act , HB2094 § 59.1-609(c)(establishing 
presumption of compliance for AI systems that are in conformity with the RMF). 


– 10 – 
 encouraging public-private partnerships and developing policies that encourage domestic chip 
development and data centers.  
The Administration should also consider promoting open data initiatives that would 
lower barriers to accessing large datasets that could be used to train and fine-tune large AI 
models. Building on the work done to make government data available at data.gov, the 
Administration should develop large datasets accessible to US businesses that could be used to 
responsibly train AI models. Doing so would enhance competition within the US by lowering the 
barrier for smaller firms to access sufficiently large datasets to train AI models. This proposal 
accords with section 5(v) of President Trump’s Executive Order 13859 of February 11, 2019, 
Maintaining American Leadership in Artificial Intelligence, which directed agencies to identify 
opportunities to use new technologies and best practices to increase access to and usability of 
open data and models. 
CTA urges the Administration to consider policies that promote innovation in safety and 
AI applications for autonomous vehicles (“AVs”). This is consistent with the goals envisioned by 
President Trump in his first term. The widespread and safe deployment of AVs will improve the 
safety of the traveling public, lower healthcare costs, improve the mobility of the elderly and 
blind and disabled Americans, bolster our supply chain, and strengthen the economy. The 
National Highway Traffic Safety Administration and Federal Motor Carrier Safety 
Administration should pursue rulemakings that assert the agencies’ exclusive authorities to test, 
approve, and oversee automated driving system technologies, enforcing compliance through 
Federal Motor Vehicle Safety Standards and Federal Motor Carrier Safety Regulations for all 
vehicle classes. Such action will help eliminate unnecessary barriers to the integration of AI 


– 11 –enabled safety-improving technologies into our transportation system, as well as ensuring 
American leadership in the AV sector. 
 In line with CTA’s comments on the Administration’s reciprocal tariffs policies, the AI 
Action Plan should use leverage gained through tariff negotiations to break down barriers—not 
build them up—and to expand opportunities for American businesses, while avoiding tariffs that 
cause inflation and lead to higher prices for consumers.13 Similarly, the AI Action Plan should 
avoid barriers to transfers of data and investments in AI.14 Specifically, the Administration 
should develop an international data center policy that permits businesses to use data centers in 
international locations subject to reasonable security controls, such as ensuring that such 
locations are certified under FedRAMP and that the data centers adhere to multi-layered 
technical and business controls to ensure data security.  
The Administration should also continue to use export controls to limit adversary access 
to critical technologies while working extensively with our allies to align U.S. measures with 
theirs. To ensure appropriate controls are in place, the Administration should adequately resource 
and modernize the Bureau of Industry and Security, including through the adoption of AI for 
supply chain analysis. The Administration should also consider revising Executive Order 14141 
on Advancing US Leadership in AI Infrastructure to remove those sections which create an 
unworkable national industrial policy for AI infrastructure through government leasing of federal 
lands. Instead, the Administration should preserve those sections of E.O. 14141 which seek to 
enable private sector innovation, development, and capacity-building through removal of 13 CTA CEO on Tariff Reciprocity Announcement , February 13, 2025, CTA, available at: 
https://www.cta.tech/Resources/Newsroom/Media-Releases/2025/February/CTA-CEO-on-Tariff-Reciprocity-
Announcement ; Gary Shapiro, Letter to Chief of Staff Susie Wiles, February 19, 2025, available here: 
https://cdn.cta.tech/cta/media/media/pdfs/cta-innovation-agenda-letter-to-wh-cos-wiles.pdf    
14 See CTA advocacy page on Trade and Tariffs, available here: https://www.cta.tech/Advocacy/Issues/Trade   


– 12 –regulations, streamlining of process, and incentives for private sector energy, infrastructure, and 
AI companies. 
The Administration should adopt energy policies that facilitate the development of AI 
technologies. Specifically, the Administration should grant the Federal Energy Regulatory 
Commission with greater authority to site and permit interstate transmission lines deemed to be 
in the national interest. This would streamline the approval process to remove barriers to 
accessing sufficient energy for data centers. In addition, the Administration should implement 
federal policies to prevent states from enacting discriminatory policies that disproportionately 
burden data centers.   
As it relates to the actual consumer technology products, the Administration should 
continue to administer the ENERGY STAR program through the Environmental Protection 
Agency.15 The guidelines for products established under the ENERGY STAR help reduce the 
energy demands of those products on the grid by driving energy efficiency gains without 
imposing burdensome regulations. As a voluntary program devised with the leadership of 
industry, ENERGY STAR is a clear example of how thoughtful guidelines can promote energy 
efficiency, consumer welfare, encourage innovation in new technologies, and enhance 
competition, all without subjecting industry to regulations that are not able to keep pace with the 
technological advancements. It is a critical path in making strides toward energy dominance and 
energy independence. 
15 Gary Shapiro, Letter to Environmental Protection Agency (EPA) Administrator Lee Zeldin, March 11, 2025, 
available here: https://cdn.cta.tech/cta/media/media/pdfs/epaadmin_energystar_lettter_cta_(03112025)_final.pdf . 


– 13 –VI. ENSURE SUFFICIENT ACCESS TO DATA FOR TRAINING AND
DEVELOPMENT OF ADVANCED AI MODELS AND SYSTEMS
The AI Action Plan should adopt balanced copyright rules that protect rights holders
while enabling AI systems to learn from prior knowledge and publicly available information. 
Specifically, the Administration should ensure access to publicly available scientific papers to 
accelerate AI in science fields. The Administration should establish that the fair use doctrine and 
text and data mining exceptions allow for uses of copyrighted, publicly available material for AI 
training purposes, so long as rights holders can opt out of such use. This mechanism will avoid 
significant impacts on rightsholders while avoiding unpredictable and lengthy negotiations with 
data holders during model development.  
VII. CONCLUSION
The Administration should capitalize on this opportunity to reset US AI policy. It can do
so by adopting policies that promote private sector growth, avoiding overbroad and burdensome 
obligations, and leveraging existing frameworks and standards. Importantly, federal AI policy 
and regulations should explicitly preempt patchwork state laws to avoid creating complicated 
overlays of overlapping state, federal, and sectoral requirements. By leveraging flexible, risk-
based approaches to AI governance, and establishing policies that enhance American firms’ 
competitiveness, this Administration can ensure continued American dominance in the 
development and adoption of AI.  


– 14 –Respectfully submitted, 
CONSUMER TECHNOLOGY ASSOCIATION 
By:      /s/ J. David Grossman  
J. David Grossman
Vice President, Policy & Regulatory Affairs 
  /s/ Kerri Haresign  
Kerri Haresign 
Senior Director, Technology & Standards  
   /s/ John Mitchell 
John Mitchell 
Senior Manager, Government Affairs  
Consumer Technology Association 
1919 S. Eads Street 
Arlington, VA 22202 
March 14, 2025 


