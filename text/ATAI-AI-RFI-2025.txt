Convening stakeholders across industries to craft principles and concrete codes of practice for 
the development and use of artificial intelligence. 
March 14, 2025 
RE: NITRD NCO, NSF, Request for Information (RFI) on the Development of an Artificial 
Intelligence (AI) Action Plan 
These comments are submitted on behalf of the Alliance for Trust in AI (ATAI), a nonprofit 
association of companies using artificial intelligence (AI) representing diverse sectors. Members 
of ATAI seek to ensure that AI can be a trusted tool by promoting effective policy and clear 
codes of practice for AI. We appreciate the opportunity to respond to the National Science 
Foundation (NSF) and Networking and Information Technology Research and Development 
(NITRD) National Coordination Office’s (NCO) Request for Information (RFI) on the 
Development of an Artificial Intelligence Action Plan (“AI Action Plan”).1 
ATAI is appreciative of this Administration's focus on ensuring that the U.S. AI ecosystem is 
competitive, vibrant, and trusted. We also urge the Administration to pursue policies that will 
ensure that the U.S. AI ecosystem remains a leader in thoughtful guidance and 
multi-stakeholder best practices for the development, integration, and deployment of AI. It is key 
to establish common language and practices to design, develop, use, and evaluate AI while 
promoting technological advancement and leadership in the digital space.  
We hope that the NSF and NCO will keep in mind the broad diversity of technologies, contexts, 
and uses of AI in developing these policies and actions. In particular, ATAI encourages 
guidelines, standards, and best practices that are broadly applicable across industries, and 
designed to be flexible over time and contexts in the evolving world of AI. We look forward to the 
forthcoming AI Action Plan and are committed to assisting in turbocharging the use of AI across 
American industries to benefit the public and private sectors alike.  
About ATAI 
The Alliance for Trust in AI brings together companies using advanced AI in many sectors to 
advocate for ways that we can build trust in all the kinds of AI that empower companies across 
the country and world. ATAI works with companies developing foundational AI models, creating 1
https://www.federalregister.gov/documents/2025/02/06/2025-02305/request-for-information-on-the-development-of-an
-artificial-intelligence-ai-action-plan


AI systems, and implementing these systems and models in their own work across industries. 
We aim to give organizations concrete guidance around how to build AI responsibly, implement 
AI principles, support learning and information sharing across sectors, and establish a shared 
voice for the many users of AI. ATAI is building on work done by technologists, policymakers, 
and academics to create a shared understanding of how to develop and use AI in trusted ways. 
Through multi-stakeholder partnership with members across industries and sectors, ATAI is 
developing definitions, principles, and codes of practice that allow developers, implementers, 
and users of AI systems to demonstrate responsibility and accountability to advance this 
technology. 
American Leadership in AI Innovation 
The United States has been a pioneer in advanced and emerging technology, and has played a 
leadership role in AI development due to three key factors, each fostering innovation and 
ensuring its continued success in the field. Together, they can help ensure that the United 
States remains at the forefront of AI development and continues to influence its global direction: ●Trust: Advancing measurement science, standards, and technology to deliver
high-quality, secure, and trusted software products. By establishing robust frameworks
for validation, the United States will foster confidence in its AI products, minimizing risks
and ensuring widespread adoption both domestically and internationally.●Partnership : Strong collaboration between government and industry allows for
innovation through R&D investments and the development of voluntary standards that
promote trustworthy products. These partnerships create an environment that
encourages both innovation and consensus-driven practices.●Global Leadership : Setting global AI standards by leveraging technological capabilities,
promoting private sector innovation, and prioritizing national defense interests. This
leadership allows the United States to shape international AI policies and ensure its
influence on the global stage.
Trustworthy and Safe Adoption of AI Across Industry 
Trust is fundamental to the widespread adoption of AI, and U.S. standards have played a critical 
role in establishing processes and measures to build that trust. The development of voluntary, 
multi-stakeholder standards and measurements, such as the National Institute of Science and 
Technology’s (NIST) Cybersecurity Framework (CSF), has accelerated the deployment of AI by 
consolidating industry best practices that have organically emerged over time.2 Similar efforts 
are underway within the NIST AI Risk Management Framework (RMF), which helps companies 
evaluate their choices in deploying AI systems and thoughtfully develop products that are 
accurate, robust, and reliable.3 By continuing to lead in global standard-setting, the United 
States can further enhance customer trust and maintain its international leadership in the 
software space. 
3 https://www.nist.gov/itl/ai-risk-management-framework 2 https://www.nist.gov/cyberframework  


As technology evolves, it is essential that standards and guidance not only address current and 
near-future risks but also remain flexible enough to adapt to the changing landscape of AI 
products, use cases, and markets. Scalability and adaptability are critical to ensure that AI 
systems can meet growing demands and adjust to fluctuating circumstances. Standards 
grounded in technical and scientific foundations provide stakeholders with the necessary tools 
to manage AI risks effectively while encouraging innovation by offering reassurance to 
developers and investors.  Given the potential risks involved in deploying AI, organizations across industries have 
developed governance frameworks aimed at addressing issues such as data integrity, safety, 
and resilience. In particular, ATAI’s members have brought together a set of high-level principles 
around development, implementation, and use of AI based on this need for harmonized risk 
management. This collaboration ensures that standards are not only theoretically sound but 
also practically feasible and beneficial. The consolidation of these insights into comprehensive 
principles has helped shape AI governance, fostering safer and more reliable systems. Risk 
management frameworks, which draw on established, consensus-driven practices, are essential 
in driving the adoption of trusted AI systems, helping organizations mitigate reputational, liability, 
and data risks. These frameworks can be adapted to secure AI systems and guide 
organizations in managing emerging AI-related challenges. Standards bodies like NIST offer consensus-based governance and technical guidance that 
should be leveraged by policymakers, ensuring that legislative language aligns with common 
definitions of AI technologies. This alignment will help reduce confusion and enhance 
compliance. 
Public-Private Partnerships 
Public-private partnerships that bring together the U.S. federal government, businesses, civil 
society, academia, and international partners are critical to advancing access to AI innovation 
infrastructure and will continue to play a significant role in its future development. The National 
AI Research Resource (NAIRR) Pilot serves as a prime example of how such partnerships can 
effectively drive progress by fostering collaboration among a range of stakeholders, fostering 
unified advancements in AI research and infrastructure.4  
Similarly, NIST's ongoing standards work demonstrates the power of these partnerships in 
developing frameworks that guide AI's ethical and technical evolution, offering safe, reliable, and 
aligned with industry best practices. This collaborative model is further supported by a long 
history of federal investment in research and development, which has helped advance 
breakthroughs and set the stage for continuous innovation.  
By enabling various companies to share resources, expertise, and knowledge, these 
partnerships promote industry-wide collaboration, ensuring that AI development benefits from a 4 https://nairrpilot.org/ 


broad perspective that incorporates various areas of expertise. To maximize their impact, these 
efforts should harmonize with regional, national, and international laws and initiatives, ensuring 
that AI innovation is aligned with global standards and regulatory frameworks. 
Global Engagement 
The United States has long been a global leader in introducing both innovative technologies and 
methods to ensure their trustworthiness, with ongoing international standards work and 
collaboration being central to this effort. Achieving global consistency in AI standards is critical 
for reducing regulatory complexity and enhancing widespread trust in AI systems. It is essential 
that NIST and the U.S. government continue to lead and participate in international discussions 
to align standards globally. NIST is already a global standards-leader, and organizations around 
the world look to their standards as neutral, scientific approaches.  
U.S. investments in foundational model development have resulted in AI models of superior 
quality, setting them apart from others that attempt to cut corners. This focus on developing core 
intellectual property not only yields better products today but also positions the United States to 
remain a leader as technology advances and computing power evolves. Encouraging other 
countries to adopt similar approaches will ensure the AI ecosystem fosters the development of 
core intellectual property and fair competition, sustaining American innovation on the global 
stage.  
To maximize the global impact of AI, international and national rules must be harmonized to 
create a unified framework for AI development that benefits all. Fragmenting best practices and 
guidelines, even from non-U.S. sources, would hinder innovation. Horizontal standards, 
applicable across sectors as well as promoting interoperability, are necessary for minimizing 
sector-specific adaptations.  
For successful international adoption, standards must be clear, implementable, 
innovation-friendly, neutral, and accessible to global users. Standards should also align with 
existing technology standards to avoid conflicts and enhance interoperability. Supporting 
frameworks like the NIST AI RMF, and promoting these standards globally in collaboration with 
international partners, will ensure consensus and drive forward a unified approach to powerful, 
trusted AI systems. 
Conclusion 
The Alliance for Trust in AI looks forward to continued collaboration with NCO and NSF to 
develop and refine voluntary standards and guidance that strengthen America's digital 
landscape, focused on supporting innovation while ensuring the security, reliability, and 
responsible use of AI. We find it incredibly important to balance innovation with responsible 
development and deployment, and we appreciate the ability to constructively weigh in on this 
important issue.  


Thank you for the opportunity to comment on this request for information. If you have questions 
or believe that we can be helpful to your work in any way, please contact ATAI’s coordinator 
Heather West, at 


