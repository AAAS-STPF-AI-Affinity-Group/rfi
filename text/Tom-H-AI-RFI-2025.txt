 
   Tom H  
Thank you for the opportunity to comment on the development of an Artificial Intelligence (AI) 
Action Plan. The rapid evolution of AI technology demands that we ensure advancements do not 
compromise user privacy or the protection of intellectual property ( IP) rights. The rate at which 
AI technologies are advancing in capability is too significant to gate from use in any contexts. 
The lack of control over flow of information when using an AI tool not only jeopardizes user 
privacy and IP but also severely res tricts critical research opportunities —especially in clinical 
settings where patient data is involved. As it stands, the amount of information that the AI tools 
and/or their company extracts from user input is not transparent whatsoever. The current lack o f 
transparency regarding the data extracted from user inputs is deeply concerning. AI tools should 
include a verifiable “private mode” that prevents data from being transmitted, stored, or used for 
training by the company or any other entities unless the u ser explicitly opts in. This option must 
be easily accessible and provide complete control to the user, ensuring that both individuals and 
organizations can safeguard their sensitive information. Moreover, complete legal assurance is 
essential for the hand ling of personal, proprietary, and clinical data. Without robust privacy 
controls, there is a significant risk that confidential information may be exposed to unauthorized 
parties. In the case of clinical data, for instance, the absence of clear safeguards  prevents 
researchers and clinicians from confidently using AI tools. Compliance with HIPAA guidelines 
is crucial here; any AI tool handling patient information must guarantee that such data is fully 
protected and not compromised in any way. Aligning these  privacy measures with existing legal 
frameworks - such as GDPR and HIPAA - would provide a strong legal and ethical foundation 
for these requirements. The present lack of these measures include restricted research 
opportunities, stifled innovation, and a general fear amongst individuals and organizations of 
data misuse that could ultimately hinder the broader adoption of AI technologies. In conclusion, I 
urge the agency to mandate that all AI tools offer a complete, and legally VERIFIABLE ‘private 
mode.’ This requirement will not only protect user data but also foster responsible innovation 
across all sectors, ensuring that the benefits of AI technology can be fully realized without 
compromising privacy or security. Thank you.  
 


