PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-cc9k-m 8x6
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1505
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Greg Colbourn
General Comment
Artificial Intelligence developm ent continues to race forward at a pace. We are not far off Artificial Superintelligence (ASI). The
developm ent of ASI poses an unprecedented security threat; a threat to the ongoing survival of the hum an race, no less. 
Please heed the worldâ€™s forem ost AI experts in academ ia and industry, when they warn of the existential threat ASI poses (see
safe.ai/statem ent-on-ai-risk). This is not a technology that can be safely developed by anyone, be they an individual, a com pany or or a
nation. Not even the great country of the United States of Am erica. 
The leaders of the largest AI com panies (OpenAI, Google, Anthropic) are engaging in suprem e hubris in thinking that they alone can
create _safe_ superintelligent AI. Especially considering the double-digit percent risk of hum an extinction they talk about; a risk that
neither US citizens nor citizens of the rest of the world have consented to taking, and one that exceeds safety thresholds for industries such
as nuclear and aviation by a factor of well over a thousand, with stakes far _far_ higher (the lives of every m an, wom an and child).
In order to safeguard both national and global security, it is param ount that the US lead efforts to prevent ASI from  being built anywhere
in the world. A bilateral agreem ent with China (second only to the US in AI capability) will be key to this. The last thing we need is to race
to the brink of catastrophe, and beyond, with China, when such a race to ASI is a suicide race by nature. 
This will be a very tough challenge, given the nature of the threat. To com pare it to nuclear arm s control is to fall short - a m ore apt
analogy would be if a single nuclear detonation would in fact end up burning off the entire atm osphere (as Manhattan Project scientists
feared as a possibility at one point), _and_ nuclear weapons had a tendency to spontaneously self-detonate. In such a world, the only way
for the hum an race to survive is to have a well-enforced global non-proliferation treaty that ensures that no nuke is ever built. 
The sam e applies now, in real life, to the building of ASI. Challenging as it m ay be to prevent it, I believe the US governm ent is up to task.
Please act swiftly.


