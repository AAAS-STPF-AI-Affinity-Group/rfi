March 14, 2025 
VIA EMAIL 
Office of Science and Technology Policy 
and NCO/NITRD 
Att’n: Mr. Faisal D’Souza 
2415 Eisenhower Avenue  
Alexandria, V A 22314 
Re: True Ventures’ Response to AI Action Plan RFI 
Dear Mr. D’Souza: 
True Ventures supports the Administration’s creation of an AI Action Plan. The Plan’s stated 
goals—to strengthen American leadership in AI, enhance national security, and perhaps most 
importantly, ensure that “unnecessarily burdensome requirements do not hamper private sector 
AI innovation”—align with True Ventures’ interest in having a favorable regulatory environment 
for small, innovative AI startups in the United States. 
True Ventures’s Interest in AI Policy 
True Ventures is a Silicon Valley-based venture capital  firm, founded in 2005 and marking our 
20th year in business.  We invest in startup company founders at the earliest stages of their 
journeys: we seek to be the first institutional investor in early-stage tech companies that are 
managed by exceptional entrepreneurs, and that create products and services in potentially large, 
untapped, rapidly growing markets.  We partner with these founders, often for a decade or more, 
providing the support—financial, informational, and psychological—to allow them to take big, 
risky swings to develop technology that could have a massive impact on the world.   Since our founding, we have made over $3 billion of investments in nearly 500 
companies—including in 70 or so artificial intelligence companies.   As early-stage investors in 
AI, we witness firsthand how a thriving startup ecosystem drives American competitiveness. 
We are writing because federal policy will play a critical role in whether these emerging AI 
startups—the innovative companies being built by the founders we support—can flourish.  The 
____________________ 
This document is approved for public dissemination. The document contains no business-proprietary or confidential 
information. Document contents may be reused by the government in developing the AI Action Plan and associated 
documents without attribution. 


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 2 
 
 stakes are high: Bad regulation could slam the brakes on AI innovation and put our country at a 
disadvantage against highly capable foreign adversaries, especially China.   
 
As detailed below, the AI Action Plan should: 
 1. Understand America’s proven and successful regulatory model for dealing with 
opportunities and risks of rapid technological change, and embrace it for AI; 
 
2. Prevent fragmented, multi-state regulation of AI, which will cede the AI advantage to our 
global adversaries, and slam the door on tech startups; 
 
3. Encourage the rapid domestic development of this most critical infrastructure through 
liability protection, as well as upping the physical and cyber defense of AI companies 
through public-private partnerships; and 
  
4. Remove regulatory impediments to abundant, clean energy. 
 
Governmental Restraint in the Face of Rapid AI Development 
 
There is a premature rush to regulate AI across the country and the world.  It is not hard to 
understand why: Although technologies underlying AI have been on the scene for a long time, 
the arrival of Open AI’s ChatGPT, and subsequent powerful models created by other companies, 
have put in public view the prospect of truly advanced artificial intelligence—a computational 
intelligence with greater-than-human intellectual and reasoning capabilities, that can interact 
with the digital (and even the physical) world, and that can solve complex problems.  People 
have mapped onto this technology both the potential for massive societal benefits, as well as the 
prospect for significant societal harm.   
The U.S. has a proven, effective historical model for dealing with rapid technological change like 
this: the light-touch regulatory model that positioned the nation to dominate successive waves of 
industrial technologies, including semiconductors, personal computers, software, and the internet 
economy.  It is not a recurring lucky streak that created the market-driven environment necessary 
for each of these waves to be born in America and to drive economic growth here and across the 
world.  Instead, it was our uniquely American approach, which allowed the government to stay 
cognizant of technological risk and address it through legislation when it arose, while not 
 


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 3 
legislatively throttling important technological development or creating a compliance 
environment that startups could not satisfy.1 
Contrary to this recent experience, there is a significant push to preemptively regulate the 
creation and development of AI models and tools in the U.S.  This is an ahistorical rejection of 
the tried-and-true U.S. model and, inexplicably, an importation of European-style 
command-and-control regulation.2  Hundreds of AI-related bills have been introduced in 
statehouses across the country,3 and many of these bills are a masterclass on how not to regulate 
AI.  
State legislators in California, Colorado, Texas, Virginia, New York, and elsewhere are proposing 
laws that would require AI developers and deployers4 to file “algorithmic impact assessments” 
and similar compliance documents with state agencies.  Several also would add new, onerous 
liability regimes designed to hold developers financially responsible for downstream harms if 
their technology is found to have played a part.  These rules, if passed, would be a gut punch to 
startups, which cannot afford a significant compliance budget or risk massive liability.  They are 
also not likely to materially diminish risk of “algorithmic bias” or other harms the laws seek to 
prevent,5 though they are sure to significantly restrain American competitiveness, and delay (or 
deny) the benefits of AI tools to society.  Our economy, and our fellow citizens, will suffer as a 
result. 
True believes that all U.S. government entities—federal, state, local, and tribal—should adopt an 
attitude of regulatory humility and restraint in the face of this technological advancement, as we 
5 Dean Ball, The EU Act is Coming to America, Hyperdimensional (available at 
https://www.hyperdimensional.co/p/the-eu-ai-act-is-coming-to-america). 4 A “deployer” is the person or organization that puts an AI system into real-world use. While developers build the 
app or train the model, deployers are the ones who integrate it into products, services, or processes (for example, a 
company incorporating an AI tool into its HR system). 3 One useful AI bill tracker is available here: https://www.multistate.ai/artificial-intelligence-ai-legislation. 2 Dean Ball, The EU Act is Coming to America, Hyperdimensional (available at 
https://www.hyperdimensional.co/p/the-eu-ai-act-is-coming-to-america).  We describe this as “inexplicable” 
because, according to this and other studies, the EU AI Act “will cost the European economy €31 billion over the 
next five years and reduce AI investments by almost 20 percent.”  See Benjamin Mueller, “How Much Will The AI 
Act Cost Europe?,” Center for Data Information (July 2021).   1 A relevant historical example of this dynamic—but by no means the only one—is the development of email 
protocols.  The federal government supported and participated in public-private partnerships to create open 
standards and interoperability of email systems, including SMTP.  The private sector used those protocols to develop 
robust commercial products.  When technology-enabled harm emerged—spam email—Congress reacted and passed 
the CAN-SPAM Act (15 U.S.C. §§ 7701–7713) in 2003. 


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 4 
 
 did in earlier phases of rapid change.  This attitude is decidedly not a “no regulation” position.  
Its main components are: 
1. Regulating uses of AI tools, and not their creation.  Restricting training methods or 
imposing broad compliance burdens stifles innovation, particularly among startups, while 
doing little to prevent actual harm.  History shows that the best regulatory frameworks, 
whether for computing, biotech, or the internet, focus on preventing misuse rather than 
constraining technological progress.  For example, no laws dictated the development of 
general purpose microprocessors, but crimes and civil wrongs committed using 
computers are effectively prosecuted.    
2. Relying on existing laws and existing regulators to police known harms. The U.S. already 
has robust legal frameworks that prohibit fraudulent and other harmful activities: 
consumer protection laws prohibit deceptive practices, anti-discrimination laws cover 
unlawful biases in employment, credit, and housing, and product liability principles 
govern defective products.  When existing law covers the harm sought to be prevented, 
no new law is necessary—especially one that will hamper the development of the 
technology.6    
3. Identifying any new, uncovered risks, and only then legislating to prevent them.  Through 
experience and robust public-private interaction, we can identify those AI-specific risks 
that are both not covered by existing law and are serious enough to merit specific 
lawmaking.     
We recommend that the AI Action Plan embrace these principles.  If adopted within the 
Executive Branch, in Congress, and in statehouses across the country, they will allow the U.S. to 
manage any emergent risks of AI while promoting technological advancement—including 
providing regulatory clarity to startups so they may develop products that have the ability to 
make people’s lives fundamentally better.  
Prevent Fragmented, Multistate AI Regulation  
 
Another lesson from the recent past: Congress’s failure to pass a federal privacy law led to states 
taking the lead in that area—and as many are with AI regulation, they took their cues from the 
EU.  Known as the “Brussels Effect,” many states adopted their own version of the EU’s General 6 Some states have already embraced this view.  For example, in Massachusetts, the Attorney General has provided 
guidance on how existing consumer protection law will be used in the context of AI (available at  
https://www.mass.gov/doc/ago-ai-advisory-41624/download). 
 
 


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 5 
Data Protection Regulation, or GDPR, but with their own twists on it.  As a result, companies 
operating across many states have had to deal with different, sometimes inconsistent, frequently 
onerous legal obligations when a data breach happens.  This has been especially costly and 
complex for startups to manage (not to mention for end users to understand).7 
The AI Action Plan should take steps to prevent the “GDPR-ification” of AI law.  A 50-state AI 
regulatory morass could push the U.S. into a dangerous trap: creating AI-related laws that only 
large, established companies can satisfy, putting markets out of reach for startups.  Even one or 
two states requiring mandatory AI impact assessments for certain applications of AI, or 
expanding developer liability, would significantly raise compliance costs and litigation risks, 
effectively ushering smaller firms out of the market.  This will lead to balkanization (i.e., 
providers not allowing their AI tools to be used in certain overregulated states), and the citizens 
of those states not receiving the benefits of cutting-edge AI technology.  But a proliferation  of 
state laws across the union—a nationwide patchwork, each with different, likely inconsistent 
requirements—would make business incomprehensibly difficult for smaller AI startups.  They 
would face having to navigate 50 different AI compliance regimes, and unlike state privacy laws 
which apply only in case of a breach, they would have to do this just to start doing business.  As 
Representative Jay Obernolte, chairman of the House Task Force on Artificial Intelligence, put 
it: If you allow 50 different state regulations to exist, what you have created is an enormous 
barrier to entry into innovation. If you’re Google . . . they’ve got buildings full of lawyers; 
they can actually navigate a regulatory landscape that complex.  The people who can’t 
navigate it are two people in a garage trying to start the next Google.8 
As the bipartisan House AI Task Force recommended, the Administration and Congress should 
work together on a single federal standard to prevent this multiplicity of state-based laws.  Even 
as OSTP and Congress work on accomplishing that goal, the Administration can—through its 
bully pulpit—advocate for the principles of legislative humility outlined above to be adopted 
throughout the country. 
AI as The Most Critical Infrastructure: Promote Its Development and Prevent Its Theft 
Development of frontier AI models, and highly useful AI tools, have the potential to enhance 
human lives in significant ways.  Some of these enhancements are foreseeable, and others will 
only emerge over time, but they include: 
8 Rep. Jay Obernolte, remarks at the State of the Net Conference, Washington, D.C., February 2024 (quote here). 7 Engine, The Privacy Patchwork Problem, March 2023 (available here). 


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 6 
 
  
➢ deeper and more rapid scientific discovery and understanding;  
➢ physical and mental health advancements that will save, prolong, and improve lives;  
➢ increased economic productivity;  
➢ more effective education and proliferation of ideas; and  
➢ smarter defense capabilities.   
 
Likewise, development of these tools in the U.S. is key to our national security and economic 
competitiveness.  Given the enormous benefits that can accrue to society from it, artificial 
intelligence is perhaps the most critical  infrastructure.  But like other critical infrastructure in the 
U.S., nearly all AI development happens in the private sector, which—while it makes innovation 
many times more robust that it would be in the government’s hands—leaves the technology 
harder to defend.   
 
The release of Chinese AI tools such as DeepSeek R1 highlighted what we already understood: 
we are not the only country working at the cutting edge of AI technology, and our nearest 
competitor and most competent adversary plans to use AI dominance (and other means) to 
counter the U.S. and the West.  Moreover, China has used illicit means to access U.S. AI 
advancements, including hacking,9 distillation of U.S. models,10 evasion of export controls,11 and 
economic espionage,12 trying to seek an advantage in this modern-day space race.  Given all of 
this, we have two recommendations to promote and protect critical AI infrastructure in the U.S. 
 
First, consider a “SAFETY Act for AI” to tamp down unpredictable liability.  One impediment to 
AI development is the emerging state legislative trend to impose liability on model and app 
developers whose technology can be shown to have played a part in downstream harms.  And as 
AI tools push further into mainstream usage, product liability and other litigation is also a 
foreseeable impediment to AI development.  To counter this trend, we recommend that the 
Administration consider another legislative model from the recent past.  After the 9/11 attacks, 
Congress determined that manufacturers of security technology that could be used to prevent 
terrorist attacks were inhibited from developing such technology by the prospect of outsized 
liability judgments against them, if their technology ended up not preventing harm.  As a result, 12 Representative federal indictment available here. 
 11 Ibid. 
 10 https://www.csis.org/analysis/deepseek-huawei-export-controls-and-future-us-china-ai-race 
 9 https://www.axios.com/2024/05/17/artificial-intelligence-experts-phishing-attack 
 
 


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 7 
Congress passed the SAFETY Act (Support Anti-Terrorism by Fostering Effective Technologies 
Act of 2002), which provides liability protections for companies that develop and deploy 
anti-terrorism technologies, ensuring that legal risks do not deter innovation in national security.  
The AI Action Plan could advocate that Congress adopt a comparable framework to shield AI 
developers from excessive tort liability, particularly for downstream misuse of their models.  By 
offering safe harbor provisions for companies—including open source developers—that meet 
voluntary safety, transparency, and risk-management standards, a “SAFETY Act for AI” could 
encourage responsible AI innovation without subjecting developers to unpredictable and outsized 
legal exposure, and would preempt state AI liability laws.   Second, consider an “AI Information Sharing and Analysis Center” (ISAC) to help the private 
sector resist attacks and other threats.  The sixteen critical infrastructure sectors—including 
energy, financial services, transportation, IT and more—use ISACs to exchange real-time 
security intelligence between industry stakeholders and the government.13  As AI becomes 
foundational to national security, financial systems, and other essential industries, and as AI 
companies in the U.S. come under greater threat from foreign adversaries, an AI ISAC would 
provide a centralized hub for AI developers to share cybersecurity threats, adversarial attack 
intelligence, and best practices for securing critical AI models—and to gain intelligence from the 
federal government on inbound threats to guard against. This proactive approach would enhance 
AI system resilience, mitigate emerging threats like model poisoning or adversarial exploits, and 
ensure that AI-driven infrastructure remains secure and competitive on a global scale. Encourage Production of Abundant, Clean Energy 
The rapid growth of AI has amplified our demand for abundant, reliable, clean energy.  The AI 
Action Plan should incorporate and build on the policy laid out in Executive Order 14154, 
“Unleashing American Energy,” which ordered agency heads to identify any regulatory or other 
impediment that unduly restricts the development of domestic energy resources, including 
nuclear.  This is a call for policymakers to streamline the licensing and review processes for 
existing and advanced nuclear technologies, ensuring that the path from application to 
deployment is as short as possible.  These steps will help secure the reliable power AI demands, 
and position the U.S. as a global leader in clean energy innovation.
13 According to Presidential Policy Directive 21, critical infrastructure sectors are those “whose assets, systems, and 
networks, whether physical or virtual, are considered so vital to the United States that their incapacitation or 
destruction would have a debilitating effect on security, national economic security, national public health or safety, 
or any combination thereof.”   


True Ventures’ Response to AI Action Plan RFI 
March 14, 2025 
Page 8 
 
 Conclusion 
 
We urge the Administration to put the people and companies that power innovation-driven 
technological development in American society—small tech startups and their founders—at the 
very center of the AI Action Plan.  By implementing the recommendations we make above, the 
U.S. can meet our national goals of strengthening American leadership in AI, enhancing national 
security, and securing the many benefits of this technology for this generation and those 
generations yet to come. 
 
We are glad to discuss this with you at your convenience. 
 Very truly yours,  
 
  /s/Gus Coldebella  
 
Gus Coldebella 
 
 
 


