PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-h827-ekzg
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1604
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  CrowdSm art
General Comment
Com m ent attached in PDF
Attachments
CrowdSm art NSF RFI on AI Developm ent Action Plan


Tom Kehler, CEO 
CrowdSmart 
Introduction 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by the 
government in developing the AI Action Plan and associated documents without attribution. 
CrowdSmart Inc. (“CrowdSmart”) appreciates the opportunity to respond to the National Science 
Foundation (NSF) Request for Information on the development of an Artificial Intelligence (AI) 
Action Plan. CrowdSmart is a provider of a collective intelligence platform that combines human 
expertise with artificial intelligence to enhance decision-making. We strongly support the 
Executive Order 14179 Removing Barriers to American Leadership in Artificial Intelligence , 
which establishes U.S. policy to sustain and enhance America’s global AI leadership to promote 
economic competitiveness and national security . In alignment with these goals, our comment 
advocates for AI architectures that amplify human collaboration and knowledge acquisition, 
especially for national security , defense, and intelligence applications. We emphasize how 
CrowdSmart’s human-machine collaboration approach accelerates decisions, improves 
forecasting accuracy , and reduces uncertainty in high-stakes environments. Finally , we offer 
concrete policy recommendations that are consistent with the AI Action Plan’s priorities to 
ensure the United States invests in scalable human-machine collaboration systems as a 
cornerstone of U.S. AI leadership and innovation. We have organized our response in a 
structured format, addressing key themes and recommendations for consideration. 
The Need for AI Architectures that Enhance Human Collaboration and Knowledge 
Acquisition 
Advancing U.S. leadership in AI requires not only cutting-edge algorithms, but also systems that 
empower human teams to work smarter and learn faster together. Nowhere is this more 
important than in national security and defense, where human judgment, creativity , and context 
knowledge remain critical. Modern AI architectures should be designed to augment collective 
human intelligence, enabling analysts, operators, and decision-makers to pool their knowledge 
with AI’s capabilities. This approach turns AI into a force-multiplier for human expertise, rather 
than a black-box replacement. The U.S. Department of Defense has recognized the importance 
of such human-machine teaming; in fact, “human-machine collaboration” was identified as one 
of five key technology areas in the Pentagon’s Third Offset strategy for regaining military-
technical advantage. 1 In practice, this means developing AI systems that facilitate real-time 
collaboration, 
1 Work, Bob. “Remarks by Deputy Secretary Work on Third Offset Strategy.” Department of Defense, 28 
April 2016, 
1 


information sharing, and joint reasoning between humans and AI across the defense and 
intelligence community. 
Enhancing knowledge acquisition is a related priority. AI tools can capture and organize insights 
from diverse human experts at scale, creating a living knowledge base that grows with each 
interaction. Within intelligence analysis and military planning, this capability helps preserve 
institutional knowledge and makes it accessible for future decisions. By leveraging collaborative 
AI platforms, agencies can continuously learn from their personnel; as well as from open-source 
intelligence and allied inputs to update assessments and strategies. This human-centric 
knowledge amplification is vital for keeping pace with fast-evolving threats. It also aligns with 
the Executive Order’s call for AI that promotes “human flourishing” , as analysts and operators 
are empowered with better information and tools to do their jobs effectively. We urge the AI 
Action Plan to make human collaboration and knowledge capture a foundational design principle 
for AI systems deployed in national security. 
Accelerating Decision-Making, Predictive Forecasting, and Reducing Uncertainty in 
High-Stakes Environments 
High-consequence national security environments from military operations to intelligence 
forecasts demand decisions that are not only fast but also informed and reliable. AI systems that 
incorporate collective human intelligence can dramatically accelerate decision-making processes 
while improving the quality of outcomes. CrowdSmart’s platform exemplifies this: it enables 
large groups of experts or stakeholders to contribute their judgments and ideas asynchronously, 
and uses AI to synthesize these inputs into actionable insights. CrowdSmart’s advancement in 
collective intelligence is in adding the concept of collective reasoning. Collective reasoning adds 
explanatory power to predictions. Collective intelligence predictions are supported by an 
explanatory, persistent, causal model. These models are generative and support a new type of 
generative AI – Generative collective intelligence. This approach compresses decision timelines by allowing parallel input and analysis, reducing 
the need for protracted meetings or hierarchical reviews. By rapidly surfacing areas of consensus 
and dissent, such platforms help leaders focus on key factors and make decisions with greater 
confidence and speed. In time-sensitive defense scenarios, where the OODA loop 
(observe–orient–decide–act) must be minimized, human-AI collaboration can provide 
commanders with real-time collective assessments, improving responsiveness without sacrificing 
deliberation. Perhaps even more critical is the impact on forecasting and uncertainty reduction. 
Predictions about future events from geopolitical shifts to battlefield outcomes are notoriously 
difficult, yet they are core to intelligence and defense planning.2 Research has shown that tapping 
2 Turan, Vehbi, et al. “Collaborative Intelligence: Harnessing Crowd Forecasting for National Security.” 
Federation of American Scientists, 27 November 2024, https://www.defense.gov/News/Speeches/Speech/Article/753482/remarks-by-deputy-secretary-work-on-th
ird-offset-strategy/. Accessed 26 February 2025. 
2 


into the wisdom of crowds can significantly boost forecasting accuracy. For example, the 
Intelligence Advanced Research Projects Activity (IARPA) conducted a multi-year tournament 
where aggregated crowd forecasts outperformed even seasoned analysts.3  
This project served as the inspiration for CrowdSmart’s platform, demonstrating that harnessing 
collective intelligence not only outstrips individual analysis but enhances the ability to generate 
explanatory models that support causal reasoning. CrowdSmart’s approach was directly inspired 
by this work and we collaborated with key figures from the IARPA forecasting project, including 
Mark Steyvers, who was part of Philip Tetlock’s Good Judgement team, and Scott Page. whose 
team placed second. Their expertise has directly influenced our methodology.  This illustrates that collective intelligence, when properly harnessed, often outstrips individual 
analysis. Moreover, crowdsourced forecasting methods offer a systematic way to quantify 
uncertainty and explore a range of outcomes, which is invaluable for national security planners . 
By consolidating probability estimates and rationales from many participants, such systems yield 
a clearer picture of risks and confidence levels, thus directly reducing uncertainty in high-stakes 
decisions. 
CrowdSmart’s AI methodology is an example of ‘third wave AI’. DARPA’s longer term view of 
AI called for a third wave of AI that is explanatory, adaptive and supports the collaborative 
interaction of AI Agents. CrowdSmart’s technology foundation is closely linked to a 
neuroscience model of adaptive learning: the Free Energy Principle and Active Inference. For 
there to be trust in AI systems, this type of architecture is critical. Explanation and contextual 
awareness are essential to collective reasoning and collaboration between agents - human and AI. CrowdSmart’s platform is designed to capture these advantages for practical use. It combines 
diverse human perspectives with AI analysis to eliminate biases and highlight evidence-based 
reasoning. Features like single blind anonymity and bias mitigation ensure that even junior or 
contrarian viewpoints are heard, countering the “loudest voice in the room” problem that can 
plague group decisions . The result is a more objective and comprehensive assessment of the 
issue at hand. In a national security context, this means decision-makers are less likely to 
overlook dissenting warnings or unconventional solutions that could prove critical.  
The platform provides a transparent audit trail of how conclusions are reached, since it 
documents the collective reasoning process. This built-in explainability aligns with the AI Action 
Plan’s emphasis on explainability and assurance of AI outputs and builds trust in the system’s 
recommendations. CrowdSmart’s experience in industry has shown that such human-machine 
“collective intelligence” workflows can deliver faster decisions and predictive accuracy gains, 
and we see tremendous opportunity to apply these benefits to defense and intelligence 
3 https://goodjudgment.io/docs/Goldstein-et-al-2015.pdf https://fas.org/publication/collaborative-intelligence-harnessing-crowd-forecasting-for-national-security/. 
Accessed 4 March 2025. 
3 


challenges. Notably, improved forecasting and decision clarity directly translate into strategic 
and economic value. As Jason Matheny, CEO of RAND Corporation and former U.S. 
intelligence official, observed, even a 1% improvement in forecasting accuracy on major national 
security decisions could save “tens of billions of dollars” by avoiding costly errors .4 When 
decisions like war or large-scale deployments carry trillion-dollar consequences, the United 
States cannot afford suboptimal judgment. By investing in collective intelligence architectures 
that sharpen forecasts and illuminate uncertainties, we bolster our national security 
decision-making and potentially save enormous resources. Crowd forecasting and 
human-machine analytical teams should thus be viewed as strategic assets. We recommend the 
AI Action Plan explicitly recognize the role of collective forecasting platforms in intelligence 
analysis and defense planning, building on earlier successful programs (e.g. IARPA’s forecasting 
experiments) to institutionalize these capabilities. Alignment with AI Action Plan Priorities: National Security, Defense, and Intelligence 
Applications 
Our recommendations strongly align with the priorities outlined for the AI Action Plan, 
particularly those related to military applications, intelligence analysis, and broad national 
security needs. The Action Plan’s scope includes topics such as “application and use (of AI) in 
government,” “national security and defense,” and “explainability and assurance of AI model 
outputs,” among others . Human-centric AI collaboration addresses these areas as follows: 
●Military Decision-Making and Operations: Incorporating collective intelligence
systems can enhance military planning, wargaming, and operational decision-making.
AI-enabled collaboration tools allow planners to aggregate input from commanders,
intelligence officers, and field operators in real time, yielding a more complete common
operating picture. This supports the Department of Defense’s push for joint all-domain
command and control, where information from across services and domains must be
synthesized quickly for commanders. By deploying human-machine collaboration
platforms, the military can better evaluate courses of action with input from diverse
experts (strategists, logisticians, coalition partners), improving the soundness of decisions
under pressure. Such use of AI directly advances the national security and defense
mission by making decision processes faster, more informed, and resilient.●Intelligence Analysis and Assessment:  As noted, collective reasoning approaches have
proven their value in intelligence forecasting. We recommend the Action Plan endorse the
adoption of crowd forecasting and analysis platforms within the Intelligence Community
(IC). This could mean expanding programs at the Office of the Director of National
Intelligence (ODNI) to use crowd-based analytic techniques for estimating geopolitical
events, technology developments, and threat levels. These methods will help analysts
quantify uncertainty and tap a broader pool of expertise, leading to more robust
intelligence assessments . Importantly, the explainable nature of these systems (with
4 See footnote 2 
4 


recorded rationales and confidence levels) addresses the assurance and transparency 
priority, ensuring that senior officials can understand why an analytic conclusion was 
reached. In an era where AI-generated intelligence must be trusted, having a clear line of 
reasoning (grounded in human judgments augmented by AI) is essential for credibility 
and accountability. ●Broad National Security Collaboration: Many national security challenges require
collaboration beyond any single agency, such as pandemic response, supply chain
security, or climate-related security risks. AI platforms that enable interagency and
cross-sector collaboration can break down silos by allowing participants from defense,
intelligence, homeland security, academia, and even industry to collectively brainstorm
and evaluate solutions. The AI Action Plan should highlight the need for tools that
facilitate such whole-of-government decision-making. By securely connecting
subject-matter experts across organizations in a structured dialogue (with AI
summarizing inputs), the government can achieve a unity of effort and insight that is
difficult to attain through traditional, sequential coordination. This broad application of
collaborative AI will strengthen national preparedness and crisis response, aligning with
the Action Plan’s call for actions in application/use of AI by government, international
collaboration, and innovation.●Trust, Ethics, and Risk Management: We recognize that introducing AI into sensitive
national security decisions must be done carefully. Human-machine collaboration
inherently provides a built-in human oversight mechanism that pure autonomy would
lack. By design, collective intelligence systems keep humans “in the loop,” using AI in a
supportive, decision-enhancing role rather than as an autonomous actor. This mitigates
risks associated with fully automated systems and aligns with principles of reliability and
controllability. Moreover, the diversity and anonymity features of platforms like
CrowdSmart help to reduce systemic biases and prevent domination by any single
agenda . We believe policy guidance in the AI Action Plan should encourage such
bias-mitigating design features to ensure AI-driven analyses are fair and robust. In
addition, standards for data security and participant privacy must be upheld (especially if
analysts are contributing sensitive judgments on classified matters); any collaborative AI
for government use should meet stringent cybersecurity requirements as part of its
adoption. A human-collaborative approach to AI in national security inherently supports
the risk management and governance aspects of the Action Plan by promoting
transparency, accountability, and ethical guardrails.Each of these points illustrates how a human-centric AI architecture can directly advance the 
priorities set forth for the AI Action Plan. By combining the scale and speed of AI with the 
judgment and creativity of humans, we unlock superior capabilities for national defense and 
security. The following section provides concrete policy steps to realize this vision. 
5 


Policy Recommendations  
To operationalize the above insights, CrowdSmart offers the following concrete policy 
recommendations for inclusion in the AI Action Plan. These recommendations are aimed at 
strengthening U.S. national security through AI architectures that enhance human collaboration 
and collective intelligence: 
1.Invest in R&D and Pilot Programs for Human-Machine Collaboration in National
Security: The federal government should direct increased research and development
funding toward AI systems that facilitate human collaboration and collective analysis.
Agencies like NSF, DARPA, and IARPA should issue solicitations specifically on
collective intelligence platforms, crowd forecasting tools, and human-AI teaming
frameworks for defense and intelligence applications. In addition, the Department of
Defense and ODNI should launch pilot programs to test these technologies in real-world
scenarios (e.g. strategic wargames, intelligence estimates). By prototyping and evaluating
in operational contexts, the government can validate performance and build a case for
broader adoption. This recommendation aligns with the Action Plan’s focus on research
and development and ensures innovative concepts transition from labs to mission use.
2.Establish Doctrine and Training for AI-Enhanced Decision Making: We recommend
that DoD and the Intelligence Community develop official doctrine, methods, and
training curricula for integrating AI-assisted collaborative analysis into decision
processes. The AI Action Plan should call for the creation of such frameworks, for
example, updates to Joint Doctrine publications or Intelligence Community Directives,
that define how collective intelligence platforms are to be used in planning, analysis, and
operations. Alongside doctrine, agencies should train personnel in facilitation and use of
these tools. Analysts and military planners should learn how to interpret AI-aggregated
inputs, how to manage crowd-sourced analytic exercises, and how to incorporate the
results into their products. Building a skilled workforce in human-AI collaboration
supports the Action Plan priority on education and workforce development and will
ensure these technologies are used effectively and responsibly.3.Promote Explainability and Auditability Requirements: For any AI deployed in
national security decision support, the Action Plan should mandate or encourage features
that provide explainable and auditable outcomes. This can be achieved by favoring
architectures (like collective intelligence systems) that keep a transparent record of
inputs, rationales, and decision pathways. As demonstrated by CrowdSmart’s platform, it
is possible to design AI tools that provide full explainability of how a conclusion was
reached . By adopting procurement preferences or standards for explainable AI, the
government will drive the industry to build systems that leaders can trust. This
recommendation ties into the explainability and assurance topic in the RFI. Specifically,
we propose that national security agencies require any AI decision support system to
include an audit trail (who/what contributed to the assessment) and the ability for humans
to interrogate the reasoning (e.g. see the underlying evidence and divergent viewpoints).
6 


Such policies will ensure accountability and enable continuous learning (by reviewing 
decision outcomes against the recorded reasoning). 
4.Incentivize Diversity and Red Teaming in AI-Assisted Analysis: To reduce risks of
groupthink or blind spots in critical decisions, the Action Plan should encourage practices
that inject diversity of thought into AI-assisted analyses. When using collective
intelligence or crowd analytic platforms, agencies should involve a wide range of
participants, drawing on different departments, ranks, demographics, and even external
experts when appropriate, to maximize perspective diversity. Policies could also establish
“red team” crowd analyses whereby alternative or dissenting analysis groups are spun up
via these platforms to challenge prevailing assumptions. By leveraging the platform’s
anonymity and scale, leaders can systematically surface contrarian insights that might
otherwise be missed. This recommendation supports the Action Plan’s interest in
technical standards for safety and risk mitigation, ensuring that AI-aided decisions are
rigorously tested against cognitive biases and errors. It also complements ongoing efforts
in the defense community to improve decision resilience under uncertainty.
5.Streamline Procurement and Increase Engagement with Innovative AI Firms:
Ensuring U.S. leadership in AI means government must effectively harness domestic
innovation. The AI Action Plan should include measures to remove barriers for the
private sector to partner with government on advanced AI, in line with the spirit of
Executive Order 14179 . We recommend streamlining procurement processes (such as
rapid prototyping authorities, Commercial Solutions Openings, and other transaction
agreements) to allow quicker acquisition of emerging AI collaboration tools.
Additionally, agencies should expand initiatives like challenge competitions, pilot
funding, and “sandboxes” where companies like CrowdSmart can demonstrate
capabilities on unclassified problems relevant to national security. By lowering
bureaucratic hurdles and encouraging public-private experimentation, the government
will accelerate the adoption of cutting-edge human-machine collaboration platforms. This
approach aligns with the Executive Order’s intent to “remove burdensome requirements
restricting private sector AI development and deployment” and ensures the United States
stays ahead in deploying beneficial AI for security missions.6.Leverage Collective Intelligence for International Collaboration: Lastly, we
encourage U.S. policymakers to explore the use of collaborative AI platforms in
coordination with allies and partners. Many security challenges (from alliance defense
planning to global threat intelligence) benefit from close collaboration with trusted
foreign partners. A secure, federated collective intelligence system could enable U.S. and
allied analysts to jointly contribute insights on shared concerns, with AI aggregating a
truly global range of expertise. The AI Action Plan’s mention of international
collaboration recognizes that American AI leadership also involves working with allies .
By spearheading development of collaboration tools that cross organizational and
national boundaries (while maintaining security and confidentiality), the U.S. can
7 


strengthen alliances and present a united front informed by the best collective thinking of 
its partners. We recommend pilot projects in this vein (for example, a U.S.-UK or Quad 
nations collaborative forecasting exercise on an emerging threat) as part of the Action 
Plan’s implementation. 
Each of these recommendations is aimed at embedding the ethos of human-machine teaming into 
the fabric of U.S. national security AI strategy. We believe that adopting these policies will drive 
significant improvements in how AI is developed, evaluated, and employed for defense and 
intelligence purposes, leading to more effective and accountable outcomes. Ensuring U.S. AI Leadership and Innovation through Human-Machine Collaboration  
CrowdSmart’s approach, and human-centric AI architectures broadly, should be viewed as 
critical components of U.S. AI leadership in the coming decade. Leadership in AI is not 
measured solely by having the fastest processors or the most complex algorithms, but by how 
effectively AI is integrated into our society and national mission areas. By championing scalable 
human-machine collaboration systems, the United States can lead in a distinctly American way: 
leveraging our open society, diverse talent pool, and democratic values to create AI that 
amplifies human intelligence and upholds our ideals. This contrasts with authoritarian 
approaches to AI that might sideline human judgment; U.S. leadership can set a global example 
for AI that respects human agency while delivering superior performance.  Investing in collective intelligence capabilities also ensures that the U.S. stays ahead of 
adversaries in decision-making superiority. In the past, U.S. technological dominance (e.g. in 
precision weapons or stealth) conferred decisive military advantages. In the future, decision 
superiority will be a key determinant of national security success. Human-machine collaboration 
is an innovation that can give U.S. decision-makers that edge, by blending the creative 
problem-solving of humans with the data-crunching power of AI. This force-multiplier effect is 
similar to past breakthroughs in intelligence (such as the integration of signals intelligence and 
human intelligence); it represents the next evolution of how we harness information. We urge the 
Administration to recognize these collaborative AI systems as strategic national assets and to 
support their development through the AI Action Plan. Such support will solidify America’s 
position at the forefront of not just AI technology, but AI application for complex 
problem-solving. Maintaining leadership requires scalability. The technologies and approaches discussed should 
not remain limited to small pilot projects; with proper investment, they can scale across agencies 
and problem sets. CrowdSmart’s own deployments in the private sector have shown that our 
platform can scale to thousands of participants, analyzing large volumes of input with AI 
assistance to yield clear recommendations . We envision similar scalability for government use, 
where entire communities of interest (for example, all analysts tracking a certain issue) could be 
engaged in collective analysis when needed. The Action Plan should therefore include a vision 
8 


for scaling up successful human-AI collaboration prototypes into enterprise-level capabilities 
across the national security apparatus. This will require sustained funding, change management, 
and leadership buy-in, all of which are achievable if the value is demonstrated early. 
By making human-centered AI collaboration a pillar of the national strategy, the United States 
will foster an innovation ecosystem that brings together Silicon Valley’s best AI advances with 
the wisdom and expertise of our people. This is a powerful formula for securing our nation and 
upholding our values in the AI era. 
Conclusion  
We strongly believe that AI architectures which enhance human collaboration and collective 
intelligence should be featured prominently in the plan, especially for mission-critical domains 
like defense and intelligence. Such approaches align with Executive Order 14179’s mandate to 
remove barriers to AI innovation and bolster national security . By implementing the policy 
recommendations outlined above, from targeted R&D investments and pilot programs to 
training, standards, and procurement reforms, the U.S. government can accelerate the adoption of 
collective intelligence platforms that improve forecasting, decision speed, and certainty in 
high-stakes situations. This will not only reduce risks and costs today, but also position America 
to out-innovate and out-decide any adversary in the future. CrowdSmart is ready to support these efforts. We are prepared to partner with government 
agencies to pilot our collective intelligence platform in national security settings and demonstrate 
its impact. We are also eager to contribute our expertise to any working groups or standards 
development related to human-machine teaming and collaborative AI. In closing, we thank you 
for considering our comments. We are confident that an AI Action Plan embracing 
human-machine collaboration will ensure the United States leads the world in leveraging AI for 
the public good and national defense, in keeping with the highest ideals of our nation. 
9 


