PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 88-3b77-4s24
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1277
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Felix De Simone 
General Comment
With thanks to the NITRD NCO and the OSTP:
I am  a policy advocate with an academ ic background covering political science and international relations, and I have spent m uch of the
last few years learning about AI and watching on in horror as we cam e closer to building system s that can outthink us. The US
Governm ent has a responsibility to keep Am ericans safe; therefore, responding to the em erging threat of sm arter-than-hum an AI m ust be
front and center of the adm inistration’s new AI Action Plan.
As an Am erican, and a hum an being, I am  deeply alarm ed by the threat that superhum an artificial intelligence m ay soon pose to our nation
and even our species. Although the vast m ajority of AI system s are safe and beneficial, efforts to build sm arter-than-hum an AI could be
cataclysm ic. Thousands of scientists and industry experts– including figures like David Sacks and Elon Musk– have warned that we don’t
know how to control sm arter-than-hum an AI, and that efforts to build these system s could cause global catastrophe.
To quote a 2024 paper coauthored by several of the world’s leading com puter scientists: “once autonom ous AI system s pursue
undesirable goals, we m ay be unable to keep them  in check [...] in open conflict, AI system s could autonom ously deploy a variety of
weapons, including biological ones [...] this unchecked AI advancem ent could culm inate in a large-scale loss of life and the biosphere, and
the m arginalization and extinction of hum anity.” (Bengio, Hinton et al, "Managing Extrem e AI Risks Am id Rapid Progress," Science,
2024).
By all m eans, we should lead in cutting-edge specialized AI innovation– with benefits in m edicine, science, productivity, and m ore. But
efforts to build sm arter-than-hum an AI risk culm inating in what Trum p’s AI Czar David Sacks term ed a “potential successor species.”
We control the world because of our intelligence – if we build som ething sm arter than us, losing control is a likely result.
An “arm s race” to build sm arter-than-hum an AI is a race with no winners – the US will not benefit from  being the first to build rogue AI
that destroys us. Instead, Am erica m ust lead in negotiating an AI Deal: an international agreem ent to prohibit developing sm arter-than-
hum an AI, until we know how to control it, while encouraging specialized AI innovation.
History has m uch to teach us about this approach. President Reagan dem anded that the Soviets negotiate on nuclear weapons, because
he realized that a nuclear war has no winners – a few years later, the US and USSR signed a treaty prohibiting interm ediate-range ballistic
m issiles. The President should adopt a sim ilar approach when it com es to superhum an AI, dem anding that China agree to negotiate to
prevent its developm ent. 
If we act now, and decisively, we can secure the Am erican– and hum an– future for generations to com e.
Thank you for your consideration,
Felix De Sim one
Concerned citizen and AI policy advocate


