March 14, 2025  
The Honorable  Kirk Dohne  
Acting Director  
National Coordination Office  
Networking and Information Technology Research and Development Program  
490 L'Enfant Plaza SW, Suite 8001  
Washington, DC 20024  
Faisal D 'Souza  
Technical Coordinator  
National Coordination Office  
Networking and Information Technology Research and Development Program  
490 L'Enfant Plaza SW, Suite 8001  
Washington, DC 20024 
Submitte d via email to : 
RE: Request for Information on the Development of an Artificial Intelligence (AI) 
Action P lan (90 FR 9088)  
Dear Acting Director Dohne and Mr. D’Souza , 
The Blue Cross Blue Shield Association (BCBSA) appreciates the opportunity to provide 
comments on the “Request for Information on the Development of an Artificial Intelligence (AI) Action Plan,” (the “RFI”) as published in the Federal Register on February  6, 2025 ( 90 
FR 9088).   
BCBSA is a national federation of independent, community -based and locally operated 
BCBS companies (Plans) that collectively cover, serve, and support 1 in 3 Americans in every ZIP code across all 50 states and Puerto Rico. BCBS Plans contract with 96% of hospitals and 95% of doctors across the country and serve those who are covered through 
Medicare, Medicaid, an employer, or purchase coverage on their own.  
AI is transforming health care by improving patient care, enhancing decision- making and 
reducing administrative burdens. For instance, AI -powered tools can be used to predict 
patients' health trajectories to better meet care needs, automate administrative tasks like 
notetaking to allow providers more time with patients and improve the identification of 
health care fraud. As global competition in AI accelerates, the U.S. must foster an 
environment that sustains and enhances its leadership in health care AI i nnovation. This 750 9th St reet NW 
Washington, D.C. 2000 1-4524 
www.BCBS.com  


requires policies that promote investment, avoid unnecessary  and duplicative processes or 
reporting, ensure regulatory clarity and consistency, and support the responsible 
development  and use of AI- driven health care solutions  with patients in mind. By balancing 
innovation with appropriate safeguards, health plans can continue to innovate AI solutions 
to realize their  full potential  to improve the health of Americans.  
BCBS Plans are focused on deploying AI to improve outcomes, offer data- driven insights 
to enhance the ability for patients  to make informed decisions on their health care, and 
relieve administrative burdens. BCBS Plans have identified and implemented AI tools to support a number of use cases, in accordance with all existing laws and consumer 
protections, including:  
•Increasing care coordination: AI is being used to identify hard- to-reach and at -risk
populations, such as  those that are more likely to have severe cases of
cardiovascular disease  or elderly members with multiple chronic conditions . AI has
enabled personalized outreach through targeted communication, AI-powered
chatbots and tailored recommendations for programs like disease management .
Furthermore, AI facilitates proactive care management by identifying care gaps,predicting likely hospital readmissions and helping coordinate care to prevent
adverse events and improve patient outcomes.
•Enhancing member experience : AI is being deployed in customer service centers
to reduce member frustration associated with long hold times, multiple transfers ,
confusion with coverage and benefit policies , and insufficiently answered questions .
In this context, AI is used by customer service representatives to appropriately
access plan data and guidelines, to answer member questions more efficiently ,
comprehensively  and consistently. This reduces wait times and improves the
accuracy and helpfulness of the information provided to members.
•Supporting interoperability: AI is supporting implementation of CMS ’
Interoperability and Prior Authorization Final Rule ( CMS -0057- F), which requires the
use of application programming interfaces (APIs) to streamline and expeditecommunications with providers and improve the member and provider experience,
including for prior authorizations.  Specifically, AI is assisting in API integration and
management, improving data validation and reducing errors.
•Fraud Detection and Prevention: AI is used to help detect fraud by using machine
learning to identify anomalies and predict  potentially  fraudulent claims based on
patterns in vast datasets of structured and unstructured data ( e.g., claims, medical
records). Techniques can include anomaly detection, predictive modeling, natural
language processing, and network analysis to identify outliers, unusual providerbehavior and potential collusion. This enhances  Special Investigations Units ’
understanding of  where to look for fraud. These actions  ensure that resources are
directed towards legitimate patient care, unnecessary costs are prevented, and
overall data integrity  is sound. This not only enhances the affordability and


accessibility of health care but also safeguards patients from fraudulent practices 
that could lead to improper billing or compromised care.  
These uses, and many others, can improve the experience with the health care system  for 
patients . While AI must be adopted responsibly  and with understanding of the inherent 
risks, it has the potential to transform the efficiency of patient care, improve health outcomes and lower health care costs. However, realizing these benefits at scale requires thoughtful public policy to help guide the development and deployment of AI in ways that 
maximize its advantages while addressing potential risks. With this in mind, we offer the 
following recommendations to help shape the AI Action Plan that fosters innovations, 
drives efficiencies and ensures alignment with existing regulatory fra meworks.  
•A multi-stakeholder advisory group should be established to guide the
development of effective AI public policy , ensuring diverse  expertise informs
policymaking.  There is currently a limited AI knowledge base due to the rapidly
evolving nature of the technology , specifically generative AI . There are also unique
nuances depending on the use case and industry, as well as inconsistent existing
laws and regulations.  A broad cross -section of stakeholders, including health plans
and private entities with both technical and industry on- the-ground expertise, will be
critical to creating effective guidance or requirements. If such guidance or
requirements are developed in a silo, there is significant risk for unintended
consequences  that could stifle innovation .
•Clear and consistent definitions are a key first step in developing future
public policy related to AI. Definitions form the scope of public policies and are
critical to ensuring there is a clear understanding of what and who is beingregulated and to what extent. Establishing standardized definitions across policieswill not only reduce burdens on stakeholders and support responsible AI adoptionbut also position the US as a global leader in AI governance and innovation.
Most notably, requirements should be focused on AI systems (AIS), not algorithms.
The National Association of Insurance Commissioners (NAIC) Model Bulletin: “Useof Artificial Intelligence by Insurers.”
1, defines a n AIS as “a machine- based system
that can, for a given set of objectives, generate outputs such as predictions,recommendations, content (such as text, images, videos, or sounds), or other
output influencing decisions made in real or virtual environments. AI Systems are
designed to operate with varying levels of autonomy .” In contrast, an algorithm
encompasses  a far broader set of processes such as a simple set of defined rules
that produce a specific result when followed, which do not necessarily include theuse of computers or information technology .
BCBSA generally supports the use of key definitions related to artificial intelligence
contained in the NAIC Model Bulletin, which has been adopted by more than 23states  to date.  While we urge the adoption of the NAIC Model Bulletin to focus on
1 https://content.naic.org/sites/default/files/inline -files/2023- 12-4%20Model%20Bulletin_Adopted_0.pdf  


AIS rather than AI more broadly, the definitions in the bulletin largely align to 
definitions contained in the National Institute of Standards and Technology (NIST) 
Artificial Intelligence Risk Management Framework (AI RMF). Developed through a consensus -driven process with cross -industry input, this framework is widely 
accepted, voluntary and designed to support innovation. Definitions should also 
account for differences in responsibility between developers of AIS and deployers of 
AIS developed by others.  
•Public pol icies regarding AI should recognize industry -specific differences
and needs. Use of AI in health care has different considerations from the use of AI
in other industries due, in part, to its direct impact on patient health, the high level of
risk associated with certain decisions and the complexity of health care data.
Additionally, health care is a highly regulated industry that must maintain the privacyof patient information pursuant to the Health Insurance Portability and Accountability
Act (HIPAA)  alongside numerous state laws and requirements. HIPAA provides a
framework for the privacy and security of health information. Some  of the provisions
within the HIPAA Privacy Rule  may impact AI and data governance for HIPAA -
regulated entities. To ensure AI policies are appropriately tailored to the health caresector, the Assistant Secretary for Technology Policy (ASTP) would be the most
appropriate entity to create and maintain, in consultation with appropriate
stakeholders , industry -specific federal standards and requirements. This model has
worked effectively for the development of standards related to other health care
policy issues, such as interoperability. ASTP sets the relevant data standards, andthose standards are adopted, as appropriate, by federal health care agencies and
industry stakeholders  through regulation.
•Future public  policy related to AIS should align to existing requirements to
achieve regulatory harmony . Many of the policy issues raised by AIS are not
novel and intersect with existing laws and regulations. Whether they require a novelpolicy approach or more modest adjustments to existing rules requires a detailedassessment of the current regulatory environment before proceeding with newrequirements. For example, covered entities under HIPAA are subject to numerous
requirements to protect the privacy and security of patient information today. Any
additional requirements on HIPAA -covered entities must balance the need to protect
patient privacy while  not adding unnecessary  burden to the regulated entities.
Alignment with HIPAA and other existing requirements will enable consistency to
ensure that requirements complement — not complicate — advances in technology.
Clear and harmonized federal standards provides greater predictability forstakeholders, supporting the development of AI solutions  and encourages
innovation.
•Federal leadership on  AI policies is essential to support innovation and
regulatory clarity. A patchwork of conflicting state and federal AI regulations
creates compliance challenges, increases operational  costs and imped es


innovation. The burden of navigating inconsistent state requirements slows the 
adoption of transformative AI solutions and detracts investments into AI 
technologies. Federal leadership on policy would support  a more consistent  
regulatory landscape offering predictability for stakeholders and fostering AI 
innovation.  
 
• Public policies should seek to address the potential for AIS to reduce 
disparities  in health care. BCBSA is committed to reducing disparities in health 
care, including in the context of AIS, and to exploring policy solutions that may be 
needed. Requirements should focus on regulation of potential harms  within the 
context of AIS, not algorithms more broadly, to improve accessibility to care  without 
unintended consequences that could stifle innovation.   
• Industry standards based on a flexible, risk- based approach are foundational 
to responsible AIS. There is a cross -stakeholder understanding that the foundation 
of responsible and trustworthy AI is in the appropriate identification, measurement , 
and mitigation of risk through governance, as well as protocols and internal controls tailored to particular AIS and use cases. It is also important to note that there is no one-size- fits-all approach to measuring, managing and mitigating the potential ri sks 
of AIS. A workable framework would be one that has incorporated the necessary 
levels of flexibility to appropriately measure risks and enable companies to tailor risk mitigation to the unique considerations of each AIS and use case. For instance, it will be important to scope AIS accountability measures through applying a risk -
based approach. Instead of imposing prescriptive requirements, such as specific tests or intricate details for the technology itself, policymakers should adopt a flexible, standards -based risk framework to guide management and oversight of 
AIS. This type of framework would account for the severity of potential consumer harm and its likelihood of occurring. The greater the potential harm and likelihood of occurring, the greater the need for accountability, governance and risk mitigation measures in both regulation and internal controls.  
 
• Transparency and accountability between developers and deployers of AIS are essential for responsible implementation and regulatory compliance. Developers  should be held accountable to disclose sufficient information to the 
deployer  to understand the model and, potentially, to comply with any regulatory 
requirements . For example,  further developing and standardizing the information 
included in AIS “model cards” with key facts by an appropriate standard- setting 
body, such as NIST, can help ensure proper disclosure from AIS developers to 
deployers and consumers.  Without such transparency, deployers will struggle to 
conduct proper due diligence on opaque, black -box algorithms, hindering 
responsible AI implementation and compliance.   
 Additionally, d evelopers must provide appropriately scoped audit rights and/or 
entitle the deployer to receive audit reports by qualified entities, such as third- party 


auditors and government agencies , as well as cooperate with the deployer 
regarding regulatory inquiries related to the deployer’s use of the developer’s 
product. While deployers have a role in compliance, if regulatory requirements are 
placed upon deployers that cannot be met without information from developers, maintaining compliance will not be possible unless there are appropriate contractual standards in place between the entities. Creating risk -based regulatory 
requirements , such as audit rights,  to su pport these contractual standards will 
support compliance from all entities on relevant AIS requirements.  
BCBSA and Plans are committed  to advancing responsible AI innovation in health care. As 
AI continues to evolve, it is essential public policy supports an environment where responsible AI -driven solutions with consumer protections can thrive, enhancing health 
care delivery and consumer experience. We encourage  policymakers to take a balanced 
approach that fosters technological advancement  and patient care without imposing 
unnecessary barriers  that could stifle innovation.  
Thank you for  the opportunity to provide input on the development of the AI Action Plan . 
We welcome the opportunity to collaborate with OSTP, NITRD and other stakeholders to shape AI policies that align with existing regulations, enhance operational efficiencies and protect consumers.  If you have any questions or want additional information, please 
contact  Jennifer Jones at  or 
Sincerely , 
Anshu Choudhri  
Vice President, Policy Development and Strategy  
This docume nt is approved for public dissemination. The document contains no business -
proprietary or confidential information. Document contents may be reused by the government in developing the AI Action Plan and associated documents without attribution.  


