March 15.  2025 
Attn: F aisal D'Souza,   
National Coordination Oﬃce (NCO) 
National Science Foundation  
 2415 Eisenhower Avenue, 
Alexandria, VA 22314  
Submitted Electronically 
Re: Requ est for Information on the Development of an Artiﬁcial Intelligence (AI) Action 
Plan [FR Doc. 2025- 02305 Filed 2 -5-25; 8:45 am] BILLING CODE 7555- 01-P  
Dear Mr.  D’Souza, 
We appr eciate the opportunity to provide our feedback and recommendations regarding your 
Agency’s eﬀorts governing the use of Artiﬁcial Intelligence (AI). We have speciﬁcally provided 
information we feel is relevant to the suggested AI policy topics rel ated to appropriate use and 
governance of AI in healthcare. We thank the Trump Administration for its focus and attention to this critical and emerging issue.    
About Advocate Health  
Advocat e Health is a not -for-proﬁt integrated delivery system and leading employer in the  
Midwest and Southeastern United States.  Headquartered in Charlotte, North Carolina, 
Advocate Health serves approximately six million patients and is engaged in hundreds of clinical trials and research studies. It is nationally recognized for its expertise  in cardiology, 
neuroscience, oncology, pediatrics, and rehabilitation, as well as organ transplants, burn treatments, and specialized musculoskeletal programs. Advocate Health employs an estimated 
162,000 team members across 69 hospitals and more than 1,000 care locations and oﬀers one 
of the nation’s largest graduate medical education programs with more than 2,000 residents and fellows across more than 200 programs. Additionally, Advocate has ﬁve skilled nursing facilities with 572 licensed beds. Committed to ensuring access to care for all, Advocate Health provides more than $6 billion in annual community beneﬁts.    
AI Beneﬁts and Opportunities in Healthcare 
AI tech nology is rapidly progressing, and we believe it will radically transform healthcare over 
the coming years. Speciﬁcally, we believe there is signiﬁcant potential for AI to reduce administrative ineﬃciencies for physicians and administrators, as well as unlock previously unavailable actionable insights from our vast data.   In addition to improved eﬃciency, as the 


technology advances AI will have profound eﬀects on improving patient and provider 
experience with care and driving improved outcomes.  Within Advocate Health, we are already seeing these beneﬁts with AI integrated within many of our operations, guiding patient engagement, and with a growing presence in the interface of patient care.   
At the core of harnessing these beneﬁts, is our belief that healthcare must lead in guiding the 
responsible development and adoption of AI.  Integrated, large systems, like Advocate Health, are uniquely positioned to evaluate the performance, equity, and safety of healthcare focused AI solutions both as pilots and at scale across diverse settings and conditions.  With such a large diverse scale, we then are able to disseminate best practice both internally and beyond to other health systems, disseminating best practices to others within the healthcare system.     
Advocate Health Approach to Responsible AI 
At Advo cate Health, we believe a robust, yet ﬂexible governance framework is paramount to 
ensure the appropriate adoption of AI while enabling bold innovation. As technology rapidly advances, the enthusiasm to adopt new AI solutions in healthcare must be balanced with the crucial need for rigorous evaluation that addresses the unique risks inherent to healthcare AI. Our Enterprise Artiﬁcial Intelligence Governance Subcommittee which is comprised of leaders across our organization including from our patien t safety, health equity, ethics, clinical 
operations, information technology, data science, research, and digital innovation work in concert to maintain robust AI governance, guided by four core principles, ensuring AI is: (1) 
equitable and ethical; (2) valid and reliable; (3) transparent; and (4) impactful.    
The fo ur core principles allow Advocate Health to address many risks speciﬁc to AI in healthcare, 
such as data quality, evolving healthcare practices, liability, workﬂow challenges, transparency, and cost. We have used these core principles to structure a fourpronged approach to AI strategy:    
1. We beli eve that comprehensive changes in healthcare will occur through the use of AI,
but progress will be uneven.  There is no single solution for all problems; no single moon shot.Some AI will be successful, and some will not.  Therefore, as technology  continues to advance,
we must continuously pursue and test multiple use cases, while determining how they
seamlessly connect for our patients and providers to harness the collective beneﬁt.
2. We beli eve that healthcare requires the highest standards of security, privacy,
transparency, validity, and evaluation for bias.  There will continue to be technology issues, suchas drift and hallucinations, for the foreseeable future.  Therefore, healthcare systems like oursmust have strong data science expertise leading eﬀective governance of review prior to
implementation and ongoing vigilance after implementation.  The local context of data andunique deployment workﬂows require this governance to be localized and, while tightlyintegrated, cannot depend only on centralized regulation.  But to be eﬀective, large health


systems  cannot be hampered by diﬀering state regulations. This will create an unnecessary 
administrative burden and result in withholding care innovations or patchwork implementation. 
3. We belie ve that the high cost of tools will require industry collaboration, rigorous
evaluation of costs and beneﬁts and rapid dissemination of best practices.  In the absence of
such rigor, healthcare will adopt expensive technology that does not actually produce the
intended outcomes; parodically leading to higher expenses and degraded population health.
Therefore, we must embrace the learning health system model in conjunction with selectedpartners in devising a business strategy that supports appropr iate AI adoption into healthcare .
This will also require collaboration with payors to cover the added expense of AI for caredelivery when it is shown to improve outcomes.
4. We belie ve that our patients, communities, and government agencies will be interested
in our approaches to and utilization of AI.  Therefore, we must have eﬀective internal andexternal communication to share lessons learned .  Transparency with patients is of paramount
concern as building and maintaining their trust and understanding of new technology is vital.
We rel y on robust evaluation and subject matter expertise to harness the beneﬁts that AI 
solutions oﬀer; while mitigating the unique risks it brings to healthcare.  Advocate Health has demonstrated our commitment to safeguarding AI by aligning our approach to President Trump’s January 2025, Executive Order entitled “REMOVING BARRIERS TO  
AMERICAN LEADERSHIP IN ARTIFICIAL INTELLIGENCE”. The Executive Order aﬃrms Advocate 
Health’s strategy to deﬁne and pursue responsible AI aligned with our mission and values.   
Use Cases   
Advocat e Health is using many forms of AI today, including neural networks and generative AI. 
The following are three examples of AI in use at Advocate today:   
1.Our org anization has one of the largest deployments nationally using computer vision
(AI) to aid our radiologist in both prioritizing scans with positive ﬁnding and moreaccurately diagnosing conditions –for example the early identiﬁcation of strokes. Th e AI
algorithms review the images and alert the radiologist to prioritize reading the scanswith potential strokes ﬁrst. Our deployment of AI for strokes has taken the time forradiology to conﬁrm a stroke diagnosis from over 25 minutes to just under 6 minutes –in
a condition where time to treatment is essential.   While this tool is greatly beneﬁcial, itis an added cost to us without additional reimbursement, as noted above. In 2024 and2025, we have expanded similar AI algorithms to many other diagnostic categories, suchas mammography, fractures, aneurysm, and pulmonary embolisms.
2.Further,  Advocate Health was the ﬁrst health system in the nation to deploy an artiﬁcial
intelligence tool designed to automate the creation of clinical documentation during
3 
 


patient visits. Nuance® Dragon® Ambient eXperience ™ Copilot (DAX™ Copilot) helps free 
clinicians to focus on delivering high -quality personalized care, improving clinical 
eﬃciency, and reducing administrative workloads associated with burnout.   
The DA X Copilot allows clinicians to create draft clinical summaries automatically and 
securely in seconds from in- person exams or via telehealth patient conversations for 
immediate review and ﬁnalizing in the Electronic Health Record (EHR). Advocate 
clinicians are seeing modest improvements in their documentation  
time across the board with a subset getting substantial time back in their day.  Nearly 
half also report improved satisfaction with their EHR interactions, representing an important step for us in preventing physician burnout.   As an example of how we believe there is a responsibility to share our learnings broadly, our teams published 
these results in New England Journal AI and JAMA Open Network.  
3.Epic Inb asket:  This AI technology oﬀered by our electronic health record vendor
leverages an LLM to provide the ﬁrst draft of a patient message.  The physician or nursethen edits the message prior to sending to the patient, thus saving signiﬁcant timeincrementally.  We have deployed this technology across our footprint.
Ethical Concerns and Risks   
It is o ur belief that the highest standards of security, privacy, transparency, validity, and 
evaluation for bias are required in healthcare. This need for high standards combined with continuing technology issues in the near term as we navigate the multiple uses of AI (i.e. drift and hallucinations) necessitates having strong data science expertise and eﬀective governance 
of use.    
These standards apply not only to healthcare providers, but also to health plans, which are 
increasingly leveraging AI. It is critical that these AI tools and algorithms do not create new 
barriers to care and treatments.  We continue to believe that care d ecisions must include 
individualized assessment of each patient’s unique context. Overall, AI and other similar tools, 
must not serve as a replacement for the judgment of experienced and qualiﬁed  clinicians .    
As you k now, some regulators have begun to tackle the issue of AI and algorithm use in health 
care, most recently in the Medicare Advantage (MA) program. The 2024 MA ﬁnal rule1, which 
went into eﬀect on January 1, 2024, attempted to require plans to disclose their use of external coverage criteria, including AI and decision support algorithms, in a publicly accessible manner. 
In the same rule, the Centers for Medicare & Medicai d Services (CMS) strengthened existing 
requirements in the MA program that determinations regarding the medical necessity of 
treatment must be “based on the circumsta nces of the speciﬁc individual… as opposed to using 
an algorithm or software that doesn’t account for an individual’s circumstances.” The rule also 


clariﬁe s that medical necessity denials must be reviewed by a physician or other appropriate 
health care professional with expertise in the ﬁeld of medicine or health care that is appropriate 
for the service at issue.    
   
We believe a key element of this rule, and one that could be further strengthened by additional 
regulatory or legislative action, is to ensure transparency around the use of AI tools.  
Stakeholders should know when AI is being used by payors to make care d ecisions, the basis for 
the AI decision -making when applicable.     
   
Business Strategy    
   
Ultimately, AI tools are very expensive to run, as the computing power needed is very high and 
highly skilled professionals are required to implement AI responsibly develop and monitor AI 
performance.    In certain medical ﬁelds, AI is poised to become th e new standard of care, with 
profound potential to enhance diagnostic accuracy and eﬃciency. Take pathology and radiology, 
for example: AI -driven tools have shown high levels of precision in interpreting imaging scans. 
However, the high cost of AI techno logies limits their widespread adoption. To accelerate the 
integration of AI in healthcare, we advocate for the introduction of reimbursement incentives. 
These incentives would facilitate the broader use of AI -powered solutions in health care, 
ultimately accelerating diagnoses, improving patient outcomes, and transforming the future of medical care.   A cost -beneﬁt analysis must be conducted, and the cost should be at least 
partially covered by the party that beneﬁts from the technology. For example, a st roke patient 
who receives care at an Advocate Health site beneﬁts from AI technology, which leads to better outcomes by saving time —time that directly translates to brain tissue saved. However, another 
community hospital, which lacks AI technology and provides slower care, receives the same payment. Therefore, there should be reimbursement incentives in place to reward hospitals that provide better and faster care through the use of advanced technology.  
  
Communications    
   
Our patients and communities trust us to utilize AI responsibly.  Therefore, we must have 
eﬀective internal and external communication, including transparency with patients.   
   
We recognize that the dynamics governing the use of AI in health care cross over the 
jurisdictions of multiple Congressional committees and federal agencies. As noted above, CMS has already begun addressing AI issues in the MA program, though much more work is required to ensure that patient access to care is not compromised. Developing a meaningful AI framework that allows these technologies to achieve real beneﬁts for consumers while minimizing threats to safety and access will require cooperation across  the federal government. 
At the same time, it is important to note this is a quickly evolving area, such that overly speciﬁc regulations may restrict innovation and ultimately may not be aligned with technological advances. As you continue to explore poss ibilities for legislation in this area, we urge you to 
  
3 
  


coordinate closely with your colleagues in Congress and the Administration to create a robust, 
patient -centered AI policy.    
***  
In con clusion of our comments, some additional considerations that are critical to the expansion 
of AI in healthcare are as follows:  
•Support AI by investing in education and training programs that will increase the numberof AI trained professionals.
•Further, the cyber risk related to AI is signiﬁcant, as AI is enabling novel approaches andtools for hackers. The government should invest in programs and processes that stay one
step ahead of and combat threat actors using AI instead of punishing and ﬁning
healthcare providers when we are the victim of a crime.
•Establish regulations that protect healthcare organizations utilizing AI without creatingadditional overhead or increasing liability. We strongly support the need for regulationsthat ensure transparency from vendors, such as implementing a standardized A I label.
This would provide clarity and accountability while minimizing unnecessary burdens onhealthcare providers.
•Finally, when regulating, do so carefully and revisit often —this is a very immature
industry. Regulations should also ensure safe innovation.
Advocat e Health thanks the Trump Administration and the National Science Foundation for 
taking this step to solicit opinions from the ﬁeld and stands ready to provide additional information and assistance however we can. We greatly appreciate your time an d attention to 
our feedback and look forward to working with you and your colleagues to ensure that technological advancements improve outcomes and access to health care guided by novel 
technology. If you have any questions on our comments, please contact Sabra Rosener, VP , 
Government Aﬀairs at 
Sincerely,  


