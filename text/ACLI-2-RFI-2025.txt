American Council of Life Insurers  | 101 Constitution Ave, NW, Suite 700  | Washington, DC 20001 -2133  
The American Council of Life Insurers is the leading trade association driving public policy and advocacy on behalf of the life insurance 
industry. 90 million American families rely on the life insurance industry for financial protection and retirement security. ACLI’s member 
companies are dedicated to protecting consumers’ financial  wellbeing through life insurance, annuities, retirement plans, long -term care 
insurance, disability income insurance, reinsurance, and dental, vision and other supplemental benefits. ACLI’s 275 member co mpanies 
represent 93 percent of industry assets in t he United States.  
acli.com  Brian Bayerle 
Chief Life Actuary 
Colin Masterson 
Policy Analyst 
August 2, 2024 
Via Electronic Submission: www.regulations.gov  
To: Department al Offices, U.S. Department of the Treasury 
RE: Uses, Opportuni ties, and Risks of Artifici al Intelligence in th e Financial Service s Sector 
(Document Citation - 89 FR 50048) 
Re: Uses, Opportunities, and Risks of Artificial Intelligence in the Financial Services Sector  
The American Council of Life Insurers (ACLI) appreciates the opportunity to provide feedback in 
response to the Treasury’s June 6th posting of a “Request for Information on Uses, Opportunities, 
and Risks of Artificial Intelligence in the Financial Services Sector” (RFI) to the Federal Register . 
ACLI  advocates on behalf of 2 75 member companies dedicated to providing products and 
services that promote consumers’ financial and retirement security. Financial security is our core 
business, and retirement security for all Americans is a critical mission. We protect 90 million 
Americ an families with financial products that reduce risk and increase financial security, including 
life insurance, annuities, retirement plans, long -term care insurance, disability income insurance, 
reinsurance, and other supplemental benefits such as dental and vision.  
Our country’s  life insurance companies have long been committed to providing access to financial 
security for all Americans, regardless of where or how they work, their life stage, or the economic 
status of their household. Life insurance products play a significant role in financial empowerment 
due to their transformative ability to provide financial security and build intergenerational wealth.  
The life insurance industry is well regulated by the insur ance  commissioners in each state, and this 
extends to the use of technology. The National Association of Insur ance  Commissioners (NAIC) 
recently developed a Model Bulletin on the Use of Artificial Intelligence Systems by Insurers  (NAIC 
AI Model Bulletin ). Critically, t he NAIC AI Model Bulletin  enumerates how existing state laws to 
protect consumers of insurance products, including the Unfair Trade Practices Model Act  (NAIC 


Model #880)  and Unfair Claims Settlement Practices Model Act  (NAIC Model #900) , apply to the 
insurer uses of advanced technologies such as AI. The NAIC AI Model Bulletin  has been adopted 
by 13 states this year, and we support broader adoption to ensure consistent requirements for 
insurers  nationwide . 
America’s life insurance industry is taking action to increase the economic opportunities  of 
financially underserved communities across the country. The adoption  of emerging  technologies 
such as AI enables  life insurers to fulfill our core mission to enhance  financial security. The following 
responses discuss these applications further.  
Question 1: Is the definition of AI used in this RFI appropriate for financial institutions? Should 
the definition be broader or narrower, given the uses of AI by financial institutions in different 
contexts? To the extent possible, please provide specific suggestions  on the definitions of AI 
used in this RFI.   
•The NAIC has developed its definition of AI, and the insurance industry has responded with
information in accordance with that definition.  Any definition developed by Treasury should
align with, or at a minimum not conflict with, definitions of AI in existing regulatory
frameworks for financial institutions.
•The Treasury definition of AI should reflect the following:
oDefinitions should be tailored to the different types of AI and the use cases and
risks they pose.  The definition used in this RFI is similar to an outdated definition put
forth by the Organization for Economic Coordination and Development (OECD) ,
which  could be narrowed for specific use cases (e.g., tiering of risks under the EU
framework) .
oThere are also distinctions between generative AI used to make decisions, without
ultimately including human input or intervention, and AI used with human decision -
making being absolute or the usage being solely for internal  efficiencies and
therefore  not impactful for customer s.
oAI covers a broad range of predictive modeling techniques that would otherwise not
be considered Artificial Intelligence.  A refinement to the definition that classifies AI
as machine learning systems that utilize artificial neural networks to make
predictions may be more appropriate.
oThe definition of AI should  exclude simple r computation tasks that companies have
been using for a long time.
Question 2 : What types of AI models and tools are financial institutions using? To what extent 
and how do financial institutions expect to use AI in the provision of products and services, risk 
management, capital markets, internal operations, customer services, regulatory compliance, 
and marketing?   
•According to a recent survey from the NAIC, life insurance companies that currently
impleme nt AI/machine learning (ML) use it primarily for  their Pricing, Marketing, Risk
Management, and Underwriting functions.
•Other, less common applications include Enhancing Agent Productivity, Agent Recruitment,
Market Segmentation, Mortality & Lapse Assumptions, Fraud Detection, Compliance,
Human Resources, Form Optical Character Recognition, Call Centers, E nterprise Risk
Management (ERM)  Stress Calibration, Disability Product Outcomes, Enterprise
Compliance, Application Processing, Applicant Non -Disclosure, Quality Assurance, Claims
Approval/Processing, Customer Service, Chatbots & L arge Language Model (LLM)


  
Assistants, Cybersecurity, and Internal Knowledge Platforms  (in this context with the use of 
code -assist tools) . 
• State insurance regulators, under their existing regulatory authority, review  models and 
algorithms in market conduct examinations to ensure compliance with the Unfair Claims 
Settlement Practices Act, the Unfair Trade Practices Act, and various state -specific laws 
regarding underwriting. Confidential, non -public sharing of this info rmation with regulators 
helps ensure compliance with these regulations.  
 
Question 3 : To what extent does the type of AI, the development of AI, or AI applied use cases 
differ within a financial institution? Please describe the various types of AI and their applied use 
cases within a financial institution.  
 
Are there additional use cases for which financial institutions are applying AI or for which financial 
institutions are exploring the use of AI? Are there any related reputation risk concerns about using 
AI? If so, please provide specific examples.  
 
• Use cases differ within an insurance company in accordance with the various business 
operations within the insurer and in compliance with particular state laws and regulations.  
In all instances, the usage is intended for financial soundness and profitable growth across 
demographi cs. Insurers continue to explore additional uses beyond the limited applications 
of today. As those new use cases arise, insurers continue their transparency with 
regulators in rate filings considering the confidentiality provisions  and are otherwise subject 
to the aforementioned state laws and regulations.  
• Our response to Question 2 describes many of the current applications of insurer s’ use of 
AI. We anticipate most insurers who are currently not using AI would do so for such 
applications.  
  
Question 4 : Are there challenges or barriers to access for small financial institutions seeking to use 
AI? If so, why are these barriers present? Do these barriers introduce risks for small financial 
institutions? If so, how do financial institutions expect to mitigate those risks?   
 
• One of the main barriers for  small er insurers is access and application of the most up -to-
date computing technology  compared to larger entities . More specifically, smaller 
companies may also find it more resource constraining with less flexibility to work with 
third-party vendors  to develop and maintain AI systems .  
 
Question 5 : What are the actual and expected benefits from the use of AI to any of the following 
stakeholders: financial institutions, financial regulators, consumers, researchers, advocacy groups, 
or others? Please describe specific benefits with supporting data and examples. How has the use 
of AI provided specific benefits to low -to-moderate income consumers and/or underserved 
individuals and communities (e.g., communities of color, women, rural, tribal, or disadvan taged 
communities)?  
 
How has AI been used in financial services to improve fair lending and consumer protection,  
including substantiating information? To what extent does AI improve the ability of financial 
institutions to comply with fair lending or other consumer protection laws and regulations? Please 
be as specific as possible, including details about cost saving s, increased customer reach, 
expanded access to financial services, time horizon of savings, or other benefits after deploying AI.  
 
• In addition to improved efficiency in processing times for underwriting decisions, it improves 
risk assessment and fraud detection accuracy.  


•The use of technology also improves insurers’ ability to reach underserved communities
through improved targeting and outreach.
•Ultimately, the goal of our member financial institutions is to provide as many customers as
possible with life insurance products including, but not limited to, life insurance, annuities,
disability income, and long-term care . AI and related technologies help make this goal more
attainable.
•Data used by insurers in emerging technologies like AI is subject to strict and
comprehensive unfair trade practices laws, actuarial standards, and privacy  and security
laws at both the state and federal level. The existing regulatory framework allows
companies to leverage innovative technology that benefits both consumers and the
industry. This balanced regulatory approach lets life insurers keep offering c onsumers the
products they want and need, while also  allowing innovations that help make insurance
coverage available to more consumers.
Question 6 : To what extent are the AI models and tools used by financial institutions developed in -
house, by third -parties, or based on open -source code? What are the benefits and risks of using AI 
models and tools developed in -house, by third -parties, or based on open -source code?  
To what extent are a particular financial institution’s AI models and tools connected to other 
financial institutions’ models and tools? What are the benefits and risks to financial institutions and 
consumers when the AI models and tools are interconnected  among financial institutions?  
•Insurers utilize the development tools that make sense depending on the use case: in-
house, third -party, or open -source code based.  While most traditional predictive modeling
techniques are developed in -house and trained using proprietary data, emerging AI
approaches are costly and require significantly larger data sets to be effective.  As such,
many financial institutions leverage and augment AI models produced by large technology
firms.
•For in -house models, improved oversight and governance may result from the increased
transparency into the models and data they use and produce , in alignment with the
company’s risk management framework.
•Many vendors are actively developing functionality using AI that insurers utilize, which can
provide easier user adoption with familiar tools. Many institutions are actively looking into
open -source models with generative AI (GenAI) as well as some of the text and image
models.  While these models are not often used directly, they may be used as a foundation
to build models on top of them.  Additionally, vendors rely on either other vendor models to
create their own solution or they can also utilize open -source models as well.  Often a
model might be partly a vendor product or open -source solution that has been modified to
be more effective at solving the business use case . Not relying on a single vendor for
solutions allows for limiting risk, ensuring that there are options for organizations to utilize
and not just a few vendors or open -source solutions available.  A potential risk for open -
source models is the lack of an established vendor certifying functionality and summarizing
new version releases .
Question 7 : How do financial institutions expect to apply risk management or other frameworks 
and guidance to the use of AI, and in particular, emerging AI technologies? Please describe the 
governance structure and risk management frameworks financial institutions expect to apply in 
connection with the development and deployment of AI. Please provide examples of policies 
and/or practices, to the extent applicable.  
What types of testing methods are financial institutions utilizing in connection with the development 
and deployment of AI models and tools? Please describe the testing purpose and the specific 
testing methods utilized, to the extent applicable.  


  
 
To what extent are financial institutions evaluating and addressing potential gaps in human capital 
to ensure that staff can effectively manage the development and validation practices of AI models 
and tools?  
 
What challenges exist for addressing risks related to AI explainability? What methodologies are 
being deployed to enhance explainability and protect against potential bias risk?  
 
• Many insurers look at best practices across sectors in the development of their risk 
management frameworks. Due to the complexity of insurers, they have robust risk 
management frameworks in place that can assist in addressing risks associated with 
technolo gy. Current risk frameworks should apply to AI just like any other application.  
Governance and accountability frameworks evolve to address responsible AI 
considerations and are applied to internally and externally sourced AI solutions. Use of AI 
should inv olve human engagement throughout the lifecycle, as appropriate.  
• In some instances, there is regulatory guidance on risk management systems and 
governance of AI. For example, the NAIC AI Model Bulletin  reiterates  decisions or actions 
impacting consumers that are made or supported by AI systems must comply with all 
applicable insurance laws and regulations including those that address unfair trade 
practices and unfair discrimination. The NAIC AI Model Bulletin sets forth jurisdiction’s 
expectations as to how insurers will govern the development  and acquisition and use of AI 
technologies . The NAIC AI Model Bulletin describes the type of information and 
documentation that state insuran ce regulators  may request during an investigation or 
examination of the entity . Other states may provide additional guidance and requirements 
related to the use of AI . 
• As for explainability, it is understood that the phrase is important for state  regulators, and 
entities should be able explain usage and tools easily. However, for the consuming public 
for insurance, there are already laws  and regulations regarding notices and disclosures that 
are sufficient and followed.  
• Approach to risk management relative to AI is consistent with enterprise approaches 
financial institutions are taking to risk management; any regulatory requirements should 
allow institutions to utilize their existing frameworks to adapt to use of AI comme nsurate 
with the risks.  
o For third party risk management, companies may  utilize best practices that include 
risk assessment, pre and post contract due diligence, contractual safeguards , and 
ongoing monitoring.  
o AI could be a benefit in risk management in addressing illicit finance risk ; it can be 
useful for identifying suspicious activities through monitoring and analyzing huge 
volumes of data in real time, and identifying patterns that need review.  
 
Question 8 : What types of input data are financial institutions using for development of AI models 
and tools, particularly models and tools relying on emerging AI technologies? Please describe the 
data governance structure financial institutions expect to apply in confirming the quality and 
integrity of data. Are financial insti tutions using “non -traditional” forms of data? If so, what forms of 
“non-traditional” data are being used? Are financial institutions using alternative forms of data? If 
so, what forms of alternative data are being used?  
 
• As data scientists look at a potential  business use case , they identify what data is available 
and best to employ . For life insurers, traditional data is the most prevalent input for pricing 
and underwriting. As more data becomes available, life insurers can refine their models 
reflecting more accurate data for improved risk assessment.  


•Insurers rely upon data provided directly from their clients, data that clients have given the
insurer permission to access ( e.g., medical history data), and data that is publicly available
or available for purchase from data vendors. Insurers are responsible for complying with all
applicable policies, laws and regulations to insure data protection and appropriate use.
•To the extent that u nstructured data is being used, it should have similar governance
expectations ; review by data owners of unstructured data is still required to ensure the
quality of that content meets the thresholds for model performance.
Question 9 : How are financial institutions evaluating and addressing any increase in risks and 
harms to impacted entities in using emerging AI technologies? What are the specific risks to 
consumers and other stakeholder groups, including low - to moderate -income cons umers and/or 
underserved individuals and communities (e.g., communities of color, women, rural, tribal, or 
disadvantaged communities)? How are financial institutions protecting against issues such as dark 
patterns – user interface designs that ca n potentially manipulate impacted entities in decision -
making – and predatory targeting emerging in the design of AI? Please describe specific risks and 
provide examples with supporting data.  
•Layered governance techniques are applied to AI solutions to ensure financial institutions
continue to protect consumers and other stakeholder groups from increases in risks and
harms.
•The use of emerging AI technologies enables  insurers to increase access to financial
products to underserved communities. Existing risk management frameworks help mitigate
additional risks associated with such technologies.
Question 11 : How are financial institutions addressing any increase in data privacy risk related to 
the use of AI models, particularly emerging AI technologies? Please provide examples of how 
financial institutions have assessed data privacy risk in their use of AI.  
In what ways could existing data privacy protections (such as those in the Gramm -Leach -Bliley Act 
(Pub. L. No. 106 -102)) be strengthened for impacted entities, given the rapid development of 
emerging AI technologies, and what examples can you provide of th e impact of AI usage on data 
privacy protections?  
How have technology companies or third -party providers of AI assessed the categories of data 
used in AI models and tools within the context of data privacy protections?  
•The life insurance industry is subject to robust  insurance privacy and data security laws that
apply to new technology (including AI) . These laws require insurers to impose robust
privacy/data security requirements on third -party vendors, including those whose AI tools
we might utilize.
•Data privacy risk can be addressed by h aving a holistic view of the risks involved in utilizing
AI, both to that of the client and internal company business systems . Additionally, different
levels of risk are associated with its usage whether related to business operations or not.
For example, a lower risk seems to exist where AI is utilized in the background in
supporting business processes  that are ultimately reviewed by a person for any errors or
omissions. Higher risks exist where there is no human component in the AI utilization
process.
•There are many possible ways to address privacy concerns, including:
oUpdating vendor onboarding and ongoing monitoring questions to specifically
address AI risk;
oUpdating contract review process and procedures ;


oInternal review and approval process for AI use cases as they move from testing to
production, including ongoing and periodic review once they are launched in
production ;
oAI risk is assessed, monitored, and sufficiently escalated at the right level within the
organization ; and
oDedicated staff across all cross functional departments that ha ve AI as part of their
core job functions and responsibilities.
Question 12 : How are financial institutions, technology companies, or third -party service providers 
addressing and mitigating potential fraud risks caused by AI technologies? What challenges do 
organizations face in countering these fraud risks? Given AI’s ability to  mimic biometrics (such as a 
photos/video of a customer or the customer’s voice) what methods do financial institutions plan to 
use to protect against this type of fraud (e.g., multifactor authentication)?  
•A layered Defense in Depth framework enables multiple technologies and procedures to
work across a wide range of services and capabilities to deliver a comprehensive set of
solutions designed to mitigate the risk of fraud or cybersecurity incidents.  This includes
electronic signatures, certificate management, encryption at rest, in motion or in some
cases while processing, as well as advanced liveness testing and modern authentication
mechanisms like hardware tokens and biometrics pattern recognition to ena ble suspicious
activity detection and alerting .
Question 14 : As states adopt the NAIC’s Model Bulletin on the Use of Artificial Intelligence Systems 
by Insurers and other states develop their own regulations or guidance, what changes have 
insurers implemented and what changes might they implement to comply or be consistent with 
these laws and regulatory guidance?  
How do insurers using AI make certain that their underwriting, rating, and pricing practices and 
outcomes are consistent with applicable laws addressing unfair discrimination?  
How are insurers currently covering AI -related risks in existing policies? Are the coverage, rates, or 
availability of insurance for financial institutions changing due to AI risks? Are insurers including 
exclusions for AI -related risks or adjusting policy  wording for AI risks?  
•The NAIC AI Model Bulletin clarifies applicability of existing state laws that define and
address unfair discrimination in the use of AI. Underwriting and rating laws have not
changed due to the adoption of the NAIC AI Model Bulletin, and insurers continue to
comply with laws regarding the prohibition of the use of protected classes in rating and
underwriting along with  the required transparency in filings and market conduct oversight.
•Industry’s current required privacy programs focus on data inputs and outputs and
permissions for those uses. Privacy requirements like transparency and consumer choice
are relevant in AI policy discussions and form some of the strongest controls on AI use . For
example, t he Gramm -Leach -Bliley Act  requires financial institutions to provide notice and
opt-out rights before sending nonpublic personal information to non -affiliated third parties
for their own use which would prohibit the industry from allowing a n AI provider to use
company data to train AI products in a way that would expose the data to others.
Question 15 : To the extent financial institutions are relying on third-parties to develop, deploy, or 
test the use of AI, and in particular, emerging AI technologies, how do financial institutions expect 
to manage third -party risks? How are financial institutions applying third -party risk management 
frameworks to the us e of AI?  


What challenges exist to mitigating third -party risks related to AI, and in particular, emerging AI 
technologies, for financial institutions? How have these challenges varied or affected the use of AI 
across financial institutions of various sizes and comp lexity?  
•While life insurers are likely investing in some technology development of varying degrees
internally, they are also using third party tools in a meaningful way, leveraging the
advancements that companies that are experts in such technology can provide. Be nefits
are that third parties are focused on continuous enhancement of the technologies that are
their business, and opportunity for faster innovation. There are risks that can be mitigated
with diligent third -party risk management and transparency. Such r isk management may
include m aturing of the existing process, engaging key stakeholders , triggers in risk
assessment framework for additional due diligence, and updating contract provisions  as
appropriate.
Question 16 : What specific concerns over data confidentiality does the use of third -party AI 
providers create? What additional enhancements to existing processes do financial institutions 
expect to make in conducting due diligence prior to using a third -party provider of AI technologies?  
What additional enhancements to existing processes do financial institutions expect to make in 
monitoring an ongoing third -party relationship, given the advances in AI technologies? How do 
financial institutions manage supply chain risks related to AI?  
•Some effective strategies for managing supply chain risk from third parties related to AI
include:
oAI Governance  - Establishing robust AI governance to oversee AI implementation.
This involves defining policies, roles, and responsibilities, ensuring ethical use, and
monitoring compliance ;
oStrengthen Cybersecurity  - Protecting against cyber threats by implementing strong
security measures. Regularly assess ing vulnerabilities, secur ing data, and
monitor ing AI systems for potential breaches ;
oData Literacy  - Developing data, cybersecurity,  and privacy literacy among supply
chain teams. Educating employees and third-party  partners about AI, data
handling, and privacy to enhance their understanding and decision -making ;
oRisk Identification  - Identifying regulatory, reputational, competency, and technology
risks associated with AI via the implementation of proactive risk mitigation
strategies ; and
oData confidentiality  - Address c oncerns when using third -party AI solutions with
data encryption, access controls, data minimization, data anonymization, data
tagging, auditing , and monitoring, employee training, and contractual safeguards.
Question 17 : How are financial institutions applying operational risk management frameworks to 
the use of AI? What, if any, emerging risks have not been addressed in financial institutions’ 
existing operational risk management frameworks?  
How are financial institutions ensuring their operations are resilient to disruptions in the integrity, 
availability, and use of AI? Are financial institutions using AI to preserve continuity of other core 
functions? If so, please provide examples.  
•The main new risks with GenAI are the intellectual property (IP) risks, the approval of
contract risk acceptances, as well as how to manage foundational models that are used in
multiple areas of a company.
•Here are some strategies for applying an operational risk management framework to AI:


oData Risks  - AI systems rely on data vulnerable to tampering, breaches, bias, or
cyberattacks. Protect data integrity, security, and availability throughout the AI
lifecycle ;
oModel Risk s - Assess algorithmic choices, training methodologies, and model
selection. Rigorous testing and validation are essential to minimize risks ;
oOperational Risks  - Consider challenges related to system deployment,
infrastructure, and scalability. Implement robust monitoring and maintenance
practices ;
oEthical and Legal Risks  - Address ethical concerns (e.g., bias, fairness) and legal
compliance. Ensure AI systems respect human rights and privacy ; and
oCommonly used AI risk management frameworks include the NIST AI Risk
Management Framework, the EU AI ACT, and ISO/IEC standards. These
frameworks guide organizations in deploying and maintaining AI systems safely and
ethically.
•Financial institutions protect themselves from disruptions of AI solutions with resilience
planning, continuous monitoring, incident response planning, and redundant capability
development.  When utilizing third -party AI solutions, robust vendor risk management,
contractual safeguards, and exit strategies such as internal capability development are
applied.
Question 18 : What actions are necessary to promote responsible innovation and competition with 
respect to the use of AI in financial services? What actions do you recommend Treasury take, and 
what actions do you recommend others take? What, if any, further actions ar e needed to protect 
impacted entities, including consumers, from potential risks and harms?  
Please provide specific feedback on legislative, regulatory, or supervisory enhancements related to 
the use of AI that would promote a financial system that delivers inclusive and equitable access to 
financial services that meet the needs of consumers and businesses, while maintaining stability and 
integrity, protecting critical financial sector infrastructure, and combating illicit finance and national 
security threats. What enhancements, if any, do you recommend be made to existing governance 
structures, oversight requirements, or risk management practices as they relate to the use of AI, 
and in particular, emerging AI technologies?  
•It is critical to consider AI in the context of its use within the specific financial services
application. Insurance companies and the technologies they deploy follow sound state
insurance regulations  that promote  innovation and competition while protecting
policyholders. As previously  stated, state insurance regulation is governed by  NAIC Model
#880 and NAIC Model #900, with greater clarification of how these laws apply to
technologies like AI through the NAIC AI Model Bulletin.  Insurers are using existing
guidance and best practices to incorporate governance around AI in their existing risk
management frameworks.
•A broad -brush regulation  is not appropriate as it would  stifle AI innovation. This is
particularly true for insurers who are heavily regulated under existing state insurance laws
per the enablement of McCarran -Ferguson.  The ideal solution is to allow for industry -by-
industry innovation in accordance with the industry’s specific laws and regulations.
Question 19 : To what extent do differences in jurisdictional approaches inside and outside the 
United States pose concerns for the management of AI -related risks on an enterprise -wide basis? 
To what extent do such differences have an impact on the development of prod ucts,  competition, 
or other commercial matters? To what extent do such differences have an impact on consumer 
protection or availability of services?  


•Through the NAIC, states periodically adopt uniform laws that provide protections for both
solvency and market conduct and in particular the unfair discrimination and unfairly
discriminatory rates standards.  But differences between the states have also enabled the
states to empower innovation and “laboratories” for greater efficiencies .
•Differences in jurisdictional approaches to AI governance inside and outside the United
States pose major concerns and challenges for multi -national companies who are
attempting to manage AI across their entire enterprise. Lack of harmonization means
compa nies have to tailor their AI governance practices, product development, third-party
due diligence , and risk management separately for each jurisdiction they operate in. The
divergent approaches can also lead to dramatically different levels of consumer pro tection
and access to AI -powered services from one jurisdiction to the next. Citizens in regions
with more permissive regulations may gain access to more innovative  AI services sooner,
while those in regions with stricter rules may face more limited availability in an effort to
comply with guardrails.


