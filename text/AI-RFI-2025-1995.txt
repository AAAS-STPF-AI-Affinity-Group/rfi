PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-f0d1-incn
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1995
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  Internet Works
General Comment
See attached file(s)
Attachments
Final_IW Response to NSF Request for Inform ation regarding AI Action Plan


1 
March 15, 2025  
Networking and Information Technology Research and Development (NITRD) 
National Coordination Office (NCO)  
National Science Foundation  
Re: Response to the National Science’s Foundation Request for Information  
Respondent:  Internet Works 
This document is approved for public dissemination.  The document contains no 
business- proprietary or confidential information.  Document contents may be 
reused by the government in developing the AI Action Plan and associated documents without attribution.  
Internet Works appreciates the opportunity to provide input on the National Science 
Foundation’s Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan.  
Internet Works is a trade association of broad member companies working together 
to right -size technology policy, particularly for midcap and other technology 
companies who fall outside of “Big Tech,” and can more appropriately be referred to 
as “Middle Tech.”   We are committed to promoting innovation, protecting freedom 
of expression, and preserving consumer choice.  Our work centers on two key 
objectives: first, advocating for policies that foster innovation, providing essential value to our users, competition, and fairness while preventing harmful regulations that create unnecessary barriers for emerging and diverse technology companies; 
and second, ensuring policymakers recognize the unique challenges and 
disproportionate impacts regulatory proposals can  have on diverse business models 
and the communities they serve . 
AI is reshaping the digital economy, and its continued growth depends on balanced policies that foster both cutting -edge research and widespread industry and 
consumer adoption.  Internet Works member companies play a critical role in this 
transformation, leveraging AI to enhance products and services, improve user 
experiences, and strengthen safety and security.  
Internet Works member companies are using AI to expand consumer choice by streamlining operations, reducing costs, and making innovative solutions more accessible.  The integration of AI into our products also provides actionable insights 
and recommendatio ns, automates customer support, and enhances digital 
interactions, allowing consumers to engage with services on their own terms.  AI-
powered tools such as chatbots, virtual assistants, and real -time translation further 


 
 
2 
improve accessibility, making digital services more inclusive and responsive to 
diverse needs. 
 
Moreover, AI plays a crucial role in safeguarding consumer data and transactions. By helping to support compliance with safety regulations, identifying threats in real 
time, and ensuring secure, seamless experiences, AI enhances digital trust.  AI-
driven monitoring systems detect anomalies, prevent cyberattacks, and reduce 
human error, making online services more reliable.  
 
In the following pages, Internet Works outlines key recommendations to ensure the 
AI Action Plan sustains U.S. leadership in AI, promotes fair competition, and fosters sustainable and responsible AI development.  
 
MIDDLE TECH AI PRINCIPLES  
 
An AI legal framework built on the below principles can drive innovative and 
impactful U.S. leadership in AI, and ensure that companies of all sizes have the 
opportunity to continue to best serve their users – consumers and businesses.  
  
Risk- Based Regulation  and Balanced Enforcement  – Smaller enterprises and 
Middle Tech companies often face disproportionate regulatory burdens that can stifle innovation and limit their ability to compete in the tech ecosystem.  AI policymakers should adopt a risk -based approach to regulation focusing on  whether 
the end use is likely to have a legal or similarly significant impact on consumers.  A graduated approach to enforcement should adapt to varying levels of risk ensuring stricter oversight where there ’s a higher risk of harm while avoiding excessive 
compliance requirements for low -risk applications.  This approach ensures that 
compliance obligations remain proportionate, practical, and innovation -friendly, 
allowing smaller enterprises and Middle Tech c ompanies to thrive while also 
encouraging broader adoption of AI and stimulating economic growth and U.S. 
productivity. 
 Regulatory Flexibility & Proportional Standards  – Ensure regulatory 
frameworks can be scaled to the size and operational capacity of all participants to prevent smaller enterprises and Middle Tech companies from being disproportionately impacted by regulations designed for the largest ones.  The goal 
of any flexible regulatory approach should be to preserve a competitive 
marketplace where smaller enterprises and Middle Tech companies can innovate and grow while still meeting essential safety standards and r esponsibilities, by 
avoiding a one -size-fits-all approach that would hinder their development.  
 Clear & Tailored Compliance Obligations – AI regulatory frameworks should 
reflect the diverse capabilities and roles of entities across the AI ecosystem.  
Effective compliance depends on clear, well -defined default obligations across the 
AI supply chain. Developers, service providers, and other u pstream actors play a 


3 
critical role in AI system integrity and should contribute meaningfully by offering 
transparency, documentation, and support to facilitate compliance.  A balanced 
regulatory approach —  where obligations are proportionate to an entity’s influence 
and role in AI development and deployment — would enhance accountability and 
minimize the risk of costly litigation that would stifle innovation while protecting both business sustainability and the integrity of the consumer experience.  
POLICY ACTIONS 
This document outlines key policy recommendations for establishing a preemptive 
federal framework on AI that builds on existing laws, preventing a fragmented patchwork of state regulations and providing legal certainty.  Such a framework 
should promote a flexible, risk -based structure that adapts to evolving AI 
technologies and business models, promoting innovation, removing unnecessary 
barriers, and strengthening AI innovation and U.S. leadership.  
A National AI Framework: Clarity, Accountability, And Innovation 
A preemptive, federal AI framework should prioritize accountability, transparency, and risk management.  It should provide clear guidelines for the responsible development, integration, and use of AI systems, ensuring that obligations are 
proportionate to an entity’s role and level of influence over an AI system.  
Recommendations:  
1.Adopt a Tiered, Risk- Based Approach
A tiered, risk -based AI framework should  align obligations with each entity’s role in 
the AI supply chain, depending on their level of control over and access to the components of an AI system and the risks associated with its use.  
●AI Developers
○Promote high -quality, lawfully obtained, and appropriatel y
representative training data to enhance model accuracy and minimize
bias and 
unintended consequences.
○Conduct and document risk assessments on model capabilities,
limitations, and potential downstream impacts across different use
cases.
○Implement security protections to prevent model poisoning ,
adversarial attacks, and unauthorized modifications, ensuring modelinte
grity.
○Provide clear documentation on key model characteristics, includi ng
training data sources and known limitations to inform downstreamusers
 and sectoral regulators (more on this in Facilitate AI Supply
Chain Transparency  below).


 
 
4 
○ Conduct ongoing testing and maintenance post -deployment to detect 
and mitigate temporal bias, model drift, and overfitting in real -world 
conditions. 
 
● AI Deployers/Downstream Deployers (Entities Implementing AI for Real -
World Use)  
○ Assess AI model risks in their specific deployment context, including sector- specific regulatory risks.  
○ Ensure AI system governance and compliance with applicable laws, 
including data privacy, transparency, fairness, and accountability 
requirements.  
○ Implement safeguards and user protections, such as transparency, 
human oversight mechanisms, and automated decision safeguards (as 
applicable).  
○ Establish security measures to ensure AI systems and outputs are not 
misused, manipulated, or accessed by unauthorized parties.  
○ Monitor AI performance post -deployment, addressing unintended 
consequences and model drift over time.  
 
2. Facilitate AI Supply Chain Transparency  
An effective tiered AI federal framework would allocate accountability fairly between 
developers and deployers based on who controls what elements in the AI supply 
chain.  Initial developers should provide downstream integrators and deployers with 
relevant  risk-related information in a structured and accessible manner, leveraging 
existing best practices (e.g., model cards) while allowing flexibility for emerging 
standards.1  Documentation should focus on: 
 
● Model training data sources (e.g., general categories, but not proprietary 
datasets). 
● Known and foreseeable risks and limitations (e.g., bias, potential misuse 
scenarios).  
● Model behavior in safety tests (e.g., adversarial robustness, accuracy 
benchmarks). 
● Guidelines for intended uses of the AI model or overall AI system.  
 
Downstream AI users should not be held accountable for outcomes outside of their 
direct control.  Liability limitations should apply for development undertaken by AI 
developers, particularly in cases where developers fail to disclose known, 
preventable risks to deployers/downstream deployers.  Likewise, the mere provision 
of a tool by a service does no t inherently confer responsibility for how users choose 
to utilize it . 
 
 
1 In practice, this documentation should take the form of structured risk reports (similar to software 
vulnerability disclosures) that help standardize AI transparency, such as the AI Model Cards framework 
(used by Google and OpenAI) . 


5 
3.Adopt a Risk- Based Balanced Approach to Enforcement
A tiered AI federal framework should adopt a risk -based, proportionate approach to 
enforcement, considering an entity’s level of control and risk exposure within the AI 
supply chain.  This requires a flexible, market -driven AI risk framework with the 
following key elements:  
●Industry- Led AI Risk Standards
○Encourage industry -driven AI risk management frameworks,
leveraging standards from organizations like the National Institute forStandards and Technology (NIST), the International Organization forStandardization (ISO), and the Institute of Electrical and Electroni cs
Engineers (IEEE).
○Establ
ish sector -specific AI risk guidelines through agencies such as
NIST, the FDA, and the FTC to ensure regulations align with industry
needs rather than imposing rigid, one -size-fits-all mandates.
○Provide incentives (e.g., safe harbors, opportunity funding) for
companies — particularly startups and small businesses — that
implement leading AI risk management frameworks.
○Foster public -private collaboration to define AI risk tiers while avoiding
excessive regulatory burdens.
●Proportionat e & Targeted Enforcement
AI regulation should focus on identifiable harms and concrete risks, ensuring
enforcement measures are reasonable, proportionate and aligned with actual
impacts.
○Risk-based oversight – Enforcement bodies should establish clea r
criteria to define high -risk a pplications, prioritizing actual harm
prevention over theoretical concerns.
○Accountability aligned with the AI supply chain – Enforcement efforts
should ensure that compliance obligations fall on the appropriate actor
within the AI ecosystem (see Adopt a Tiered, Risk- Based
Approach) .
○Balanced Enforcement Approaches – Enforcement should balance
oversight and innovation.  It should prioritize risk -proportionate
mechanisms, and where possible rely on self -assessments, voluntary
best practices, and industry standards to ensure compliance remainspractical, adaptable, and conducive to innovation.
AI And Content Moderation  
Internet Works recognizes the transformative potential of AI in content moderation, recommendation systems, and platform governance.  We also emphasize the need for a risk- based, balanced regulatory approach that preserves innovation, ensures 
effective con tent moderation, and upholds the foundational protections of Section 


 
 
6 
230 of the Communications Decency Act , which has long supported free expression 
and entrepreneurial growth in the digital economy.  
AI will increasingly become a critical tool for platforms in mitigating harmful 
content, improving user experiences, and maintaining compliance with existing legal and regulatory frameworks.  As NSF considers its AI governance strategy, we 
urge a policy approach that supports innovation in AI -driven moderation while 
ensuring transparency and accountability without unintended regulatory burdens 
that could limit free expression or create new liabilities for American businesses.  To ensure that AI governance frameworks, particularly as they apply to content 
moderation issues, align with platform needs while safeguarding a robust online 
discourse.  
 
Recommendations:  
 
1. Ensuring AI Governance Respects Free Expression and Platform Accountability 
Platforms rely on AI to enforce community guidelines, protect users, and combat 
unlawful content.  AI governance should not introduce rules that limit platforms’ ability to moderate content effectively or incentivize over -removal of lawful speech 
out of liability concerns . 
 
2. Avoiding One -Size-Fits-All Mandates  
As discussed before in Adopt a Risk- Based Balanced Approach to 
Enforcement, a risk -based AI governance framework should distinguish between 
high-risk AI applications and AI tools that assist in product functionality and 
moderation.  Regulations that apply overly broad compliance obligations to AI -
driven moderation systems could discourage platforms from investing in better tools to protect users and ensure an open, dynamic online s pace. 
 
3. Aligning AI Rules with Section 230 Protections  
AI governance policies must not weaken the core principles of Section 230, which has enabled platforms to moderate content while protecting free expression.  At the 
same time, we recognize the need for increased transparency and accountability in 
AI decisi on-making.  A balanced approach should allow platforms to retain 
discretion over moderation policies while ensuring users understand how AI is applied.  
 
Foster Competition and Collaboration  
To ensure U.S. leadership in AI, policymakers should focus on enforcing competition 
laws in AI markets, promoting open AI ecosystems, and fostering structured 
collaboration between government, industry, and academia.  
  
 
 


7 
Recommendations:  
1.Ensure a Level Playing Field for all American Companies
As explained above (see A National AI Framework: Clarity, Accountability, 
and Innovation ), a tiered AI federal framework developed under the AI Action 
Plan would prevent excessive regulatory compliance costs from disproportionately 
impacting startups, smaller businesses and Middle Tech companies, which would affect their ability to compete.  I n addition to this, the AI Action Plan should 
empower authorities to enforce existing competition laws in the AI space to prevent 
companies with market power from stif ling innovation.  For example, authorities 
should actively monitor market developments and intervene to prevent such firms 
from restricting smaller businesses and Middle Tech companies’ access to essential 
AI resources (i.e., compute resources, training da ta, cloud services) and risk -
related information, which are critical for smaller companies to enter the market, as 
well as to develop and deploy AI solutions competitively.  
Furthermore, access to open source AI models, open weights AI models, and other AI components, which enables businesses to develop, adapt and apply AI in ways that best fit their needs and those of their users, offers significant opportunities in 
fostering a level playing field, thereby enhancing competition and innovation in AI.  
Policymakers should explore policies that promote a strong and secure open 
ecosystem for AI.  
2.Foster Public -Private Partnerships
As AI continues to shape industries and economies, public -private collaboration will 
be essential in advancing research, setting best practices, and fostering innovation, as well as addressing economic, national security and consumer protection priorities. 
To navigate AI’s evolving challenges, ongoing engagement between government, 
industry, academia, and civil society should facilitate practical, risk -based 
approaches that support AI safety, transparency and global competitiveness.  
Bringing together these stakeholders will allow for the development of a science -
backed, risk -based AI framework that will ensure AI’s responsible development, 
deployment, and long -term impact and foster economic growth and public trust.  
Avoid Overregulation, Future-Proof Regulations, and Ensure 
Alignment  
The AI Action Plan should encourage the development of a principles -based, 
forward- looking framework that focuses on harmonization, ongoing market 
assessment, and global cooperation to maintain U.S. AI leadership.  Where needed, 
policymakers should priorit ize the development of technology -neutral regulation 
that is adaptive, targeted, and proportionate  to support innovation.  


 
 
8 
Recommendations:  
 
1. Review and Harmonize   
Before introducing new AI regulations, policymakers should conduct a 
comprehensive gap analysis to prevent overlapping or conflicting rules.  Rather 
than creating entirely new regulatory structures, regulators should be invited to 
develop strategies on how they will apply existing sectoral laws  — such as privacy, 
consumer protection, and cybersecurity — to AI use cases and ensure a cohesive, 
streamlined approach that reduces regulatory complexity while maintaining 
business continuity and effective oversight.  
 
We believe policymakers are presented with a unique opportunity at this stage to 
introduce a federal preemptive privacy law.  The current patchwork of state privacy 
laws creates regulatory fragmentation, increasing costs and uncertainty for businesses while limiting the scalability of AI -driven solutions.  A uniform federal 
framework would provide clear, consistent rules that protect consumer privacy without stifling technological progress.  By ensuring strong, but flexible protections, aligned with global standards, the U.S. can promote responsible AI development, 
enhance economic competitiveness, and safeguard national security interests -all 
while reinforcing American values of innovation, individual rights, and market -
driven growth.  
 
2. Prevent Regulatory Fragmentation  
Policymakers should adopt a unified federal approach to AI governance to avoid regulatory fragmentation.  The patchwork of conflicting state -level regulations that 
have been enacted and will soon be in effect will create unnecessary complexity, making comp liance particularly challenging for businesses — especially startups, 
smaller enterprises and Middle Tech companies.  Ensuring federal -level 
harmonization would provide businesses with greater legal certainty while fostering 
a consistent AI governance fram ework.  
 
Regulators should also be tasked with conducting ongoing AI market assessments 
to identify emerging risks and opportunities.  Regulatory bodies and courts must 
continuously interpret and update AI regulations, issuing guidelines and clarifications as new c hallenges arise.  This approach ensures legal certainty while 
preventing outdated or excessively rigid compliance mandates that could hinder AI -
driven growth.  
 
3. Position the U.S. as a Global AI Leader  
U.S. AI regulations should serve as a baseline for global governance, aligning international standards, and reducing compliance burdens for multinational companies.   By leading international AI cooperation, the U.S. can shape globally 
recognized policies that foster innovation, competitiveness, and market expansion while preventing regulatory fragmentation.  
 


9 
The AI Action Plan should include provisions that would enable the U.S. to enter 
into strategic partnerships with key allies to establish common AI standards.  It 
could also propose the creation of a U.S. -led AI Competitiveness Council, housed 
within the Department of Commerce, to collaborate with industry leaders and 
ensure that domestic AI regulations remain globally competitive.  This council would 
play a critical role in:  
●Promoting the U.S. as the leading architect of global AI rules that promote an
open and competitive global market for AI.
●Ensuring American businesses remain at the forefront of AI innovation and
leadership.
The EU AI Act , in turn, represents an important effort to establish baseline 
obligations for AI systems and general- purpose AI models.  These obligations aim 
to promote transparency to downstream providers and users, accountability, and risk-based governance.  Internet Works recognizes the value of these foundational 
requirements, particularly in ensuring trust in AI systems and regulatory clarity 
across markets.  A structured approach to AI safety, documentation, and human oversight can help align global standa rds and foster responsible innovation.  
However, the EU AI Act  also pres ents challenges the U.S. should carefully consider. 
The implementation and oversight of its broad and complex compliance framework — combined with its extraterritorial reach — could disproportionately impact 
smaller AI developers and create unnecessary regulatory burdens for U.S. businesses operating in Eur ope.  As established in this document, Internet Works 
companies urge the U.S. to aim to strike a balance — embracing principles that 
enhance AI safety and public trust while ensuring that regulation does  not 
undermine competition, scalability, or technological leadership.  
4.Favor Adaptable, Principles -based Regulation
AI-specific regulations should be technology -neutral and adaptable, ensuring they 
remain relevant as technology evolves.  They should focus on broad principles applicable across different AI applications, avoiding rigid classifications that may 
quickly bec ome outdated.  Overly prescriptive rules risk stifling innovation and 
imposing unnecessary burdens on businesses. 
Additionally, as mentioned above (see A National Framework: Clarity, 
Accountability and Innovation ), compliance requirements should be risk -based, 
offering flexible options that vary depending on the use case and potential risks of 
each AI system.  A one -size-fits-all approach could lead to unnecessary regulatory 
burdens while failing to more effectivel y address high- risk AI applications. 
By implementing pro -innovation, risk -based policies, the U.S. can solidify its AI 
leadership, foster a diverse and competitive AI ecosystem, and promote responsible 
AI development.  


10 
CONCLUSION 
Internet Works appreciates the NSF’s leadership in developing an AI Action Plan 
that strengthens U.S. competitiveness, fosters innovation, and supports responsible development.  As AI continues to evolve globally, ensuring that American businesses — particularly smaller enterprises and Middle Tech companies — can 
compete and scale is critical to maintaining U.S. leadership.  
A risk -based, proportionate approach to AI governance will be essential.  As 
explained above, overly rigid regulations could hinder innovation, particularly for startups and small businesses that lack the capacity and means of larger firms.  To keep the U. S. at the forefront of AI development, the NSF should prioritize policies 
that: 
●Enable a dynamic, open, and competitive AI ecosystem where startups, smallbusinesses, and Middle Tech companies can develop, deploy, and utilize AI
without undue regulatory burdens.
●Encourage investment in AI research and public -private partnerships t o
unleash the benefits of AI and strengthen U.S. competitiveness.
●Adop
t flexible, risk -based governance frameworks that support responsible
AI innovation while keeping compliance scalable.
Intern et Works remains committed to advancing policies that drive AI innovation, 
empower smaller enterprises and Middle Tech companies, and ensure U.S. 
leadership in the global AI economy.  We appreciate the opportunity to contribute to this discussion and look forward to continued collaboration in shaping a future -
ready AI ecosystem. 
Respectfully submitted,  
Peter Chandler  
Executive Director, Internet Works 
https://www.theinternet.works/ 


