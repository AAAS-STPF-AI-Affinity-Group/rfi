From:
To:Cc:Subject:Date:Bob London UK
ostp-ai-rfi
 [External] AI Action Plan
Friday, March 7, 2025 9:29:42 AM
To whom it may concern: 
One way to accelerate the adoption of AI algorithms in healthcare settings is to  
consider the option of ‘selective deployment’. Full details of the ‘selective deployment’  
approach, which was recently published by bioethics researchers at the University of  
Oxford, are available here ( https://onlinelibrary.wiley.com/doi/10.1111/bioe.13281 ). 
The abstract of this paper is as follows: 
“Machine-learning algorithms have the potential to revolutionise diagnostic and
prognostic tasks in health care, yet algorithmic performance levels can be materially
worse for subgroups that have been underrepresented in algorithmic training data.
Given this epistemic deficit, the inclusion of underrepresented groups in algorithmic
processes can result in harm. Yet delaying the deployment of algorithmic systems
until more equitable results can be achieved would avoidably and foreseeably lead to
a significant number of unnecessary deaths in well-represented populations. Faced
with this dilemma between equity and utility, we draw on two case studies involving
breast cancer and melanoma to argue for the selective deployment of diagnostic and
prognostic tools for some well-represented groups, even if this results in the
temporary exclusion of underrepresented patients from algorithmic approaches. We
argue that this approach is justifiable when the inclusion of underrepresented patients
would cause them to be harmed. While the context of historic injustice poses a
considerable challenge for the ethical acceptability of selective algorithmic
deployment strategies, we argue that, at least for the case studies addressed in this
article, the issue of historic injustice is better addressed through nonalgorithmic
measures, including being transparent with patients about the nature of the current
epistemic deficits, providing additional services to algorithmically excluded
populations, and through urgent commitments to gather additional algorithmic training
data from excluded populations, paving the way for universal algorithmic deployment
that is accurate for all patient groups. These commitments should be supported by
regulation and, where necessary, government funding to ensure that any delays for
excluded groups are kept to the minimum. We offer an ethical algorithm for algorithms
—showing when to ethically delay, expedite, or selectively deploy algorithmic systems
in healthcare settings.”
Submitted by Robert Vandersluis, DPhil Candidate in Population Health at the
University of Oxford. Robert is a US Citizen.
This document is approved for public dissemination. The document contains no
business-proprietary or confidential information. Document contents may be reused


by the government in developing the AI Action Plan and associated documents
without attribution.


