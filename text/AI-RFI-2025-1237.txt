PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 13, 2025
Status: 
Tracking No. m 87-vzfl-59uo
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1237
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Blackford 
Middleton  
General Comment
See attached file(s)
Attachments
Middleton.Fed AI Action Plan


 
Middleton Public Comment on U.S. Federal AI Action Plan  1      
Expert Review of Public Comment on Federal AI Action Plan for Healthcare  
Executive Summary:  
This letter  provides an expert -level public comment submitted in response to the Request for 
Information (RFI) for the development of a Federal Artificial Intelligence (AI) Action Plan.  
The comment advocates for a multi -level AI governance framework, robust post -market 
surveillance mechanisms for AI, particularly in healthcare, the indispensable role of human 
oversight, the necessity of explainable AI recommendations, and the strategic in tegration of 
curated knowledge sources to optimize AI performance for licensed clinicians. The analysis 
presented makes recommendations that are strongly supported by current research and are 
critical for the safe, effective, and responsible integration of  AI, especially within the healthcare 
domain.  
Prioritizing these aspects in the Federal AI Action Plan will be essential for sustaining America's 
AI leadership while ensuring responsible innovation. Key recommendations include establishing 
a clear multi -level governance structure, mandating comprehens ive post -market surveillance, 
emphasizing human oversight in AI applications, promoting the development and deployment of 
explainable AI, strategically integrating curated knowledge sources, and ensuring regulatory 
alignment across federal agencies.  
Introduction:  
The development of a Federal AI Action Plan is a significant national initiative aimed at fostering 
America’s leadership in artificial intelligence while prioritizing responsible innovation. Public 
input, solicited through Requests for Information published in the Federal Register, plays a 
crucial rol e in shaping the strategic direction of this plan. This letter undertakes an expert review 
to make a public comment submitted in response to the RFI, focusing on its arguments 
concerning AI governance, post -market surveillance, human oversight, explainable AI, and the 
integration of curated knowledge, particularly within the healthcare sector. The purpose of this 
analysis is to provide a comprehensive evaluation of these critical considerations, drawing upon 
relevant research to inform policymakers involved in the formulation and implementation of the 
Federal AI Action Plan. By examining the evidence supporting the claims made in the public 
comment, this report seeks to contribute to the development of a robust a nd effective national 
strategy for AI in healthcare.  
The Foundational Imperative for Multi -Level AI Governance:  
This comment emphasizes the critical need for a well -defined and adaptable AI governance 
framework that operates cohesively across local, regional, and federal levels, especially within 
the diverse landscape of healthcare. While federal leadership is undou btedly essential for 
setting overarching policies, ethical guidelines, and interoperability standards, the inherently 
varied contexts in which AI is deployed across different sectors, including healthcare, 
necessitate that governance also be deeply embedde d at the local and regional levels. This 
multi -tiered approach ensures that the development and deployment of AI are not only guided 
by consistent overarching principles but are also responsive to the specific needs, values, and 
regulatory landscapes of di fferent communities, healthcare systems, and research institutions. 
For instance, the application of AI in a rural healthcare setting may present different challenges 
and require different considerations compared to its use in a large urban academic medica l 


 
Middleton Public Comment on U.S. Federal AI Action Plan  2      
center. Governance mechanisms at the local level can be tailored to address these unique 
nuances more effectively than a purely centralized federal approach. Furthermore, the 
establishment of interoperability standards at the federal level is paramount. Th is would ensure 
that diverse AI systems utilized within different healthcare organizations can communicate and 
exchange data securely and efficiently, which is crucial for seamless patient care and effective 
health information management. Imagine a patient  transitioning their care between healthcare 
providers in different states; their AI -driven health records should be readily accessible and 
understandable by the new providers, a scenario that necessitates common data standards and 
protocols established at  the federal level.  
Several sources corroborate the public comment's assertion regarding the current challenges in 
the AI landscape, including the absence of clear regulatory frameworks, the immaturity of 
existing governance structures, and inconsistencies in their applicatio n. These challenges 
underscore the urgency for the Federal AI Action Plan to provide much -needed clarity and 
structure to the currently fragmented AI governance environment. The lack of well -defined rules 
can create uncertainty for innovators and developer s, potentially stifling progress, while 
inconsistencies in application can lead to uneven levels of safety and ethical considerations 
across different healthcare settings. A multi -level governance approach, as proposed here, is 
supported by research that s uggests the necessity of developing a framework that aligns with 
ethics and fundamental human values, involving governments, corporations, and citizens as 
interdependent stakeholders. Examining the relationships between these groups through 
dimensions of t rust, such as competence, integrity, and benevolence, provides practical insights 
for enhancing user experiences and informing public policy related to AI. This perspective adds 
the crucial dimension of trust between various stakeholders as a fundamental e lement for 
effective multi -level AI governance. If healthcare providers, patients, or the broader public lack 
trust in the AI governance mechanisms, they will be less inclined to adopt or rely on AI 
technologies, hindering their potential benefits.  
AI governance, as defined by some research, encompasses a multi -layered approach that 
spans from organizational structure to regulatory alignment, emphasizing the establishment of 
standardization and regulatory frameworks to guide AI development and deploy ment. This 
reinforces the idea that multi -level governance needs to incorporate both top -down regulatory 
frameworks set by governmental bodies and bottom -up organizational practices implemented by 
individual healthcare providers and institutions. Federal r egulations can establish the broad 
boundaries and requirements for AI use, but individual healthcare organizations need to develop 
their own specific policies and procedures to ensure compliance and foster responsible AI 
adoption within their unique operat ional contexts. An effective AI governance model can be 
further conceptualized through a three -level approach: operational implementation within 
business units, ethical decision -making and escalation through an ethics committee, and 
executive oversight at the senior management level. This provides a concrete structural model 
for how multi -level governance can function in practice within a healthcare organization. 
Operational teams directly using AI in their daily workflows can handle initial governance at t heir 
level, while more complex ethical concerns can be escalated to a dedicated committee for 
thorough evaluation, and ultimately, the executive board provides overall strategic direction and 
accountability for AI governance across the organization. While the primary focus of the Federal 
AI Action Plan is domestic, it is important to acknowledge that AI governance has international 
dimensions and requires cooperation across different sectors. These sources emphasize the 
need for multi -stakeholder and multi -level collaboration in managing the global impacts of AI, 
proposing a framework that involves governments, corporations, and citizens. Therefore, the US 
AI Action Plan should consider international standards and foster collaboration with other 
nations on A I governance to ensure a cohesive global approach to this transformative 


 
Middleton Public Comment on U.S. Federal AI Action Plan  3      
technology.  
To effectively address the challenges posed by the evolving AI landscape, the AI Action Plan 
should prioritize a clear delineation of responsibilities and jurisdictional authority across federal 
agencies, state and local governments, and individual organiz ations involved in AI development 
and deployment. This includes explicitly defining the roles of regulatory bodies such as the FDA 
in the context of healthcare AI [1, 6 -7], as well as the responsibilities of healthcare providers and 
institutions in ensurin g the safe and ethical usage of AI. Clearly defining the FDA's role is 
particularly critical given the increasing proliferation of AI -enabled medical devices and the need 
for robust regulatory oversight to ensure their safety and effectiveness. Ambiguity r egarding 
which agency is responsible for overseeing specific aspects of AI in healthcare can lead to 
regulatory gaps, delays in approvals, and potential risks to patient safety. The evolving AI 
landscape presents several inherent challenges, including algo rithmic bias, the often -opaque 
nature of AI decision -making (the "black box"), and the risks associated with uncontrolled or 
poorly governed AI systems, often termed "shadow AI". These challenges underscore the 
necessity for clearly defined responsibilitie s for monitoring, auditing, and mitigating these risks 
at all levels of the governance framework. Without a designated entity or individual accountable 
for checking for and addressing bias in AI algorithms, for example, these biases can easily go 
undetecte d and potentially lead to discriminatory outcomes or harm to patients.  
Furthermore, the development and implementation of AI governance face global challenges 
such as fragmented disciplinary collaboration, ineffective multilateral coordination, and 
disconnects between policy design and grassroots implementation. The US Federal AI Action 
Plan needs to proactively address these potential pitfalls to ensure its effectiveness in the US 
context. Policies developed in isolation, without meaningful input from experts across various 
disciplines or without careful consideration o f the practicalities of implementation at the local 
level, may ultimately fail to achieve their intended goals. The need for AI governance to address 
critical aspects such as compliance with regulations, ethical considerations, and fostering public 
trust is also  paramount. Principles and frameworks developed by organizations like NIST, 
OECD, and the European Union provide valuable guidance in this regard, and the Action Plan 
should aim to align with these established standards to promote consistency and avoid 
redundant efforts. In the specific context of US healthcare, several AI governance frameworks 
and guidelines have been proposed or implemented, highlighting the need for adaptive 
strategies, robust oversight around potential biases, and strong engagement from  both 
healthcare leadership and regulatory bodies. These healthcare -specific initiatives offer concrete 
examples and principles that can inform the structuring of AI governance within the broader 
federal plan, recognizing the unique risks and ethical consi derations inherent in the healthcare 
domain.  
Recognizing the dynamic nature of AI technology, policymaking and governance structures 
must incorporate mechanisms for continuous evaluation, iterative review, and timely revision. 
Rigid, pre -defined controls may quickly become outdated or ill -suited to a ddress new 
capabilities and potential risks. The regulatory framework should therefore embed feedback 
loops that capture the real -world consequences of AI deployment, allowing for adaptive 
adjustments to policies and guidelines. This necessitates the devel opment of novel evaluation 
methodologies that can keep pace with the rapid evolution of AI while maintaining rigorous 
standards for safety, efficacy, and fairness. Expert consensus, as demonstrated in the 
development of digital health competency frameworks  and AI guideline recommendations, 
provides a valuable model for establishing such adaptable frameworks [1, 13 -14]. The inherently 
dynamic nature of AI technology necessitates that its governance framework be a "living" 
document, capable of evolving and ad apting in response to new technological advancements, 


 
Middleton Public Comment on U.S. Federal AI Action Plan  4      
emerging risks, and real -world experiences. Unlike traditional regulations designed for more 
static technologies that are designed for more static technologies, AI governance requires built -in 
mechanisms for regular updates and revisions to remain relevant and effective. The inclusion of 
continuous monitoring mechanisms and feedback loops is crucial for refining gove rnance structures 
over time.  Regular audits and assessments are essential to ensure the ongoing effectiveness and 
relevance of AI governance pr actices, allowing for adjustments based on the actual impact and 
performance of AI systems in healthcare settings. Implementing proactive AI governance measures 
early on can also provide a significant competitive advantage for organizations and ensure thei r 
long-term sustainability [2]. By establishing clear guidelines and responsibilities from the outset, 
healthcare organizations can mitigate potential risks, enhance public trust, improve efficiency, and 
foster a culture of responsible innovation. Waiting for regulations to become fully established and 
potentially rigid may make it more challenging for organizations to adapt their practices later.  
Establishing Robust Strategies for Post -Market Surveillance of AI and Agents in Healthcare:  
Given the capacity of AI systems, particularly those powered by Large Language Models (LLMs), to 
learn, adapt, and potentially evolve their behavior after deployment, a regulatory approach solely 
focused on pre -market evaluation is insufficient to ensure ongoing safety and effectiveness. Drawing 
parallels with the well -established post -market surveillance practices for pharmaceuticals and 
traditional medical  devices, the AI Action Plan must prioritize the development and rigorous 
implementation of comprehensive post -market surveillance mechanisms for AI and AI agents in all 
sectors, especially healthcare . This analogy with the pharmaceutical and medical devic e industries is 
critical for understanding the necessity of ongoing monitoring of AI in healthcare. Just as the long -
term effects and safety of a new drug are carefully tracked after it is released to the market, the 
performance, safety, and potential for evolving behavior of AI systems in healthcare must also be 
continuously monitored in real -world use. Established post -market surveillance (PMS) practices in 
these domains, overseen by regulatory bodies like the FDA, involve systematic data collection, 
analysis, and reporting to detect adverse events and ensure the continued safety and effectiveness 
of products . These established practices provide a wealth of knowledge and experience that can 
inform the development of similar mechanisms tailored for AI in h ealthcare. For medical devices 
specifically, regulations like 21 CFR Part 822 outline the requirements for PMS, emphasizing the 
importance of real -world data, user feedback, and manufacturer responsibility for ongoing 
surveillance [23 -24]. The principles o f risk -based surveillance, where higher -risk devices undergo 
more stringent monitoring, and the active collection of data from various sources, including users 
and healthcare professionals, are useful for establishing PMS for AI -enabled medical devices [25 -
28]. 
Key strategies for effective post -market surveillance should include:  
●Standardization of Governance and Adverse Event Reporting : Establishing
standardized protocols for defining, identifying, collecting, and systematically monitoring
AI-related safety events and potential harms, in close collaboration with patient safety
organizations, healthcare providers, and regulatory agencies, is crucial. This will enable
the systematic tracking of both the intended benefits and any unintended negative
consequences of AI deployment in real -world settings. The development of a common
reporting framework for AI incidents, as suggested by the OECD,  provides a valuable
starting point. Standardization is paramount for enabling effective aggregation and
analysis of data related to AI performance and safety across diverse healthcare
environments. Without common definitions for AI -related adverse events and
standardized reporting formats, it will be exceedingly difficult to identify overarching
trends and patterns that could indicate systemic issues or emerging risks associated


 
Middleton Public Comment on U.S. Federal AI Action Plan  5      
with AI deployment. The EU AI Act also mandates post -market monitoring for high -risk 
AI systems, requiring providers to actively collect and analyze data on their performance 
throughout their lifecycle. This international regulatory trend further underscor es the 
importance of establishing robust PMS mechanisms for AI in the US.  
●Continuous Performance Monitoring and Evaluation:  Implementing robust mechanisms
for the ongoing monitoring and evaluation of AI system performance after deployment is
essential. This includes tracking key performance indicators (KPIs), identifying potential
biases that may emerge or become amplified ove r time ("bias in, bias out"), and continuously
assessing the clinical utility, safety, and effectiveness of the AI in diverse patient populations
and real -world clinical workflows. Continuous monitoring is vital because the performance of
AI systems can fl uctuate over time due to various factors, such as shifts in the underlying
data (data drift) or updates to the AI model itself. A pre -market assessment of an AI system's
performance provides only a snapshot in time and may not accurately reflect its long -term
behavior or effectiveness in the complex and ever -changing real -world healthcare
environment. Research argues strongly for more robust post -market surveillance of AI in
healthcare, noting the limitations of current FDA frameworks that primarily focus o n
premarket evaluation [31]. The FDA's current approach may not adequately address the
practical challenges of continuously monitoring AI performance across diverse patient
populations and clinical settings.
●Mandatory AI Use Reporting and Comprehensive Documentation:  Establishing clear
standards for AI use reporting and comprehensive documentation, including detailed
metadata on the underlying algorithms, training data provenance, model architecture,
intended use cases, and performance metrics, is vital for ensuring tr ansparency,
accountability, and the ability to trace the AI's behavior. This documentation should
ideally break down impacts by specific model use phases and clearly defined use cases.
Comprehensive documentation serves as a foundational element for transp arency and
accountability in the use of AI in healthcare. Detailed records of an AI system's design,
training data, performance metrics, and intended applications are essential for
understanding how the system functions and for investigating any potential issues or
adverse events that may arise. This information is also crucial for regulatory oversight
and for facilitating independent audits of AI systems. While AI itself can be leveraged to
aid in post -market surveillance, including automating the generati on of regulatory
documents and analyzing real -world data, the establishment of clear and standardized
reporting requirements remains paramount. AI tools can help manage and analyze the
vast amounts of data generated through PMS, but well -defined guidelines  are necessary
to ensure that the right types of data are collected and reported in a consistent manner.
●Effective Incident Reporting and Remediation Systems:  Establishing clear and
accessible pathways for clinicians, patients, and other stakeholders to report incidents,
adverse events, or near misses associated with AI use is paramount. Learning from
these reported incidents will be crucial for iterative improv ements to AI systems, the
development of effective risk mitigation strategies, and the implementation of necessary
corrective actions. Easy and reliable mechanisms for reporting AI -related incidents are
essential for capturing a complete understanding of t he technology's impact in real -world
clinical practice. If the reporting process is cumbersome, unclear, or if there are
concerns about potential repercussions for reporting, many incidents, particularly near
misses or subtle issues, may go unreported. Est ablishing a culture of open reporting,
where healthcare professionals and patients feel comfortable raising concerns without
fear of penalty, is crucial for effective post -market surveillance. The information gleaned
from these reports can then be used to drive iterative improvements to AI systems,
develop more effective strategies for mitigating identified risks, and implement necessary
corrective actions to prevent future occurrences.


 
Middleton Public Comment on U.S. Federal AI Action Plan  6      
●Periodic Independent Auditing and Validation:  Implementing a system for periodic
auditing and independent validation of deployed AI systems, potentially conducted by
qualified third -party experts, can provide an objective assessment of their ongoing safety,
effectiveness, fairness, and adherence to e volving regulatory standards. Independent audits
offer an unbiased perspective on the performance and safety of AI systems, potentially
identifying issues or areas of concern that internal teams might overlook due to familiarity or
inherent biases. Engagin g qualified third -party experts to conduct these audits can further
enhance their objectivity and credibility. These periodic assessments can evaluate not only
the technical performance of the AI system but also its adherence to evolving regulatory
require ments, ethical guidelines, and standards for fairness and equity. This added layer of
scrutiny can provide greater assurance to patients, healthcare professionals, and regulators
regarding the trustworthiness and responsible use of AI in healthcare.
●Active Solicitation and Integration of User Feedback:  Actively soliciting and thoughtfully
incorporating feedback from clinicians, other healthcare professionals, and patients on their
experiences with AI tools is essential for identifying areas for improvement, uncovering
potential risks or usability issues , and ensuring that AI systems effectively meet the needs of
end-users in diverse clinical contexts. Feedback from the individuals who directly interact
with AI systems in their daily clinical practice or as patients receiving care provides
invaluable insi ghts into the real -world usability, effectiveness, and potential challenges
associated with these tools. Actively seeking out and carefully considering this feedback is
crucial for identifying areas where AI systems can be improved, uncovering previously
unforeseen risks or usability issues, and ultimately ensuring that these technologies are
effectively meeting the needs of end -users across diverse clinical settings and patient
populations. This user -centered approach is essential for the successful and re sponsible
integration of AI into healthcare workflows.
The Essential Roles of Human Oversight in AI -Driven Healthcare:  
This comment highlights the critical importance of human oversight in the development and 
implementation of AI in the healthcare sector. Research strongly supports the benefits of 
incorporating human intelligence and judgment into AI systems, often referred to as Human -in-the-
Loop (HITL) approaches . HITL AI is characterized by continuous human involvement throughout the 
AI lifecycle, including data  annotation, model training, validation, and real -time operation. This 
ongoing interaction allows for iterative learning, where the AI system evolves by incorporating 
feedback from human experts, refining its algorithms and enhancing its ability to handle complex or 
ambiguous situations. Furthermore, human oversight is crucial for ensuring that AI decisions adhere 
to ethical standards and societal norms, mitigating the risk of bias and unintended consequences 
that may arise from fully autonomous systems . T he integration of human expertise with the speed 
and precision of machine learning creates a collaborative synergy that aims to produce more 
accurate, adaptable, and ethical AI solutions. In the context of healthcare, skilled healthcare 
professionals actin g as the "human in the loop" are indispensable for guiding AI systems effectively 
and ethically . While AI can analyze vast amounts of data and identify patterns, it often lacks the 
clinical intuition, empathy, and nuanced understanding of individual patie nt circumstances that only a 
human can provide. This collaboration between human expertise and AI capabilities leads to better 
and more precise outcomes, ensuring that AI enhances rather than replaces the critical human 
element in healthcare.  
The benefits of human oversight in AI extend to several key areas. It ensures ethical decision -
making, where humans define ethical guidelines and review AI outputs for biases and discrimination . 
Human oversight also fosters accountability, ensuring transparency in AI systems and providing a 
mechanism for addressing errors [36]. Moreover, humans provide adaptability and contextual 
understanding, complementing AI's analytical power with the ability  to navigate dynamic situations 
and consider diverse perspect ives [36]. This continuous feedback loop, where humans intervene to 


 
Middleton Public Comment on U.S. Federal AI Action Plan  7      
correct errors and refine outputs, enhances AI learning and improves the accuracy and reliability of 
algorithms over time [38]. In healthcare specifically, HITL AI can aid in medical diagnostics and 
treatment planning, with human doctors validating and ref ining AI -generated results to ensure 
accuracy and safety.  This human validation is critical in a field where mistakes can have severe 
consequences. The complexities of human involvement in AI systems require careful consideration, 
including differentiating  between having a human directly "in the loop" versus "near the loop," and 
the importance of involving patients in the governance of AI systems that affect their care [39]. While 
persistent human involvement in every AI decision may not be scalable, ensuri ng human oversight 
at critical junctures and incorporating patient perspectives are essential for responsible AI 
implementation. Research shows that human oversight in AI medical diagnosis and treatment is 
crucial for ethical application, clinical intuitio n, unique perspectives, skill refinement, responsibility, 
control, and reducing patient harm.  
Conversely, there are significant risks associated with over -reliance on fully autonomous AI in 
healthcare without adequate human oversight.  These risks include the potential for errors in 
diagnosis or treatment recommendations, breaches of patient privacy due to compromised AI 
systems, the perpetuation or amplification of biases present in the training data leading to unequal 
care, a lack of the essential personal touch and empathetic understanding that human practitioners 
offer, and the danger of diagnost ic over reliance  where clinicians may become overly dependent on 
AI and overlook critical aspects of a patient's condition. Furthermore, errors made by AI systems can 
propagate if the AI continues to learn from incorrect data, reinforcing these mistakes. Unequal 
access to  sophisticated AI technology could also widen existing health disparities. The ethical 
considerations surrounding the use of fully autonomous AI in life -and-death decisions and the 
complexities of assigning accountability in case of AI -driven errors are also significant concerns [42 -
45]. Therefore, it is crucial to maintain human clinical judgment as central to patient care [8]. AI 
should serve as a tool to support and augment the expertise of healthcare professionals, not as a 
replacement f or their critical thinking, nuanced understanding, and ethical considerations [46]. The 
ultimate responsibility for patient well -being must remain with human clinicians, who can interpret AI -
generated information within the broader context of a patient's i ndividual needs and circumstances.  
The Necessity for Explainable AI Recommendations in Clinical Practice:  
This comment emphasizes the necessity for AI recommendations in clinical practice to be 
explainable. Explainable AI (XAI) is a field dedicated to making AI models more interpretable and 
transparent, ensuring that their decision -making processes can be understoo d and trusted by 
clinicians and other stakeholders . This is particularly crucial in healthcare, where the rationale 
behind a diagnosis or treatment recommendation can have profound implications for patient 
outcomes [48 -50]. XAI aims to overcome the " black box" problem associated with many advanced AI 
models, such as deep learning networks, whose intricate workings are often opaque even to their 
developers. By providing insights into how an AI system arrives at a particular conclusion, XAI 
fosters trus t among clinicians, who are more likely to adopt and rely on AI tools if they can 
understand the reasoning behind their recommendations [51]. Furthermore, explainability enhances 
transparency in healthcare processes, allowing for greater scrutiny and valid ation of AI -driven 
insights [52 -55]. 
The implementation of XAI in healthcare presents both challenges and significant benefits. 
Challenges include the need for extensive and high -quality datasets to train AI models effectively, 
the substantial computational resources required for many XAI tec hniques, and the inherent 
difficulties in deploying XAI solutions in real -world clinical settings due to data quality and availability 
issues [51]. Additionally, there is often a trade -off between the accuracy of an AI model and its 
interpretability; highl y accurate complex models may be less explainable, while more interpretable 
models might sacrifice some predictive performance [56 -58]. Ensuring legal and regulatory 
compliance, particularly with data privacy regulations, also poses a challenge for XAI imp lementation 


 
Middleton Public Comment on U.S. Federal AI Action Plan  8      
[59-61]. Despite these hurdles, the benefits of XAI in healthcare are substantial [62]. XAI can 
improve diagnostic accuracy by allowing clinicians to understand the factors that contributed to an 
AI's diagnosis, potentially revealing previously unrecognize d relationships between symptoms and 
diseases [63 -65]. It also plays a crucial role in advancing personalized treatment plans by providing 
interpretable insights into individualized recommendations, clarifying the criteria behind suggested 
therapies or med ications based on a patient's unique genetic, environmental, and lifestyle factors 
[66-68]. By making AI decision -making processes transparent, XAI enhances accountability, allowing 
clinicians to identify potential errors or biases in AI outputs and ensuri ng that AI systems 
complement rather than replace human judgment [49]. The necessity for explainable AI in clinical 
practice stems from the fundamental need for clinicians to understand and trust the tools they use to 
make critical decisions about patient care.  
The Strategic Importance of Integrating Curated Knowledge Sources to Optimize AI 
Performance for Licensed Clinicians:  
This comment also highlights the strategic importance of integrating curated knowledge sources to 
optimize the performance of AI systems used by licensed clinicians. Research indicates that AI 
benefits significantly from access to high -quality, verified information, leading  to improved accuracy 
and a reduction in the generation of incorrect or nonsensical outputs, often referred to as 
hallucinations [69 -72]. Curated knowledge bases, which are carefully selected and organized 
collections of authoritative inf ormation, can provide AI systems with a reliable and up -to-date source 
of medical knowledge, thereby enhancing the trustworthiness and utility of their recommendations 
for healthcare professionals [73 -77]. The integration of such knowledge sources can lead  to more 
accurate diagnoses, more effective treatment planning, and better overall patient outcomes.  
The benefits of using curated knowledge sources in AI for healthcare extend beyond just improving 
accuracy [78 -80]. These sources can also facilitate automated updates to AI systems with the latest 
medical findings, improve the efficiency of knowledge retr ieval and analysis, and enhance the 
integration of AI with existing healthcare support systems [81 -84]. By providing AI with access to a 
centralized and validated repository of medical information, healthcare organizations can ensure that 
clinicians are re ceiving recommendations based on the most current evidence -based practices [85 -
87]. Techniques like Retrieval -Augmented Generation (RAG) play a crucial role in leveraging curated 
knowledge [78]. RAG is a method that enhances the capabilities of Large Langu age Models by 
allowing them to access and incorporate information from external, curated data sources in real -time 
[79]. In healthcare, RAG can enable clinicians to ask complex medical questions and receive 
accurate, contextually relevant answers that are grounded in the latest research, clinical guidelines, 
and patient data [80]. This approach can significantly improve clinical decision support, accelerate 
medical research, enhance patient engagement through better communication, and streamline 
administrat ive tasks within healthcare organizations [88 -93]. 
Furthermore, the integration of curated knowledge sources, such as knowledge graphs and verified 
databases, is strategically important for mitigating the risks of data poisoning, where malicious actors 
introduce false information into AI training data [71] . By grounding AI outputs in trusted and curated 
knowledge, healthcare organizations can increase the reliability and trustworthiness of AI 
recommendations, safeguarding against the propagation of misinformation that could potentially 
harm patients. Knowle dge graph -based agents, for example, can integrate non -codified knowledge 
from LLMs with structured knowledge from medical concept graphs to improve the accuracy and 
specificity of medical reasoning and question answering. This approach acts as a "truth fi lter," 
helping to identify and prevent the spread of inaccurate or harmful information, thereby increasing 
confidence in the use of AI in mission -critical healthcare settings.  
Navigating the Regulatory Landscape for AI in US Healthcare:  


 
 
 
Middleton Public Comment on U.S. Federal AI Action Plan   
9       
The FDA's recent efforts, including the release of draft guidance documents and action plans, 
indicate a proactive approach to addressing the complexities of AI in healthcare [94 -112]. These 
initiatives highlight the agency's recognition of the need for a flexible and adaptive regulatory 
framework that can keep pace with the rapid adv ancements in AI technology. The FDA's focus on 
the Total Product Lifecycle (TPLC) approach is particularly relevant for AI, as it emphasizes the 
importance of ongoing monitoring and evaluation of AI systems after they are deployed. This aligns 
with the ear lier discussion on the necessity of robust post -market surveillance mechanisms.  
 
Furthermore, the regulatory landscape for AI in healthcare extends beyond the FDA. Other 
agencies, such as the Office of the National Coordinator for Health Information Technology (ONC), 
also play a crucial role in shaping the regulatory environment. The O NC's Health Data, Technology, 
and Interoperability (HTI -1) Final Rule, for example, includes provisions related to the transparency 
of AI-powered decision support interventions in Electronic Health Records (EHRs) [11]. These 
regulations underscore the need  for coordination and alignment across different agencies to ensure 
a cohesive and effective approach to AI governance in healthcare.  
 
The emergence of Large Language Models (LLMs) and other forms of generative AI has added 
another layer of complexity to the regulatory landscape [113 -116]. These technologies possess 
unique capabilities and potential risks that may require different regula tory strategies compared to 
traditional AI -based medical technologies. The potential for LLMs to generate misinformation or 
biased outputs, for instance, necessitates careful consideration of how these systems are validated 
and monitored. The imperative fo r regulatory oversight is particularly pronounced for LLMs in 
healthcare, given their potential to impact clinical decision -making and patient safety.  
 
Conclusion and Recommendations: Prioritized Action Items:  
This analysis of the relevant research and related policies reveals a strong consensus on the critical 
importance of the issues raised. The need for multi -level AI governance, robust post -market 
surveillance, essential human oversight, explainable AI recommendations, and the strategic 
integration of curated knowled ge sources are all vital for ensuring the safe, effective, and 
responsible adoption of AI in healthcare. These issues are interconnected, but some require more 
immediate attention and foundational work to enable others.  
To effectively address these imperatives and to guide the development of the Federal AI Action 
Plan, the following recommendations are proposed, presented in order of priority, with designated 
responsible entities : 
I. Foundational Pillars (Highest Priority):  
1. Establish a Clear Federal AI Governance Framework for Healthcare (Priority 1):  
 
○ Action:  Define the roles, responsibilities, and jurisdictional authority of federal 
agencies (specifically including the FDA, HHS, ONC, NIST, and potentially a new 
dedicated AI oversight body) in regulating AI in healthcare. This framework must 
address pre -market  evaluation, post -market surveillance, data privacy, algorithmic 
bias, and liability. It should explicitly address the unique challenges of Large 
Language Models (LLMs) and other generative AI technologies in healthcare.  
○ Target Entity:  Congress (to enact legislation), HHS (to lead interagency 
coordination), FDA (to develop specific guidance for AI/ML as a medical device), 
ONC (to address AI in health IT and interoperability), NIST (to develop standards and 
best practices for AI safety a nd trustworthiness).  
○ Rationale:  This is the highest priority because a clear, comprehensive federal 
framework is essential for all other actions. Without it, there's a risk of regulatory 


 
Middleton Public Comment on U.S. Federal AI Action Plan  10      
gaps, inconsistencies, and stifled innovation. This framework must be established 
before  widespread deployment of AI in high -stakes healthcare applications.  
2.Develop and Mandate Standards for Post -Market Surveillance of Healthcare AI
(Priority 2):
○Action:  Create mandatory reporting requirements for AI -related adverse events in
healthcare, mirroring existing systems for pharmaceuticals and medical devices. This
includes standardized definitions of "adverse event" and "near miss" specific to AI,
along with c lear reporting pathways for clinicians, patients, and healthcare
organizations. Develop protocols for continuous performance monitoring, including
metrics for accuracy, bias, and clinical utility.
○Target Entity:  FDA (primary responsibility for medical device and pharmaceutical
surveillance), HHS (to coordinate with patient safety organizations), and a potential
public -private collaborative (including healthcare providers, AI developers, and
patient advocacy group s) to develop reporting standards.
○Rationale:  Post-market surveillance is crucial for identifying and mitigating risks that
may only emerge after deployment. This needs to be established early to capture
data on the real -world performance and safety of AI systems.
3.Promote and Incentivize the Development and Adoption of Explainable AI (XAI) in
Healthcare (Priority 3):
○Action:  Fund research into XAI techniques specifically tailored for healthcare
applications. Develop guidelines and best practices for implementing XAI in clinical
settings. Consider incorporating XAI requirements into regulatory approval processes
for high -risk AI systems. Create educational resources for clinicians on interpreting
and using XAI outputs.
○Target Entity:  NIH (to fund research), NIST (to develop standards and guidelines),
FDA (to consider XAI in regulatory approvals), professional medical organizations (to
develop educational resources), and academic institutions.
○Rationale:  Explainability is essential for building trust and ensuring that clinicians
can understand and validate AI recommendations. This will facilitate adoption and
responsible use of AI in clinical practice.
II. Enabling Actions (Medium Priority):
4.Foster the Integration of Curated Knowledge Sources into Healthcare AI Systems
(Priority 4):
○Action:  Support the development and maintenance of high -quality, curated and
computable (interoperable) medical knowledge bases (e.g., knowledge graphs,
verified clinical guidelines). Incentivize AI developers to utilize these resources (e.g.,
through grants, partnerships, or regulatory requirements). Develop standards for
interoperability between AI systems  and curated knowledge sources. Promote and
provide training resources for Retrieval -Augmented Generation (RAG).
○Target Entity:  NIH (to fund research and development of knowledge bases), NIST
(to develop interoperability standards), professional medical organizations (to curate
and maintain knowledge resources), and private sector AI developers.


 
Middleton Public Comment on U.S. Federal AI Action Plan  11      
○Rationale:  Curated knowledge sources are essential for improving the accuracy,
reliability, and safety of AI systems, particularly in mitigating the risk of
"hallucinations" and data poisoning.
5.Establish Mechanisms for Meaningful Human Oversight of AI in Healthcare (Priority
5):
○Action:  Develop guidelines and best practices for implementing Human -in-the-Loop
(HITL) approaches in various healthcare settings. These guidelines should address
ethical considerations, workflow integration, and the allocation of responsibility
between humans an d AI. Provide training for healthcare professionals on how to
effectively interact with and oversee AI systems.
○Target Entity:  FDA (to incorporate HITL considerations into regulatory guidance),
professional medical organizations (to develop guidelines and training programs),
healthcare institutions (to implement HITL workflows), and AI developers (to design
systems that support h uman oversight).
○Rationale:  While human oversight is crucial, its implementation needs to be carefully
considered to avoid creating bottlenecks or undue burden on clinicians. Clear
guidelines and training are essential for effective and ethical integration of human
oversight.
III. Supporting and Sustaining Actions (Ongoing Priority
1.Data Governance and Quality Initiatives (Ongoing):
●Action:  Invest in initiatives to improve the quality, representativeness, and
accessibility of healthcare data used to train and validate AI systems. Establish
standards for data curation, labeling, and sharing. Promote the use of federated
learning and other pri vacy-preserving techniques to enable data sharing while
protecting patient confidentiality.
●Target Entity:  ONC (to develop data standards and promote interoperability), NIH
(to fund research on data quality and bias mitigation), healthcare organizations (to
implement data governance policies), and data science communities.
●Rationale:  High-quality data is essential for the development of reliable and
unbiased AI systems. Addressing data quality issues and promoting responsible data
sharing practices will be crucial for the long -term success of AI in healthcare.
2.Ethical Considerations and Bias Mitigation (Ongoing):
●Action:  Establish an ongoing advisory body or task force dedicated to addressing
ethical considerations related to AI in healthcare, including algorithmic bias, patient
privacy, and informed consent. Develop tools and methodologies for detecting and
mitigating bi as in AI algorithms. Promote research on the ethical implications of AI in
healthcare.
●Target Entity:  HHS (to establish the advisory body), NIH (to fund research), FDA (to
incorporate ethical considerations into regulatory guidance), and academic
institutions (to conduct ethical research and develop bias mitigation tools).
●Rationale:  Ethical considerations are paramount in healthcare AI. Ongoing attention
and expertise are needed to address emerging ethical challenges and ensure that AI
systems are used in a fair, equitable, and responsible manner.
3.Workforce Development and Training (Ongoing):
●Action:  Invest in training programs to equip healthcare professionals with the skills
and knowledge needed to effectively use and oversee AI systems. Develop curricula
for medical, nursing, and other healthcare education programs that address AI
literacy and comp etency. Support initiatives to train data scientists and AI developers
in healthcare -specific considerations and ethical principles.


 
Middleton Public Comment on U.S. Federal AI Action Plan  12      
●Target Entity:  HRSA (to fund training programs), professional medical organizations
(to develop curricula), academic institutions (to integrate AI into education), and AI
developer communities.
●Rationale:  The successful integration of AI into healthcare requires a workforce that
is comfortable and competent in using these technologies. Ongoing training and
education are essential to ensure that healthcare professionals can effectively
collaborate with AI s ystems and make informed decisions.
4.Patient Engagement and Empowerment (Ongoing):
●Action:  Develop resources and initiatives to educate patients about AI in healthcare
and empower them to participate in decisions about its use in their care. Promote
transparency and open communication about how AI is being used in clinical
settings. Support pat ient advocacy groups in representing the interests of patients in
AI governance discussions.
●Target Entity:  AHRQ (to develop patient education materials), patient advocacy
groups, healthcare organizations (to promote transparency), and community health
centers.
●Rationale:  Patients are key stakeholders in the use of AI in healthcare. Engaging
and empowering patients will build trust, ensure that their values are considered, and
promote the responsible use of AI.
By prioritizing and implementing these recommendations in a structured and ongoing manner, the 
Federal AI Action Plan can effectively navigate the complex landscape of AI in healthcare. This 
comprehensive approach will foster innovation, ensure patient saf ety, and uphold ethical principles, 
ultimately leading to better health outcomes for all Americans. The continued dedication to these 
actions and the collaborative efforts of all stakeholders will solidify the United States' leadership in 
the responsible d evelopment and deployment of AI in healthcare.  
Works cited  
1. (PDF) A multilevel framework for AI governance - ResearchGate, accessed March 13, 2025,
https://www.researchgate.net/publication/372234650_A_multilevel_framework_for_AI_governan
ce
2. What is AI Governance? - Holistic AI, accessed March 13, 2025,
https://www.holisticai.com/blog/ai -governance
3. Governance model for ethical AI - AI for Impact, accessed March 13, 2025,
https://aiforimpacttoolkit.gsma.com/responsible -ai/governance -model -for-ethical -ai
4. Conceptualizing Global Governance of AI, accessed March 13, 2025,
https://www.cigionline.org/publications/conceptualizing -global -governance -of-ai/
5. [PDF] A multilevel framework for AI governance - Semantic Scholar, accessed March 13,
2025, https://www.semanticscholar.org/paper/c212c67bd15d7887b451f4f058253bfa0668bb12
6. AI Governance | Sngular, accessed March 13, 2025, https://www.sngular.com/insights/356/ai -
governance -challenges -and-perspectives
7. The AI Governance Challenge: How to Foster Trust - Dataiku blog, accessed March 13,
2025, https://blog.dataiku.com/the -ai-governance -challenge
8. AI Governance: Essential Insights for Organisations: Part I – Understanding Meaning,
Challenges, Trends, and Best Practices in AI Governance, accessed March 13, 2025,
https://www.twobirds.com/en/insights/2025/ai -governance -essential -insights -for-organisations -
part-i--understanding -meaning -challenges -trends -a
9. Global AI Governance: Where the Challenge is the Solution - An Interdisciplinary, Multilateral,
and Vertically Coordinated Approach - arXiv, accessed March 13, 2025,
https://arxiv.org/html/2503.04766v1


 
 
 
Middleton Public Comment on U.S. Federal AI Action Plan   
13       
10. An Overview of AI Governance for 2025: Examples and Best Practices - Domo, accessed 
March 13, 2025, https://www.domo.com/glossary/ai -governance  
11. Advancing Healthcare AI Governance: A Comprehensive Maturity ..., accessed March 13, 
2025, https://www.medrxiv.org/content/10.1101/2024.12.30.24319785v1.full -text 
12. Artificial intelligence governance framework for healthcare - Masooma Hassan, Elizabeth M. 
Borycki, Andre W. Kushniruk, 2025 - Sage Journals, accessed March 13, 2025, 
https://journals.sagepub.com/doi/10.1177/08404704241291226?icid=int.sj -full-text.similar -
articles.1  
13. AI Governance in Health Systems, accessed March 13, 2025, 
https://healthpolicy.duke.edu/sites/default/files/2024 -
10/AI%20Governance%20in%20Health%20Systems.pdf  
14. Global Regulatory Frameworks for the Use of Artificial Intelligence (AI) in the Healthcare 
Services Sector - PMC, accessed March 13, 2025, 
https://pmc.ncbi.nlm.nih.gov/articles/PMC10930608/  
15. AI Governance - IQVIA, accessed March 13, 2025, 
https://www.iqvia.com/solutions/innovative -models/artificial -intelligence -and-machine -
learning/ai -governance  
16. What is AI Governance? Benefits, needs, regulations and tips on ..., accessed March 13, 
2025, https://www.woodwing.com/blog/what -is-ai-governance  
17. AI Governance: How to Mitigate Risks & Maximize Benefits - Atlan, accessed March 13, 
2025, https://atlan.com/know/ai -readiness/ai -governance/  
18. Secure Your Future: The Benefits of Ethical AI Governance - Lumen Blog, accessed March 
13, 2025, https://blog.lumen.com/secure -your-future -the-benefits -of-ethical -ai-governance/  
19. Artificial Intelligence Governance & Alignment with Enterprise Governance - Medium, 
accessed March 13, 2025, https://medium.com/@gopalakrishnabehara/published -in-a-z-
magazine -d5a39aeac069  
20. Chapter 8. Post -Marketing Surveillance | Pharmacoepidemiology : Principles and Practice, 
accessed March 13, 2025, 
https://accesspharmacy.mhmedical.com/content.aspx?sectionid=40428529&bookid=438  
21. Postmarketing surveillance - Wikipedia, accessed March 13, 2025, 
https://en.wikipedia.org/wiki/Postmarketing_surveillance  
22. Post Market Surveillance - ArborMetrix, accessed March 13, 2025, 
https://www.arbormetrix.com/post -market -surveillance/  
23. Understanding post -market surveillance for medical devices - Qualio, accessed March 13, 
2025, https://www.qualio.com/blog/post -market -surveillance  
24. 21 CFR Part 822 -- Postmarket Surveillance - eCFR, accessed March 13, 2025, 
https://www.ecfr.gov/current/title -21/chapter -I/subchapter -H/part -822 
25. www.nsf.org, accessed March 13, 2025, https://www.nsf.org/knowledge -library/post -market -
surveillance -what -you-need -to-know -to-ensure -patient -
safety#:~:text=Section%20522%20states%20post%2Dmarket,have%20serious%20adverse%2
0health%20consequences.  
26. Medical Devices: Postmarket Surveillance [4.0 RAC] - RAPS, accessed March 13, 2025, 
https://www.raps.org/products/medical -devices -postmarket -surveillance -40-rac 
27. Post Market Surveillance: What You Need to Know to Ensure Patient Safety - NSF, 
accessed March 13, 2025, https://www.nsf.org/knowledge -library/post -market -surveillance -
what -you-need -to-know -to-ensure -patient -safety  
28. Postmarket Surveillance - Definition & Requirements | Greenlight Guru, accessed March 13, 
2025, https://www.greenlight.guru/glossary/postmarket -surveillance  
29. Article 72: Post -Market Monitoring by Providers and Post -Market Monitoring Plan for High -
Risk AI Systems | EU Artificial Intelligence Act, accessed March 13, 2025, 
https://artificialintelligenceact.eu/article/72/  


 
Middleton Public Comment on U.S. Federal AI Action Plan  14      
30. Top 10 operational impacts of the EU AI Act  – Post-market ... - IAPP, accessed March 13,
2025, https://iapp.org/resources/article/top -impacts -eu-ai-act-post-market -monitoring -sharing -
enforcement/
31. We Need More Robust Post -Market Surveillance For Health Care AI, accessed March 13,
2025, https://www.healthaffairs.org/content/forefront/we -need -more -robust -post-market -
surveillance -health -care-ai
32. Generative AI in clinical operations: Transforming post -market surveillance - Cognizant,
accessed March 13, 2025, https://www.cognizant.com/nl/en/insights/blog/articles/generative -ai-
in-clinical -operations -transforming -post-market -surveillance
33. Human in the Loop AI: Keeping AI Aligned with Human Values, accessed March 13, 2025,
https://www.holisticai.com/blog/human -in-the-loop-ai
34. Understanding Human in the Loop: Where Humans Meet Machines - Light -it, accessed
March 13, 2025, https://lightit.io/blog/understanding -human -in-the-loop-where -humans -meet -
machines/
35. Be the Human in the Loop - AI Prompt Engineering in Health ..., accessed March 13, 2025,
https://utahtech.libguides.com/c.php?g=1414754&p=10541874
36. The crucial role of humans in AI oversight - Cornerstone OnDemand, accessed March 13,
2025, https://www.cornerstoneondemand.com/resources/article/the -crucial -role-of-humans -in-ai-
oversight/
37. AI and Human Oversight: A New Era in Reducing Medical Billing Errors, accessed March
13, 2025, https://medtechintelligence.com/feature_article/ai -and-human -oversight -a-new-era-in-
reducing -medical -billing -errors/
38. Underlying Gaps in the AI Healthcare Boom: Human Oversight is Key - IKS Health,
accessed March 13, 2025, https://ikshealth.com/insights/blogs/underlying -gaps -in-the-ai-
healthcare -boom -human -oversight -is-key/
39. Human Near the Loop: Implications for Artificial Intelligence in Healthcare - Sage Journals,
accessed March 13, 2025,
https://journals.sagepub.com/doi/10.1177/10547738241227699?icid=int.sj -full-text.citing -
articles.63
40. Full article: From “Human in the Loop” to a Participatory System of ..., accessed March 13,
2025, https://www.tandfonline.com/doi/full/10.1080/15265161.2024.2377114
41. 5 Major Disadvantages of AI in Healthcare - Keragon, accessed March 13, 2025,
https://www.keragon.com/blog/disadvantages -of-ai-in-healthcare
42. Trust and medical AI: the challenges we face and the expertise needed to overcome them,
accessed March 13, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC7973477/
43. Risks of Artificial Intelligence (AI) in Medicine, accessed March 13, 2025,
https://www.pneumon.org/Risks -of-Artificial -Intelligence -AI-in-Medicine,191736,0,2.html
44. Benefits and Risks of AI in Health Care: Narrative Review - PMC, accessed March 13, 2025,
https://pmc.ncbi.nlm.nih.gov/articles/PMC11612599/
45. Six Risks of AI in Healthcare: A Short Primer - Health IT Answers, accessed March 13,
2025, https://www.healthitanswers.net/six -risks-of-ai-in-healthcare -a-short -primer/
46. (PDF) Artificial Intelligence -Generated Content Needs a Human ..., accessed March 13,
2025, https://www.researchgate.net/publication/381931333_Artificial_Intelligence -
Generated_Content_Needs_a_Human_Oversight
47. Survey of Explainable AI Techniques in Healthcare - PMC, accessed March 13, 2025,
https://pmc.ncbi.nlm.nih.gov/articles/PMC9862413/
48. Explainable AI in Healthcare Imaging for Medical Diagnoses - 1st Edition | Elsevier Shop,
accessed March 13, 2025, https://shop.elsevier.com/books/explainable -ai-in-healthcare -
imaging -for-medical -diagnoses/saba/978 -0-443-23979 -3
49. The Promise of Explainable AI in Digital Health for Precision Medicine: A Systematic
Review, accessed March 13, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC10971237/


 
 
 
Middleton Public Comment on U.S. Federal AI Action Plan   
15       
50. As the rush toward AI in healthcare continues, explainability is crucial, accessed March 13, 
2025, https://www.healthcareitnews.com/news/rush -toward -ai-healthcare -continues -
explainability -crucial  
51. Addressing Challenges of Explainable AI in Healthcare - Sano Science, accessed March 13, 
2025, https://sano.science/addressing -challenges -of-explainable -ai-in-healthcare/  
52. Explainable AI (XAI) in healthcare: Enhancing trust and transparency in critical decision -
making - World Journal of Advanced Research and Reviews, accessed March 13, 2025, 
https://wjarr.com/sites/default/files/WJARR -2024 -2936.pdf  
53. Towards Transparent Healthcare: Advancing Local Explanation Methods in Explainable 
Artificial Intelligence - PMC - PubMed Central, accessed March 13, 2025, 
https://pmc.ncbi.nlm.nih.gov/articles/PMC11048122/  
54. A survey of explainable artificial intelligence in healthcare: Concepts, applications, and 
challenges - USIR, accessed March 13, 2025, https://salford -
repository.worktribe.com/output/3336234/a -survey -of-explainable -artificial -intelligence -in-
healthcare -concepts -applications -and-challenges  
55. Explainable Artificial Intelligence (XAI): Concepts and Challenges in Healthcare - MDPI, 
accessed March 13, 2025, https://www.mdpi.com/2673 -2688/4/3/34  
56. Four Principles of Explainable Artificial Intelligence - NIST Technical Series Publications, 
accessed March 13, 2025, https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8312.pdf  
57. (PDF) Explainable AI in Healthcare - ResearchGate, accessed March 13, 2025, 
https://www.researchgate.net/publication/342600571_Explainable_AI_in_Healthcare  
58. Explainable AI, but explainable to whom? - arXiv, accessed March 13, 2025, 
https://arxiv.org/pdf/2106.05568  
59. A Guide to Explainable AI Using Python, accessed March 13, 2025, 
https://thepythoncode.com/article/explainable -ai-model -python  
60. Explainable AI (XAI) in healthcare: Enhancing trust and transparency in critical decision -
making - ResearchGate, accessed March 13, 2025, 
https://www.researchgate.net/publication/384435119_Explainable_AI_XAI_in_healthcare_Enha
ncing_trust_and_transparency_in_critical_decision -making  
61. What is Explainable AI (XAI)? - IBM, accessed March 13, 2025, 
https://www.ibm.com/think/topics/explainable -ai 
62. Survey of Explainable AI Techniques in Healthcare - MDPI, accessed March 13, 2025, 
https://www.mdpi.com/1424 -8220/23/2/634  
63. Explainability for artificial intelligence in healthcare: a multidisciplinary perspective, accessed 
March 13, 2025, https://d -nb.info/1224744632/34  
64. Explainable AI in healthcare - Macquarie University, accessed March 13, 2025, 
https://www.mq.edu.au/research/research -centres -groups -and-facilities/healthy -
people/centres/australian -institute -of-health -innovation/our -projects/explainable -ai-in-healthcare  
65. Should AI models be explainable to clinicians? - PMC - PubMed Central, accessed March 
13, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11391805/  
66. The Importance of Explainable Artificial Intelligence Based Medical Diagnosis - IMR Press, 
accessed March 13, 2025, 
https://www.imrpress.com/journal/CEOG/51/12/10.31083/j.ceog5112268/htm  
67. The Importance of Explainable AI in Healthcare - Excellarate - Encora, accessed March 13, 
2025, https://insights.encora.com/insights/the -importance -of-explainable -ai-in-healthcare  
68. Explainable artificial intelligence in emergency medicine: an overview, accessed March 13, 
2025, https://www.ceemjournal.org/m/journal/view.php?number=509  
69. AI Databases - Artificial Intelligence in Medicine - LibGuides at PCOM Library, accessed 
March 13, 2025, https://libguides.pcom.edu/ai_medicine/databases  
70. Top 7 AI Knowledge Management Tools for 2025 - Knowmax, accessed March 13, 2025, 
https://knowmax.ai/blog/ai -knowledge -management -tools/  


 
Middleton Public Comment on U.S. Federal AI Action Plan  16      
71. KGARevion - An AI Agent for Knowledge -Intensive Biomedical QA ..., accessed March 13,
2025, https://zitniklab.hms.harvard.edu/projects/KGARevion/
72. FunctionalMind ™: Leveraging Medical Generative AI, Knowledge Bases, and Clinical
Agents to Help Clinicians Apply the Latest Evidence -Based Care, accessed March 13, 2025,
https://www.johnsnowlabs.com/functionalmind -leveraging -medical -generative -ai-knowledge -
bases -and-clinical -agents -to-help-clinicians -apply -the-latest -evidence -based -care/
73. AI in Knowledge Management: Benefits, Concerns and Future - Aisera, accessed March 13,
2025, https://aisera.com/blog/ai -knowledge -management/
74. The role of AI in content curation - AIContentfy, accessed March 13, 2025,
https://aicontentfy.com/en/blog/role -of-ai-in-content -curation
75. What is Content Curation? Why is it important to your enterprise? - Northern Light, accessed
March 13, 2025, https://northernlight.com/what -is-content -curation/
76. AI -Powered Content Curation: Success Stories in Knowledge Management - BKMI,
accessed March 13, 2025, https://bellykm.com/en/ai -powered -content -curation -success -stories -
in-knowledge -management/
77. 10 Benefits of an AI Knowledge Base and 8 Top Providers - Giva, accessed March 13,
2025, https://www.givainc.com/blog/ai -knowledge -base/
78. RAG - Reveal HealthTech, accessed March 13, 2025, https://revealhealthtech.com/rag/
79. [2502.04413] MedRAG: Enhancing Retrieval -augmented Generation with Knowledge
Graph -Elicited Reasoning for Healthcare Copilot - arXiv, accessed March 13, 2025,
https://arxiv.org/abs/2502.04413
80. Harnessing RAG in Healthcare: Use -Cases, Impact, & Solutions ..., accessed March 13,
2025, https://hatchworks.com/blog/gen -ai/rag -for-healthcare/
81. Integrating Retrieval -Augmented Generation with Large Language Models in Nephrology:
Advancing Practical Applications - PMC - PubMed Central, accessed March 13, 2025,
https://pmc.ncbi.nlm.nih.gov/articles/PMC10972059/
82. Improving large language model applications in biomedicine with ..., accessed March 13,
2025, https://academic.oup.com/jamia/advance -article/doi/10.1093/jamia/ocaf008/7954485
83. Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph -Augmented LLMs,
accessed March 13, 2025, https://arxiv.org/html/2501.14892v1
84. Integrating Generative Artificial Intelligence in ADRD: A Framework for Streamlining
Diagnosis and Care in Neurodegenerative Dis - arXiv, accessed March 13, 2025,
https://arxiv.org/pdf/2502.06842
85. Toward expert -level medical question answering with large language models, accessed
March 13, 2025, https://www.researchgate.net/publication/387826586_Toward_expert -
level_medical_question_answering_with_large_language_models
86. Human -AI collaboration in large language model -assisted brain MRI differential diagnosis: a
usability study - ResearchGate, accessed March 13, 2025,
https://www.researchgate.net/publication/389656973_Human -
AI_collaboration_in_large_language_model -
assisted_brain_MRI_differential_diagnosis_a_usability_study
87. The foundational capabilities of large language models in predicting postoperative risks
using clinical notes - PubMed Central, accessed March 13, 2025,
https://pmc.ncbi.nlm.nih.gov/articles/PMC11814325/
88. (PDF) Medical large language models are vulnerable to data ..., accessed March 13, 2025,
https://www.researchgate.net/publication/387827766_Medical_large_language_models_are_vul
nerable_to_data -poisoning_attacks
89. Study Warns of Risks from Medical Misinformation in Large Language Models, accessed
March 13, 2025, https://www.azorobotics.com/News.aspx?newsID=15632
90. (PDF) Closing the Automation Gap: Robust AI for Dual -Stain Cervical Cancer Screening
Triage - ResearchGate, accessed March 13, 2025,


 
Middleton Public Comment on U.S. Federal AI Action Plan  17      
https://www.researchgate.net/publication/389554427_Closing_the_Automation_Gap_Robust_AI
_for_Dual -Stain_Cervical_Cancer_Screening_Triage  
91.프로페서  H의 메디톡 , accessed March 13, 2025, https://medtalk.tistory.com/
92. A New National Purpose: Accelerating UK Science in the Age of AI - Tony Blair Institute,
accessed March 13, 2025, https://institute.global/insights/tech -and-digitalisation/a -new-national -
purpose -accelerating -uk-science -in-the-age-of-ai
93. Improving large language model applications in biomedicine with retrieval -augmented
generation: a systematic review, meta -analysis, and clinical - Oxford Academic, accessed
March 13, 2025, https://academic.oup.com/jamia/advance -article -
pdf/doi/10.1093/jamia/ocaf008/61442713/ocaf008.pdf
94. Methodology for Conducting Post -Marketing Surveillance of ..., accessed March 13, 2025,
https://pmc.ncbi.nlm.nih.gov/articles/PMC10171062/
95. Artificial Intelligence for Drug Development - FDA, accessed March 13, 2025,
https://www.fda.gov/about -fda/center -drug-evaluation -and-research -cder/artificial -intelligence -
drug-development
96. FDA Perspective on the Regulation of Artificial Intelligence in Health Care and Biomedicine,
accessed March 13, 2025, https://pubmed.ncbi.nlm.nih.gov/39405330
97. FDA offers new draft guidance to developers of AI -enabled medical devices, accessed
March 13, 2025, https://www.healthcareitnews.com/news/fda -offers -new-draft-guidance -
developers -ai-enabled -medical -devices
98. FDA strengthens AI regulation to ensure patient safety and innovation in healthcare,
accessed March 13, 2025, https://www.news -medical.net/news/20241016/FDA -strengthens -AI-
regulation -to-ensure -patient -safety -and-innovation -in-healthcare.aspx
99. Artificial Intelligence and Machine Learning in Software as a Medical Device - FDA,
accessed March 13, 2025, https://www.fda.gov/medical -devices/software -medical -device -
samd/artificial -intelligence -and-machine -learning -software -medical -device
100. FDA Releases Draft Guidance on AI -Enabled Medical Devices | Insights, accessed March
13, 2025, https://www.gtlaw.com/en/insights/2025/1/fda -releases -draft-guidance -on-ai-enabled -
medical -devices
101. FDA Issues Comprehensive Draft Guidance for Developers of Artificial Intelligence -
Enabled Medical Devices, accessed March 13, 2025, https://www.fda.gov/news -events/press -
announcements/fda -issues -comprehensive -draft-guidance -developers -artificial -intelligence -
enabled -medical -devices
102. New FDA Policies Could Limit the Full Value of AI in Medicine, accessed March 13, 2025,
https://greenlighthealth.com/new -fda-policies -could -limit-the-full-value -of-ai-in-medicine/
103. FDA's Regulation of AI/ML SaMD - NAMSA, accessed March 13, 2025,
https://namsa.com/resources/blog/fdas -regulation -of-ai-ml-samd/
104. New FDA Regulations on Artificial Intelligence and Machine Learning in Medical Devices,
accessed March 13, 2025, https://galendata.com/new -fda-regulations -on-artificial -intelligence -
and-machine -learning -in-medical -devices/
105. Artificial Intelligence and Medical Products - FDA, accessed March 13, 2025,
https://www.fda.gov/media/177030/download
106. FDA Action Plan for AI/ML in SaMD (Software as a Medical Device) -, accessed March 13,
2025, https://starfishmedical.com/resource/fda -action -plan-for-ai-ml-in-samd -software -as-a-
medical -device/
107. Shooting for the Moon: The Evolution of Key AI/ML Regulations Governing Certain Health
Care Products and Services - Latham & Watkins LLP, accessed March 13, 2025,
https://www.lw.com/admin/upload/SiteAttachments/AHLA -Connections -August23 -Deixler -
Richards -Speros -Beaton.pdf
108. Artificial Intelligence/Machine Learning (AI/ML) -Based.:Jf/


 
Middleton Public Comment on U.S. Federal AI Action Plan  18      
109. FDA Releases Draft Guidance on Evaluating the Risk and Credibility of AI Used in
Establishing Drug and Device Safety, Effectiveness, and Quality | Morrison Foerster, accessed
March 13, 2025, https://www.mofo.com/resources/insights/250116 -fda-releases -draft-guidance
110. Artificial Intelligence -Enabled Device Software Functions: Lifecycle Management and
Marketing Submission Recommendations - FDA, accessed March 13, 2025,
https://www.fda.gov/media/184856/download
111. FDA officials outline perspectives on regulating AI in healthcare - Sedgwick, accessed
March 13, 2025, https://www.sedgwick.com/blog/fda -officials -outline -perspectives -on-regulating -
ai-in-healthcare/
112. Artificial Intelligence and Machine Learning (AI/ML) -Enabled ... - FDA, accessed March 13,
2025, https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -
and-machine -learning -aiml-enabled -medical -devices
113. The imperative for regulatory oversight of large language models (or generative AI) in
healthcare - ResearchGate, accessed March 13, 2025,
https://www.researchgate.net/publication/372188323_The_imperative_for_regulatory_oversight
_of_large_language_models_or_generative_AI_in_healthcare
114. [PDF] The imperative for regulatory oversight of large language models (or generative AI)
in healthcare | Semantic Scholar, accessed March 13, 2025,
https://www.semanticscholar.org/paper/0893549771094fac547432cb4f84e9605c911a86
115. Section 5 - Navigating the Regulatory Landscape: An Analysis of Legal and Ethical
Oversight for Large Language Models (LLMs) | HIMSS, accessed March 13, 2025,
https://legacy.himss.org/resources/section -5-navigating -regulatory -landscape -analysis -legal -
and-ethical -oversight -large
116. DHAC Executive Summary TPLC Considerations for Generative AI -Enabled Devices -
FDA, accessed March 13, 2025, https://www.fda.gov/media/182871/download


