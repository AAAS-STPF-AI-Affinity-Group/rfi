AAP Headquartera 
345 Pali( Blvd 
Itasca, IL 6
.14 
Phone:630 
Fax: 847/4 
E-mail: 
www.aap.org 
Reply to 
AAP Washington Office 
601 13th St NW, Suite 400N 
Washington, DC 20005 
Phone: 202/347-8600 
E-mail:
Executive Commltlee 
President 
Susan J. Kressly, MD, FAAP 
President-Elect 
Andrew D. Racine, MD, PhD, FAAP 
Immediate Past President 
Benjamin D. Hoffman, MD, FAAP 
Secretary/Treasurer 
Patricia Flanagan, MD, FAAP 
CEO/EXecutive Vice President 
Mark Del Monte, JD 
Board of Directora 
District I 
Patricia Flanagan, MD, FAAP 
District II 
Jeffrey Kaczorowski, MD, FAAP 
District Ill 
Lenore R. Jarvis, MD, MEd, FAAP 
District IV 
Patricia Purcell, MD, MBA, FAAP 
DistrictV 
Jeannette ·ua· Gaggino, MD, FAAP 
District VI 
Claudia Preuschoff, MD, FAAP 
District VII 
Susan Buttross, MD, FAAP 
District VIII 
Greg Blaschke, MD, MPH, FAAP 
District IX 
Eric H. Ball, MD, FAAP 
DistrictX 
Madeline M. Joseph, MD, FAAP 
At Large 
Angela M. Ellison, MD, MSc, FAAP 
Atlarge 
Kristina W. Rosbe, MD, FAAP 
Atlarge 
Joelle N. Simpson, MD, FAAP American Academy of Pediatrics � 
DEDICATED TO THE HEALTH OF ALL CHILDREN" .. 
March 14, 2025 
Sethuraman Panchanathan, PhD 
Director 
National Science Foundation 
2415 Eisenhower Ave 
Alexandria, VA 22314 
Re: Request for Information on the Development of an Artificial Intelligence (Al) Action Plan
This document is approved for public dissemination. The document contains no business­
proprietary or confidential information. Document contents may be reused by the government 
in developing the Al Action Plan and associated documents without attribution. 
Dear Dr. Panchanathan: 
On behalf of the American Academy of Pediatrics (AAP), a non-profit professional organization 
of more than 67,000 primary care pediatricians, pediatric medical subspecialists, and pediatric 
surgical specialists dedicated to the health, safety, and well-being of all infants, children. 
adolescents, and young adults, I write to provide comments in response to the request for 
information (RFI) from the Office of Science and Technology Policy (OSTP) regarding the 
development of an Artificial Intelligence (Al) Action Plan. 
The AAP appreciates the opportunity to provide comments on this RFI, and the following 
provides the Academy's input on several areas outlined in the RFI for consideration to inform 
the development of the Al Action Plan. 
Cybersecurity 
In order to strengthen the Al marketplace, the AAP believes it is essential that cybersecurity, 
data intelligence practices, and classification of data are placed under specifically outlined 
security classifications that are easy to fol low as necessary measures for assessing benefits and 
trade-offs. Transparent policies and transparency regarding the development and use of the 
technology that does not prevent assessment, comparison, and versioningwould be helpful, 
particularly in knowing the extent of training data. Higher levels of security classification 
requiring in-house infrastructure with robust cybersecurity infrastructure that has minimum 
requirements for ages of systems, operating systems, cloud security etc. would need careful 
assessment in any area to be deployed. Lower levels of security may be considered for 
contracted development, licensing of Al software, and similar use cases, again with specific 
requirements outlined to any contracting entity around designs, proof of concept, beta testing, 
and surveillance of any systems with agreement to oversight in place. Further, independent 
oversight is essential to ensuring objective assessments of performance and security testing. 
, 


Model Development 
It is essential that the design and algorithms of Al models take into account who designs the algorithms and 
what information is utilized to train the model. The AAP recommends specific guidelines around the process of 
selecting authors, reviewers, and beta testers from a variety of backgrounds, including age and sex, to 
minimize biases and ensure fairness. 
Application and use 
Al models used in pediatric health care must be trained on appropriately representative pediatric data, given 
the physiological, developmental, and social differences between children and adults. Special considerations 
should be made for developmental stage-specific Al tools, ensuring that Al recommendations account for age­
related variations in diagnosis and treatment. We also urge caution when deciding when and how to use Al in 
health care settings; there are some practice areas in which the use of Al, such as predictive technology, could 
have adverse outcomes.; Al should be used to enhance, not replace, pediatric clinical decision-making, 
particularly in high-risk areas like neonatology, child abuse assessments, and mental health. 
Additionally, in the early stages of incorporating Al systems, it is vital to maintain a focus on function/decision 
making within the algorithms. Initially, the systems should be trained to learn very specific functions but not 
perform functions or make decisions that affect people directly. Furthermore, a transparent 
risk/benefit/potential harm analysis should be conducted, including what underlying data sets were used to 
inform the technology and whether this technology should be only applied/restricted to certain populations. 
Administrative processes that are straightforward, requiring some specific information gathering with finite 
data sets and decision tools, should be performed initially. For example, within the health care setting, Al may 
be able to help with a prior authorization document for obtaining authorization from insurance entities for an 
alternative medication or piece of equipment . As mentioned previously, beta testing this infrastructure is 
critical and consideration to parallel their function with a current state to evaluate accuracy prior to any real­
world deployment. 
Further, transparency is important when utilizing Al tools. As an example, Al tools are often used for 
processing payment claims and reading notes for review/appeal, and it would be helpful for both patients and 
providers to be aware that Al tools were utilized for these purposes. The AAP recommends a tag or 
acknowledgement such as "this patient care note was generated using ambient listening and Al" as well as the 
name of the company whose product is being used. 
Education and workforce 
The AAP strongly recommends that Al-based educational tools be rigorously evaluated to prevent potential 
developmental harm, particularly in early childhood learning and socialization. Transparency is crucial in Al­
powered digital learning tools, ensuring parents and educators understand how algorithms influence 
children's educational experiences. Additionally, Al-driven mental health applications for children (e.g., 
chatbots, emotion detection tools, etc.) should have clear ethical guidelines, with an emphasis on preventing 
unintended psychological effects. 
Regarding workforce education, pediatricians and child health professionals should receive dedicated training 
in Al literacy, including how Al systems generate recommendations, potential biases, and limitations in 
pediatric contexts. Within the Al Action Plan, the AAP recommends including support for medical education 
programs that integrate Al ethics and practical Al use cases in pediatrics. Federal agencies should work with 
medical societies, including the AAP, through the standard public notice and comment process under the 
Administrative Procedure Act, as wel I as other advisory bodies such as those created by the Federal Advisory 
2 


-
. A t t te standardized Al competency guidelines for pediatric healthcare professionals in a Committee c , o crea 
transparent and informed manner. 
Explainability and assurance of Al model outputs 
Maintaining clear and consistent definitions and expectations surroundi~g Al/~achine learn~ng (ML) for 
companies is important. Updates to the regulatory frameworks that provide gu1~ance regardm~ needs for 
explainability and interpretability rather than simple monitoring of outcomes will help c~mp~~1es understand 
what is needed for particular use cases. Al tools used in pediatrics should have clear explam~b1hty 
requirements to ensure that clinicians and families understand Al-gene~ated recommendations. Parents and 
guardians should have access to Al decision-making rationales when Al 1s used to support or automate 
healthcare-related decisions affecting their children. 
Similar to clinical decision support or references in electronic health records (EH Rs) such as growth charts 
derived from the Centers for Disease Control and Prevention (CDC) or World Health Organization (WHO) 
growth curves, it would be helpful to include a way to link to references to increase assurance of Al model . 
outputs. This would allow users to use the information provided by Al systems or services for "assistance" but if 
it is not consistent with what the professional knows, they can access the reference and have a way to confirm 
that either the technology is wrong or that they had incomplete knowledge. 
Data privacy and security throughout the lifecyc/e of Al system 
Data privacy and security is essential for the successful adoption of Al within clinical settings. Children's data is 
particularly sensitive and has long-term implications for identity protection . As such, Al policies should include 
stricter protections for pediatric data than for adult data. Al models that interact with pediatric patient data 
should comply with both the Health Insurance Porta bi I ity and Accountability Act (HI PAA) and the Children's 
Online Privacy Protection Act (COPPA) to ensure that privacy measures are in place. Further, the AAP 
recommends that Al systems handling pediatric data are required to incorporate privacy-preserving 
techniques such as differential privacy and secure multi-party computation. While the protections afforded by 
HIPAA and COPPA are essential to protecting children, there are at present no broad-based, nationwide data 
privacy protections in place to protect all children and adolescents, a reality which has led to widespread data 
collection from young people across their devices and accounts. Th is has significant implications for the 
development of Al, which depends on the processing of vast quantities of data and may present significant 
risks to user privacy and Al model performance, particularly as Al products increasingly blur the I ine between 
everyday uses and clinical care. We believe a robust data privacy framework to protect all young people is 
essential to the successful development of Al. 
Overall, the HIPAA framework is reasonable for safeguarding patient privacy in clinical settings, but the HHS 
Office of Civil Rights (OCR) will need to further clarify and equip the existing HIPAA framework to safeguard 
patient privacy with regards to Al. Using Microsoft Azure as an example, to provide HI PAA-compliant services, 
they must assume that HIPAA violations could occur in any patient inputs. Though unlikely, there are fringe 
cases where an a~gorithm could accept user input as training data and then inadvertently share it in response 
to a separate patient request, leading to a HIPAA infraction. While these cases would be somewhat unusual 
they repr~sent a risk with applying any large language model (LLM). At some point, even with significant ' 
~uman rei~forcementtraining, algorithms may behave unpredictably in unusual or fringe cases. HIPAA would 
~ikely qualify these unusual cases as violations in the current form, but as stated previously, further clarification 
1s needed. 
3 


Risks 
Al systems are designed to learn from human interactions and have limi~ed abili~ to filter inf~r,:nation with 
human context around sociocultural infrastructure and abstract human 1~teract1o_ns. As sue~. 1t 1s n~cessary to 
assume that these systems will carry implicit bias and pose a significant risk of ma1or errors in learning and 
returning responses as a result. The AAP recommends intentional mitigation efforts at several levels to ensure 
Al systems or services advance equitable outcomes and mitigate risks. 
These systems also pose significant risks to the health and development of young peopl~. Anecdo~al .. 
experience suggests that Al-powered image generation tools have allowed for the creation of falsified, explicit 
images, often known as Deepfakes, that can leave young people feeling violated and humiliated. In one case, 
reporting has indicated that students at one high school created Deepfakes of a :lassmate bas~d o~ photos 
found on line and circulated those images to other students. This deeply concerning example highlights the 
perils of developing Al without accounting for the developmental age of young people. The widespread 
commercialization of these powerful technologies will unfortunately lead young people of all ages to test the 
limits of the technology, beyond the use cases likely envisioned, with the potential to lead to harmful 
outcomes. A framework for the development of Al must account for the developmental stage of young people 
as these tools become a growing part of young people's lives. 
Regulation and governance 
Metrics beyond the performance of Al on leaderboards or tasks developed by the computer science community 
need to be created, particularly those which seek to examine the linguistic properties of text beyond syntactic 
or grammatical measures. Al should be treated like any other technology, and robust measurement of 
performance beyond project objectives (e.g. sustainability, validity, reliability) should be identified. 
Additionally, ensuring that there is a clear understanding of the data definitions of performance and clear 
goals of performance and performance surveillance is critical. The AAP also recommends that mechanisms are 
put in place to collect and review unintended consequences for those who perceive negative impacts of this 
technology and to ensure that there is accountability for any harm caused by Al-enabled tools or services. 
Additionally, federal agencies should collaborate with the AAP and other experts to develop pediatric-specific 
Al standards, including safety benchmarks and performance metrics. The AAP recommends Al regulation that 
incorporates a pediatric risk assessment framework, ensuring that Al used in pediatric care does not 
inadvertently reinforce biases, compromise safety, or lead to inappropriate decision-making. For example, 
pediatric-specific Al governance frameworks should address concerns related to Al-assisted child welfare 
decision-making, ensuring that Al does not exacerbate disparities in social services or foster care. 
Procurement 
Any procurement should be driven by a wi 11 ingness to use generative Al appropriately, rather than exp I icitly 
altering the technology. Particularly in the context of removing images and videos from a platform, enhancing 
the use of barcoding or digital watermarking technology can potentially serve as a first line of defense but it is 
p_ossible that t~e adaptation of commercial systems wil I result in such technology being subverted or ' 
circumvented." Ultimately, it will be critical to ensure that the technology's use is tracked and managed 
properly. 
The Academy recomme_nds establishing standard pre-procurement specific questions around products and 
system~ to hel~ d_e~ermi~e -~hether they incorporate any type of Al, as these would be important for 
~valuation. An initial definition of Al would be important as a starting point to develop a tool that can be 
everaged to vend_ors around any systems being offered. This would require Al expertise, but a specific 
assessment tool can be developed as a standard process for evaluation of any system for procurement. 
4 


Thank you again for the opportunity to provide comments on this request for information. The Academy 
would welcome the opportunity to work with OSTP as the Al Action Plan is developed and implemented. If we 
can be of further assistance, please contact Patrick Johnson in our Washington, DC office at 
pjobasoo@aap org. 
Sincerely, 
Susan J. Kressly, MD, FAAP 
President 
SJK/ncp 
;_ See, "Does artificial iorelligence discriroioate io child neglect case assessmentsr , ABA Journal, December,, 2023.
"Nguyen A, Yosinski J, Clune J. Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable 
Images. In Computer Vision and Pattern Recognition (CVPR '15), IEEE, 2015.
5 


