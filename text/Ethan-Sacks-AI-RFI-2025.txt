From: Ethan Sacks
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Sunday, March 16, 2025 10:50:34 AM
CAUTION: This email originated from outside your organization. Exercise caution when opening attachments or
clicking links, especially from unknown senders.
To whom it may concern,
I am a professional writer and a former journalist and I am writing to voice my concerns about A.I.Like all technologies, A.I. has its potential benefits, but it needs to be developed with guardrails to prevent abuses
and dangerous potential outcomes.
Artificial intelligence applications like ChatGPT and Dall-E violate copyright law blatantly to steal other people’s
work without permission or compensation for its machine learning. Then it just regurgitates that work piecemeal,billing it as “new.” That’s not capitalism; that's theft. It’s artificial, but it’s not really intelligent. And it financiallydevastates people like me, whose work is being stolen. Every source scraped for machine learning must becompensated and willingly give permission. These companies are trying to make money off our work for free.
These A.I. technologies are being developed without any regard for the tremendous power requirements for servers
and cooling. Aside from the environmental damage for future generations, which to be blunt, I know theadministration doesn’t care about, we don’t have the power grid to support this unchecked growth of A.I.development.
Also, applications like Dall-E allow for the creation of fake images and video that can be used by malicious actors,
including foreign enemies of the United States, to spread disinformation. There must be protections put in place toprevent a Wild West situation regarding this technology.
This technology is being used to upend entire industries leaving more and more people out of work, rendering their
skills obsolete, without any kind of thought put into how they can be trained for new potential jobs. Are we preparedto have most of the population unemployed and desperate? That’s how instability leads to chaos and violence on ahuge scale. Companies will look to make as much profits as possible, but no one stands to benefit if the entiresystem collapses.
Then there is the ultimate doomsday scenario: Down the line, once super intelligence is inevitably reached in
however many years it takes, we will have a self-aware computer that is 1,000 times smarter than we are. Right nowthat sounds like science fiction, something out of The Terminator. But that’s the end goal of this technology:Powerful computer that can think on their own running important systems. Noted experts in the field are currentlysounding alarms. We will not be able to stop one if it deems humanity expendable. We certainly won't be able to outthink it. So, isn’t it important that we prepare some kind of checks to protect ourselves by developing with somekind of regulations and safeguards built in?
I’m not a Luddite, I’ve spent a lot of time and effort reading the works of A.I. experts and scientists. I know there is
potential - that largely hasn’t been reached yet - for positive applications, including the medical sciences.
But that’s not what is currently happening. There is a scramble by competing companies facing to be first in new
developments without any kind of thought as to long term implications. We need to develop smarter not faster. Thestakes are too high not to be careful.
Thank you for listening.


________________________________
All e-mails to and from this account are for NITRD official use only and subject to certain disclosure requirements.
If you have received this e-mail in error, we ask that you notify the sender and delete it immediately.


