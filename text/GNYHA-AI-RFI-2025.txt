March 
Fourteen  
2 0 2 5 
Kirk D ohne 
Acting Dire ctor 
Networking and Information Technology Research and Development 
National Coordination Office  2415 Eisenhower Avenue 
Alexandria, VA 22314 
Re: R equest for Information on the Development of an Artificial Intelligence Action Plan  
Dear Acting Director Dohne: 
Greater New York Hospital Association (GNYHA) is pleased to provide these comments in 
response to the Request for Information (RFI) on the Development of an Artificial Intelligence (AI) Action Plan, published in the Federal Register on February 6, 2025. GNYHA is a trade association that represents more than 200 hospitals and health systems in New York, New Jersey, 
Connecticut, and Rhode Island. Since 2023, GNYHA has convened an AI Advisory Group 
comprised of experts from our member hospitals and health systems to examine the potential benefits and challenges with AI integration in health care. We have discussed their ongoing 
development of strategies to harness the power of AI to perform important biomedical and health 
services research, apply those findings to improve health outcomes, and use AI to create 
operational efficiencies.  
AI can be used to improve billing and finance operations and  reduce administrative burdens by 
bringing more efficiencies to care in areas such as call center management. In clinical applications, AI has the potential to revolutionize patient care through precision medicine, tailoring treatment based on the specific needs and genetic makeup of a patient. AI tools can also lighten the workload for clinicians by supporting clinical documentation, detecting diabetic 
retinopathy, and analyzing electrocardiograms. AI can help radiologists identify subtle 
abnormalities and patterns in screening mammograms and other breast imaging techniques, potentially leading to earlier and more accurate cancer detection, while also reducing workload and false positives. AI has the potential to advance medicine and improve health outcomes for 
millions of Americans, and the United States is positioned to be a dominant player in AI , 
reassert ing the premier place America holds in the technology and health care industries . It is a 


pivotal time in the development of the field, however, and careful consideration must be taken 
prior to developing policies and regulatory standards affecting this burgeoning area.  
In su mmary, we strongly urge the Office for Science and Technology Policy , the Networking 
and Information Technology Research and Development National Coordination Office, and 
the Federal government at large  to promote policies  that foster collaboration and provide 
open -source model availability; increase the oversight of  and strengthen privacy and security 
requirements for AI vendors that partner with hospitals ; modernize the AI regulatory 
processes that currently exist within the Food and Drug Administration ( FDA); and prohibit 
the misuse of AI in the claims review process by insurers and benefit plans.  
GNYHA provides  the following comments on several of the AI policy topics identified in 
the RFI.  
AI Application a nd Use ; Open -Source Development  
Not all health care organizations and hospitals have the same level of resources and technical 
expertise in  AI. The Fe deral government should implement policies to ensure that hospitals 
lacking in resources or infrastructure are not left behind. This goal can be achieved by creating targeted financial  investments for hospitals and health systems to foster collaboration with 
institutions that are leading in AI innovation. These additional investments will further accelerate the creation of AI-based solutions to many of the country’s medical challenges. In addition, AI models that are developed with Federal funds should be made open source or be structured in a way to promote maximal collaboration to  promote widespread adoption by as many hospitals as 
might benefit. Financial investments and making federally funded models maximally 
available would reduce development time and costs for hospitals and health systems, accelerate AI adoption , and drive learning and innovation so that all health care 
organizations are able to advance the delivery of  care and patient outcomes .  
Explainability and Assurance of AI Model Outputs 
Non-hospital AI v endors should be required  to demonstrate that their AI technologies  operate 
safely and responsibly by adhering to regulations set forth by the F ederal government . This  
requirement will address the integration  and implementation concerns of  health care 
organizations and the communities that they serve . In addition, private vendors must provide 
assurances to  hospitals that their models perform as intended and  are r outinely  reviewed for 
quality and safety . Placing full responsibility on hospitals and other health care organizations to 
meet this quality assurance standard would create obstacles to seamless AI integration in 
hospitals. While  full explainability  of AI output  is not always possible, F ederal regulation s 
should require that vendors demonstrate that their tools work as intended and consistently  
produce reliable outcomes .  


The Federal government’s focus in this area should be private vendors that seek to work with 
hospitals, not hospitals themselves. Hospitals  have a tremendous amount of oversight from the 
Federal government and state authorities already to ensure that care is safe for all patients . For 
instance, hospitals are expected to root out and address instances of bias to ensure patients are not harmed by AI applications, but vendors are not expected to do the same. Private vendors that 
sell AI tools to hospitals and other health care facilities  should be held to the same laws and 
regulations to ensure safe patient care. Ensuring AI vendor accountability through increased 
oversight would help hospitals mak e informed decisions about AI adoption and use.  
Data Privacy and Security 
As AI tools continue to be developed by a proliferation of vendors, the Federal government 
should ensure that privacy and security standards, including those in the Health Insurance 
Portability and Accountability Act (HIPAA) of 1996, appropriately apply to those vendors that work with hospitals and other HIPAA- covered entities.  For those vendors that do not meet the 
definition of business associate under HIPAA, there should be reasonable standards for them to 
meet  to protect the information they will have access to.  
There are many open questions in the area of privacy and security raised by AI vendors’ work 
with hospitals, including who should be liable for breaches of information and system failures 
and how to define the ethical uses of information. There is a need for government guidance and 
standard -setting in this area, particularly since many AI vendors are large companies against 
which most hospitals have minimal, if any, leverage in the market to negotiate contract terms and conditions, including limitations on liability. Reasonable Federal standards and enforcement 
would maximize vendor accountability and compliance. To ensure security and ethical data use, 
private vendors working with health care organizations should be, at minimum, required to disclose their d ata sharing practices, including whether they are sharing or selling data to foreign 
entities.  
Regulation and Governance 
The FDA  should consider updating its existing regulatory framework for the oversight of AI 
tools. GNYHA hospitals have stated that approval from the FDA  provides reassurance that a 
vendor model or device has undergone regulatory review.  The FDA should consider pathways for the expedited review of AI tools. A concern that 
hospitals have when acquiring AI tools and negotiating contracts with AI vendors is the lengthy 
FDA clearance process, which can delay AI tool implementation. Given the constantly evolving nature of AI technology, requiring a new review and application with each version or iteration also presents challenges to those seeking FDA approval. To address these challenges, the FDA 
should streamline its review process and allow opportunities for expedited review.   


Another suggested update to the existing regulatory framework would be tasking the FDA with 
the oversight of AI tools that are not classified as Software as Medical Devices (SaMDs). Leaving the responsibility of safety assurance and tool assessment to hospitals could slow adoption, as hospitals would be tasked with taking this on themselves. A standardized regulatory and review process for non-SaMD AI tools would provide clarity and consistency across 
hospitals nationwide.   
Risks of AI in Insurance and Claims  
GNYHA urges the F ederal government to prohibit insurers and benefit plans from misusing AI in 
the claims review process . Recent media coverage and legislative reports flag concerns with the 
correlation between automation and increased denials  of medical care .
1 We recognize the 
opportunities available to all organizations, including health insurance companies, to increase 
efficiencies by using AI. While payers continue to adopt technology in pursuit of administrative efficiencies, it is imperative that denials of medical claims not be automated without an opportunity 
for an appropriately qualified physician to review the denial. Each denial of a health care service 
must be  based on careful review of the individual patient’s unique medical history and 
circumstances, including the treating provider’s recommendation. The Centers for Medicare & Medicaid Services ( CMS ) has explicitly cautioned Medicare Advantage ( MA) plans  that 
algorithms and AI  must comply with all requirements applicable to the coverage determination 
process .
2 MA regulations require medical necessity determinations to be based on an individual 
patient’s circumstances, and thus algorithms that base determinations on larger data sets are impermissible. Additionally, AI  may not be used to shift coverage criteria over time. C overage 
criteria must be static and publicly accessible. CMS has also directed MA plans that they must understand the coverage criteria built into an algorithm or software tool that generates coverage 
decisions and ensures  their compliance .
3  
The Se nate Permanent Subcommittee on Investigations recently noted serious questions about the 
correlation between an increased use of AI and increased denials  of medical services . Based on a 
review of post -acute discharges and denials by three MA  plans, the Subcommittee recommended 
enhanced MA plan reporting and audit to enhance transparency and  flagged the need to ensure 
predictive technology does not have undue influence on human reviewers, pressuring them to 
“rubber stamp” denials.  These policy directiv es underscore a general principle that health plans 
should not be able to use AI to circumvent medical necessity review process requirements. Plans should be prohibited from relying on AI to deny care. Additionally, given the evolving AI 
1 Senate Report: Refusal of Recovery: How Medicare Advantage Insurers Have Denied Patients Access to Post -
Acute Care https://www.hsgac.senate.gov/wp- conte nt/uploads/2024.10.17 -PSI-Majority -Staff -Report -on-Medicare -
Advantage.pdf .  
2 Frequently Asked Questions related to Coverage Criteria and Utilization management Requirements in CMS Final 
Rule (CMS -4201- F), February 6, 2024. 
3 89 Fed. Reg. 99458 (December 10, 2024) .  


landscape, transparency is key . Plans should be required to disclose to regulators, consumers , 
and providers how they use AI in the claims review process.   
Other  Considerations  
AI implementation in health care has the potential to improve efficiency, reduce administrative 
burdens, revolutionize patient care, and lighten the workload for physicians. However, excessive regulation creates barriers to implementation. Hospitals and health care systems must navigate many regulatory requirements, risking significant penalties for noncompliance. For instance, GNYHA members engaged in AI research are concerned about the proposed cut to funding from 
the National Institutes of Health (NIH). The NIH issued supplemental guidance to the 2024 NIH 
Grants Policy Statement: Indirect Cost Rates announcing th at “there will be a standard indirect 
rate of 15% across all NIH grants for indirect costs in lieu of a separately negotiated rate for indirect costs in every grant.”
4 New York State is the second -largest recipient of NIH funding, 
and we estimate that New York will lose around $850 million due to the cap on indirect costs.5 
Reductions in financial support for research will slow down costly AI innovation and limit the ability of health care providers and health systems to implement AI advancements.  
Thank you f or the opportunity to provide these comments. GNYHA welcomes the Federal 
government’s development of an AI Action Plan,  and we are committed to working with 
policymakers so that Americans can benefit from all the applications in health care that are 
available.  
If you have any questions or would like further information on GNYHA’s recommendations, please contact Erin DuPree, MD , (  /  or Tim Johnson 
(  / 
4 NOT -OD-25-068: Supplemental Guidance to the 2024 NIH Grants Policy Statement: Indirect Cost Rates NOT -OD-
25-068.  
5 New York Congressional delegation bipartisan letter  to the National Institutes of Health (NIH). February 14th, 2025.  


Sincerely,  
Erin DuPree, MD, FACOG 
Senior Vice President and Physician Executive 
Quality and Clinical Initiatives  
Tim J ohnson 
Senior Vice President and  Executive Director, Center for GME , Health Workforce, and Population 
Health  
Executive Director, GNYHA Foundation 
This document is approved for public dissemination. The document contains no business -
proprietary or confidential information. Document contents may be reused by the government in developing the AI Action Plan and associated documents without attribution.  


