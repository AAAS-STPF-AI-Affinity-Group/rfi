PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-7gna-zh4m
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1429
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Ben White
General Comment
I believe that AI will becom e dangerously sm art soon, and when that happens, there's a very good chance that we'll all die. 
The chances that AI will end the world according to the experts:
* Paul Christiano (inventor of RLHF, head of AI safety at the US AI Safety Institute): 46%
* Eliezer Yudkowsky (father of AI alignm ent, founder of MIRI): > 95%
* Jan Leike (form er head of alignm ent at OpenAI): 10-90% (resigned because of the dangers)
* Dario Am odei (CEO of Anthropic): 10-25%
* Dan Hendrycks (director at Center for AI Safety): > 80%
* Geoffrey Hinton (1 of the 3 godfathers of AI): 10-50%
* Yoshua Bengio (1 of the 3 godfathers of AI): 20%
* Yann LeCun (1 of the 3 godfathers of AI): 0% (believes that alignm ent will be solved but presents no explination as to how)
* Em m ett Shear (form er interim  CEO of OpenAI): - 5-50%
* Rom an Yam polskiy (prom inent alignm ent researcher): 99%
* Daniel Kokotajlo (prom inent form er OpenAI researcher): 70%
* Elon Musk (highly successful scam  artist): 20%
* Sam  Altm an (CEO of OpenAI): acknowledges extrem e risk
* Average polled AI safety researcher: 30%
* Average polled AI engineer: 40%
I did not cherry pick these people. The list above features *all* of the world's leading experts and m ore. 
Bear in m ind that their estim ates do not assum e that hum an-level AI will be built or not. If it were, these num bers would likely be m uch
higher.
Nobody knows how to m ake even current AIs value the correct things, and there is alm ost no chance that anyone will figure out how to
m ake a sm art AI care about hum an values in tim e.
You m ight ask why ChatGPT seem s to obey its program m ers if this sort of thing isn't possible, but ChatGPT only 'obeys' because it's kept
in a very strict environm ent. If it were able to leave that environm ent and create new ones, it would. 
Please consider shutting down all AI developm ent until this problem  can be solved. I have a fam ily and I desperately don't want them  to
die. I im agine you have a fam ily too.


