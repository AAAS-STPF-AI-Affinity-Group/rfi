PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-l3ay-vldq
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-2376
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: Kevin Flanagan  
General Comment
The ideal action plan for "AI", as we are m isleadingly referring to these generative LLM program s, is that they shouldn't exist. If that isn't
possible, they certainly shouldn't be allowed to be "trained" on any sort of copyrighted m aterial.
Not only is LLM scraping of copyrighted m aterial so that m achines can autom atically plagiarize them  terrible as a policy from  the
perspective of fairness and proper credit and com pensation, but the proposal subm itted here would allow ANYONE to have access to...
pretty m uch anything. Google is one of the prim ary m overs behind this request, but if it were to go through, anyone claim ing to be "training
a GenAI" would be allowed to look at Google's closed-source, proprietary software. Does that sound like less of a security issue than the
current status quo?


