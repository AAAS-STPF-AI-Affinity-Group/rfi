1 
Intel Corporation Response to the Request for Information on 
the Development of an Artificial Intelligence (AI) Action Plan 
This document is approved for public dissemination. The document contains no business-
proprietary or confidential information. Document contents may be reused by the government in 
developing the AI Action Plan and associated documents without attribution.  
Intel Corporation (“Intel”) is one of the world’s leading semiconductor companies and the only 
leading-edge logic manufacturer based in the U.S. Intel’s full spectrum of hardware and software 
platforms offer open and modular solutions that support AI workloads and fuel emerging usages 
like AI at the edge and AI PCs, pioneering innovations that will advance the future of AI and 
help to solve the world’s most complex challenges.   
Intel supports a risk-based, multi-stakeholder approach to proposed AI policy measures that is 
informed by international standards (e.g., ISO/IEC) and voluntary frameworks such as the 
National Institute for Standards and Technology (“NIST”) AI Risk Management Framework 
(RMF). Intel encourages AI policy measures that consider context and sector specific use cases 
and applications rather than horizontal requirements and urges that care be taken so that 
regulatory initiatives are limited to issues not already covered by existing laws, regulations, or 
international standards. Intel looks forward to partnering with the Administration to deliver on 
advancing the AI Action Plan and on President Trump’s “Made in America” goals.  
We offer the following response to the Networking and Information Technology Research and 
Development (“NITRD”) National Coordination Office’s (“NCO”) Request for Information on 
behalf of the Office of Science and Technology Policy (“OSTP”) regarding the development of 
an Artificial Intelligence (“AI”) Action Plan (the “AI Action Plan”).   
U.S. Manufacturing 
Intel was founded in the U.S. and has been innovating, investing, and supporting global 
semiconductor manufacturing and R&D for more than 50 years. Intel currently employs 
approximately 45,000 people in the U.S. Since the company’s founding in 1968, Intel has both 
designed and manufactured its own integrated circuits (“ICs” or chips). Intel designs and 
produces a wide range of products from AI in the cloud to AI at the edge to AI PCs. Intel 
Foundry offers leading-edge process nodes, industry-leading packaging and test technologies to 
other companies, and we are working with the IP ecosystem to provide a rich portfolio of 
semiconductor and systems IP as well.  
Intel is undertaking an expansion of its U.S. chipmaking capacity, investing $100 billion in the 
U.S. to expand chipmaking capacity and capabilities in Arizona, New Mexico, Oregon, and 
Ohio. Later this year, Intel expects to begin production of chips on the Intel 18A process node, 
which provides groundbreaking innovations including gate-all-around transistors and backside 


2 power. 
At the AI Action Summit in Paris in February 2025, Vice President J.D. Vance stated that “the 
Trump Administration will ensure that the most powerful AI systems are built in the U.S. with 
American designed and manufactured chips.”1 Intel has the capacity and capabilities to help 
deliver on the Trump Administration goal as articulated by Vice President Vance. Policies that 
facilitate utilization of these capabilities could help achieve this vision.  
Production of logic chips for AI systems is among the most technologically complex 
manufacturing processes in the world. A modern leading-edge chip fab may cost more than $20 
billion to build and can take years to become operational. To remain at the leading-edge of 
chipmaking, companies must invest at the scale of billions of dollars annually in research and 
development efforts. This explains why, twenty-five years ago, dozens of companies competed 
in leading-edge manufacturing, while today only three manufacturers remain – Samsung, TSMC, 
and Intel.  
Operationally, chip manufacturing is highly complex and requires inputs ranging from expensive 
cutting-edge lithography equipment to specialized chemicals utilized in the manufacturing 
process. Regulatory approvals/compliance requirements and associated processes are causing 
delays and uncertainty in the supply chain. For example, while niche chemicals used in 
semiconductor manufacturing may be subject to extensive regulations in some foreign 
jurisdictions, approvals are fast-tracked in others. By comparison, the lengthy and costly 
approval process in the U.S. impacts the ability to make cost-competitive and timely innovations, 
and in some cases could even result in supplier decisions to not provide compounds needed for 
innovation and manufacturing in the United States.  
Potential Policy Actions: 
To support the President’s desire to expand U.S. manufacturing, the Administration could
support an extension of Section 48D, known as the Advanced Manufacturing Investment
Credit, which is important for driving manufacturing capacity to enable long-term
investments in critical technologies beyond 2026 (when the provision expires).
To further accelerate the President’s “Made in America” agenda, the Administration
could partner with semiconductor companies that are manufacturing in the U.S. on
measures that increase demand for American-made chips. There are several mechanisms
that could help support increased demand including:
oNew tax policies, such as an enhanced tax deduction for customers who purchase
U.S.-made wafers or other critical products, which would help ensure that critical
technologies that are designed in America are also manufactured domestically.
oDirect the Federal Acquisition Regulation Council, Customs and Border Protection,
and other relevant agencies to amend the country of origin and domestic content
regulations to take into account the location of where the most valuable parts of the
manufacturing process for leading-edge chips occurs, as well as research and
development, in these determinations.
oWhen engaging in Federal Acquisition Regulation (FAR) governed contracts, extend
existing domestic preferences to also include “Made in America” wafers when


3 procuring systems and AI capabilities, including for refreshes and updates. 
oProvide mechanisms to encourage private and public sector operators of critical
infrastructure – including system integrators, cloud service providers, and others – to
preference systems and AI capabilities with wafers “Made in America.”
Chemicals approvals and regulations impacting semiconductor manufacturing should be
improved to ensure a level playing field for U.S. manufacturers and their suppliers.
Supporting an Open Ecosystem for AI 
Open models for AI can facilitate transparency, competition, and innovation. Open-source 
initiatives like TensorFlow and PyTorch have allowed developers to collaborate and accelerate 
innovation. Open-Source development is often governed and stewarded by consortia of industry 
and academia to ensure neutral, horizonal competition where market forces through developer 
action drive the future of innovation and consumption. Building on the proven technological 
open ecosystem successes of the past, standards, standardized processes, and ubiquitous access 
have fueled the last four decades of technological advancement while also facilitating secure 
design and implementation.  However, to achieve these benefits, open development will also 
need to continue to prioritize robust security protocols and standards to identify, address, and 
report potential vulnerabilities. Openness not only allows for faster advancement of technology 
and innovation, but also faster, transparent discovery of potential harms and mitigation.   
Open ecosystems can provide a wide range of benefits including interoperability, lower costs, 
and reduced complexity. As entities consider how and when to adopt AI, key factors often 
include cost, ease of implementation, relevant use cases, ability to retain control of company 
data, increased speed, etc. Open ecosystems, including open-source software, can provide 
valuable solutions addressing these factors, lowering barriers to entry for AI adoption and 
preventing vendor lock-in. Therefore, it is important to cultivate an environment where open-
source solutions and open ecosystems can flourish while accelerating new technology adoption. 
Potential Policy Actions: 
In order to empower American businesses to compete and win in the global sphere,
fostering open ecosystem solutions is essential. The Administration should adopt a
measured approach such as active monitoring of open-weight AI models to assess
emerging risks while preserving the benefits of open innovation, rather than imposing
restrictions on open weight AI models.
The AI Action Plan could encourage the use of open-source systems through mechanisms
such as facilitating access to government data, as appropriate, in standardized format.
Government investments in AI and research, such as National Labs, should be built on,
advance, and promote standards-based interoperable ecosystem development.
Application and Use (Public and Private Sector)  
Just as a wide range of AI applications and use cases exists, so too does a corresponding range of 


4 solutions, from proprietary to open source, from cloud to edge to PCs. Therefore, it is important 
to not have a one-size-fits-all approach to the AI Action Plan. Although much of policymaker 
focus has been on the requirements, opportunities, and risks associated with leading “Frontier 
Models” and increasing energy needs for data centers to support these models, there are many 
other benefits for businesses and consumers that can be met by a wide array of AI solutions. For 
example:  
An enterprise deciding to implement AI to increase efficiency on a factory floor may
choose to deploy an open-source edge solution due to the following factors:  1) keeping
data under company control; 2) ability to customize an AI model on top of an existing
open-source solution to keep cost and complexity down; and 3) low latency allows an
Edge AI solution to gather and react in real-time to data from sensors or images.
A government agency deciding to implement AI may choose to deploy AI PCs due to the
following factors: 1) improved operational efficiency; 2) AI-enhanced security and
manageability that goes beyond standard PCs, offering advanced protection and control;
and 3) real-time data processing.
These examples help illustrate why it is important to consider the breadth of AI solutions. 
Potential Policy Actions:   
Ensure that AI solutions besides “Frontier Models” are incorporated as appropriate into
the AI Action Plan especially with respect to applications/use cases.
Consider the wide array of AI solutions (e.g., cloud, edge, AI PCs, etc.) available for
procurement purposes.
Export Controls 
During the AI Action Summit in Paris, Vice President Vance stated that “this administration will 
ensure that American AI technology continues to be the gold standard worldwide and we are the 
partner of choice for others -- foreign countries and certainly businesses -- as they expand their 
own use of AI.”2 In order to fulfill this goal, it is important that any U.S. export controls do not 
undermine U.S. technological leadership and competitiveness, while effectively mitigating 
national security risks.  
Potential Policy Actions: 
Undertake a thorough review of existing and planned export controls, such as the two
interconnected Interim Final Rules on Framework for AI Diffusion and Due Diligence for
Advanced Computing Integrated Circuits, to establish a control framework that clearly
targets and addresses national security risks. This framework should keep pace with
technological advances while de-controlling mature or less sensitive technologies. Once
the framework is established, a comprehensive evaluation of the entire design-to-
production life cycle (including implementation challenges and regulatory impacts)
would facilitate clarity and consistent application of the regulations.


5 Securing the AI Lifecycle 
Security must serve as one of the core pillars of effective AI policy. As threats to the AI 
ecosystem continue to grow in sophistication, there needs to be a corresponding evolution of AI 
security throughout the development and supply chain lifecycle, including appropriate risks and 
controls, covering AI products and model generation, integration, and consumption. This 
approach will need to extend beyond security capabilities to include research, design, build, 
secure development, and support. The U.S. government should encourage the adoption of best 
practices that integrate security principles across the AI product security assurance lifecycle, 
with strategies for disposal or long-term retention. These best practices should be further 
supported with hardware-based security mechanisms to further safeguard advanced AI and 
supercomputing systems.  
In order to protect models from tampering and unauthorized access, it is crucial to ensure strong 
isolation and integrity in hardware for AI workloads. This includes using confidential computing 
capabilities and other hardware-based security measures to prevent data breaches and ensure 
confidentiality, as well as regular audits and monitoring to verify that AI model hosting 
infrastructure remains unaltered (i.e., checking for software updates, configuration changes, and 
potential security threats). Deploying Trusted Execution Environments (TEE) ensures that data 
and computations remain secure and in the owner’s custody, even in untrusted environments, and 
this technology should be uniformly available across different processor types to maintain 
consistent protection. TEEs can be further augmented through the use of federated learning 
techniques in multi-vendor and multi-cloud environments that enables collaborators to jointly 
train an AI model while keeping their intellectual property private to themselves.  
Finally, implementing mechanisms to track training datasets and sources is vital for identifying 
and filtering AI-generated training data. This includes redesigning sensor networks and content 
capture technology to label AI-based content to enhance transparency and accountability and 
ensure that output labelling cannot be circumvented. The prioritization of data-driven 
transparency and integrity should extend to securing the AI supply chain as well and involves 
using frameworks and tools for collecting machine-readable provenance of training data, models, 
and software applications, (e.g., software bill of materials [SBOM]).   
Potential Policy Actions: 
The AI Action Plan aims to support the stated U.S. policy to “sustain and enhance
America’s global AI dominance in order to promote human flourishing, economic
competitiveness, and national security.”3 By focusing on hardware security, data privacy,
and AI supply chain integrity, the U.S. can enhance its AI capabilities and address
national security concerns effectively. The plan should incentivize efforts to secure the
AI lifecycle such as those above.
The creation of standards capturing industry best practices in security AI system
development should be reinforced through procurement requirements across the Federal
enterprise. This includes both software and hardware security provisions highlighting the
Secure Development Lifecycle (SDL), the need for confidential computing capabilities,
and better transparency and accountability mechanisms.


6 Explainability & Transparency 
To ensure a level playing field for AI developers, clear expectations must be set for documenting 
and explaining the steps taken to assess the functionality of AI systems within foreseeable 
contexts of use. This includes providing detailed documentation on model training processes, 
data sources, and validation methods. Developers should be encouraged to explain how their 
models make decisions and the limitations of their models. This transparency will help users and 
downstream developers understand the reliability and appropriateness of AI systems for their 
specific needs.   
Establishing clear benchmarks and standards for AI model performance and explainability will 
enable stakeholders to select suitable models for their specific use cases. These benchmarks 
should be developed in collaboration with industry experts, academia, and regulatory bodies to 
ensure they are comprehensive and widely accepted.  
Potential Policy Actions: 
Continue investing in the ongoing work of the National Institute of Standards and
Technology (NIST), including the voluntary guidelines in the AI Risk Management
Framework and the work that has been done within the U.S. AI Safety Institute.
Research & Development 
Supporting the establishment of high-quality datasets and benchmarks is essential for advancing 
AI research and development. Publicly available datasets can enable researchers to train and 
evaluate their models effectively and accelerate innovation by providing a common ground for 
comparison and collaboration. Additionally, benchmarks should be updated regularly to reflect 
the latest advancements in AI technology.   
Providing robust compute infrastructure is crucial for scaling algorithmic innovation. This 
includes investing in high-performance computing (HPC) resources, cloud platforms, and 
specialized hardware to support the development and deployment of advanced AI models. 
Access to powerful compute resources will enable researchers to experiment with complex 
models and large datasets, driving breakthroughs in AI capabilities.   
Potential Policy Actions: 
Consider mechanisms to encourage research and development in this space.
Make available, as appropriate, federal data in standardized data formats.
Invest in HPC AI infrastructure for national security and scientific research.
International Standards 
In the rapidly evolving field of artificial intelligence, international collaboration is crucial. 
International standards are a key vehicle for supporting U.S. innovation and technology 
leadership in contributing to the global evolution of AI. They enable global market access for 
industry, interoperability among products and services, global supply chains, and enhanced 


7 consumer welfare by increasing economies of scale and competition. International standards are 
especially important for addressing areas that benefit from consistent or harmonized global 
approaches such as areas related to technical interoperability, reliability, risk management, 
security, etc. Therefore, we recommend that the development and adoption of international 
standards be a focus of the action plan to meet the needs of U.S. stakeholders in the adoption of 
AI to existing industries and in the creation of new AI-related industries.  
 Potential Policy Actions: 
Reinforce the importance of the public-private partnership in the development of
international standards and recognize the importance of having government experts,
especially technical standards experts from NIST, participating consistently, as
appropriate, in relevant international standards development.
International Collaboration on Privacy-Preserving AI 
In privacy-sensitive areas like healthcare, effective international collaboration is important to 
ensure the development and deployment of reliable and regulatory-compliant AI models across 
geographic borders. However, differences in privacy regulations (such as GDPR, CCPA, 
HIPAA) hampers international collaboration by complicating interoperability and data exchange. 
The development and adoption of privacy-preserving AI frameworks and techniques, such as 
federated learning, can facilitate AI collaboration. Public-private cooperation when developing 
guidelines and international standards can facilitate secure AI model development and 
deployment by improving the protection of data, while federated AI frameworks such as OpenFL 
and benchmarking infrastructure such as MedPerf can enable high-risk AI applications to meet 
accuracy standards. Rather than relying on strict data retention rules such as those developed for 
medical devices, regulated AI models—especially in healthcare and finance—could transition to 
real-world performance monitoring of AI models, ensuring continuous oversight without 
unnecessary data storage risks.   
Potential Policy Actions: 
Support the development and adoption of privacy-preserving AI frameworks and
techniques, such as federated learning, in critical sectors to address complex challenges to
collaboration stemming from different privacy regulations (such as GDPR, CCPA,
HIPAA) that hampers interoperability and data exchange, as well as updating data
retention rules as appropriate.
*** 
Intel welcomes the opportunity to discuss our feedback to this request for information. We look 
forward to continued engagement with the OSTP on the AI Action Plan.  


