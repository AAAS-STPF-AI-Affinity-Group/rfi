PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 89-kg09-6t71
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1657
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  ACT | The App Association
General Comment
See attached for com m ents of ACT | The App Association
Attachments
ACT Com m ent re AI Action Plan (14 Mar 2025) (w appendix)


1 
March 14 , 202 5 
Faisal D'Souza  
Networking and Information Technology Research and Development  
National Coordination Office  
National Science Foundation  
2415 Eisenhower Avenue  
Alexandria, V irginia  22314  
RE: Comments of ACT | The App Association , Request for Information on the 
Development of an Artificial Intelligence (AI) Action Plan  (90 FR 9088 ) 
Dear Mr. D'Souza : 
ACT | The App Association (App Association) appreciates the opportunity to submit 
views to the National Science Foundation’s Networking and Information Technology 
Research and Development (NITRD) National Coordination Office (NCO) in response to 
its request for information  on behalf of the Office of Science and Technology Policy 
(OSTP)  to inform  the development of an Artificial Intelligence (AI) Action Plan.1 The App 
Association is committed to accomplishing policy actions needed to sustain and 
enhance America's AI dominance, and to ensure that unnecessarily burdensome 
requirements do not hamper private sector AI innovation . 
This document is approved for public dissemination. The document contains no 
business -proprietary or confidential information. Document contents may be  
reused by the government in developing the AI Action Plan and associated documents 
without attribution.  
The App Association represents thousands of small business software application 
development companies and technology firms that create the technologies that drive  
internet of things (IoT) use cases across consumer and enterprise contexts . Today, the 
value of the ecosystem the App Association represents —which we call the app 
economy —is $1.8 trillion and is responsible for 6.1 million American jobs, while serving 
as a key driver of the $8 trillion IoT revolution .2 Alongside the world’s rapid embrace of 
mobile technology, our members create the  innovative solutions that power IoT across 
modalities and segments of the economy.  We support OMB’s goal of ensuring federal 
agencies  instill proper  safeguards that prioritize  economic and national security, privacy, 
1 NSF, Request for Information on the Development of an Artificial Intelligence (AI) Action Plan , 90 FR 
9088  (2025), available at: https://www.federalregister.gov/documents/2025/02/06/2025 -02305/request -
for-information -on-the-development -of-an-artificial -intelligence -ai-action -plan.  
2 ACT | The App Association, State of the App Economy (2022), 
https://actonline.org/wpcontent/uploads/APP -Economy -Report -FINAL.pdf . 


2 
 civil liberties  and more  when utilizing AI and other advancements in technology and 
innovation . 
 
AI-driven algorithmic decision tools and predictive analytics  are having , and will 
contin ue to  have , substantial direct and indirect effects on Americans. Some forms of AI 
are already in use  to improve American consumers’ lives today ; for example,  AI is used 
to detect financial and identity theft and to protect the communications networks upon 
which Americans rely against cybersecurity threats .  
 
Moving forward, a cross use cases and sectors, AI has incredible potential to improve 
American consumers ’ lives through faster and better -informed decision making  enabled 
by cutting -edge distributed cloud computing . As an  example, healthcare treatments and 
patient outcomes  stand poised to  improve disease  prevention  and conditions, as well as 
efficiently and effectively treat diseases through automated analysis of X-rays and other 
medical imaging . AI will  also play an essential role in self -driving vehicles and could 
drastically reduce roadway deaths and injuries. From a governance perspective, AI 
solutions will d erive greater insights from infrastructure and support efficient budgeting 
decisions . 
 
Today, Americans encounter  AI in their lives incrementally through the improvements 
they have seen in computer -based services they use, typically in the form of 
streamlined processes, image analysis , and voice recognition  (we urge consideration of 
these forms of AI as  “narrow” AI) . The App Association notes that this “narrow” AI 
already provides  great societal benefit . For example, AI -driven software products and 
services revolutionized the ability of countless Americans with disabilities to achieve 
experiences in their lives far cl oser to the experiences of those without disabilities.  
 
Nonetheless, AI also has the potential to raise a variety of unique considerations for 
policymakers , making the Administration’s planned AI Action Plan a timely and 
necessary foundation for future government AI policies . We strongly encourage 
alignment of the  AI Action Plan  with the App Ass ociation ’s comprehensive AI policy 
principles :  
 
1. Harmonizing and Coordinating Approaches to AI  
 
A wide range of federal, local, and state laws prohibit harmful conduct regardless 
of whether  the use of AI is involved. For example, the Federal Trade Commission 
(FTC) Act prohibits unfair or deceptive acts or practices, and states also have 
versions of these prohibitions in their statute s. The use of AI does not shield 
companies from these prohibit ions. However, federal and state agencies alike 
must approach the applicability of these laws  in AI contexts thoughtfully and with 
great sensitivity to the novel or evolving risks AI systems  present. Congress and 
other policymakers must first understand how existing frameworks  apply to 
activities involving AI to avoid creating sweeping new authorities or agencies that  
awkwardly or inconsistently overlap with current the AI Action Plan. 
 


3 2.Quality Assurance and Oversight
The AI Action Plan should utilize risk -based approaches to ensure that the use of 
AI aligns with  any relevant recognized standards of safety,  and efficacy. Small 
software and device  companies benefit from understanding the distribution of risk 
and liability in building, testing,  and using AI tools. To the extent, t he AI Action 
Plan address es liability , it should ensure the appropriate  distribution and 
mitigation of risk and liability. Specifically, those in the value chain with the  ability 
to minimize risks  based on their knowledge and ability to mitigate should have  
appropriate incentives to do so. Some recommended areas of focus include:  
•Ensuring AI is safe  and efficacious.
•Encouraging AI developers to consistently utilize rigorous procedures and
enabling them to document their methods and results.
•Encouraging those developing, offering, or testing AI systems intended for
consumer use to provide truthful and easy -to-understand representations
regarding intended use and risks that would be reasonably understood by
those intended, as well as expected, to use the AI solution.
The AI Action Plan should ensure that a gencies apply existing policies to the use 
of AI prior to advancing new policies to only fill existing gaps; foster a risk -based 
approach to recognize the diverse and heterogenous use cases for AI; and align 
to international standards —including ISO42001 li fe cycle quality management 
standard.  
The App Association also urges OSTP  to align with our recommendations on the 
roles and interdependencies in the AI value chain, which support the theme of a 
shared responsibility for safety and efficacy.3 In this framework, the App 
Association proposes clear definitions of stakeholders across the healthcare AI 
value chain, from development to distribution, deployment, and end use; 
discusses roles for supporting safety, ethical use, and fairness for each of these 
important stakeholder groups that  are intended to illuminate the 
interdependencies between these actors, thus advancing the shared 
responsibility concept.  
3.Thoughtful Design
The AI Action Plan should encourage design of AI systems that are informed by 
real-world  workflows, human -centered design and usability principles, and end -
user needs. AI systems  should facilitate a transition to changes in the delivery of 
goods and services that benefit consumers and businesses. The design, 
development, and success of AI should leverage collaboration and dialogue 
among users, AI technology developers, and other st akeholders to have all  
perspectives reflected in AI solutions.  
3 This framework is included as Appendix A  to this comment.  


4 
 4. Access , Infrastructure,  and Affordability  
 
The AI Action Plan should enable products and services that involve AI systems 
to be  accessible and affordable. Significant resources may be required to scale 
systems.  Policymakers should also ensure that developers can build accessibility 
features into their  AI-driven offerings and avoid policies that limit their 
accessibility options.  
 
The U.S. government should take proactive measures to strengthen American AI 
infrastructure to ensure access and affordability. The AI Action Plan should :  
• Provide f ederal agenc ies with g reater authority to site and permit interstate 
transmission lines deemed critical to national interests. This includes 
streamlining approvals and, if necessary, leveraging eminent domain.   
• Prevent states from imposing regulations that disproportionately burden 
data centers  that are critical for AI processing .   
• Accelerate the development of domestic nuclear power, including small 
modular reactors (SMRs), through streamlined regulations, tax incentives, 
and loan guarantees. This will provide a stable, low -carbon power source 
for data centers.  
 
5. Data Bias  
 
The errors in  datasets used for AI innovation  will remain one of the more 
pressing issues with  AI systems that utilize machine learning techniques in 
particular. Regulatory agencies should  examine data provenance and bias issues 
present in the development and uses of AI solutions  to ensure that bias in 
datasets does not result in harm to users or consumers of products or  services 
involving AI, including through unlawful discrimination.  
 
6. Research and Transparency  
 
The AI Action Plan should support and facilitate research and development of AI 
by prioritizing  and providing sufficient funding while also maximizing innovators’ 
and researchers’ ability to  collect and process data from a wide range of sources. 
Research on the costs and benefits of  transparency in AI should also be a priority 
and involve collaboration among all affected  stakeholders to develop a better 
understanding of how and under which circumstances  transparency mandates 
would help address risks arising from the use of AI systems.  
 
We appreciate President Trump’s acknowledgment, in the January 23 Executive 
Order establishing the President’s Council of Advisors on Science and 
Technology, of the critical research and innovation enabled by initiatives such as 
the National Science Foundation’s National Artificial Intelligence Research 
Resource (NAIRR). Launched i n 2024, NAIRR provides researchers with access 
to datasets, models, training, cloud computing, and AI credits to drive 
groundbreaking advancements in AI applications across defense, healthcare, 


5 energy, and other sectors vital to U.S. competitiveness.  However, the 
technology developer -donated credits that support NAIRR will expire at the end 
of the two -year pilot. While Congress has allocated some funding for the 
program’s administration, NAIRR’s  continuation depends on congressional 
appropriations for researcher technology credits. The NAIRR Task Force —
formed under the National AI Initiative Act of 2020, signed into law by President 
Trump —estimated that sustaining NAIRR requires $2.25 billion in federal 
appropriations over six years to ensure researchers have the resources needed 
to develop transformative AI solutions and address society’s most pressing 
challenges. The task force recommended congressional appropriations of $750 
million every two y ears, and we urge the Administration to incorporate this 
essential funding into future budget proposals to Congress.  
7.Modernized Privacy and Security Frameworks
The many new AI-driven uses for data, including sensitive personal information, 
raise privacy  questions. They also offer the potential for more powerful and 
granular privacy controls for  consumers. Accordingly, any policy framework 
should address the topics of privacy, consent,  and modern technological 
capabilities as a part of the policy development process. Requirements created 
pursuant to the AI Action Plan  must be scalable and assure that an individual’s 
data is properly protected, while  also allowing the flow of in formation and 
responsible evolution of AI. A balanced framework  should avoid undue barriers to 
data processing and collection while imposing reasonable data  minimization, 
consent, and consumer rights frameworks.  
8.Standards
The advantages of industry -led standardization in AI development are well 
established  and have been reinforced by the first Trump Administration  in 
Executive Order 13859 , which  emphasized the need for the U nited States  to 
drive the development of technical standards, reduce barriers to AI testing and 
deployment, and enable both new AI -driven industries and AI adoption across 
existing sectors. A key benefit of private sector and stakeholder participation in AI 
developmen t is the flexibility it provides to adapt to the rapid evolution of the 
technology. American companies have been at the forefront of AI innovation, and 
the U nited States  must continue to harness and support their leadership. The 
most effective approach is to sustain a private -sector -driven model, with strong 
government support.   
While private industry should lead AI standardization efforts, the U.S. 
government plays a vital role in supporting and participating in these initiatives. 
This includes providing resources, investing in research to sustain America’s AI 
dominance, and faci litating contributions to global standards. Additionally, the 
Trump Administration should take proactive steps to prevent AI standardization 
from being undermined by standard -essential patent (SEP) challenges that have 


6 
 affected other technologies, such as cellular and Wi -Fi. The longstanding U.S. 
model —where the government promotes and backs private, voluntary, and 
consensus -based standard setting —remains the best path forward.   
 
The United States has the leading global patent system due to its strong  
emphasis on developing mechanisms that support innovation and foster 
competition and technological progress. When patent holders choose to 
contribute their technologies to a technical standard, they understand and agree 
that their patents may be needed to enable reasonable access to the standard 
and provide standard -setting organizations (SSOs) with a commitment that they 
will license their SEPs on fair, reasonable, and non -discriminatory (FRAND) 
terms to balance the anticompetitive risks associated with standard setting. The 
SEP holder understands and agrees that , by contributing to the standardization 
process, it cannot unduly exclude competitors from a standard past requiring a 
license  on FRAND terms . Opportunistic SEP holders have distorted this system 
by taking advantage of SSO policies that have ambiguous definit ions of FRAND 
to manipulate a fair licensing negotiation process by, for example, overcharging 
or refusing to license to certain entities in a supply chain. Since SSOs facilitate 
access to technical standards that touch various industries, these opportunis tic 
SEP holders plague many verticals, always looking for the next market to extract 
additional and unrelated value for their SEP. The anticompetitive harms 
experienced in the SEP licensing ecosystem disrupt fair usage of technical 
standards that support e fficient innovation.  
 
The AI Action Plan should position the U.S. government to:  
• Restrict the ability of foreign SEP holders to impose injunctions on U.S. 
companies in foreign jurisdictions.  
• Leverage diplomatic influence to pressure foreign governments to prevent 
their courts from enabling SEP -related hold -ups that disadvantage 
American businesses.   
• Implement domestic safeguards to curb SEP hold -up, including  reforming 
the U.S. International Trade Commission  (ITC) to limit foreign entities from 
leveraging costly SEP exclusion orders against U.S. companies ; and 
defending the Supreme Court’s eBay  decision, which eliminated the 
automatic presumption of injunctions in patent disputes.  
 
9. Global Leadership and Trade  
 
To maintain America’s AI leadership, the AI Action Plan must include a strong 
international strategy that keeps foreign markets open to U.S. AI. To achieve this 
and strengthen both economic and national security, we urge you to advance a 
U.S.-led vision of innovation -driven AI governance, protec t critical AI assets, and 
prevent foreign governments from obstructing U.S. AI innovators and deployers.  
We encourage the AI Action Plan to address the U.S.  role as a global leader that 
advocate s for a holistic vision of trustworthy AI rooted in American values, 


7 designed to empower workers , and drive global economic growth . The AI Action 
Plan should enable the U.S. government to : 
•Proactively engage with foreign governments to prevent harmful AI
policies that undermine U.S. leadership, restrict commercial AI
deployment, or block significant U.S. AI investments.
•Refine and enforce export control policies to restrict adversaries' access to
critical technologies.
•Reinforce core U.S. digital trade policies to uphold cross -border data
flows, resist forced data localization, and protect AI’s algorithmic integrity
(including model weights) from exploitation or coercive transfers, ensuring
AI’s full potential is realize d.
•Aggressively safeguard U.S. digital market access from policies that erode
competitiveness, seek unauthorized access to trade secrets, or impose
excessive taxes and regulatory burdens on American companies , such as
the European Union’s (EU’s) AI Act and the EU’s Digital Markets Act .
•Strengthen a trusted AI ecosystem that secures national and economic
interests, including critical infrastructure, by enhancing cybersecurity
measures.
•Embed AI priorities into the negotiating framework of future trade
agreements, including free trade agreements  and industry -specific
accords.
•Lead the AI and digital agenda across key international forums (UN, G7,
WTO, G20, OECD), ensuring the U nited States  remains at the forefront of
global AI governance.
•Proactively engage with foreign governments shaping AI regulations to
safeguard U.S. market access and champion an innovation -driven
approach —advocating for adherence to global technical standards,
leveraging existing regulatory frameworks where applicable , and
promoting pro -innovation policies like open government data.
10. Education
The AI Action plan  should support education for the advancement of AI, promote 
examples  that demonstrate the success of AI, and encourage stakeholder 
engagements to keep  frameworks responsive to emerging opportunities and 
challenges.  
•Consumers should be educated as to the use of AI in the service(s) they
are using.
•Academic education should include curriculum that will advance the
understanding of and  ability to use AI solutions.
11. Intellectual Property
The protection of intellectual property (IP) rights is critical to the evolution of AI. In 
developing  approaches and frameworks for AI governance, policymakers should 


8 ensure that compliance  measures and requirements do not undercut  safeguards 
for IP or trade secre ts. 
AI is an important tool for innovators and authors of creative works to use in their 
process to develop IP protected works. Similarly, AI as we know it is constantly 
evolving , and its capability is not fully realized at this time. In order to continue 
incent ing innovative and creative works within the AI space and through the 
assistance of AI, the U.S. Patent and Trademark Office and the U.S. Copyright 
Office must focus their IP issuance and registration analysis on the amount of 
human involvement rather than AI  involvement.  
While promoting transparency, we advise against disclosing proprietary 
information, such as training data. The mere fact that a model was trained on 
specific data does not guarantee its effectiveness for a given use case. Instead, 
the scient ifically sound and industry -standard approach to assessing 
performance is testing the model in its intended environment using data 
representative of the target population.  
The App Association appreciates OSTP’s consideration of the above views.  
Sincerely,  
Brian Scarpelli  
Senior Global Policy Counsel  
Chapin Gregor  
Policy Counsel  
ACT | The App Association  
1401 K St NW (Ste 501)  
Washington, DC 20005  


ACT | The App Association  AI Roles & 
Interdependency Framework  
1 Overview:  Artificial Intelligence (AI), especially generative AI, is already a powerful tool  for consumers and companies . App 
Association small business members have a vital role in advancing AI’s positive impacts  by identifying new and novel opportunities 
where the responsible use of AI can solve expensive problems and provide new efficiencies for consumers and businesses.  
While AI capabilities are already positively transforming American society, the App Association also recognizes that the same  
capabilities raise unique challenges that the government, private sector, and others have an important role in addressing acr oss 
development, distribution, deployment, and end use phases. The App Association has worked proactively  with its diverse and 
innovative community of small businesses  to develop this consensus taxonomy, which describes the roles and interdependencies of 
variou s actors in the value (or supply) chain of AI solutions . These roles include several AI/ML developer subgroups, deploying 
organizations, end users, standard -setting organizations, certification and test beds, specialty boards and licensing bodies, and 
academic institutions. Many of these stakeholders map to acto rs in the National Institute for Standards and Technology’s (NIST’s) AI 
Risk Management Framework (RMF), which we indicate on the far right of the matrix below.  
While  the App Association has created comprehensive policy principles for AI governance , there we have several recommendations 
from this roles and interdependencies document . The App Association recommends : (1) that requirements placed on small 
business AI developers and users be based on demonstrated harms; (2) the leveraging  of a risk -based approach to AI harm 
mitigation where the level of review, assurance, and oversight is proportionate to those demonstrated harms; and (3) that 
those in AI value chains with the ability to minimize risks based on their knowledge and ability hav e appropriate 
responsibilities and incentives to do so.  


ACT | The App Association  AI Roles & 
Interdependency Framework  
2 Stakeholder Group  Definition  Roles  NIST AI RMF 
Actor Tasks  
AI/ML Developers  Someone who designs, codes, 
researches, or produces an AI/ML 
system or platform for internal use 
or for use by a third party.  
See below for defined 
Subgroups of this Stakeholder 
Group along with 
recommendations specific to 
that Subgroup.  •Informing deployers and users of data
requirements/definitions, intended use
cases/populations and applications (e.g., disclosing
sufficient detail allowing providers to determine when an
AI-enabled tool should reasonably apply to the individual
they are t reating), including whether the AI/ML tools are
intended to augment human work versus automate
legal and regulatory requirements.
• 
existing AI/ML guidelines on research and ethics,
leading standards, and other resourc es.
•Employing algorithms that produce repeatable results
and, when feasible, are auditable, and make decisions
that comply with relevant sector -specific requirements.
•Using risk management approaches that scale to the
potential likely harms posed in intended use scenarios to
support safety, protect privacy and security, avoid
•Providing information that enables those further down
the value chain can assess the quality, performance,
•Aligning with relevant ethical obligations and
international conventions on human rights and
supporting the development of new ethical guidelines to
address emerging issues.AI 
Deployment; 
Operation and 
Monitoring; 
Test, 
Evaluation, 
Verification, 
and Validation 
(TEVV); 
Human 
Factors; 
Domain 
Expert; AI 
Impact 
Assessment; 
Governance 
and Oversight  
Stakeholder 
Subgroup  Definition  Roles  NIST RMF Actor Tasks  
Foundation 
Model 
Developer  Someone who creates or 
modifies large and 
generalizable machine 
learning models that can be Building on the cross -AI/ML Developer roles 
noted above:  
• 
might be present in its Foundation Model, AI Deployment; Operation and 
Monitoring; Test, Evaluation, Verification, 
and Validation (TEVV); Human Factors; workflows, and status of/compliance with all applicable
Prioritizing safety, effectiveness, transparency, and data
privacy and security from the earliest stages
of design, leveraging (and, where appropriate, updating)
harmful outcomes.
and utility of AI/ML tools.
Assessing what efficacy and safety issues


ACT | The App Association  AI Roles & 
Interdependency Framework   
 
3 
 Stakeholder 
Subgroup  Definition  Roles  NIST RMF Actor Tasks  
used/adapted for various 
downstream tasks and 
applications, such as 
natural language 
processing, computer 
vision, or software 
development.  and documenting steps taken to mitigate 
those issues in its Transparency 
Documentation (e.g., Transparency 
Notes, System Cards and product 
documentation).  
• Providing clear guidance on (1) how to 
use and adapt its Foundation Model for 
various foreseeable downstream tasks 
and applications, and (2) what limitations 
or risks may arise from doing so based 
on challenges discovered during testing 
and deployment.  Domain Expert; AI Impact Assessment; 
Governance and Oversight  
AI Platform 
Developer  Someone who leverages 
existing foundation models 
and builds an industry -
agnostic platform that 
enables other developers 
to access, customize, and 
deploy these models for 
various use cases and 
applications, such as 
natural language 
processing, computer 
vision, and/or software 
development.  Building on the cross -AI/ML Developer roles 
noted above:  
• 
using or modifying existing foundation 
models for its AI Platform, and 
documenting these issues and steps 
taken to address them in its transparency 
documentation (e.g., tra nsparency notes, 
system cards and product 
documentation).  AI Deployment; Operation and 
Monitoring; Test, Evaluation, Verification, 
Domain Expert; AI Impact Assessment; 
Governance and Oversight  
Use Case AI 
Platform 
Developer  Someone who creates or 
uses AI -powered platforms 
that are tailored for a 
particular domain or sector. 
These platforms may 
leverage foundation models 
(or other types of machine 
learning models or 
solutions), such as AI 
platforms, that are suitable 
for domai n-specific Building on the cross -AI/ML Developer roles 
noted above:  
• Meeting specific requirements and 
standards of the domain to address 
unique accuracy, efficacy, explainability, 
and compliance needs.  
• Testing for, identifying, and mitigating any 
domain -specific outcomes or 
performance needs, and documenting 
these issues and the steps it has taken to 
address them in its transparency AI Deployment; Operation and 
Monitoring; Test, Evaluation, Verification, 
and Validation (TEVV); Human Factors; 
Domain Expert; AI Impact Assessment; 
Governance and Oversight  Testing for, identifying, and mitigating             and Validation (TEVV); Human Factors;
safety issues that may arise from
efficacy and safety issues that may affect


ACT | The App Association  AI Roles & 
Interdependency Framework  
4 Stakeholder 
Subgroup  Definition  Roles  NIST RMF Actor Tasks  
problems and data 
sources.  documentation (e.g., transparency notes, 
system cards and product 
documentation).   
AI Solution 
Developer  Someone who creates 
complete digital tools and 
technologies for a domain. 
They may build or 
incorporate AI solutions 
with both use case AI 
platforms, which are 
specialized for the domain, 
and AI platforms, which are 
more general and 
adaptable for various use 
cases and applications.  Building on the cross -AI/ML Developer 
responsibilities noted above:  
•Specifying appropriate uses for its
issues that may exist in the underlying
foundation models, AI platforms, or
domain -specific AI platforms.
•Designing user interfaces to enable an
end user to safely and effectively act
upon the output of the tool, such as
providing explanations, feedback
mechanisms, or human oversight options,
providing clear documentation to
Deploying Organizations and Users t oAI Deployment; Operation and 
Monitoring; Test, Evaluation, Verification, 
and Validation (TEVV); Human Factors; 
Domain Expert; AI Impact Assessment; 
Governance and Oversight  
Stakeholder Group  Definition  Role s NIST AI RMF 
Actor Tasks  
Deploying 
Organization  Someone who is  deploy ing 
solutions built by AI Solution 
Developers. They may also have 
their own internal IT staff that 
employ use case AI  platforms or 
general AI platforms to develop 
their own custom AI solutions . Respecting that  managing AI/ML risks will be more challenging 
for small to medium -sized organizations depending on their 
capabilities and resources:  
•Adopting  AI/ML Developer  instructions for use,
specify ing appropriate uses for Users  through
may exist in the underlying foundation models, AI
platforms, or use case AI platforms.
•Developing and leveraging solutions that augment
efficiencies in automation, facilitate administrative
simplification/reduce workflow burdens, and are  fit for
purpose.
•Setting organization policy/d esign ing workflows to
reduce the likelihood that a User will act upon the outputAI 
Deployment; 
Operation and 
Monitoring; 
Domain 
Expert; AI 
Impact 
Assessment; 
Procurement; 
Governance 
and Oversight  governance policies to avoid safety issues thatsolution to avoid amplifying safety
help them avoid safety issues.


ACT | The App Association  AI Roles & 
Interdependency Framework  
5 Stakeholder Group  Definition  Role s NIST AI RMF 
Actor Tasks  
safety issues (tailored explanations, feedback 
mechanisms, and/or human oversight options ). 
•Assuring that AI/ML systems allow for the individualized
assessment of domain -specific circumstances and
flexibility to override automated decisions, ensuring that
use of AI/ML does not improperly reduce or withhold
intended benefits or inappropriately ove rride human
judgement.
•Developing support mechanisms for the use of AI/ML by
providers based on validation, aligning with decision -
making processes familiar to the domain and high -
quality evidence.
•Developing organizational guidance on how the AI
solution should and should not be used.
•Creating engagement pathways to support dialogue  with
AI use case developers, AI solution developers, or any
other applicable AI/ML developer, to enable  ongoing
updates to address evolving risks and benefits of AI
solution uses .
•Creating risk -based, tailored communications and
engagement plans to enable  easily understood
explanations to customers about how the AI solution
was developed, its performance  and maintenance , and
how it aligns with the latest best practices and regulatory
requirements.
AI End Users  Someone  who directly interact s 
with or benefit s from the AI 
solutions that are built by AI 
Solution  Developers or by the 
internal IT staff of the Deploying 
Organization . Respecting that managing AI/ML risks will be more challenging 
for small to medium -sized organizations depending on their 
capabilities and resources:  
•Aligning with consensus AI/ML definitions, present -day
and future AI/ML solutions, the future of AI/ML changes
and trends.
•Taking required training and incorporating  employer
guidance about  use of AI/ML solutions .
•Documenting  (through automated processes or
otherwise)  and reporting any issues or feedback to theAI 
Deployment; 
Operation and 
Monitoring; 
Domain 
Expert; AI 
Impact 
Assessment; 
Procurement; 
Governance 
and of the tool in a way that would cause efficacy or


ACT | The App Association  AI Roles & 
Interdependency Framework  
6 Stakeholder Group  Definition  Role s NIST AI RMF 
Actor Tasks  
harms (where AI/ML’s use is known by the User).  
•Ensuring there is appropriate  review of the output or
recommendations from each AI solution prior to acting
on it to make decisions, if relevant  (where AI/ML’s use is
known by the User) .
•Raising awareness of and acting according to
customers’ rights and choices when using AI solutions,
such as consent, access, correction, or deletion of their
personal data.Oversight ;  
Human 
Factors  
Standard -Setting 
Organizations  An organization whose primary 
function is developing, 
coordinating, promulgating, 
revising, amending, reissuing, 
interpreting, or otherwise 
contributing to the usefulness of 
technical standards to those who 
employ them.  •Develop ing and promot ing adoption of international
voluntary/non -regulatory consensus standardized
approaches and resources to steward a shared
responsibility approach to technology standards that
include or are otherwise related to AI.Human 
Factors; 
Domain 
Expert; AI 
Impact 
Assessment; 
Governance 
and Oversight  
Certification 
Bodies & Test Beds  A certification body is a third -party 
organization that assures the 
conformity of a product, process  or 
service to specified requirements.  
A test bed is a platform for 
conducting rigorous, transparent, 
and replicable testing of scientific 
theories, computing tools, and new 
technologies to a standard.  •Creat ing and mak ing available transparent and reliable
processes for the assurance of conformity to voluntary
AI standards.
•Creating and mak ing available voluntary sandbox
environments  to help evaluate the usability and
performance of AI/ML -based  high-performance
computing applications to  advance the understanding of
how reliable and efficacious AI, and to provide an
appropriate assurance of reliability and efficacy.Test, 
Evaluation, 
Verification, 
and Validation 
(TEVV); 
Human 
Factors; 
Domain 
Expert; AI 
Impact 
Assessment; 
Governance 
and Oversight  
Accrediting and 
Licensing Bodies, 
Specialty Societies 
and Boards  Accrediting and licensing bodies 
are governing authorities that 
establish the suitability of any 
participating certification body. 
Notably, state -level board s serve •Based on needs and expertise, develop ing and setting
the standard of practice/behavior  and ethical guidelines
to address emerging issues with the use of AI/ML in the
relevant domain .
•Identifying  the most appropriate uses of AI -enabled
technologies and d evelop ing and disseminat ingTest, 
Evaluation, 
Verification, 
and Validation 
(TEVV); 
Human developer, such as errors, vulnerabilities, or


ACT | The App Association  AI Roles & 
Interdependency Framework  
7 Stakeholder Group  Definition  Role s NIST AI RMF 
Actor Tasks  
this purpose for certain professions  
to standards set by each state.  
Specialty societies are 
organizations for specialized 
professionals . guidance and education on the responsible deployment 
of AI/ML , both generally and for specialty -specific uses . Factors; 
Domain 
Expert; AI 
Impact 
Assessment; 
Governance 
and Oversight  
Academic 
Education 
Institutions  Tertiary educational institutions, 
professional schools, or forms a 
part of such institutions, that teach 
and award professional degree s. •Develop ing and teaching  curriculum that will advance
understanding of and ability to use AI/ML solutions
responsibly , which should be assisted by inclusion of
data scientists and engineers as instructors  as needed .
•Develop ing curriculum to advance the understanding of
data science research to help inform ethical bodies.Human 
Factors; 
Domain 
Expert; AI 
Impact 
Assessment  


