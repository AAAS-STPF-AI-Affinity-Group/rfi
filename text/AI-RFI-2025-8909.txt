PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-37ow-pm 2e
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-8909
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anthony Lilienthal
Em ail:  
General Comment
I would like to protest the deregulation and the 'rem oval of guard rails' in the developm ent of AI. We speak of national security, yet
rem oves an individual's ability to fight to have their inform ation rem oved from  AI training databases. We need these guardrails, especially
in the absence of governm ent or third party oversight. Others will speak to the integrity of artists (which I agree with wholeheartedly);
however, let m e approach this from  a different angle.
Recent events have illustrated that we NEED tighter regulation on AI, ones shore up the trust in the data we find from  our news and
inform ation sources. This is NOT an argum ent that 'we are on a slippery slope', that if we do not stop it now, we will have no ability to
stop it later. ALREADY TODAY, we are seeing exam ples of slander and dehum anization when bad actors use freely available AI tools.
We have seen im provem ents in deepfakes and faked videos (a couple exam ples include the president kissing Elon Musk's feet and the
stolen likenesses of celebrities/business owners in com prom ising and som etim es pornographic content). These are only a couple of the
issues we've already seen, and AI is only continuing to im prove each day. Thankfully, m any of our current exam ples have been easy to
detect due to their flagrancy; however, as AI use continues to grow, its ability to alter video, visual, written, and listening m edia will only
becom e harder to detect. We NEED a way to police this. The governm ent is a beast to direct, and thus it cannot contend with the rapidly
growing space of AI. As legislature is developed to regulate the industry, we m ust em power the people to regulate it for them selves, to
hold the AI industry accountable for the works it uses and the inform ation it presents. This includes the ability to take legal action and/or to
rem ove an individual's inform ation (personal, statistical, legal, artistic, etc)from  AI training databases. Do NOT "rem ove the guardrails" of
the AI industry. Make sure these industries are held to task and m ade to work for Am ericans; not in spite of Am ericans.


