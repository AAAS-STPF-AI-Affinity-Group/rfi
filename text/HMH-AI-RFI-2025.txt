Via Electronic Submission - 
Michael Kratsios 
Director 
Office of Science and Technology Policy 
Executive Office of the President 
1600 Pennsylvania Ave 
Washington, DC 20500 
March 15, 2025  
RE: Request for Information on the Development  of an Artificial 
Intelligence  (AI) Action Plan (Docket No. NSF_FRDOC_0001-3479, 
90 FR 9088)  
Dear Director Kratsios, 
On behalf of Hackensack Meridian Health (HMH), we thank you for the  opportunity  
to comment on the Office of Science and Technology Policy (OSTP) Request for 
Information on the Development of an Artificial Intelligence (AI) Action Plan (or the 
“AI Action Plan”).1 
HMH is the largest, most comprehensive, and truly integrated health care network in 
New Jersey, comprising a network of hospitals that includes three academic medical 
centers, one university teaching hospital, two children’s hospitals, nine community 
hospitals, a behavioral health hospital, two rehabilitation hospitals and one 
long-term acute care hospital. Six of our 18 hospitals maintain robust academic 
medical programs. HMH also has more than 500 patient care locations, including 
ambulatory care centers, surgery centers, home health services, long-term care and 
assisted living communities, ambulance services, lifesaving air medical 
transportation, fitness and wellness centers, rehabilitation centers, urgent care 
centers and physician practice locations. HMH has more than 36,000 team members 
and more than 7,000 physicians within its network and is a distinguished leader in 
health care philanthropy, committed to the health and well-being of the 
communities it serves. 1 90 Fed. Reg. 9088 (February 6, 2025). 
343 Thornall Street | Edison, NJ 08837 |  | HackensackMeridianHealth.org 


Letter to Director Kratsios re: Docket No. NSF_FRDOC_0001-3479 
March 15, 2025 
Page 2 
 
 
 
HMH is integrating AI-powered tools into the network, enhancing healthcare 
delivery and improving patient outcomes. Some specifics include, AI is being used to 
analyze mammograms in real time, highlighting signs of breast cancer, enhancing 
diagnostic accuracy, leading to timely intervention and better outcomes. 
Additionally, AI assisted robotic precision surgery is being used to enhance 
precision, enabling minimally invasive procedures with smaller incisions. HMH also 
utilizes AI for optimizing hospital workflows and managing electronic health records 
efficiently. This strategic adoption of AI reflects HMH’s commitment to innovation 
and excellence in healthcare. 
 
Overview of HMH’s Comments 
 
HMH supports the responsible development and deployment of AI in health care 
and recognizes the critical role of government policy in shaping AI innovation. We 
appreciate the opportunity to provide input on the AI Action Plan and strongly 
advocate for policies that promote safe, effective, and equitable AI adoption while 
avoiding unnecessary regulatory burdens that could stifle innovation. 
 
Our comments focus on several key areas, including the need for standardized 
compliance frameworks for AI developers, clear liability structures for AI-driven 
clinical decision-making, and sustainable reimbursement models to support AI 
integration in health care. We urge OSTP to prioritize policies that ensure AI systems 
used in health care are transparent, validated, and aligned with patient safety 
standards, while also fostering a regulatory environment that encourages continued 
AI advancement. HMH recommends leveraging existing frameworks to 
promote responsible AI development, adopting liability models that 
begin to shift some responsibility for AI-related risks to developers, 
ensuring predictable Medicare and Medicaid coverage for AI-enabled 
medical applications, and strengthening data privacy frameworks for AI 
use in health care.  
 
Establish Compliance Standards for AI Developers to Promote 
Responsible AI 
 
Health care organizations such as HMH increasingly rely on AI-driven tools for 
clinical decision-making, patient monitoring, and operational efficiency. However, 
inconsistent development standards and a lack of transparency in AI models pose 
risks to patient safety and the quality of health care being delivered. Without clear 
guidelines, hospitals and providers struggle to assess whether AI systems adhere to  
 


Letter to Director Kratsios re: Docket No. NSF_FRDOC_0001-3479 
March 15, 2025 
Page 3 
responsible development practices, mitigate bias, and function reliably across 
diverse patient populations. 
We recommend that regulators mandate AI developers to adhere to standardized 
frameworks for responsible AI, such as the National Institute of Standards and 
Technology (NIST) AI Risk Management Framework (RMF)2, which provides 
guidelines on fairness, transparency, bias mitigation, and explainability. AI vendors 
should be required to demonstrate compliance with such standards through 
independent audits and certifications. Hospitals and health care providers can then 
use compliance status as a criterion in AI procurement decisions, shifting some of 
the responsibility for responsible AI use onto AI developers. 
Establish Clear AI Liability Frameworks at Federal Level 
One of the most pressing concerns among physicians and hospitals is determining 
liability when AI-driven recommendations lead to patient harm. AI introduces an 
element of shared decision-making between the physician, the patient, and the AI 
system, creating uncertainty over who holds responsibility for AI-related medical 
errors. Current legal frameworks do not fully address this issue, leaving health care 
organizations at risk of liability exposure without clear protections. 
HMH recognizes the immense potential and unique risks associated with deploying 
AI in patient care. As health care organizations, such as HMH, consider larger 
investments in medical AI tools, they face growing concerns about liability risks, 
both regarding third-party harm and potential losses to their own assets and income. 
Importantly, AI adoption also introduces new insurance challenges for health care 
providers, especially related to coverage for system failures or adverse outcomes. 
We recommend regulators adopt a federal risk-based liability model where AI 
developers bear primary liability for the safety, accuracy, and fairness of their 
systems. This approach aligns with the American Medical Association's (AMA) Policy 
H.480.939, which states that the parties best positioned to manage AI risks should
be responsible for them.3 Developers of autonomous AI with clinical applications
should be required to hold medical liability insurance and indemnify hospitals
against harm from system failures. Meanwhile, hospitals and physicians should not
be held liable for decisions made based on AI recommendations, if they adhere to
established medical standards.
3 https://www.ama-assn.org/system/files/ama-ai-principles.pdf 2 https://www.nist.gov/itl/ai-risk-management-framework 


Letter to Director Kratsios re: Docket No. NSF_FRDOC_0001-3479 
March 15, 2025 
Page 4 
 
 
 
 
Ensure Federal Reimbursement for AI Usage in Health Care 
 
Despite AI’s potential to improve clinical outcomes and health care efficiency, its 
adoption is often hindered by uncertain reimbursement structures. Medicare, 
Medicaid, and private insurers lack clear policies on how AI-driven medical services 
should be reimbursed, discouraging providers and health care organizations from 
integrating AI solutions that require upfront investment. Without financial 
incentives, hospitals may struggle to justify the costs associated with AI adoption. 
 
We recommend that Medicare and Medicaid establish clear and predictable 
reimbursement policies for AI-enabled medical technologies, clinical applications, 
and services. Coverage decisions should be based on AI’s demonstrated impact on 
patient outcomes, ensuring that reimbursement captures both the cost and value of 
AI integration.  
 
Strengthen Data Privacy Frameworks for AI in Health Care 
 
The integration of AI into health care operations is transforming patient care, 
diagnostics, and operational efficiency. However, as AI systems increasingly process 
large volumes of sensitive health information, existing data privacy and 
cybersecurity frameworks must evolve to ensure robust protections while supporting 
continued innovation. AI introduces unique privacy risks that challenge traditional 
data protection models, particularly regarding the potential for re-identification of 
de-identified data and the responsible use of patient information for AI 
development. 
 
Under current frameworks like the Health Insurance Portability and Accountability 
Act (HIPAA), organizations can use health data for research or other secondary 
purposes if the data is deidentified.4 HIPAA permits two methods for this: (1) the 
"Safe Harbor" method, which requires the removal of 18 specific identifiers such as 
names, geographic information, and biometric data; and (2) the "Expert 
Determination" method, where a qualified expert assesses the data to confirm that 
the risk of re-identification is statistically minimal. HMH is concerned that 
advancements in computing power and data processing techniques are making 
re-identification of this de-identified data increasingly feasible. This raises concerns 
that traditional HIPAA de-identification standards may no longer provide sufficient 4 https://www.hhs.gov/hipaa/for-professionals/special-topics/de-identification/index.html 
 
 


Letter to Director Kratsios re: Docket No. NSF_FRDOC_0001-3479 
March 15, 2025 
Page 5 
protection, particularly as AI vendors often seek to use health data for continuous 
product development. Furthermore, certain types of health information, such as 
voice recordings from ambient AI technologies, are inherently difficult or even 
impossible to fully de-identify, posing further privacy risks. 
To promote responsible AI development while safeguarding patient trust and 
privacy, HMH recommends a series of targeted actions to strengthen data protection 
in the context of AI technologies. 
●First, federal regulators should modernize HIPAA and other health
privacy frameworks to explicitly address the complexities
introduced by AI. This includes clarifying how AI applications interact with
existing HIPAA protections and establishing clear guidelines that enable
responsible AI-driven research while maintaining strong standards for data
privacy. Modernized frameworks would help ensure that AI systems handling
personal health data are appropriately regulated, supporting both innovation
and patient confidence.
●Second, regulators should establish stronger privacy guidelines for
AI vendors who use health data for product development. While
HIPAA’s de-identification mechanisms and safe harbor protections offer a
foundational level of security, they may not be sufficient to mitigate the
growing risk of re-identification. Vendors should be required to adhere to
responsible data use agreements that extend beyond standard
de-identification practices, ensuring ethical and transparent use of patient
data throughout product development. For data types that cannot be fully
de-identified, such as voice data, regulators should also consider establishing
additional protections to ensure data is handled responsibly and with a high
standard of privacy.●Third, HMH regulators should promote consumer choice
mechanisms. Regulators should require clear options for patients to opt in
or opt out of having their data used for AI model development, even when the
data is technically de-identified. This approach strengthens transparency,
respects patient autonomy, and helps build trust in AI-driven health care
solutions by ensuring individuals have a voice in how their data is used.


Letter to Director Kratsios re: Docket No. NSF_FRDOC_0001-3479 
March 15, 2025 
Page 6 
Conclusion 
HMH strongly supports the Administration’s efforts to drive innovation in AI,  
recognizing the transformative potential of these technologies to enhance health care 
delivery, improve patient outcomes, and advance medical research. However, as AI 
becomes increasingly integrated into clinical decision-making and operational 
processes, it is essential to establish clear and thoughtful federal guardrails to ensure 
that AI systems are transparent, validated, and aligned with patient safety standards. 
Thank you for the opportunity to comment on the AI Action Plan.  We would  be 
pleased to discuss any of the above in greater detail at any time. If you have 
questions, please feel free to contact me at  or 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused 
by the government in developing the AI Action Plan and associated documents 
without attribution. 
Sincerely, 
Sarah Lechner 
Senior Vice President, Chief of External Affairs  


