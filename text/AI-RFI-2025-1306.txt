PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 14, 2025
Status: 
Tracking No. m 88-g9dr-9k52
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1306
Com m ent on FR Doc # 2025-02305
Submitter Information
Em ail:  
Organization:  AI & Partners, B.V.
General Comment
To the Office of Science and Technology Policy,
AI & Partners applauds the White House’s com m itm ent to fostering AI innovation while ensuring security, ethical governance, and
econom ic growth. We urge policym akers to prioritize public-private partnerships, robust regulatory fram eworks, and sustainable AI
infrastructure. Transparency, fairness, and security m ust be foundational to AI developm ent, particularly in high-risk applications. By
balancing innovation with responsible oversight, the U.S. can lead global AI governance while safeguarding national interests. We
appreciate the opportunity to contribute and look forward to policies that support trustworthy AI for all.
Thank you,
Michael Charles Borrelli
AI & Partners, B.V.
Attachments
OSTP - AI Action Plan- Request for Inform ation - 2025-03-12


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
1 
The White House   
Office of Science and Technology Policy (OSTP)  
1600 Pennsylvania Ave NW  
Washington, DC 20500  
Request for Information on Artificial Intelligence Action 
Plan1 
To the Office of Science and Technology Policy,  
AI & Partners appreciates the opportunity to contribute to the ongoing efforts of the U.S. government 
in shaping the future of artificial intelligence (AI). As a global leader in AI governance, we commend the 
White House’s commitment to ensuring that AI development aligns with American values of innovation, 
security, and economic competitiveness. This letter outlines our recommendations for advancing 
trustworthy AI innovation , establishing global leadership in AI governance, and ensuring AI remains a 
force for economic growth while mitigating security risks.  
The advancement of AI is pivotal to ensuring the United States remains the global leader in innovation, 
economic growth, and national security. In response to Executive Order 141792, this document outlines 
key policy recommendations for the AI Action Plan, focusing on regulatory frameworks that foster 
innovation while maintaining oversight and eliminating unnecessary barriers that hinder AI 
development and deployment.  
A well -balanced AI policy should ensure responsible innovation, prevent monopolistic control, and 
uphold ethical standards while encouraging rapid development. Given AI's pervasive influence across 
industries, the U.S. must implement a legal and regulatory structure that supports g rowth without 
stifling competition or risking security. This document aims to highlight necessary legislative, regulatory, 
and governance measures to secure America's AI leadership.  
1. Push  Multi -Stakeholder Collaboration Within
Regulatory Confines
1.1 Foster Public -Private Partnerships and Compliance Frameworks  
Collaboration between government agencies, academia, and the private sector is essential for ensuring 
AI hardware development aligns with national security and innovation policies.  
Regulatory bodies should develop compliance frameworks that incentivize AI chip innovation while 
addressing intellectual property concerns, antitrust issues, and export control laws. Research grants 
should be structured with legal requirements that encoura ge compliance with national interests.  
1 https://www.federalregister.gov/documents/2025/02/06/2025 -02305/request -for-information -on-the-development -of-an-artificial -intelligence -ai-action -plan   
2 https://www.federalregister.gov/documents/2025/01/31/2025 -02172/removing -barriers -to-american -leadership -in-artificial -intelligence   


Registered address: 
2 
Strategic Policy Recommendations:  
•Public -Private Research Initiatives : The government should establish collaborative research
programs with private semiconductor firms and academic institutions to accelerate AI hardware
innovation. These initiatives should focus on developing energy -efficient AI chips, quantum
computing cap abilities, and next -generation semiconductor materials.
•Export Control Laws : Regulatory agencies should refine and enforce export control laws to
prevent sensitive AI hardware technologies from being acquired by adversarial nations. Clear
guidelines should be set regarding the export of AI chips and related intellectual property to
maintain a competitive advantage in AI development.
•Compliance and Security Standards : The establishment of clear security standards for AI chip
manufacturing will prevent vulnerabilities and ensure that AI hardware meets national security
requirements. Government agencies should work closely with industry leaders to enforce
compliance wit h cybersecurity best practices.
•Investment in Workforce Development : Training and education programs should be expanded
to equip the workforce with the necessary skills to support AI chip manufacturing. Universities
and technical colleges should collaborate with AI hardware companies to create specialized
curricula that a ddress industry demands.
Why this matters?  
A robust compliance framework ensures that investments in AI hardware do not lead to monopolization 
or intellectual property theft. The dominance of a few corporations in the semiconductor industry could 
stifle innovation and limit competition, making it e ssential to implement regulations that encourage fair 
market practices. Additionally, strong intellectual property protections will prevent foreign competitors 
from illicitly acquiring U.S. -developed AI chip technologies.  
Public -private partnerships should operate within a legal structure that safeguards U.S. technological 
interests, preventing adversarial nations from gaining access to critical AI infrastructure. In recent years, 
concerns over foreign acquisitions of semic onductor firms have highlighted the need for stringent 
investment review mechanisms. Strengthening oversight in AI hardware investments will ensure that 
U.S. advancements remain secure and competitive.  
Moreover, AI chip manufacturing requires a highly skilled workforce. Addressing talent shortages 
through education and training programs will ensure that the U.S. remains at the forefront of 
semiconductor innovation. Government funding for AI hardware rese arch should be accompanied by 
workforce development initiatives to create a pipeline of engineers, scientists, and technicians equipped 
to support the evolving demands of the industry.  
2.Encourage Data Center  Development While Driving
Energy Efficiency
As AI adoption continues to expand, the infrastructure supporting AI models —including data centers 
and cloud computing systems —must evolve to meet increasing computational demands. The rapid 
proliferation of AI applications has led to significant energy co nsumption, placing strain on power grids 
and raising concerns about sustainability. Ensuring that AI infrastructure operates efficiently while 


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
3 
maintaining security and environmental responsibility is paramount to achieving long -term 
technological and economic stability.  
2.1 Drive Regulatory Frameworks for Sustainable AI Infrastructure  
Given AI's intensive energy consumption, policymakers must implement regulations that mandate 
energy -efficient data center operations. Legislative measures should require AI -driven companies to 
meet energy efficiency standards, invest in renewable energy, and follow sustainability reporting 
guidelines. Compliance incentives such as tax breaks should be offered to companies that adopt green 
computing practices.  
Strategic Policy Recommendations:  
•Mandatory Energy Efficiency Standards : The government should establish regulations requiring
data centers to meet stringent energy efficiency benchmarks. This includes standards for power
usage effectiveness (PUE), cooling efficiency, and overall carbon footprint reduction.
•Renewable Energy Investments : Companies operating large -scale AI data centers should be
incentivized to transition to renewable energy sources, such as solar, wind, and hydroelectric
power, through tax credits and subsidies.
•Sustainability Reporting Requirements : AI companies should be required to disclose their
energy consumption, carbon emissions, and sustainability initiatives in regular reports.
Transparent reporting will encourage accountability and industry -wide adoption of green
practices.
•Incentivizing Innovation in Energy -Efficient AI Hardware : Investment in energy -efficient AI chips
and cooling technologies should be prioritized. Research and development grants can be
allocated to companies pioneering advancements in low -power AI processing.
•Smart Grid Integration : AI data centers should be integrated with smart grid technologies that
optimize energy distribution and reduce peak -load demand. This will enhance grid resilience
and lower the overall energy impact of AI operations.
Rationale:  
AI processing consumes vast amounts of energy, and inefficient data centers contribute significantly to 
carbon emissions. Without sustainable policies, the expansion of AI -driven applications could 
exacerbate climate change and strain national energy resou rces. Implementing regulatory measures to 
improve energy efficiency will ensure AI development does not come at the cost of environmental 
degradation, aligning AI growth with national climate goals.  
The demand for computational power is expected to surge with advancements in deep learning and 
large -scale AI models. To mitigate environmental consequences, a multi -faceted approach combining 
regulatory oversight, private sector initiatives, and technolog ical innovation is necessary. Encouraging 
the adoption of energy -efficient hardware and promoting clean energy solutions will help balance AI's 
transformative potential with environmental sustainability.  
2.2 Encourage Policies on Cloud and Edge Computing Expansion  
Expanding edge computing capabilities requires regulatory safeguards to ensure data security and 
minimize cyber threats. Policymakers should establish national guidelines for decentralized AI data 


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
4 
processing, ensuring that edge AI development adheres to data protection laws. Cybersecurity 
regulations should be enhanced to mitigate vulnerabilities associated with distributed AI systems.  
Strategic Policy Recommendations:  
•National Standards for Edge Computing Security : Regulatory agencies should establish uniform
security standards for decentralized AI processing. These standards should include encryption
requirements, data anonymization protocols, and compliance with existing data protection
laws.
•Stronger Cybersecurity Regulations : Edge computing introduces unique security risks due to its
decentralized nature. New policies should mandate AI companies to implement robust security
frameworks, including end -to-end encryption, multi -factor authentication, and AI -driven threat
detectio n systems.
•Data Sovereignty and Compliance : AI applications that rely on cloud and edge computing should
comply with national data sovereignty laws. Companies should be required to process and store
sensitive data within national borders to prevent unauthorized foreign access.
•Investment in Secure Edge Infrastructure : The government should provide funding for research
and development in secure edge computing technologies. This includes innovations in
hardware security modules (HSMs), secure processing units (SPUs), and tamper -resistant AI
chips.
•Collaboration with Industry Stakeholders : Public -private partnerships should be established to
create best practices for secure cloud and edge AI deployments. Industry leaders, government
agencies, and cybersecurity experts should collaborate on developing threat mitigation
strategies.
Rationale:  
As AI moves toward decentralized processing models, ensuring robust security in cloud and edge 
computing is essential. Traditional cloud computing models concentrate data in centralized servers, 
making them prime targets for cyberattacks. The shift toward edge AI —where processing occurs on 
local devices rather than centralized data centers —reduces latency and enhances efficiency but 
introduces new security challenges.  
Without stringent regulations, decentralized AI systems could become vulnerable to data breaches, 
unauthorized access, and cyber threats. Government regulations should mandate best practices to 
prevent security breaches, protect consumer data, and maintain  system integrity across decentralized 
AI applications. Furthermore, clear guidelines on data storage and processing locations will enhance 
compliance with privacy laws and safeguard against foreign cyber espionage.  
As a result of prioritizing security in cloud and edge computing, policymakers can support the growth of 
AI while ensuring data integrity and user privacy. The future of AI infrastructure must be built on a 
foundation of security, efficiency, and sustainability to unlock  the full potential of AI without 
compromising national and global interests.  


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
5 
3.Reinforce Trustworthy AI Model Development and
Open -Source AI
As AI systems continue to evolve, ensuring ethical, transparent, and secure development practices is 
essential. AI models influence decision -making in critical sectors, including healthcare, finance, and law 
enforcement, making regulatory oversight a necessity. At the same time, open -source AI presents 
opportunities for innovation but also raises concerns regarding security and misuse. Policymakers must 
strike a balance b etween fostering AI advancement and mitigating risks through comprehensive legal 
and regulatory frameworks.  
3.1 Prioritise Ethical and Transparent AI Models  
Regulatory frameworks should require AI models, especially those used in critical sectors, to adhere to 
transparency and explainability mandates. Government oversight should ensure that AI algorithms used 
in healthcare, finance, and law enforcement comply with non -discrimination laws and fairness 
standards. Regular audits should be mandated to assess AI systems for biases and ethical concerns.  
Strategic Policy Recommendations:  
•Mandatory Transparency and Explainability Standards : AI models should be designed to provide
clear and interpretable explanations for their decisions. Developers must document and
disclose model behavior, decision -making criteria, and data sources.
•Bias Auditing and Fairness Compliance : AI systems should undergo regular independent audits
to identify and mitigate biases, ensuring compliance with anti -discrimination laws. Companies
deploying AI in critical areas must submit fairness reports outlining potential biases and
corrective measu res.
•Sector -Specific AI Regulations : AI models used in healthcare, finance, and law enforcement
should be subject to sector -specific guidelines. For instance, healthcare AI must comply with
patient privacy laws, while financial AI should align with fair lending practices.
•AI Governance Boards and Ethical Review Committees : Establishing government -backed AI
oversight committees can ensure that high -risk AI applications adhere to ethical standards.
These committees should be composed of legal experts, ethicists, technologists, and industry
representatives.
•Public Disclosure for High -Impact AI Systems : AI models influencing public policy, legal
decisions, or essential services should be required to publish transparency reports detailing
their algorithms, limitations, and ethical considerations.
Rationale:  
AI models have the potential to reinforce systemic biases if not properly regulated. Unchecked AI 
decision -making can lead to discrimination in hiring, lending, medical diagnosis, and law enforcement. 
Legal requirements for transparency will help ensure AI -driven decisions are fair, accountable, and 
justifiable, preventing discrimination and ethical violations.  
The need for fairness in AI systems is evident from past incidents where biased AI models 
disproportionately affected marginalized groups. Implementing strict auditing and explainability 


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
6 
standards will increase public trust in AI applications while promoting responsible innovation. Ensuring 
that AI models remain interpretable and explainable will also facilitate regulatory compliance and 
reduce the risks associated with opaque algorithms m aking critical decisions.  
3.2 Ensure Legal Protections and Licensing for Open -Source AI  
Policymakers should implement legal safeguards for open -source AI development to balance innovation 
with security risks. Intellectual property laws must be adapted to address AI -generated content and 
licensing agreements. National AI repositories should be  governed by legal frameworks that promote 
responsible use while preventing malicious exploitation.  
Strategic Policy Recommendations:  
•Licensing and Usage Agreements : Open -source AI projects should be required to include legally
binding licensing agreements specifying ethical usage guidelines. These agreements should
prohibit the development of AI for malicious purposes, such as deepfake creation, automated
disinforma tion campaigns, and cyberattacks.
•Intellectual Property Adaptations for AI -Generated Content : Current IP laws must be updated
to address AI -generated content, including determining ownership rights for AI -created works
and protecting open -source contributors from unauthorized commercial exploitation.
•National AI Repositories : Establishing government -regulated AI repositories can ensure
responsible access to open -source AI tools. These repositories should vet AI models for ethical
compliance before allowing public distribution.
•Risk Assessment Frameworks for Open -Source Contributions : Developers should be required to
perform security and ethical risk assessments when contributing to open -source AI projects.
Regulatory bodies can provide guidelines to classify AI models based on their potential risks and
societal impact.
•International Collaboration on Open -Source AI Governance : AI policy should be harmonized
across international jurisdictions to prevent regulatory gaps that allow malicious actors to
exploit open -source AI tools. A global AI ethics consortium can facilitate collaboration among
governments, research institutions,  and private -sector stakeholders.
Rationale:  
Open -source AI facilitates innovation but also introduces risks, including misuse by bad actors. While 
open collaboration accelerates AI research and democratizes access to cutting -edge technology, it also 
raises security concerns, particularly when AI too ls can be repurposed for harmful applications.  
For instance, AI -generated deepfakes have been used for political misinformation, fraud, and identity 
theft. Without proper safeguards, open -source AI could also be leveraged for cyberattacks, automated 
hacking tools, or unethical surveillance practices. L icensing frameworks will help maintain control over 
AI development while allowing open collaboration in research and development.  
3.3 Support Private Sector AI Regulation  
Policies should foster AI innovation in the private sector while enforcing consumer protection laws. 
Regulatory frameworks must address AI’s impact on labor markets, consumer data rights, and ethical AI 


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
7 
use in corporate environments. Standards for AI liability should be established to ensure accountability 
for AI -driven decisions that impact consumers.  
Strategic Policy Recommendations:  
•Consumer Protection and AI Transparency : Companies using AI -driven products and services
should be required to disclose how AI models impact consumers, particularly in critical sectors
such as finance, healthcare, and employment.
•Ethical AI Development Standards : Corporations should implement ethical guidelines to prevent
AI misuse, including bias mitigation strategies and compliance with responsible AI frameworks.
•AI Impact Assessments : Businesses should conduct AI impact assessments before deploying AI
technologies that could significantly affect consumer rights, employment, or public safety.
These assessments should be reviewed by regulatory bodies to ensure compliance.
•AI and Labor Market Protections : Policies should address the impact of automation on
employment, providing workforce transition programs, retraining initiatives, and AI -related job
creation incentives.
•Data Privacy and AI Liability Laws : Strengthening AI -specific data privacy laws will help protect
consumer information. Companies should also be held accountable for AI -generated decisions
that result in harm, ensuring legal recourse for affected consumers.
•Competition and Antitrust Measures : Regulations should prevent monopolistic practices in AI
markets, ensuring fair competition and preventing large corporations from stifling innovation
through restrictive AI patents and proprietary models.
Rationale:  
Unchecked AI development in the private sector may lead to unethical practices, monopolization, or 
labor displacement. AI -driven decision -making can affect individuals’ access to jobs, financial services, 
and healthcare, making regulatory oversight essenti al. For example, AI -powered hiring tools must be 
scrutinized to prevent biased employment practices, and AI -based loan approval systems must comply 
with anti -discrimination laws.  
4.Require Explainability and Assurance of AI Models
As AI systems become more integrated into critical aspects of society, ensuring their transparency, 
fairness, and reliability is essential. High -risk AI applications, such as those used in healthcare, finance, 
law enforcement, and autonomous systems, must be subject to rigorous oversight. Explainability and 
assurance frameworks will help build public trust in AI -driven technologies by ensuring that AI decisions 
are interpretable, ethical, and compliant with legal standards.  
4.1 Foster Transparent AI Decision -Making  
AI models used in high -risk applications should be subject to mandatory explainability requirements. 
Regulations should require AI systems in autonomous vehicles, healthcare, and financial decision -
making to provide interpretable outputs. AI assurance fram eworks should standardize evaluation 
methodologies for algorithmic transparency.  


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
8 
Strategic Policy Recommendations:  
•Mandatory Explainability Standards : AI developers should be required to design models that
provide clear explanations for their decisions. This is particularly crucial in fields such as medical
diagnostics, loan approvals, and automated legal assessments, where opaque decision -making
could  result in significant consequences.
•Sector -Specific Explainability Guidelines : Different industries require different levels of AI
interpretability. For example, in healthcare, AI diagnostic models should be required to generate
justifications for their recommendations, while in finance, automated lending algorithms must
demonstrat e fairness and risk assessment transparency.
•Standardized AI Transparency Frameworks : AI assurance methodologies should be established
to assess the explainability of models. These frameworks should define measurable
transparency criteria and create benchmarks for compliance.
•User -Friendly AI Explanations : AI systems interacting with consumers should provide
understandable explanations for their decisions. For example, AI -powered hiring tools should
offer applicants insights into why they were or were not selected.
•Explainability Testing in AI Certification : Before deployment, AI systems should undergo rigorous
explainability assessments to ensure compliance with legal and ethical requirements. These
tests should be conducted by independent auditors and regulatory bodies.
Rationale:  
Opaque AI decision -making can lead to distrust and systemic bias. AI systems that operate as "black 
boxes" create risks by making decisions without human interpretability, making it difficult to challenge 
or correct errors. In high -stakes fields, such as m edical treatment planning or criminal justice, a lack of 
transparency can result in serious harm to individuals and erode public trust in AI technologies.  
Mandatory explainability requirements will ensure AI -driven decisions are ethical, legally compliant, and 
understandable to both experts and consumers. Transparency frameworks will also encourage AI 
developers to adopt best practices in ethical AI design, mitigating risks associated with biased or 
discriminatory decision -making.  
4.2 Implement AI Auditing and Compliance Regulations  
An AI regulatory body should oversee compliance auditing to ensure AI models meet legal, ethical, and 
safety standards. Certification requirements should be established for AI -driven products to ensure 
adherence to regulatory frameworks before deployment.  
Strategic Policy Recommendations:  
•Creation of AI Oversight Agencies : Governments should establish independent regulatory
bodies responsible for auditing AI models, ensuring they meet transparency, fairness, and safety
standards before deployment.
•Mandatory AI Compliance Audits : AI-driven systems should be subject to regular compliance
audits conducted by independent reviewers. These audits should assess bias, ethical concerns,
and security vulnerabilities in AI algorithms.


Register ed address: Bercylaan 105,  
Amsterdam 1031KP, Netherlands 
9 
•Certification for AI Deployment : AI systems used in high -risk applications should obtain
regulatory certification before public use. Certification criteria should include explainability
standards, bias assessments, and security evaluations.
•AI Model Documentation Requirements : AI developers should be required to maintain detailed
documentation on model training data, algorithmic changes, and decision -making processes.
This documentation should be accessible to auditors and regulatory agencies.
•Whistleblower Protections for AI Ethics Violations : Employees and researchers who expose
unethical AI practices should be granted legal protections, ensuring they can report AI -related
misconduct without fear of retaliation.
Rationale:  
AI audits help prevent errors, discrimination, and security vulnerabilities. Without proper oversight, AI 
models can reinforce biases, make erroneous decisions, or become targets for adversarial attacks. 
Auditing and certification processes will ensure tha t AI systems adhere to ethical and legal standards 
before they impact consumers and businesses.  
A standardized compliance framework will also provide clarity for AI developers, setting clear 
expectations for responsible AI deployment. Establishing independent regulatory agencies will create a 
mechanism for continuous AI oversight, ensuring long -term accountability and consumer protection.  
Thank you for considering our comments. We look forward to seeing the final Artificial Intelligence 
Action Plan in place.  
Kind regards,  
Sean Musch , AI & Partners  
Michael Borrelli , AI & Partners  
Charles Kerrigan , CMS  
Sean Musch  
CEO/Founder  
AI & Partners  
12 March 2025  


