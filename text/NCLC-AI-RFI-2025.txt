March 15, 2025  
Faisal D’Souza, NCO  
2415 Eisenhower Ave.  
Alexandria, VA 22314  
Re: Request for Information on the Development of an Artificial Intelligence (AI) Action Plan  
The National Consumer Law Center (NCLC)1 submits these comments on behalf of its low -
income clients in response to the Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan (Plan) issued by the Office of Science and Technolo gy Policy (OSTP), 
the Networking and Information Technology Research and Development National Coordination 
Office (NITRD NCO).2  The widespread adoption of artificial intelligence, including machine 
learning and generative technology (collectively AI) in a ll aspects of American life has potential 
benefits for consumers, including by reducing the cost of goods and services.  The use of AI in 
housing and consumer credit, banking and other critical financial transactions, however, may 
lead to unlawful discrimi nation in violation of consumer protection, fair lending and civil rights 
laws.  The building of data centers and other infrastructure may harm consumers and 
communities by increasing the cost of energy.  An Action Plan must guard against the systemic 
risks posed to consumers by the deployment of AI systems with the capacity to make decisions 
regarding these important life activities, and the costs associated with the build -out of the 
infrastructure.   
Below we highlight a sampling of the uses and systemic risks posed to consumers that should 
be addressed in an AI Action Plan.  The risks to consumers related to financial products and 
services and housing are fully detailed in our previously submitted comment letter.3   
1 The National Consumer Law Center, Inc. (NCLC)  is a non -profit Massachusetts Corporation, founded in 1969, 
specializing in low -income consumer issues, with an emphasis on consumer credit. On a daily basis, NCLC provides 
legal and technical consulting and assistance on consumer law issues to legal services, government, and private 
attorneys representing low -income consumers across the country. NCLC publishes a series of practice treatises on 
consumer credit laws and unfair and deceptive practices.  NCLC attorneys have written and advocated extensively 
on all aspects of consumer law a ffecting low -income people, conducted trainings for tens of thousands of legal 
services and private attorneys, and provided extensive oral and written testimony to numerous Congressional 
committees on various topics.  In addition, NCLC attorneys regularly provide comments to federal agencies on the 
regulations under consumer laws that affect low -income consumers.  
2 90 Fed. Reg. 9088 (February 6, 2025).
3 NCLC response to Request for Information on Uses, Opportunities, and Risks of Artificial intelligence in  the
Financial Services Sector  available at https://www.nclc.org/wp -content/uploads/2024/08/Treasury -RFI-on-AI-
August -2024.pdf .   


The AI Action Plan should address the  environmental and energy insecurity risks posed by 
data centers.  
The growing use of AI will create demand for more data centers, which in turn will affect the 
availability and cost of local communities’ and regions’ energy and water resources and pose 
potential risks of harm for utility customers and communities.  AI is driving the growth in data 
center energy usage, with data centers representing 4.4% of total U .S. electricity consumption 
in 2023 and estimates that data center energy consumption growth co uld reach 6.7% to 12% of 
total U .S. electricity consumption by 2028.4  By dramatically driving up electricity demand, the 
development of data centers create a risk that energy bills will increase.  There are also 
environmental risks for the communities whe re these data centers are located. Back up 
generation to protect data centers from outages could increase air pollution (e.g., if the back -up 
generation is diesel). Cooling data centers requires water and this could affect water sources 
and also affect wat er bills for consumers (for example, if the water usage causes scarcity).  The 
constant noise from a data center can be seen as a nuisance by residents.5   
To mitigate these risks, the AI Action Plan should include community engagement. These plans 
should also include strategies to ensure that consumers’ electric and water bills are protected 
from AI -related increases and that low -income consumers, in particular, have access to 
affordable and reliable electricity and water.   
The AI Action Plan must guard a gainst discrimination and other abuses in the credit, banking, 
financial services and housing markets.  
To promote economic opportunity and human flourishing consumers need ready access to 
affordable housing, fairly priced credit , and other financial produc ts and services.  Yet problems 
have occurred in consumer -facing uses of AI including with respect to marketing and 
advertising of housing and credit, underwriting and pricing of credit, evaluation of collateral, 
customer service, servicing and collections,  and noncredit uses including fraud detection and 
the monitoring and closure of bank accounts.6  The collection and use of consumer data, how it 
is used and whether it is used with permission, also drives problematic outcomes from decision -
making models.  
4 LBNL 2024 United States Data Center Energy Usage Report  (Dec. 2024), pp 6 -7.
5 Virginia Joint Legislative Audit and Review Commission, “ Data Centers in Virgini a 2024 , Report to the Governor
and General Assembly of Virginia (Dec. 9, 2024), Executive Summary.  
6 See NCLC response to Request for Information on Uses, Opportunities, and Risks of Artificial intelligence in the
Financial Services Sector  available at https://www.nclc.org/wp -content/uploads/2024/08/Treasury -RFI-on-AI-
August -2024.pdf .   


AI systems must be transparent and explainable to fully protect consumers and comply with 
consumer protection laws.  The Equal Credit Opportunity Act (ECOA), for example, requires that 
creditors give applicants to credit an adverse action notice - a statem ent outlining the reasons 
for the denial of credit or for taking other adverse action on an application.7  Explaining the 
credit decision and compliance with the ECOA’s notice requirement is particularly challenging 
for creditors who use more complicated A I models in credit decisions; yet such transparency is 
essential for consumers denied credit to make a successful follow -up application.  
The use of AI by housing providers and the financial services industry has the potential either to 
improve access to cr edit for all consumers or to amplify historical patterns of discrimination.  
An Action Plan should encourage the private sector to mitigate these risks through rigorous 
compliance with fair lending and consumer protection laws.  This includes efforts to de tect and 
mitigate bias in the models and similar efforts to seek less discriminatory alternatives.    
An AI Action Plan should call for the rigorous evaluation of data sources including data provided 
by vendors or third -party party organizations.  The coll ection of data should be voluntary – that 
is the consumer knowingly consents to the collection and use of the data and the data should 
be used for the purpose for which the consumer granted permission.  Moreover, private 
entities in their fair lending eval uations of AI generated decisions should be mindful of the 
exclusion, unfair treatment or higher pricing of consumers of color who are voluntarily or 
involuntarily excluded from data sets.   
Any technology no matter how complex must comply with the ECOA’s adverse action notice 
requirement.  Compliance with this mandate aids consumers and government oversight of this 
technology.  
An AI Action Plan must prioritize government oversight to prevent abuses; industry self -
regulation is not enough.  
Industry self -mon itoring and self -policing of complicated and opaque AI sys tems will not work.  
This hands -off model was pursued by the Consumer Financial Protection Bureau (CFPB) in its 
failed oversight of the creditor Upstart with No Action letters in 2017 and 2020.8  Despite 
assertions that the company had tested their models for fair lending compliance, an 
independent review confirmed that Upstart’s AI model charged higher interest rates to 
hypothetical applicants who attended community colleges, historically black coll eges and 
universities (HBCUs), and Hispanic serving institutions (HSIs).9  This bias in the creditor’s 
underwriting process was not caught by the CFPB.  The Bureau failed to independently test 
7 15 U.S.C. § 1691(d)(2).
8 Upstart No -Action appl ication to the CFPB (Sept. 2017)
https://files.consumerfinance.gov/f/documents/201709_cfpb_upstart -no-action -letter -request.pdf  
9 Educational Redlining , Student Borrower Protection Center, Feb. 2020, available at
https://protectborrowers.org/wp -content/uploads/2020/02/Education -Redlining -Report.pdf   


Upstart’s assertions, and instead relied on the company’s repre sentations rather than conduct 
its own analysis.  
The private industry often fails to adequately monitor its technology for discriminatory impact 
and compliance with consumer protection laws, especially when the technology is deployed in 
the field.  However , high -risk systems that make consequential decisions increase the risk of 
harm to consumers and should receive the highest level of regulatory scrutiny to ensure they 
are safe and effective.  
Additional Recommendations 
In addition to the recommendations  outlined above, to foster innovation and address the 
systemic risks posed to consumers by the widespread and rapid adoption of this technology, 
OSTP and NITRD NCO should embed the following general principles in the Action Plan:  
▪The private sector in its development and deployment of AI must produce models that
are transparent, explainable and in compliance with fair lending and consumer
protection laws;
▪Businesses must r outinely test their models to ensure that the outputs are fair,
empirically derived, and statistically sound, and accurately predict risk or achieve other
valid objectives;
▪Businesses using AI must h ire individuals from diverse backgrounds to evaluate the
effect of AI on consumers of color and other protected groups; and
▪The private sect or and government agencies must e ngage a diverse group of key
stakeholders, including civil rights organizations, consumer advocates, and impacted
community members to receive ongoing feedback on impact of AI in the market for
consumer products and service s.
Conclusion  
In addition to the potential benefits of AI, an AI Action Plan must address the potential harm 
consumers face from the deployment of AI. This includes potentially unlawful and 
discriminatory practices in housing , credit and financial services , and energy insecurity posed by 
data centers.  Such practices create barriers to opportunity and undermine consumers’ 
economic stability.     
Thank you for the opportunity to comment on this important topic.  If you have questions 
about these comments, pl ease contact Odette Williamson at  or 617 -542-
8010.  
This docum ent is approved for public dissemination.  The document contains no business -
proprietary  or confidential informatio n.  Document contents may be reused by  the go vernment 
in developing the AI Actio n Plan and associated documents without attribution.  


Respectfully submitted,  
National Consumers Law Center (on behalf of its low -income clients)  


