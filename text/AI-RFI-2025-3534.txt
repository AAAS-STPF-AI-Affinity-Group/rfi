PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-uy1r-wg36
Com m ents Due: March 15, 2025
Subm ission Type: Web
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-3534
Com m ent on FR Doc # 2025-02305
Submitter Information
Name: JW Jones  
General Comment
I have subm itted m y com m ent as an attachm ent in order to preserve form atting and enhance readability. I hope that's OK.
Attachments
Com m ent


To whom it may concern, 
AI needs creators (writers, artists, filmmakers, musicians, designers, academics, etc.). If AI is 
only as good as the data it's trained on, then harming those who create that data by 
disregarding their IP rights will retard AI development. To this end, protecting human creators 
must be part of this plan. Copyrights must be respected and protected. 
Despite recent statements from OpenAI and Google, there are real doubts about whether 
upending copyright laws to benefit tech companies would even result in more advanced AI. 
There’s a growing consensus that scale alone will not lead to significantly more advanced or 
capable models.[2][3] 
The Chinese-developed Deepseek-R1 only used a fraction of the training data and compute and 
managed to match or exceed the capabilities of both ChatGPT and Gemini, proving that 
advances are likely to come not from scaling but from efficiency, optimization, new architectures, 
and innovation. 
Technology companies themselves protect their own IP rights fervently. Google is worth around 
two trillion dollars. The idea that they can’t pay for training data – that they must have it all, and 
for free – is hard to believe. 
The creative sector in the United States was responsible for over a trillion dollars in 2022, or 
4.3% of America’s GDP.[1] Undermining one industry to benefit another is short-sighted; it’s 
robbing Peter to pay Paul. We need a balanced strategy, one that supports both industries. 
If you are inclined to side with tech companies and their “fair use” argument to train AI models 
on copyrighted materials, I’d ask you to also consider the following proposals: 1.Transparency. AI developers should be required to maintain a searchable list of all the
data they used to train a model.
2.Opting-Out of Training Sets. An IP holder should have the right to request that the
developer remove their work from the training set of pre-existing and future models. If
something is posted online that clearly states it is not to be used for training, that request
must be honored. This includes websites who don’t wish to be scraped for data. Perhaps
something like a no-call list could be established to make it easier for creators to opt-out
of AI training.3.User Consent on Online Platforms. Online platforms like YouTube, Facebook, X,
Pinterest, Instagram, and ArtStation, and SoundCloud, should not be allowed to bundle
and sell user-created content to AI developers without each user's individual and explicit
permission.


4.Added Tax for High-Revenue AI Developers. AI developers whose revenue exceeds a
certain threshold should pay an added tax to fund programs that support human
creators.
5.Automated Licensing System. Establish a government research grant, funded by AI
companies, to develop automated licensing solutions. If an AI model references a
copyrighted work in a generated output, the copyright holders should receive royalties for
it.
6.Required Labeling of AI-Generated Content. All images, text, and audio should be
marked by the developer or publisher with a tamper-resistant identifier – and its removal
should be punishable by a fine or removal of the offending content. People should know
if what they’re looking at or hearing is real. This might also add incentives for
companies and publishers to use human artists and creators rather than AI.
7.Training Data Must be Gathered From Legitimate Sources. Scraping shadow
libraries for training data should not be allowed.
8.Increased Penalties For Copyright Infringement by Generative AI Products. If a
developer makes a model that, intentionally or unintentionally, reproduces a trademarked
property, or generates obviously copyrighted images, text, music, or portions thereof –
the end user and the developer should be held responsible for that infringement.
9.Increased Penalties For Deepfakes. If a developer makes a model capable of
generating a facsimile of someone’s appearance or voice without their permission, then
both the user and developer should be liable for any damages caused by the recreation.
10.Copyright Limitation. Update the Copyright Act of 1976 to add a provision that only
human-created content can be copyrighted.
Thank you. 
Footnotes  
[1] Arts.gov press release on the creative sector’s contribution to the U.S. economy:
https://www.arts.gov/news/press-releases/2024/arts-cultural-sector-hit-all-time-high-2022-value-added-us-
economy?utm_source=chatgpt.com
[2] ArXiv paper, Scaling Laws Do Not Scale:
https://arxiv.org/pdf/2307.03201
[3] TechCrunch article on AI scaling laws and diminishing returns:
https://techcrunch.com/2024/11/20/ai-scaling-laws-are-showing-diminishing-returns-forcing-ai-labs-to-cha
nge-course/?utm_source=chatgpt.com


 
 
 


