PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-21br-ld4x
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-7952
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Nia Bickford
Em ail:  
General Comment
I am  a software engineer specializing in high-perform ance com puting. I have two pieces of input.
First, m achine learning m odels m ust not be perm itted to train on unlicensed content. Recent research such as Carlini et al.'s "Extracting
Training Data from  Diffusion Models" [2023, https://arxiv.org/abs/2301.13188] dem onstrates that diffusion m odels (the current state of
the art for im age generation) can m em orize and regurgitate their training data. Nasr et al.'s "Extracting Training Data from  ChatGPT"
[2023, https://arxiv.org/abs/2311.17035] shows the sam e for text-based Large Language Models. System s that produce substantial
copies, that substitute for the original works, and which are operated com m ercially, m ay well fail the principles of fair use, harm  Am erican
creators, and should not be exem pted from  copyright requirem ents.
Secondly, m achine learning m odels should apply robust, visible and m achine-readable waterm arks to their output. Shum ailov et al. [2023,
https://arxiv.org/abs/2305.17493] dem onstrated that LLM quality degrades as a higher fraction of their input is produced by other LLM
m odels. As an increasing am ount of the text on the Internet is generated by LLMs and several ML m odels are trained indiscrim inately on
Internet content with little or no way to filter out LLM content, we m ay well see a "m odel collapse" situation: m odels of 2026 and later
m ay be lower-quality than those of 2025, because the input corpus has becom e so contam inated. Sim ilarly, robust waterm arking would
help guard against im personation attacks, like those of "deepfake" m odels. Models such as these allow im personating of individuals
appearances' and voices, dam aging the credibility of public figures.
It's im portant for m e to m ention that the above statem ents and opinions are m y own, and m ay not represent those of m y em ployer.
Thank you.


