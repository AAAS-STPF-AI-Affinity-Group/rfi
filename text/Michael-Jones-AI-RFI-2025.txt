From: Michael Jones
To: ostp-ai-rfi
Subject: [External] AI Action Plan
Date: Monday, March 17, 2025 9:18:58 AM
CAUTION: This email originated from outside your organization. Exercise caution when opening
attachments or clicking links, especially from unknown senders.
Hello,
Thank you for taking the time to be open to comment regarding the continued investment and
development of utilizing Artificial Intelligence (A.I.).   The definition of A.I. has been muddled
and I will limit my comments to the utilization of Large Language Models (LLMs)specifically.
  Broadly, the risks and harms outweigh the advantages of utilizing these
technologies at this time.   Focused study should be considered far more on publicized and
robust wins like advancements in protein folding for biomedical scientific advancement.(https://www.science.org/content/article/powerful-new-ai-software-maps-virtually-any-
protein-interaction-minutes )
LLMs have only achieved any utility by being trained on vast amounts of copywritteninformation.
  This is broadly copyright infringement, especially as the protected information
was obtained without disclosure or compensation to the protected parties.   This includes
authors, artists, and publishers.   The business models used by the current domestic LLM
companies is seemingly based on theft and should be abandoned, not given specialpermissions.
  (https://arstechnica.com/tech-policy/2025/03/openai-urges-trump-either-settle-
ai-copyright-debate-or-lose-ai-race-to-china ,
https://www.theverge.com/2025/1/14/24343692/meta-lawsuit-copyright-lawsuit-llama-
libgen ).  Additionally, there are now concerns that the LLM training models have grown so
large that they have already consumed all independently available information.   As LLMs use
the training base to synthesize results, the lack of fresh data will produce asymptotic results.  
There is a ceiling to an LLM's  usefulness and if have achieved it, and it's likely we have, the
technology is at a stalled point.   The next concern is data rot, where newer generated AI will
be trained on LLM outputs.   This is 'new' data, but not fresh and will produce diminishing
returns in future LLM performance. (see below).   In short, that usefulness ceiling looks more
likely to come down than go up.
Additionally, the utilization of these tools, LLM chatbots, have been found to produce
generally false results.   (https://www.bbc.com/mediacentre/2025/bbc-research-shows-issues-
with-answers-from-artificial-intelligence-assistants ). The technology is not at a place where it
is useful to provide guidance of feedback to general users.   The output of these systems,
contested to be illegally procured, is also unreliable. In a professional capacity, the use ofChatGPT produced verifiably false information that was critical for export duties,
 a
hallucination.   If we had not manually double checked the information we would have been
closed out of trade for an undetermined time and financial loss.   The lesson gained for us was
that the use of LLMs for guidance resulted in more worker labor and time, not less.(https://www.forbes.com/sites/bryanrobinson/2024/07/23/employees-report-ai-increased-
workload/ )  These hallucinations, which do not seem to be able to be refined out of the
systems will end up causing decision making errors when these assistants are utilized.   It is a
matter of time and severity of those failures.


Energy consumption of the sites used to produce these results in a timely fashion has become a
strain on the utility grid where they are used.   Recently, a firm in China released DeepSeek
with some wild claims.   Most of these claims have been rightfully met with speculation,
however, some of the considerations that haven't been completely refuted (energy
consumption) hasn't been. Domestic LLM companies are pushing to expand the usage ofdomestic electricity supply and it is imperiling municipalities grid stability.
  What Deep Seek
is showing is that the "just go bigger" mentality of American developers should be treatedwith incredible skepticism.
  There are smarter ways to approach this without causing
brownouts or exacerbating infrastructure challenges by re-activating decommissioned energystations.
  Energy consumption and a growing dependence on LLMs will increase the
likelihood of targeting critical civilian infrastructure for the purposes of destabilizing aresponse in the event of aggressive state action.
In short, publicly available (even through subscription) does not produce reliable results to
help robust decision making for the purposes to aid in national security at this time.
  It should
be deprioritized in favor of separate technological applications like scientific study andseparate technological advancement.
  It should not be considered as a replacement for
personnel or personnel based tasks.   
Thank you for your attention to this matter,Michael Jones


