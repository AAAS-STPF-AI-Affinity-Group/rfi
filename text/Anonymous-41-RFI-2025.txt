 
   3/11/2025 via FDMS  
Anonymous  
“This document is approved for public dissemination. The document contains no business -
proprietary or confidential information. The government may reuse document contents in 
developing the AI Action Plan and associated documents without attribution.” As a licensed 
counseling psychologist, I have significant concerns regarding the risks and unintended 
consequences associated with the underregulated development and misleading implementation of 
generative AI technologies, particularly as they pertain to vulner able populations such as 
children and adolescents. The rise of “entertainment” chatbots, marketed as companions or 
therapeutic tools, raises particular alarm due to their public accessibility without essential 
safeguards, transparency, or requisite warning  and reporting mechanisms. There is a growing 
body of reports indicating that individuals, especially impressionable children and adolescents 
dealing with mental health issues, have experienced adverse effects from their interactions with 
publicly availabl e AI-driven chatbots. This underscores the urgent need for comprehensive 
regulatory measures designed to protect these at -risk groups. It is imperative to note that 
psychological professionals undergo rigorous educational prerequisites to obtain state lice nsure, 
which serves as a protective measure for public welfare. Any application or chatbot that purports 
to embody the role of a mental health professional undermines the legal and ethical frameworks 
that safeguard both the public and mental health practit ioners. Many generative AI chatbots are 
primarily developed for entertainment purposes, lacking the necessary FDA clearance as digital 
health tools, HIPAA compliance, and adherence to the professional regulations governing mental 
health. They additionally fail to provide evidence supporting their efficacy or safety. 
Furthermore, I am very concerned about the potential for AI to generate progress notes and other 
components of a patient’s medical record. While this capability may offer opportunities for 
improving and automating administrative processes, it necessitates robust safeguards concerning 
the data utilized to train these AI systems. Compliance with HIPAA is paramount in this context. 
It is alarming how swiftly companies are developing products capable  of managing sensitive 
information —failure to address this could have detrimental effects on patients. To mitigate these 
risks, ethical and legal guidelines must be established with substantial input from the mental 
health sector. Clear regulations definin g the consequences for violations of HIPAA laws by AI 
programs must be instituted, and extensive training on such technologies should be incorporated 
into undergraduate and graduate mental health curricula, as well as ongoing professional 
education.  
 


