INTROD UCTION:  
I submit the following proposals to the Office of Science and Technology Policy regarding the Trump 
Administration’s AI Action Plan to sustain and enhance American AI leadership. My suggestions fall under the following categories:  research initiatives, education, infrastructure, and  healthcare . 
RESEARCH INITIATIVES : 
 Several federal agencies are already investing in cutting-edge AI research such as the NSF, 
DARPA, and NIST . These efforts are admirable and could be expanded to accelerate the development of 
generalizable knowledge in key areas such as healthcare or materials science.  
These funding opportunities can incentivize researchers towards specific fields of study  and in particular 
shape their approaches. To this end, we ought to consider what types of second -order effects may result 
from these efforts. For example, not requiring the labelling of synthetic content might accelerate research 
today but might have a secondary effect in  that Americans may find it  more difficult to distinguish 
“deepfakes” from authentic media in the future . Some  tradeoffs are difficult to quantify yet  should be 
considered before taking one side or the other. Moreover, there should be a structured and transparent 
decision -making approach when evaluating these tradeoffs and among reviewers. This can be achieved by 
completing the following five step plan : 
1. Defining Tradeoff Criteria 
a. Develop and explicitly list evaluation factors  (cost, technical merit, risk, societal impact) 
and their relative weights in funding opportunity documents  
b. Clearly state the relative importance of non -cost factors as “significantly more 
important”, “approximately equal to or “significantly less important” than cost 
c. Use best practices from acquisition tradeoff processes as outlined in FAR.
i 
2. Enhance Reviewer Training and Guidance  
a. Develop targeted training for review panel members on tradeoff analysis and Multiple Criteria Decision Analysis techniques . 
b. Use case studies from prior reviews to illustrate effective tradeoff evaluations. 
3. Integrate Structured Decision -Making Tools  
a. Implement standardized forms and decision matrices within the review process to collect 
reviewers’  assessments of each criterion.  
b. Normalize and aggregate scores across multiple dimensions.  
c. Require that the rationale for any decision to award a higher -priced proposal be clearly 
documented, as is done in FAR tradeoff processes.  


4.Foster  Collaborative Review Practices
a.Host webinars or workshops for potential applicants and reviewers to clarify tradeoff
evaluation criteria early in the funding cycle.
b.Provide detailed feedback to applicants regarding tradeoff considerations in proposals .
c.Establish a post -award review process to assess the impacts of the tradeoffs made during
selection resulted in successful outcomes and use this data to refine criteria for futurefunding opportunities.
5.Enhance Transparency and Accountability
a.Make evaluation criteria and tradeoff guidelines publicly available and easily accessiblein funding opportunity announcements.
b.Require that evaluation reports include a summary of how tradeoffs were assessed.
c.Ensure that all tradeoff decisions are fully documented  and reproducible.
d.Implement an internal audit process to periodically review the consistency of tradeoffevaluations.
This plan provides a structured, transparent, and iterative approach to reviewing tradeoffs in AI funding 
opportunity design, drawing on practices from federal acquisition and evaluation frameworks. By using 
structured decision -making tools, federal agencies can enhance the overall quality of the funding process 
by better aligning resource allocation with national research priorities.  
EDUCATION:  
AI will have broad impacts across our society, and in some cases is already doing so , e.g. AI is 
increasing worker productivity.   We need to equip our students and workforce with the skills and tools 
they need to succeed. Therefore, I suggest enacting the following plan to improve AI literacy and 
proficiency across every education level .  
1.Approaches by Education Level :
a.K-12:
i.Create a national framework (e.g., building on initiatives like AI4K12) thatdefines what AI literacy means at various grade levels, from basic algorithmicthinking in elementary school to ethical considerations in high school.
ii
ii.Embed AI  topics within math, science, social studies, and computer science
curricula. For example, use data analysis projects in math classes.


iii. Introduc e hands -on projects and competitions (e.g., robotics challenges, coding
clubs) to encourage experiential learning and problem -solving using AI /ML
tools.
b.Higher Education:
i.Develop undergraduate and graduate courses that cover both the technical
foundations (machine learning, data science) and societal implications (ethics,policy) of AI.
ii.Encourage student -led research or capstone projects that require designing and
implementing AI -driven solutions, linking academic theory with real -world
applications.
c.Lifelong Learning:
i.Offer short courses, boot camps, and online modules to help current professionals
and non- traditional students update their AI skills.
2.Teacher Training and Professional Development
a.Establish nationwide workshops and seminars for teachers to deepen their understanding
of AI concepts and modern educational tools.
b.Create centralized online repositories of AI teaching resources (curriculum guides, lessonplans, interactive simulations) that are regularly updated.
3.Infrastructure and Resources Development:
a.Invest in school -based AI labs and makerspaces equipped with computers, AI software,
and robotics kits to facilitate hands -on learning.
b.Foster public –private partnerships to secure technology donations, guest lectures, and
real-world project collaborations that expose students to current AI practices.
4.Quality Improvement :
a.Develop standardized assessments and project evaluations that measure both technical
understanding and critical thinking about AI /ML.
b.Use surveys and performance metrics to gather feedback from teachers, students, and
parents, refining curricula and teaching methods on a regular basis.
5.Implementation:
a.Establish a task force to define national AI literacy standards and develop a
comprehensive framework  as well as a suitable timeline for enactment.
b.Begin pilot programs in select districts, evaluate outcomes, and then scale successful
initiatives nationwide.


By sy stematically integrating AI literacy into every educational level,  we can empower students to thrive 
in an AI -driven future. This plan not only prepares students for emerging challenges but also positions our 
nation as a leader in AI education.  
INFRASTRUCTURE: 
 The training and operation of AI models is resource intensive,  and demand is rapidly increasing. 
The United States must create domestic conditions suitable for the continued development and operation 
of AI in order to sustain our advantage in this field. Therefore, this administration  should plan to increase 
the supply of energy and AI infrastructure in the following ways.  
1. Policy and Regulatory Reform : 
a. Review and remove barriers from legacy policies that hinder rapid deployment of AI 
infrastructure , building on actions such as the “Removing Barriers to American 
Leadership in Artificial Intelligence” executive order.iii 
b. Collaborate with state, local, and tribal authorities to reduce or eliminate  regulatory 
redundancies for vital infrastructure projects.  
2. Infrastructure Modernization and Expansion: 
a. Appropriat e funds for or incentivize via tax credits the construction of  new energy 
facilities , data centers,  fiber-optic networks, and the modernization of existing electrical 
grid infrastructure . 
3. Transparency  and Stakeholder Engagement : 
a. Publish progress reports and maintain an open data portal for stakeholders to track developments in AI infrastructure and energy supply projects  
By integrating AI infrastructure development with strategic energy supply enhancements, the federal government can foster an ecosystem that supports U.S. technological leadership and economic growth.  
HEALTHCARE: 
AI has the potential to revolutionize healthcare, from improving diagnostic accuracy to 
optimizing the allocation of healthcare resources. However, its integration  raises critical ethical concerns, 
including data privacy, bias, transparency, accountability, and informed consent. Inadequate ethical 
safeguards can erode trust, which has been shown to c orrelate with a variety of negative outcomes , 
such as decreased  care quality, underutilization of healthcare resources, and critically, healthcare 
outcomes  such as quality of life and patient satisfaction.
ivv The federal government must lead by 
establishing a robust regulatory framework that mandates ethical standards for AI use in healthcare. This 


fram ework should integrate ethical principles from traditional sources  as well as consensus-based formats 
such as FUTURE -AI.vi 
1.Objectives:
a.Ensure Patient Safety and Trust.
b.Protect Patients Rights and Privacy .
c.Establish Accountability and Transparency .
d.Foster Innovation with Ethical Oversight .
2.Policy Framework:
a. Develop and mandate a federal AI ethics framework that incorporates core
ethical principles (beneficence, non -maleficence, autonomy, and justice) as well
as novel criteria such as transparency, accountability, and explainability.
b.Establish an independent, multidisciplinary AI oversight board with
representatives from all  relevant stakeholder groups (healthcare providers, AI/ML
experts, ethicists, patient advocates, and regulators) to oversee AI applications in
healthcare and biomedical research.
c.Define liability clearly to ensure that responsibility is allocated properly amongdevelopers, providers, and institutions.
3.Data Governance:
a.Ensure that all AI systems used in healthcare comply with the relevant statutory
requirements as defined by HIPAA and other privacy laws.
b.Mandate de-identification and anonymization protocols for patient data used in
AI training and testing.
c.Create or empower an existing federal agency to oversee data governancepractices for healthcare AI.
d.Establish guidelines for informed consent and data sharing to reduce risks of datamisuse.
4.Transparency, Explainability  and Oversight:
a.Require developers to document and share the design, training data, and
performance metrics of AI systems and tools when they are to be used in
providing patient care  or biomedical research with human subjects.
b.Encourage the use of explainable AI (XAI) methods so that healthcare providerscan understand and trust AI recommendations.
vii
c.Ensure t hat AI tools serve as decision -support systems, where final decisions are
made by human providers.


d. Design and implement training for healthcare professionals on interpreting AI 
outputs and their responsible use in healthcare.  
5. Liability and Accountability: 
a. Clearly define legal responsibilities and liability for harms resulting from the use 
of AI systems  in healthcare. This includes establishing accountability for 
developers, manufacturers, healthcare institutions, and providers.  
b. Impose meaningful penalties for non-compliance with ethical standards and data 
privacy laws.  
6. Stakeholder Engagement:  
a. Involve patients, providers, ethicists, and developers in the design and continuing 
review of AI ethical guidelines.  
b. Organize workshops and deliberations to gather public input to ensure that policies reflect the needs and concerns of all stakeholders. 
7. Education  and Research : 
a. Build on suggested proposals in the Education section, fund education and 
training programs for healthcare providers  and AI developers on ethical AI use 
and design.  
b. Support research on AI ethics, fostering academic partnerships and grants that 
promote best practices in the ethical design and application of AI in healthcare. See Research Initiatives . 
8. International Collaboration: 
a. Partner with international organizations such as the WHO and EU to align ethical 
standards and regulatory frameworks  to facilitate sharing data across institutions .  
This plan aims to ensure that AI technologies in healthcare are ethical and transparent, and by extension, 
trustworthy . By establishing governance structures, clear legal frameworks, data protection standards, and 
stakeholder engagement, the federal government can lead the way in harnessing AI’s potential to improve patient care. 
CONCLUSION:  
In conclusion, the proposals outlined above form a  strategy for sustaining American AI leadership across 
several domains. Through AI  research initiatives, we can drive innovative discoveries and ensure that 
research conducted is aligned with our research priorities. Enhancing AI literacy and skills through 
systematic educational reforms will empower our current and future workforce to succeed in an AI-driven 
world. Furthermore, modernizing our national infrastructure and energy supply will provide the 


foundati on necessary to support advanced AI applications. Finally, by establishing a regulatory 
framework and oversight mechanisms in healthcare, we can protect patient and participant rights, mitigate 
bias, and ensure accountability in healthcare and biomedical research . Together, these proposals  enshrine 
the ethical use of AI across critical sectors and position the United States to be a global leader in AI for 
years to come .  
Signed,  
Nicolas Jean -Louis Hargraves Oliver  
FAIR USE STATEMENT:  
“This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI 
Action Plan and associated documents without attribution.”  
Moreover, this document  reflects only the opinion of the author and in no way reflects the opinion of his 
employer or institution(s).  
CITATIONS: 
AI4K12. “AI4K12.” Accessed March 1 0, 2025. https://ai4k12.org/.  
Birkhäuer, Johanna, Jens Gaab, Joe Kossowsky, Sebastian Hasler, Peter Krummenacher, Christoph 
Werner, and Heike Gerger. “Trust in the Health Care Professional and Health Outcome: A Meta-
Analysis.” PLOS ONE  12, no. 2 (February 7, 2017): e0170988. 
https://doi.org/10.1371/journal.pone.0170988.  
Crigger, Elliott, Karen Reinbold, Chelsea Hanson, Audiey Kao, Kathleen Blake, and Mira Irons. 
“Trustworthy Augmented Intelligence in Health Care.” Journal of Medical Systems  46, no. 2 
(January 12, 2022): 12. https://doi.org/10.1007/s10916-021- 01790- z. 
“FAR | Acquisition.GOV.” Accessed March 1 0, 2025. https://www.acquisition.gov/browse/index/far. 
LaVeist, Thomas A., Lydia A. Isaac, and Karen Patricia Williams. “Mistrust of Health Care 
Organizations Is Associated with Underutilization of Health Services.” Health Services Research  
44, no. 6 (2009): 2093 –2105. https://doi.org/10.1111/j.1475-6773.2009.01017.x.  
Lekadir, Karim, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F. Frangi, Alena Buyx, Anais Emelie, 
Andrea Lara, et al. “FUTURE -AI: International Consensus Guideline for Trustworthy and 
Deployable Artificial Intelligence in Healthcare.” arXiv, July 8, 2024. https://doi.org/10.48550/arXiv.2309.12325.  
The White House. “Removing Barriers to American Leadership in Artificial Intelligence,” January 23, 
2025. https://www.whitehouse.gov/presidential -actions/2025/01/removing-barriers-to -american -
leadership -in-artificial-intelligence/. 
i “FAR | Acquisition.GOV . ”  


ii “AI4K12. ”  
iii “Removing Barriers to American Leadership in Artiﬁcial Intelligence.”  
iv LaVeist, Isaac, and Williams, “Mistrust of Health Care Organizations Is Associated with Underutilization of 
Health Services.”  
v Birkhäuer et al., “Trust in the Health Care Professional and Health Outcome.”  
vi Lekadir et al., “FUTURE -A I .” 
vii Crigger et al., “Trustworthy Augmented Intelligence in Health Care.”  


