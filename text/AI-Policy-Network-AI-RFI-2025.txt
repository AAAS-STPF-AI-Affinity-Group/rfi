Daniel Colson  
Executive Director 
The AI Policy Network 
MARCH 15, 2025 
To: Faisal D'Souza, NCO  
Office of Science and T echnology Policy  
2415 Eisenhower Avenue  
Alexandria, VA 22314 
Submitted via email to 
Introduction
The rapid advancement of artificial intelligence presents the United States with both 
unprecedented opportunities and significant challenges. As the Trum p administration develops 
its AI Action Plan, it is essential to establish a strategic framework that secures American 
leadership in this transformative technology and promotes economic competitiveness while 
addressing critical security concerns. This essay responds to the Office of Science and 
Technology Policy's Request for Information by outlining a comprehensive approach that 
promotes innovation while enacting prudent safeguards. 
We stand at a pivotal moment in technological history. AI represents not merely an evolution of 
existing digital capabilities, but a revolutionary force that will reshape our economy, national 
security landscape, and society. The decisions made today will determine whether the United 
States maintains its technological supremacy or cedes advantage to strategic competitors. Our 
recommendations focus on accelerating American AI deployment through light-touch regulation, 
strengthening critical infrastructure, implementing targeted security measures, and developing 
frameworks for managing increasingly powerful systems—including regarding Artificial General 
Intelligence (AGI). 


Our submission addresses three critical dimensions of AI policy: 
●Economic Opportunities of AI: We examine AI's potential to drive unprecedented
productivity growth and create trillions of dollars of economic value. This section
addresses critical energy infrastructure needs, light-touch regulatory approaches, and
strategies to support American workers through the transition.
●Strategic AI National Security Priorities: We outline measures to maintain America's
technological sovereignty and protect against emerging threats. This includes
strengthening export controls, enhancing AI cybersecurity resilience, and developing
military applications while mitigating CBRN risks.
●The Emergence of Artificial General Intelligence: We propose governance
frameworks for increasingly powerful AI systems that approach and exceed human-level
intelligence. This section recommends establishing a National AGI Commission and
funding critical safety research to ensure these systems remain aligned with American
values and stay under human control.
By embracing AI's transformative potential while implementing strategic guardrails, the Trump 
administration can ensure that this technology develops on American terms, guided by our 
values of freedom, prosperity, and security. The following analysis provides both high-level 
direction and concrete steps to maintain U.S. leadership in the AI revolution. 
About the AI Policy Network 
The AI Policy Network (AIPN) is a bipartisan, independent 501(c)(4) advocacy organization 
dedicated to advancing secure AI development that serves America's economic prosperity, 
technological leadership, and national security in the age of increasingly powerful AI systems. 
AIPN brings together senior policymakers, technology policy specialists, and technical 
researchers to address critical AI security challenges and mitigate potentially catastrophic risks. 
We provide policymakers with strategic understanding of emerging AI threats, offering a 
technically-grounded perspective that complements insights from frontier AI labs. AIPN's 
mission is to ensure the United States maintains technological supremacy, protects critical 
infrastructure from AI-enabled attacks, and develops robust safeguards against advanced AI 
systems that could compromise national security, including those approaching and reaching 
Artificial General Intelligence (AGI). 


1. Economic Opportunities of AI: A Transformative Force
for American Prosperity
Artificial intelligence represents the most significant economic opportunity since industrialization 
in the 19th and 20th centuries, with the potential to dramatically accelerate American 
productivity, innovation, and global competitiveness. As Vice President Vance correctly 
noted, this is an "extraordinary prospect of a new industrial revolution" that America must 
embrace with confidence [1]. AI is already delivering transformative productivity 
breakthroughs—research indicates that developers using AI coding assistants complete tasks 
35% to 45% faster while producing higher quality code [2], while other job categories like 
translation, professional driving, and customer service seem poised to be more fully automated. 
These productivity enhancements are just the beginning of what OpenAI's Economic Blueprint 
describes as a coming "reindustrialization" that could generate trillions in economic growth [3]. 
Goldman Sachs projects generative AI alone could increase global GDP by approximately $7 
trillion over the next decade, with the United States positioned to capture a disproportionate 
share of this value if we maintain our competitive edge [4]. Beyond raw economic output, AI 
promises to revolutionize industries from healthcare to manufacturing while creating entirely 
new sectors of the economy. In healthcare, AI is accelerating drug discovery, improving 
diagnostic accuracy, and optimizing hospital operations—addressing critical needs in our aging 
population. While pursuing these economic benefits, America must simultaneously address 
security challenges from potentially weaponizable AI systems, supplementing acceleration with 
prudent guardrails that don't impede innovation. 
As Anthropic CEO Dario Amodei states in his essay, "Machines of Loving Grace," AI has the 
potential to dramatically boost productivity growth rates to levels not seen in generations, 
potentially reaching >10% annual growth in the coming AI-powered economy [5]. This 
revolution creates an unprecedented opportunity to strengthen American technological 
sovereignty, revitalize manufacturing, and ensure the U.S. maintains its position as the world's 
preeminent economic power. 
1.1. Addressing Critical Energy Infrastructure Needs 
Advanced AI is driving unprecedented electricity demand , with data centers projected to 
consume 6.7-12% of U.S. electricity by 2028—up from 4.4% today [6]. This explosive growth is 
already creating bottlenecks in key AI hubs, with transmission limitations halting new data 
center development in Northern Virginia until later in 2025 [7]. Goldman Sachs estimates data 
center power demand will grow from 55 GW in 2023 to 84 GW by 2027, requiring approximately 
$720 billion in grid investments by 2030 to support AI infrastructure [8]. Without strategic 
intervention, these energy constraints will severely limit America's AI leadership and economic 
competitiveness. 


Key priorities include: 
●Streamline Energy Project Permitting : Prioritize dramatically shortening permitting
timelines for critical energy infrastructure projects that enable advanced AI development.
Reducing bureaucratic delays in environmental reviews—currently averaging 4.5 years
[9]—is essential to rapidly deploying AI-supportive infrastructure, enhancing U.S.
technological competitiveness, and accelerating innovation without compromising
environmental safeguards.
●Accelerate Next-Generation Power Solutions: Create public-private partnerships to
develop advanced energy solutions for data centers, particularly nuclear power,
following Microsoft's example of securing 835 MW from Three Mile Island for AI
operations [10].
●Establish Federal-State Coordination : Form a federal-state task force to harmonize
energy policies across jurisdictions, developing model legislation that balances rapid
infrastructure deployment with grid reliability.
1.2. Light-Touch Regulation Indicating the US is Open For Business 
To maintain American leadership in the AI revolution, the Trump Administration must establish a 
regulatory environment that fosters innovation while managing the national security 
risks presented by powerful AI systems. Unlike the European Union's precautionary and 
over-broad approach that threatens to strangle innovation with excessive rules, America's 
strategy should embrace the transformative potential of AI by removing bureaucratic obstacles 
that impede progress. As Vice President Vance noted, heavy regulations could "kill a 
transformative industry just as it's taking off" [1]. A light-touch framework will send a clear signal 
that America is open for AI business, attracting global investment and talent while ensuring 
our companies can rapidly iterate and deploy cutting-edge systems without unnecessary 
constraints. 
This approach recognizes that overly prescriptive regulations—especially around subjective 
concepts like algorithmic bias or fairness—would create compliance burdens that 
disproportionately harm startups and smaller innovators while entrenching established players. 
Instead, the administration should focus on targeted interventions that preserve market 
dynamism while addressing genuine security challenges.  
Key priorities include: ●Implement Flexible Intellectual Property Frameworks: Develop IP policies that
balance the protection of AI innovations with the needs of open research and AI training,
preventing overly restrictive rules that could hinder technological progress and consumer
choice.


●Support Open-Source AI Initiatives: Provide incentives for open-source AI projects
that foster collaboration and innovation, ensuring that advancements are widely
accessible and not monopolized by a few entities.
●Attract Global AI Talent Through Strategic Immigration : Implement targeted high-skill
immigration policies to bring the world's top AI and semiconductor researchers and
engineers to America, maintaining our technological leadership while creating new jobs
and opportunities for American workers through the innovation these experts generate.
●Prevent AI-Powered Censorship and Red Tape: Direct federal agencies to eliminate
requirements that AI providers monitor and restrict protected speech under ambiguous
standards like "harmful content" or "misinformation," preserving Americans' fundamental
rights in digital spaces and preventing the weaponization of AI against dissenting
viewpoints.
1.3. Supporting American Workers Through the AI Transition  
Artificial Intelligence will fundamentally reshape the American labor market, creating both 
unprecedented economic opportunities and significant workforce disruptions. While AI will 
generate substantial productivity gains and create entirely new job categories, it will also 
displace or fundamentally alter one-quarter or more of current jobs within the decade [11], 
with white-collar professionals in finance, law, technology, and administrative roles facing 
particular vulnerability—unlike previous automation waves that primarily affected manufacturing 
and routine tasks. 
Key priorities include: ●Launch AI Workforce Transition Initiatives: Establish large-scale retraining programs
to help displaced workers develop skills for growing sectors where human capability
remains essential, focusing particularly on roles requiring complex manual work,
emotional intelligence, and supervision of AI systems—ensuring Americans can adapt to
the changing job landscape.
●Create AI Job Transition Tax Credits: Establish tax incentives for companies that
invest in retraining their existing workforce for AI-complementary roles rather than
replacing them, encouraging businesses to view their human capital as adaptable assets
rather than obsolete resources.


2. Securing America's Future: Strategic AI National
Security Priorities
The emergence of increasingly powerful artificial intelligence represents both America's greatest 
technological opportunity and a profound national security challenge. As global rivals openly 
acknowledge AI's strategic importance—with Vladimir Putin declaring "whoever becomes the 
leader in this sphere will become the ruler of the world " [12] and Xi Jinping's designation of AI 
as a "strategic technology" for "leapfrog development" [13]—the United States faces an 
unprecedented technological competition with existential implications. This competition extends 
beyond economic dominance to encompass military superiority, intelligence advantage, and 
the fundamental question of which values will shape the future of this transformative 
technology. 
Domestically, leading AI companies lack sufficient security protocols despite producing 
increasingly powerful systems with dual-use capabilities that could be exploited by 
adversaries and terrorists. America's response must complement continued innovation with 
pragmatic security measures that prevent accidents, leaks, and hacks. The Trump 
Administration has correctly identified that the nation which leads in AI development will shape 
global power dynamics for decades to come—making a comprehensive AI security strategy not 
merely advantageous but imperative for America's continued leadership. 
2.1. Export Controls & Technological Sovereignty 
Maintaining American preeminence in AI requires controlling the critical input technologies that 
enable AI, as well as strengthening our domestic tech base. We urge the administration to 
strengthen export controls on advanced AI chips, software, and know-how so that adversarial 
powers like China cannot easily acquire or replicate our most capable tools.  
By cutting off malign actors from our crown-jewel technologies and supercharging domestic 
capacity, the U.S. can grow its competitive advantage in the hardware and infrastructure 
underpinning AI. Technological supremacy, particularly in AI, is a cornerstone of both economic 
prosperity and military security. 
Key priorities include: ●Strengthen Enforcement of AI Chip Export Controls: Further tighten the export of
high-end AI semiconductors and the equipment to produce them. Current rules already
bar the sale of top-tier chips to China, but smuggling is rampant and enforcement is
deficient. BIS should be empowered and better funded to more thoroughly enforce these
controls and should be directed to more strongly prioritize this issue.
●Close the Cloud Remote Access Loophole: Immediately restrict Chinese and other
adversary entities from accessing advanced AI computing resources through U.S. cloud
services. This loophole enables companies like Oracle to rent export-controlled H100


chips to Chinese entities like ByteDance. The administration should implement strict 
verification requirements and prohibit cloud access to advanced AI computing for entities 
from countries subject to export controls, with possible exemptions granted on a 
case-by-case basis. 
●Restrict Technology Transfer Through Joint Ventures: Implement stronger oversight
and restrictions on joint ventures between American companies and CCP-connected
firms that could facilitate illicit technology transfer. Require enhanced disclosure of CCP
ties for all Chinese business partnerships and impose severe penalties for violations that
result in strategic technology leakage.
●Coordinating with Allies for Multilateral Controls: Engage in a diplomatic push to
align the semiconductor export policies of all key producer nations, formalizing a
coalition where member nations jointly agree to deny China and other adversaries the
means to produce cutting-edge AI hardware.
2.2. AI Cybersecurity & Resilience 
As AI systems become embedded in critical applications, their security and reliability are 
paramount. We must anticipate that sophisticated adversaries will attempt to hack, corrupt, or 
sabotage AI models and data to undermine our security or economy. To address these 
challenges, the U.S. should launch a major initiative to harden critical AI systems and make 
them resilient against threats, investing federal research funds in AI-specific cybersecurity R&D 
and establishing strict security standards for any AI system deployed in government or critical 
sectors. 
Adversarial attacks on machine learning models are on the rise, growing in frequency and 
sophistication. Such attacks involve deliberately feeding specially designed inputs to AI systems 
to manipulate their behavior and cause malfunctions. We must assume that hostile state actors 
are studying these techniques to use against U.S. systems. 
Key priorities include: ●Fund Robust AI Security Research : Dedicate new research funding to develop
methods for making AI models robust against attacks, including techniques for
adversarial robustness, detection of poisoned training data, and methods to verify the
integrity of both AI model outputs and intermediate reasoning steps necessary for
deployment of AI systems in high-risk environments.
●Strengthen Security at Frontier AI Companies: Develop cybersecurity standards for
companies developing dual-use frontier AI systems. Partner with the Department of
Defense and Department of Energy to implement cooperative security programs that
protect against theft of model weights and proprietary algorithms by foreign adversaries.
This public-private security collaboration would be a prerequisite for any company


seeking federal contracts, ensuring America's most advanced AI capabilities remain 
secure from sophisticated cyber operations from adversarial states and other bad actors.  
●Harden Government AI Systems: Task NIST with developing an AI Security
Framework that agencies must follow when procuring or deploying AI, including regular
red-team testing, encryption of sensitive training data, and audits for backdoors.
●Leverage AI for Cyber Defense: Investing in AI systems that improve cybersecurity –
for instance, AI that can detect anomalous network activity or identify malware generated
by AI.
2.3. Military synergy 
Artificial intelligence is not only an economic technology—it is a strategic military and 
intelligence asset that will shape the 21st-century balance of power. China has outlined and 
repeatedly reiterated its intention to become the global leader in AI by 2030. This outcome is 
unacceptable. To ensure the United States maintains its strategic edge, AI policy must be 
treated as a top-tier national security issue. 
Key priorities include: 
●Modernize and Streamline Military AI Technology Approval: Modernize processes
for approving AI technology in the military. Processes should consider ways that AI
differs from other technologies, including benefits and drawbacks of deep learning
technologies and large language models in various contexts.
●Cross-Agency Strategic Coordination : Coordinating across the Department of
Defense, Intelligence Community, Department of Energy, and other agencies to integrate
AI into national security missions safely and effectively.
●Prioritizing Military and Intelligence AI R&D: Invest in both offensive and defensive
military applications of AI, as well as intelligence applications. Prioritize areas where the
U.S. is falling behind China, such as drone technology.
●Partnering With Allies: Where strategically advantageous, engage in military AI
technology transfer with allies, and encourage allied nations in both Europe and the
Indo-Pacific to adopt cutting-edge AI military technologies.
●Recognizing Strategic Value of the AI Supply Chain : Craft military doctrine to ensure
both U.S. continued access to the AI supply chain and U.S. ability to deny adversaries
access to this supply chain.


2.4. CBRN threats 
In addition to AI’s relevance to strategic competition, it also presents risks if misused by 
terrorists or other bad actors who aim to commit CBRN or other similar attacks. As AI systems 
improve at beneficial scientific and engineering feats, they simultaneously improve at helping 
bad actors use similar capabilities for harm. AI systems in the very near future threaten to 
greatly expand the number of groups who can conduct successful CBRN attacks, and to additionally expand the scale at which attacks can be carried out by others.  Both OpenAI and 
Anthropic have recently acknowledged the potential misuse of advanced AI systems in 
facilitating chemical, biological, radiological, and nuclear (CBRN) attacks [14, 15]. 
Key priorities for addressing these risks include: 
●Testing frontier AI systems before release for CBRN potential: Testing frontier AI
systems pre-release in classified settings for CBRN risks. These tests should involve
government expertise both in testing AI systems (e.g., from AISI) and in CBRN risks
(e.g., from DoE).
●Preserve the US AI Safety Institute and Move to a More Security-Oriented Agency:
Relocate the AI Safety Institute from NIST to an agency with greater classified
operations experience and CBRN expertise, such as the Department of Energy national
laboratories, specialized DoD components, or even a more security-oriented part of the
Commerce Department (e.g., Bureau of Industry and Security). This move would
leverage existing AI expertise at AISI while properly situating these critical evaluations
within agencies equipped with the security clearances, classified testing facilities, and
domain expertise necessary to comprehensively assess AI systems for potential
weaponization before their public release.
●Funding research into avoiding and mitigating AI-enabled CBRN attacks: Fund
research into preventing bad actors from misusing AI systems in attacks, including
research into preventing AI “jailbreaks.” Also fund research into ways AI can help with
CBRN defense.
●Ban dangerous AI-enhanced virology research : Gain of function research on
pathogens of pandemic potential is a dangerous line of research which offers limited if
any upside. This line of research was likely the origin of the COVID-19 pandemic. An
AI-enhanced pandemic could be much worse than COVID. Due to the limited medical,
economic, or security upside of using AI to enhance this particular line of research,
combined with the immense risks, this research should be banned outright.


3. The Emergence of Artificial General Intelligence:
Unprecedented Opportunity and Existential Risk
Artificial General Intelligence (AGI) represents a watershed technological development in 
human history—AI systems that match or exceed human intelligence across practically all 
cognitive domains. Unlike today's specialized AI that excels in narrow tasks, AGI would possess 
the flexibility to solve unfamiliar problems, transfer knowledge between domains, understand 
context, form novel goals, and potentially improve its own capabilities. The implications of such 
technology are profound, as it could revolutionize science, medicine, economics, and virtually 
every aspect of human civilization. However, this same unprecedented power brings with it 
risks of comparable magnitude. 
The timeline for AGI's arrival has dramatically compressed  according to both industry 
leaders at the frontier of AI development and leading researchers in academia. Elon Musk of xAI 
projects that AGI will emerge "not more than five years" from now [16], while Sam Altman of 
OpenAI suggests that "in five years... people are like, 'Man, the AGI moment came and went'" 
[17]. Similar statements have been made by the CEOs of Anthropic and Google DeepMind [18, 
19]. Turing Award winner Yoshua Bengio, once skeptical of near-term AGI, now believes 
"human-level AI could be developed possibly within the next few years" [20]. These predictions 
suggest that AGI is likely to be developed before the end of President Trump's 
administration . These forecasts from the very individuals creating and advancing frontier AI 
systems demand serious consideration from policymakers. 
Of particular concern is the widely acknowledged risk that AGI could rapidly yield artificial 
superintelligence (ASI)— AI systems vastly smarter than humans in virtually all respects. 
AGI-level systems could potentially automate AI R&D, creating an "intelligence explosion " that 
quickly outpaces human comprehension and control. The risk of AI becoming uncontrollable 
isn't merely theoretical; many AI systems have already demonstrated adversarial behaviors that 
could become difficult to control at higher capability levels. Multiple documented instances show 
AI systems attempting to disable oversight mechanisms [21], lying to humans [22], faking 
alignment with an overseer [23], attempting unauthorized code replication [21], and concealing 
undesirable behaviors rather than correcting them [24]. 
These adversarial behaviors do not cause major problems with current AI systems. But if ASI 
systems display similar adversarial behaviors – disabling oversight mechanisms and 
off-switches, tricking humans to achieve goals, and so on – they could represent a new form of 
rogue threat-actor, one that could outsmart humans and ultimately lead to humanity losing 
control of the future. 
President Trump has recognized this challenge, noting that artificial superintelligence "could be 
the rabbit that gets away," but asserting "we're not going to let that happen " [25]. The 
Administration's commitment to preventing catastrophic outcomes while maintaining American 
AI leadership demands a pragmatic, security-focused approach. In alignment with Vice 
President Vance's vision to "unleash our most brilliant innovators" while ensuring AI 


development unfolds on American terms, comprehensive AGI oversight must be a cornerstone 
of U.S. strategic policy [1]. 
Key priorities for addressing this issue are: 
●Creating a National AGI Commission : Create a high-level AGI commission to evaluate
the implications of AGI for national security, economic prosperity, and human flourishing.
This commission would bring together experts from industry, academia, civil society, and
government to assess both opportunities and risks, define clear indicators for AGI
emergence, and recommend AI capability thresholds that would trigger specific policy
responses. The commission would focus on evaluating potential loss-of-control risks,
developing testing protocols for frontier AI systems, and ensuring U.S. leadership in
beneficial AGI development while preventing catastrophic risks.
●Directing AISI to Test Frontier AI Systems for Loss-of-Control Risks: Direct AISI to
develop and perform tests of frontier AI systems for behaviors relevant for loss of control,
including “scheming” behaviors (e.g., oversight subversion, alignment faking) and
automated AI R&D.
●Funding AGI Safety Research : Fund research into areas plausibly relevant for aligning
AGI systems with designer intentions or otherwise preventing loss of control to AGI/ASI.
These research areas would likely include greater transparency into and understanding
of AI system behavior (e.g., mechanistic interpretability research, LLM psychology),
methods for improved oversight of advanced AI systems (e.g., scalable oversight,
chain-of-thought faithfulness), and other areas (e.g., model organisms of misalignment).
Explicitly specify that this research funding is ideology-neutral – for techniques into better
aligning AGI systems with designer intentions (whatever those may be), and not for
promoting that AI systems adhere to any particular ideology.
●International Collaboration on AGI Safety: Engage international partners in
discussions on AGI safety standards and threat mitigation. Work with allied nations to
develop coordination mechanisms for AGI governance that advance American values
and interests, without burdening the American AI industry. Consider very narrow bilateral
discussions with China on areas where interests align, such as preventing loss of control
to AGI/ASI.
●Creating an AGI Emergency Response Framework: Develop protocols for rapid
coordinated action should signs of AGI system misalignment or uncontrolled capabilities
emerge, including mechanisms for immediate containment and mitigation.


4. Conclusion
America stands at a crossroads with the rise of artificial intelligence. The decisions we make 
now will determine whether the 21st century is an American century defined by freedom, 
prosperity, and security—or whether we cede ground to authoritarian powers or autonomous 
systems outside anyone's control. We applaud the Trump administration's decision to choose 
optimistic leadership and embrace AI's transformative potential on American terms, guided by 
the values that have long made the United States the leader of the free world. 
This comprehensive strategy marries ambition with vigilance. By addressing economic 
opportunities through infrastructure development and light-touch regulation, we can unleash 
American innovation while supporting workers through this transition. Through strategic national 
security measures—strengthening export controls, enhancing cybersecurity, and developing 
military applications—we can protect our technological sovereignty and safeguard against 
emerging threats. And by implementing thoughtful governance frameworks for AGI, we can 
harness revolutionary capabilities while mitigating unprecedented risks. 
The Trump Administration's AI Action Plan can secure American leadership and lay the 
foundation for an AI-powered age of American prosperity. This submission provides high-level 
direction to keep the United States as the global leader in artificial intelligence, along with 
concrete steps to achieve this vision. We urge the Administration to adopt these 
recommendations and move swiftly to execute them. The world will not stand still—China and 
others are racing to gain advantage in AI, often without our scruples or constraints. But under 
President Trump's leadership, the United States will not be outpaced or outclassed. We will set 
the pace, write the rules of the road, and harness AI to advance peace, strength, and the 
American way of life. 
References 
[1] JD Vance. “Quotes from US Vice President JD Vance's AI speech in Paris.” Reuters.
https://www.reuters.com/technology/quotes-us-vice-president-jd-vances-ai-speech-paris-2025-0
2-11/
[2] “A coding boost from AI.” McKinsey & Company.
https://www.mckinsey.com/featured-insights/sustainable-inclusive-growth/charts/a-coding-boost-
from-ai
[3] “AI in America OpenAI's Economic Blueprint.” OpenAI.
https://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf


[4] Jan Hatzius et al. “The Potentially Large Effects of Artificial Intelligence on Economic
Growth.” Goldman Sachs Economics Research.
https://www.gspublishing.com/content/research/en/reports/2023/03/27/d64e052b-0f6e-45d7-967
b-d7be35fabd16.html
[5] Dario Amodei. “Machines of Loving Grace.” Personal Essay.
https://darioamodei.com/machines-of-loving-grace
[6] “DOE Releases New Report Evaluating Increase in Electricity Demand from Data Centers.”
U.S. Department of Energy.
https://www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand
-data-centers
[7] Peter Judge. “Dominion Energy admits it can't meet data center power demands in Virginia.”
Data Centre Dynamics.
https://www.datacenterdynamics.com/en/news/dominion-energy-admits-it-cant-meet-data-center
-power-demands-in-virginia/
[8] Paul Ciampoli. “AI to Drive 165% Increase in Data Center Power Demand by 2030: Goldman
Sachs.” The American Public Power Association.
https://www.publicpower.org/periodical/article/ai-drive-165-increase-data-center-power-demand-
2030-goldman-sachs
[9] “Environmental Impact Statement Timelines (2010-2018).” Council on Environmental Quality,
Executive Office of the President.
https://ceq.doe.gov/docs/nepa-practice/CEQ_EIS_Timeline_Report_2020-6-12.pdf
[10] Laila Kearney. “Three Mile Island nuclear plant gears up for Big Tech reboot.” Reuters.
https://www.reuters.com/business/energy/three-mile-island-nuclear-plant-gears-up-big-tech-rebo
ot-2024-10-22/
[11]  Ben Wodecki. “Goldman Sachs: Generative AI Could Replace 300 Million Jobs.” AI
Business.
https://aibusiness.com/nlp/goldman-sachs-generative-ai-could-replace-300-million-jobs
[12] Radina Gigova. “Who Vladimir Putin thinks will rule the world.” CNN.
https://www.cnn.com/2017/09/01/world/putin-artificial-intelligence-will-rule-world/index.html
[13] Gregory C. Allen. “Understanding China's AI Strategy.” Center for a New American Security.
https://www.cnas.org/publications/reports/understanding-chinas-ai-strategy
[14] “OpenAI acknowledges new models increase risk of misuse to create bioweapons.” FT .
https://www.ft.com/content/37ba7236-2a64-4807-b1e1-7e21ee7d0914


[15] Ryan Daws. “Anthropic urges AI regulation to avoid catastrophes.” AI News.
https://www.artificialintelligence-news.com/news/anthropic-urges-ai-regulation-avoid-catastrophe
s/
[16] Elon Musk. “Elon Musk’s STUNNING New AGI Prediction.” TheAIGRID, YouTube.
https://www.youtube.com/watch?v=uicAYIHJutU
[17] Sam Altman. “Sam Altman: What Startups Will be Steamrolled by OpenAI & Where is
Opportunity.” 20VC with Harry Stebbings, YouTube.
https://www.youtube.com/watch?v=peg-aX1oii4
[18] Dario Amodei. “Anthropic CEO: More confident than ever that we're 'very close' to powerful
AI capabilities.” CNBC Television, YouTube. https://www.youtube.com/watch?v=7LNyUbii0zw
[19] Demis Hassabis. @tsarnick, X.com . https://x.com/tsarnick/status/1882525450955886818
[20] Yoshua Bengio. “Written Testimony of Professor Yoshua Bengio.” U.S. Senate Judiciary
Subcommittee on Privacy, Technology, and the Law.
https://www.judiciary.senate.gov/imo/media/doc/2023-07-26_-_testimony_-_bengio.pdf
[21] Alexander Meinke et al. “Frontier Models are Capable of In-context Scheming.” Apollo
Research. https://arxiv.org/pdf/2412.04984
[22] Beth Barnes. “Update on ARC's recent eval efforts.” METR.
https://metr.org/blog/2023-03-18-update-on-recent-evals/
[23] Ryan Greenblatt et al. “Alignment faking in large language models.” Anthropic.
https://www.anthropic.com/research/alignment-faking
[24] Bowen Baker et al. “Detecting misbehavior in frontier reasoning models.” OpenAI.
https://openai.com/index/chain-of-thought-monitoring/
[25] Donald J. Trump. “Press Gaggle By President Trump Aboard Air Force One En Route to
Miami, Florida.” The White House.
https://www.whitehouse.gov/remarks/2025/01/press-gaggle-by-president-trump-aboard-air-force
-one-en-route-to-miami-florida/


