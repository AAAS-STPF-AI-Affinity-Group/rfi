 
 
March 14, 202 5 
 
Michael Kratsios  
Director  
Office of Science and Technology Policy  
The White House  
1650 Pennsylvania Avenue  
Washington, D.C. 20504  
 
Sethuraman Panchanathan   
Director  
National Science Foundation  
2415 Eisenhower Avenue  
Alexandria, VA 22314  
 
RE: Artificial Intelligence Action Plan  Request for Information  
 
Submitted via email  to: ostp-ai-rfi@nitrd.gov    
 
Dear  Directors  Kratsios  and Panchanathan : 
 
AHIP is the national association that represents health insurance plans that provide coverage, 
services, and solutions for over 205 million Americans through public programs such as 
Medicare and Medicaid, employer -sponsored insurance, and the individual in surance 
market.  AHIP appreciates the opportunity to provide comments to the Office of Science and 
Technology Policy (OSTP) and the National Science Foundation (NSF) on the Request for 
Information (RFI) on the Development of an Artificial Intelligence (AI) Action Plan.  We agree  
fully  that, with the right government policies, the United States can solidify its position as the  
global  leader in AI and secure a brighter future for all Americans.   
 
As Americans increasingly interact with AI in many facets of life, including across the 
health  care system, it is important to create balanced policies that help realize the potential 
of AI  and promote innovation, while also promoting  safety and build ing trust among 
patients and stakeholders.  The Administration , including through  the Department of Health 
and Human Services (HHS), can play an important role in advancing  the use of AI in the health 
care system by improving coordination and consistency across federal agencies, investing in AI 
standards development and education, and continuing to collaborate with stakeholders by 
participating in, and leveraging recommendations from, public -private partnerships.  
 
Below, we provide a snapshot of  the current state of health plan use of AI and provide i nput on 
high-priority policy actions  and considerations for AI in health care . 
 
 

 
Page 2 
Health Plan Use of AI  
 
Use of AI in health care presents growing opportunities for health plans to help consumers  
employees, providers, and other partners  in improving health outcomes and the health care 
experience , as well as  in gaining internal operational efficiencies  and reducing costs . 
Examples of where AI is being used to bring value to the health care continuum include:  
• Consumers :  
o Offering chatbots for simple member questions.  
o Facilitating quick and accurate answers for members' complex health benefits 
questions by customer service representatives.  
o Providing health plan apps that include pricing estimates , among other features.  
o Supporting consumer appeals processing by extracting information from faxed 
appeals and instantly generat ing a fully formed digital case file, for human 
review.  
• Clinical :  
o Cleaning, integrating, normalizing, and a nalyzing vast amounts of data faster and 
more efficiently than traditional statistical methods.  
o Supporting provider partners by identifying gaps in care  and potential safety 
issues.  
o Improving predictive analytics of patient risks to enable proactive disease and 
care management  in partnership with providers .  
o Researching disease pathways, treatment options,  and likely outcomes.  
o Supporting customized patient care plans, early interventions, and customized 
treatment.  
• Administrative :  
o Near real -time approval s of prior authorizations based on appropriate 
documentation and member clinical history .  while potential denials are always 
subject to  human review.  
o Contributing to efficient claims processing  and reductions in administrative costs , 
including flagging claims processing issues to reduce errors and support claims 
operators.  
o Promoting  payment integrity by helping to identify patterns of payment 
abnormalities, enabling health plans to engage productively with their provider 
partners to reduce waste  and prevent fraud.  
 
Policy Recommendations  
 
AHIP  urges consideration of the following guiding principles  to support clarity, coordination, 
and consistency  in the federal government’s  approach to  health  care AI. 
 
• Take a Federal Approach:  A consistent national approach to AI oversight would  ensure  
protect ion of  patients  while minimizing additional administrative burdens and costs.   

 
Page 3 
• Define “AI”: Legislation should define AI and other terms consistent with the National 
Institute of Standards  & Technology’s (NIST) AI Framework to build a national shared 
language.  
• Rely on Existing Laws:  New legislation should not duplicate existing laws and instead 
should only fill gaps in existing health data and consumer protection laws and 
regulations.  
• Provide High -Level Oversight:  Guardrails that permit flexibility should be established , 
and technologies or standards that may become outmoded should not be named in law.  
• Promote Risk -Based Approaches: Policies should point to risk -based standards and 
confine any third -party evaluation requirements or government audits to “high -risk” uses.  
• Protect Intellectual Property: Policies should require developers to provide sufficient  
transparency for deployers and explainability for consumers and should not  put American 
companies at a competitive disadvantage by requiring  disclosure of  proprietary 
information . 
• Engage in Public -Private Partnerships:  The government should look to learnings from 
the private sector and collaborate with stakeholders to advance AI and inform policy.  
• Advance Standards: Laws and regulations should defer to industry standards where they 
exist and fund efforts to address ongoing gaps  as technology evolves.  
• Guard Privacy:  Health plans are already subject to robust privacy regulations . While  a 
national privacy law is needed to extend patient protections to all entities that hold health  
care data,  establishing  a new private right of action would chill innovation  and raise 
costs . 
 
Additionally, w e encourage efforts to  partner  with states  to promote  guardrails that can 
serve as guiding principles and foster uniformity  among  the federal government and  state 
regulators. These efforts should i nclude all relevant stakeholders , including consumers,  to ensure 
comprehensive  input is captured  and  AI developers, deployers, and end-users  have the 
opportunity to contribute to the development of any new policies are principles .  
 
Infrastructure to Support AI Innovation  
 
Standards and Frameworks  
 
Stakeholders in the private sector have been collaborating for several years to develop 
governance, ethical, and practice standards for organizations developing and deploying AI to  
protect consumers while fostering AI. AHIP has joined business and technology leaders as well 
as consumer advocates to advance principles, best practices, and standards. For example, AHIP 
has worked with the Consumer Technology Association on developing st andards of 
trustworthiness and recommendations for bias management  and continues to work with them to 
identify areas in which new standards are needed .12  
 
1https://shop.cta.tech/collections/standards/products/the -use-of-artificial -intelligence -in-healthcare -trustworthiness -
cta-2090   
2 https://shop.cta.tech/a/downloads/ -/b5481e81fe7f99aa/9d1895627bdd6e27   

 
Page 4 
AHIP strongly encourages use of these and other existing national frameworks and standards in 
developing any new federal policy . This would help avoid duplication and promote  a streamlined 
oversight structure to support continued innovation. For example, the  NIST AI Risk 
Management Framework, developed with robust input from stakeholders, including AHIP, 
provides a foundation for understanding and applying methods for “tiering” of risks associated 
with AI.3 Further, as the Administration seek s to develop  and promote  the innovation  potential  
that AI offers, it is important that federal law preempt state laws. Many states are releasing new 
provisions and requirements that could stifle the development of AI and hamper  efforts  to 
standardize  technologies . Alignment on common principles and uniform guardrails across  
Congress and the Administration is critical for AI to be used to its full potential.  The NIST AI 
Framework should inform core components of the Action Plan , such as definitions, to 
provide consistency  across  federal AI initiatives . 
 
Addressing  AI Risk  
 
Governance is key to promoting trustworthy, ethical AI. Health plans  have established 
governance models and  are continually assessing potential risks  for the use of AI in health 
care, including  those related to  safety , ethics, privacy,  and security . At this point in the maturity 
model , health plans aim to identify and prioritize high-value and low -risk use cases for 
development and deployment . However, a s plans  build and deploy  more sophisticated AI 
solution s over time, the work today to establish  a responsible and ethical foundation for use will 
be critical for organizations to navigate the greater risk to realize the greater reward .  
 
Any policies that address AI oversight should apply a risk -based approach . Algorithms that 
speed processing of claims and have been in place for decades are far lower risk  than, for 
example, solutions that recommend potential treatment pathways to be shared with clinicians . 
Flexibility to right -size business practices and mitigation techniques based on risk is necessary to 
realize the potential of AI , while avoiding overly restrictive, infeasible, or misaligned policies 
that risk stifling innovation.  Aligni ng with the NIST AI RMF categories and ensuring adequate 
human oversight for use cases that result in critical decisions for members and patients can 
further support risk mitigation.  Further, AI coupled with interoperability can advance the health 
system ’s ability to ensure better care for patients and administrative support for providers.  
 
Consistent with a risk -based approach, w e do not support requirements to broadly subject  
underlying AI technology to mandatory outside review or audit.  Many health plans  are 
proactively employing their own risk -based approaches and optimizing existing data governance 
structures for internal applications of AI.  Health plans are also proactively testing and 
performing assessments on their AI solutions as part of a multifaceted risk -based approach to 
ensure AI systems perform as designed.  The federal governmen t should  focus on monitoring 
outcomes  and not micromanage business practices through requir ed third -party 
evaluation , audits, or disclosure of proprietary information . If the federal government 
chooses to require outside testing, it should focus  only on developers  who sell access to large -
 
3 https://www.nist.gov/itl/ai -risk-management -framework  

 
Page 5 
scale , foundation or general -purpose AI , or providers who internally develop  high-risk clinical 
applications  that generate decisions that could lead to adverse  direct patient impact . It would be 
tremendously costly to seek outside review of all AI solutions  and duplicative of plans ’ own 
internal work   
 
Trustworthy Development & Responsible Use  
 
Successful use of AI to enhance high -quality, affordable care will depend on responsible 
approaches to both AI development and AI deployment. In the current environment, there are no 
established standards for delineating roles and responsibilities across the AI environment , 
including between AI “developers” and “deployers,” if an adverse outcome occurs from the use 
of AI.  
 
Currently, there is also a lack of broadly applicable, established requirements or standards 
for AI vendors to transparen tly disclos e key elements of tools  that would enable deployers to 
proactively assess the potential risk of errors, safety hazards, or discrimination, including to 
support evaluation efforts during the initial procurement phase of adopting new AI technology.  
Of particular concern are the GenAI models that, for example, develop new content, images, 
video, and audio. These GenAI models are t rained on massive amounts of data and generally 
offer little transparency into the datasets used to train the models and other key components of 
the model’s design. While we recognize the need to protect intellectual property,  AI 
developers should be required to share relevant details with purchasers to inform efforts to 
identify and manage risk while optimizing safety and effectiveness.  One approach would be to 
focus on “use disclosures” that are relevant and useful  to deployer organizations in mitigating 
meaningful/tangible risks  but at the same time prevent additional disclosure or monetization . 
 
Transparency is a key enabler of trust and is a critical component of successful deployment and 
use of AI. Patient, consumer, and caregiver education is critical to helping individuals understand 
better  what AI is and how it might be used. The core principles of AI transparency and 
explainability go together  - transparency with explainability will provide consumers and 
other end -users with useful, actionable information . For example, developers of high -risk AI 
tools can utilize plain language examples of ho w the AI tool was designed and how it forms the 
basis of its decisions. As appropriate, AI developers and deployers can also provide information 
on the data used to train the AI tool to contribute to transparency efforts. In promoting 
transparency,  consideration should be given  to not overwhelming consumers  with a high volume  
of disclosures . Broad disclosure requirements  could , in practice,  undermine trust  and, in turn , 
reduce consumers’ willingness to interact with, and experience  the benefits of, AI and other 
emerging technologies . 
 
Advancing Public -Private Efforts  
 
AHIP believes public -private partnerships and collaboration can play an important role in 
facilitating data -driven efforts  to advance AI. The Action Plan should promote ongoing 
opportunities for public -private evidence generation and dissemination on best practices  to 

Page 6 
support successful AI development and use. This could include partnering with stakeholders 
to better understand potential applications, use cases, and risks associated with AI. These 
findings should be used to guide the developme nt of best practices, guidelines, and standards and 
prioritize resource allocation to ensure investm ents are high-value for the health care sector.  
Conclusion  
Thank you f or your consideration of our input. AHIP appreciates your efforts to engage 
stakeholders as you identify AI prior ities a nd actions. We look forward to working with you to 
advance AI, including opportunities to support innovation in health care. If you have questions, 
please contact me at 
Sincerely, 
Danielle A. Lloyd  
Senior Vice President, Private Market  Innovations & Quality Initiatives  
4 This document is approved for public dissemination. The document contains no business -proprietary or 
confidential information. Document contents may be reused by the government in developing the AI Action Plan 
and associated documents without attribution.  

