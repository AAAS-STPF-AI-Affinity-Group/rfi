PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-39ob-l75d
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-8955
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Abraham  Marsen
Address: United States,  
Em ail:  
General Comment
Generative content engines, currently im properly classified as "artificial intelligence" such as ChatGPT are a danger to United States
Citizens on several levels.
The data harvested is a privacy violation the likes of which we have never seen before, reaping personal or insecure data without any
discernm ent. This can expose banking/governm ent inform ation, personal diaries, passwords, and m ore if the engine is quiried in the
correct way.
It has been shown to harvest anything, including illegal m aterial like CSAM (https://arstechnica.com /tech-policy/2024/08/nonprofit-
scrubs-illegal-content-from -controversial-ai-training-dataset/) or be capable of creation of it. This further extends to the creation of
revenge pornography where a user can create false chat logs, im ages, and m ore graphically depicting anyone in any act.
Evidence-based law will be increasingly harder to prove beyond a doubt when defense can access tools to reliable create false alibis that
withstand basic scrutiny.
Scam s using "Artificial intelligence" are on the rise, where voice captures, false im ages, videos are all produced with relative ease and high
believability.
All of this is before even considering the m ass dam age it incurs upon those in creative fields. Any business or person who is not currently
already at the top and able to pay OpenAI and its com petitors to keep their content out of content engines or safeguard it will have their
own creations plundered, plucked apart, and recobbled into things that only prom ote m onopolies and stifle creative work.
We are also seeing corporate in-house usage leading to m ass firings across m any industries and various levels of unem ploym ent are rising.
We are even seeing instances where som e groups are allowing the "artificial intelligence" to m ake decisions, which could lead to legal
situations where there is no 'person' to take responsibility for an action that has caused great harm .
Please. Do not allow "artificial intelligence" a pass. Please do not allow generated content to create chaos that cannot be undone. It will
cause harm . It will costs lives. It will and is creating suffering and loss.


