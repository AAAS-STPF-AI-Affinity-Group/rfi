VIA ELECTRONIC DELIVERY TO: 
March 14,  2025  
Faisal D'Souza  
National Coordination Office  
2415 Eisenhower Avenue  
Alexandria, VA 22314 
RE: AI Ac tion Plan – Comments of the Biotechnology Innovation Organization 
regarding National Science Foundation ( NSF) request for Information on the 
Development of an Artificial Intelligence (AI) Action Plan  (90 FED.REG. 9088 , 
02/06/2025)  
Dear Mr . D’Souza: 
On behalf  of its member organizations, the Biotechnology Innovation Organization (“BIO”) 
submits this Comment to the  National Science Foundation and Office of Science and 
Technology Policy  in response to the February 6, 2025 , Federal Register notice soliciting 
information  on the development of an Artificial Intelligence Action Plan (the “ AI Action 
Plan”). This document is approved for public dissemination.  The document contains no 
business -proprietary or confidential information; d ocument contents may be reused by 
the government in developing the AI Action Plan and associated documents without 
attribution.  
BIO i s the world’s largest trade association representing biotechnology companies, 
academic institutions, state biotechnology centers, and related organizations across the United States. BIO members range from startup companies developing their first comme rcial products to large biopharmaceutical, agricultural , and biotechnological 
product manufacturing corporations . The use of artificial intelligence and machine 
learning (together: “AI”) tools is becoming increasingly common, though not  yet 
ubiquitous, among BIO’s member companies, who deploy this technology to assist in drug discovery, clinical or field trial design, manufacturing process improvements, and a range of other applications.  
BIO appla uds the Administration’s interest in developing national policies for sustaining 
and enhancing America's AI preeminence  in order  to promote human flourishing, 


economic competitiveness, and national security.  To that end, we would  like to offer a few 
high- level recommendations  below:  
Maint ain flexibility  to account for specific needs of different business models and 
industry sectors : BIO members regard AI as an important and powerful addition to their 
arsenal of tools  with which they  create and accelerate innovation in an already 
comprehensively regulated space. When BIO members use AI (or other tools)  to 
augment , for example,  the discovery of new therapeutic molecules, the development of 
drought - or pest -resistant crops, or the design of novel industrial enzymes for biofuel 
production, they already must ensure compliance with highly specific regulatory schemes  
designed to ensure that new biotechnology products are researched, developed, and 
deployed safely, reliably,  lawfully,  and res ponsibly . We trust that the  Administration will 
ensure that any new national AI policies will map smoothly onto existing sector -specific 
regulatory frameworks . This should be done in ways that draw on the experience and 
ongoing work of specialized regulatory agencies and their regulated industries, and that enhance, rather than encumber, the efficient operation of these regulatory frameworks.  
National uniformity:  Increasing commercial use of AI tools  and the related collection, 
use, and dissemination of consumer data is already generating significant legislative and 
regulatory activity at the state level. There is a risk that new national AI policies could stand in tension with a patchwork of state health data privacy and consumer protection 
laws in ways that create nonuniformity, business uncertainty, and unrealistic compliance and reporting burdens. While much can be learned from ongoing state efforts in AI safety, accountability, and transparency , the Administration should push for harmonization 
across different developing state frameworks and consider whether certain aspects of AI governance should be reserved exclusively to the United States.  
Maint ain the ability of US businesses and researchers to responsibly collect, use, 
and aggregate  data across state lines and international borders. AI tools cannot be 
developed or deployed without access to large and high- quality data sets. As the 
Administration considers the development of national AI policies, it should ensure that biotechnology firms can access and utilize the most robust and comprehensive data sets,  
not just for research but as part of the development of accurate AI systems.  Ability to  
access data in a timely and efficient manner drives biotechnology innovation that is critical to our success in the life sciences industry. The Administration should work with our global allies to protect private sector access to the best genomic, genetic  and biologic data. 
Should key nations take steps to block their data from inclusion in public databases, U.S. AI systems may not be as accurate or efficient and could slow our industry’s ability to innovate and compete.  
At the s ame time, the Administration should ensure that proprietary or sensitive data sets 
are given adequate protections to safeguard against not only data theft, but IP theft or 


duplication of products. Open AI models, in particular have the potential to expose large 
or sensitive data sets, which are under threat of theft by adversarial foreign actors for both the health and agricultural sectors. BIO encourages any AI policy to consider public sector data sets, those that belong to private industry, and those developed within academia and the specific, nuanced steps needed for each individually. To maintain U.S. 
dominance in AI and biotechnology, AI inputs must be given the same protections as AI products.   
Conside rations of AI use in drug development. As a transformative tool, AI will soon 
span the full range of drug development activities  – from discovery and preclinical testing 
to post - approval studies, pharmacovigilance, and manufacturing. The FDA's current 
regulatory framework ensures the safety and efficacy of products approved for U.S. patients, guided by the principle of assessing the benefit of a medical product against its potential risks  to patients . Accordingly, the risks of incorporating AI across drug discovery 
and development should be considered on a use- case basis. This would include a 
consideration of the AI model influence (the weight of the model in the totality of evidence for a specific decision) and decision consequence (the potential consequences of a wrong decision).  
BIO agrees w ith the FDA that  the potential patient risk  related to  the use of AI in drug 
discovery is low. Patients will generally benefit from reductions in research time for the 
discovery of molecules for further investigation. When it comes to clinical trials, AI has the potential to be useful in, for example,  site selection, recruitment, and demographic 
balancing of control and treatment groups. However, as AI becomes more integrated in the actual design of clinical trials, the assessment of endpoints, and the manufacturing of approved therapies, the associated risks may increase.  
In every  phase of drug development, industry and regulators should work collaboratively 
to establish best practices for AI development and use and the type and amount of evidence adequate for the FDA to accurately assess whether AI is fit for purpose for t he 
specific context of use. Evidence requirements will vary based on use, and industry and regulators should work together to create clear expectations. As AI and machine learning has increased in salience over the past decade, the FDA has already set fort h a number 
of guidance documents and other publications. These materials provide a valuable beginning and a basis for refinement.  
BIO has encourage d FDA to consider the following recommendations for further 
engagement between industry and regulators:  
(i) Clarify the scope of regulatory oversight to increase stakeholder
understanding. The primary focus should be on areas where FDA hasregulatory authority.


(ii) Strive for consistent terminology, such as  the FDA's Digital Health and Artificial
Intelligence Glossary. We believe the FDA could take a leading role in further
defining terms critical to the regulatory process.
(iii) Adapt "Good Machine Learning Practices" (GMLP) to the use of AI in drugdevelopment, using medical device practices as a starting point. The adaptedPractices should include considerations for AI model design, development,testing, and performance. The standards should specify the degree oftransparency required for the Agency to evaluate regulatory submissions.
(iv) Draft a risk assessment and credibility framework for AI for different contextsof use, such as clinical research and manufacturing. New frameworks shouldbuild on established ones when possible.
(v) Clarify regulatory expectations for validation of AI models.  Detailed
expectations for testing, evaluation, verification, and validation will enablebetter understanding among developers.
(vi) Clarify requirements for regulatory submissions and commercially confidentialinformation. Clear and detailed enumeration of FDA expectations oninformation to include in dossiers is essential. Transparency needs to bebalanced with the protection of innovation for drug and technology developers.
(vii) Adopt an agile approach to regulatory oversight to ensure it is responsive tochanging technology. Given the early stage of AI use in drug development andthe emergence of new technologies and best practices, BIO has recommended
that the FDA consider principles -based recommendations, Q&As, and
discussion papers rather than formal guidance.
(viii) Step up discussions with appropriate foreign drug regulatory authorities aboutharmonizing regulatory principles applicable to AI use.
Intellectual property (IP).  BIO members use AI as a tool to augment a wide range of 
research and development activities, and it is critical that innovative products that were discovered and developed with the use of AI remain eligible for IP protection. However, 
troubling questions have been raised about the patentability of inventions where the 
inventor’s discovery was facilitated in important ways by the use of an AI tool. Current examination guidance in the U.S. Patent and Trademark Office (USPTO) grapples with these questions and seems to offer a workable framework for now,  but it  applies U.S. 
patent law concepts such as  “conception” and joint inventorship in new , unfamiliar , and 
ill-fitting  ways. It will be important to carefully monitor how well these historic tests will 
work to account for the impact of AI and other computational tools on the patentability of resulting inventions.  
It will also be im portant to monitor whether the United States may be deviating in important 
and unnecessary ways from how foreign patent systems address similar questions about the use of AI and other computational tools in the invention process. The USPTO Guidance implicitly but clearly casts doubt upon the substantive patentability of inventions 


that result from the use of AI. It suggests that even where there has been some human 
involvement, there may be no patentable invention because no natural person contributed “enough” -- and the specter of unpatentability is there even if the invention is otherwise 
perfectly novel, unobvious, and properly described. Foreign patent offices that have confronted the question, in contrast, don’t seem to view the involvement of computational tools as a potentially patentability -destroying event in the way the USP TO Guidance 
implies.  
Finall y, BIO has cautioned the USPTO and public policymakers against premature and 
reflexive actions in response to the increasing adoption of AI and other computational tools among US innovators. There is nothing inherently harmful or problematic about novel and unobvious inventions just because they were generated with the help of AI tools. In fact, public discourse should celebrate the emergence of efficiency -enhancing 
tools that allow more US innovators, including in biotechnology, to make more inventions more quickly, cheaply, and efficiently.  
Thank you f or the opportunity to comment on these critical issues. We look forward to 
further engagement with you as the NSF’s work moves forward.  
Respect fully submitted,  
/s/ Ph
yllis Arthur  
Executive Vice President  and Head,  Health care Policy & Programs  


