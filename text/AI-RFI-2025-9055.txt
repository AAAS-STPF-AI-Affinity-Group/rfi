PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8b-3dio-ph6i
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-9055
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Mike Richards
General Comment
Generative AI is not a race we need to concern ourselves with winning. Like NFTs or the "Meta-verse", it is a bubble whose benefits and
capabilities have been wildly overstated by tech executives chasing investor cash and stock prices. The actual technology is unreliable,
unsustainably expensive, wasteful to lim ited resources, and will becom e increasingly difficult to m onetize as the public continues to grow
m ore and m ore frustrated with how hard it's being pushed on us against our will.
More concerningly, com panies are being given the green light to steal copyrighted m aterial as training data. The m odels that fuel generative
AI are constructed from  widespread harvesting of text, photos, video, m usic, and even people's faces and voices. All to be regurgitated
later at the discretion of com panies who do not own this property and have no license to use it. This is, m ake no m istake, theft. And the
attem pt to replace the creators of these copyrighted works by stealing their property out from  under them  will not only open the door to
an endless series of legal battles, but also directly threatens countless jobs in the fields that AI seeks to "replace". None of this provides
personal, practical, creative, or econom ic benefit to the Am erican people.
There is also a grave risk posed by the ease of m isinform ation this technology enables. Text based m odels like ChatGPT and Google's
search sum m aries are notorious for providing laughably inaccurate inform ation, inform ation that m ay even prove dangerous if concerning
vital topics such as m edical advice. Com panies open them selves up to extrem e liability by positioning these autom ated system s as
legitim ate sources of inform ation, and represent a direct risk to any m em bers of the public who trust them  to be so.
The potential for deliberate deception is even worse. There have already been phone scam s using AI powered voice cloning, and the
ability to convincingly m im ic any person from  a m inim um  of available data will have devastating interpersonal, professional, and even
political consequences. Further escalation of generative AI will inevitably lead to, for exam ple, an endless supply of videos of the President
saying and doing com prom ising things that will be indistinguishable from  real footage. Every public figure with enough cloneable data will
becom e a target of the internet's whim s, no m atter how m alicious, inappropriate, or dam aging.
Generative AI is a solution in search of a problem . It's a technology begging for abuse and offering little in return but overinflated prom ises.
The bubble is already popping. No am ount of resources poured into it can stop that. Those resources are finite, and better spent on things
that will actually directly help the public.


