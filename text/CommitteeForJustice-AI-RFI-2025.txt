NATIONAL SCIENCE FOUND ATION
OFFICE OF SCIENCE AN D TECHNOLOGY POLICY
Re: Request for Information on the Development
of an Artificial Intelligence
SUBMITTED MARCH 15, 2025  
BY 
CURT LEVEY  
PRESIDE NT 
THE COMMITTEE FOR JU STICE
Note: This document is approved for public dissemination. The document contains no business
proprietary or confidential information. Document contents may be reused by the government in
developing the AI Action Plan and associated documents without attribution.
Introduction 
The Committee for Justice (CFJ)
important Request for Information
pursuant to President Trump’s Executive Order.
Administration’s objective of maintaining America’s continued leadership and
dominance in artificial intelligence
Action Plan can help to ensure that the United States is the
AI competition. 
CFJ favors pro-innovation AI policies that promote competition
transformative potential, while 
unnecessary regulation that would slow
AI industry. While furtherance of these goals
focus these comments on the pol
alleging that the developers of
material used to train these models.
These comments consist of recommendations for 1) regulations and policies that can be
directly implemented by the Trump Administration, 2) Congressional action on copyright
1 Generative AI models are ones that produce complex output patterns
text— after being trained on datasets consisting ofThe Committee for Justice  
1629 K Street, N.W.—Suite 300  
Washington, DC 20006  
ATION   
D TECHNOLOGY POLICY  
Request for Information on the Development
of an Artificial Intelligence Action Plan 
 
STICE  
is approved for public dissemination. The document contains no business
proprietary or confidential information. Document contents may be reused by the government in
developing the AI Action Plan and associated documents without attribution.  
(CFJ)  appreciates the opportunity to respond to this
Request for Information regarding t he development of an AI Action Plan
pursuant to President Trump’s Executive Order.  We strongly support the Trump
Administration’s objective of maintaining America’s continued leadership and
artificial intelligence and believe the policy decisions incor p
to ensure that the United States is the winner of the intense
AI policies that promote competition  and realize
while discouraging burdensome litigation and avoiding
that would slow technological progress and growth in America’s
furtherance of these goals  implicates a wide range of issues
the pol icies implicated by the recent series of lawsuits
alleging that the developers of generative AI models have infringed the c opyrights on
used to train these models.1
recommendations for 1) regulations and policies that can be
directly implemented by the Trump Administration, 2) Congressional action on copyright
Generative AI models are ones that produce complex output patterns —typically images, audio, video
after being trained on datasets consisting of materials of the same data type. (202) 
commi tteeforjustice.org 
@CmteForJustice  
Page | 1Request for Information on the Development 
is approved for public dissemination. The document contains no business -
proprietary or confidential information. Document contents may be reused by the government in 
appreciates the opportunity to respond to this 
he development of an AI Action Plan 
We strongly support the Trump 
Administration’s objective of maintaining America’s continued leadership and 
porated into the 
winner of the intense global 
and realize  AI’s 
avoiding 
technological progress and growth in America’s 
implicates a wide range of issues , we 
lawsuits 
opyrights on 
recommendations for 1) regulations and policies that can be 
directly implemented by the Trump Administration, 2) Congressional action on copyright 
images, audio, video , or 


The Com mittee for Justice  Contact:  | Page | 2and related legislation that the Administration should encour age, and 3) judicial 
interpretations of existing law that the Administration should advocate for in legal 
memoranda and in court documents—including amicus briefs—as courts struggle with 
the legal issues presented by recent litigation concerning generative AI.  
In sum, we recommend that the Administration’s Action Plan encourage the treatment of 
copyright-protected material used in AI training as fair use rather than copyright 
infringement, while focusing protection for copyright holders on the outputs of 
generative AI models, asking whether the outputs are substantially similar to the 
copyrighted training data. 
Committee For Justice 
Founded in 2002, CFJ is a nonprofit legal and policy organization that promotes and 
educates the public and policymakers about the rule of law and the benefits of 
constitutionally limited government. As part of this mission, CFJ advocates in Congress, 
the courts, and the news media about a variety of law and technology issues, involving 
intellectual property, antitrust law and competition policy, administrative law and 
regulatory reform, artificial intelligence, free speech, data privacy, and the impact of all 
these on innovation and economic growth. 
Curt Levey, the author of these comments, is an attorney with a previous career as an 
artificial intelligence scientist, as well as legal and policy experience in intellectual 
property, including copyright. Prior to attending Harvard Law School, Mr. Levey studied 
AI at Brown University, earning undergraduate and Master’s degrees in computer 
science. He then joined HNC Software, an AI startup company, where he worked for 
five years as a staff scientist and invented and implemented a patented technology that 
provides explanations and confidence measures for the decisions made by neural 
networks.2 The technology saw worldwide use in an AI system that detects payment-
card fraud. More recently, Mr. Levey has written about AI policy3 and organized and 
moderated4, as well as participated in5, panels on the problem of bias in AI. On May 2, 
2 https: //patents.justia.com/patent/5398300 . 
3 See, e.g., https://www.wsj.com/articles/algorithms-with-minds-of-their -own-1510521093  (2017);  
https: //thehill.com/opinion/technology/432093-american-arti ficial-intelligence-strategy-offers-promising-
start (2019);  
https: //thehill.com/opinion/technology/444568-congress-can- bring-the-government-into-the-age-of-
artificial-intelligence  (2019); 
 https:/ /thehill.com/opinion/4563767-department-of-justice-i s-best-choice-to-police-ai-competition  (2024). 
4 https:/ /fedsoc.org/events/artificial-intelligence-and-bias  (2021) 


 
 
The Co mmittee for Justice      Contact:  |  Page | 3  
 2023, he testified at the U.S. Copyright Office’s listening se ssion on the use of artificial 
intelligence to generates works of visual art6. 
 
Comments 
 
Issues surrounding the use of copyrighted material to train generative AI models have 
been at the forefront of legal and public debate over the past few year due to the filing of 
lawsuits claiming that the developers of generative AI models—including image 
generators and large language models—have infringed the copyrights on material 
contained in the training datasets. These datasets are used (some say “ingested”) by 
the models as part of the machine learning process.  
 
The complaint in Getty Images v. Stability AI , which targets the Stable Diffusion model, 
is typical.7 It alleges infringement based both on the use of copyrighted images to train a 
generative AI model and on the possibility of that model generating images highly 
similar to and derivative of copyrighted images used in training. 
 
The training materials that are used to build generative AI models and are at issue in 
these lawsuits come primarily from internet-crawled, publicly available material.8 To the 
extent that AI model builders want to use curated datasets or any other data that is not 
publicly available, their only lawful option is to contract for access to the data, and thus 
copyright infringement is not typically an issue. 
 
In the short term, courts will have to resolve the issue of infringement by use of 
copyrighted material in training. In the longer term, this Administration’s Action Plan 
should urge Congress to step in and clarify the law—presumably by amending the 
Copyright Act of 1976—like it has done before when new technology has resulted in 
difficult new issues under copyright law. The approach to generative AI and copyright 
protection recommended in these comments should guide any statutory changes 
enacted by Congress, but it is also relevant to federal regulators and the courts, as they 
resolve novel legal issues. 
 
  
                                                                                                                                                       
5 https ://regproject.org/event/live-podcast-is-artificial-in telligence-biased-and-what-should-we-do-about-it  
(2020 ); 
https://fedsoc.org/events/artificial-intelligence-anti-dis crimination-bias  (2023); 
https ://fedsoc.org/events/is-ai-woke-in-what-ways-and-shou ld-we-worry  (2024). 
6 https ://www.copyright.gov/ai/agenda/2023-Visual-Arts-Agen da.pdf . 
7 1:23- cv-00135, (D. Del. filed 2023). 
8 See https://www.brookings.edu/articles/the-politics-of-ai-chat gpt-and-political-bias . 


The Com mittee for Justice  Contact:  | Page | 4A fair use regime is vital to American AI leadership  
Mainta ining American leadership in AI requires building the world’s leading generative 
AI models, such as ChatGPT. Training these frontier models, in turn, requires access to 
huge amounts of data from the broadest possible range of sources, including in large 
part publicly available, copyrighted material. That access would be threatened should 
American courts and lawmakers, in response to lawsuits, decide that the use of this 
material in training constitutes copyright infringement rather than fair use.  
Given such a regime, the largest players in the AI industry could afford to license some 
fraction of copyrighted training material. However, the practical effect would be to 
substantially limit the mountain of data that has made American leadership in AI 
possible and to make what access remains unpredictable, subject to lengthy 
negotiations, and generally more complicated. This would create steep barriers to entry 
that would make it difficult for smaller, newer innovators to compete with the AI giants 
that have much larger budgets and many more lawyers. 
What the Action Plan should strive for is a balanced copyright regime that allows 
American AI models to learn from all of mankind’s accumulated knowledge and 
creation, while protecting creators from the unauthorized duplication of their works. 
Fortunately, the fair use doctrine, a longstanding part of American copyright law, allows 
for transformative uses of copyrighted works. Generative AI models learn to produce 
new and different works—whether art, music, video, text, or the like—from examples 
and would thus seem to be the very definition of transformative. But courts and 
policymakers have yet to decide the question. Among the most important objectives of 
this Administration’s AI Action Plan should be definitive resolution of this question in 
favor of fair use.  
The alternative is to allow AI companies based in nations, such as China, that do not 
respect the protection of intellectual property, to gain an unfair advantage over 
American companies. As a practical matter, a Chinese company training a frontier AI 
model will have access to virtually all the world’s data, copyrighted or not. However, if 
American courts and lawmakers rule against fair use access to copyrighted training 
data, AI companies in the United States will have only limited use of such data, making 
it difficult for them to compete on a playing field where data is king. Moreover, if the 
intent of the courts and lawmakers was to give priority to protecting creators, that 
intention will be largely thwarted as China and similar nations make unauthorized use of 
copyrighted training material to produce the leading generative AI models that creators 
are worried about. 


The Com mittee for Justice  Contact:  | Page | 5Of course, the Administration’s Action Plan should also include aggressive efforts to 
convince the nations of the world to adopt and enforce a balanced copyright regime 
similar to our own and to avoid putting obstacles in the way of America companies’ use 
of publically available foreign data for training. However, that is easier said than done. 
Human versus machine learning  
Whethe r we are talking about the courts, which must be guided by existing statutes and 
precedent, or Congress, the good news is that there is no need to reinvent the wheel 
when approaching the question of copyright infringement by generative AI models. The 
similarities between machine learning in generative AI models and the manner in which 
human creators learn from a lifetime of examples makes it possible to apply the well-
settled law governing the latter to the former with a result that will guarantee the robust 
access to training data necessary for American competitiveness. The Trump 
Administration’s new AI Action Plan should encourage this approach. 
In order to understand the similarities, consider that human creators learn a skill—
painting or writing music, for example—from exposure to countless examples of art, 
music, and the like. The creator is not born with that skill. As a human learns from each 
new example, the synaptic strengths between neurons in their brains are slightly 
modified to reflect the new learning. 
Similarly, neural networks, the technology underlying generative AI models, learn to 
generate images, music, and the like by being presented with a very large number of 
examples. Neural networks consist of analogues to biological neurons and synapses, 
typically simulated in software. As with humans, learning takes place as the synaptic 
strengths (“weights”) are slowly modified in response to training examples. 
It is well-settled law that a human learning a skill from the ingestion of publically 
available, copyrighted material does not constitute copyright infringement, even if that 
human goes on to compete with the creators of the original material without merely 
duplicating their work. OpenAI refers to that as the “freedom to learn” from copyrighted 
material and we see no  statutory, policy, or logical reasons to deny that same freedom 
to the builders of AI models.9 If a human is free to learn about, say, painting from 
viewing copyrighted art works, does it make sense to say that a generative AI models 
cannot do the same? 
9 See https://openai.com/global-affairs/openai-proposals-for-the- us-ai-action-plan . 


 
 
The Co mmittee for Justice      Contact:  |  Page | 6  
 There seems to be a common misconception that a trained gene rative AI model retains 
copies, in some form, of the individual training material. Take, for example, the 
complaint in Andersen v. Stability AI , alleging copyright infringement by popular image-
generating AI models.10 The attorneys for the plaintiffs, who also represent plaintiffs in 
several of the other leading legal challenges to generative AI, assert that “By training 
Stable Diffusion on the Training Images, Stability caused those images to be stored at 
and incorporated into Stable Diffusion as compressed copies." 
 
In actuality, a trained AI model retains no copies of the training material. Retaining 
specific examples would be at odds with the objective of machine learning, which is to 
extract patterns and generalize  from training data, rather than remember it. In fact, it is 
this aspect of neural networks, learning subtle relationships and patterns and encoding 
that knowledge in the interplay of the model’s weights, that makes the behavior of AI 
models so hard to control and explain. 
 
Again, this is similar to how humans learn. While humans are capable of remembering a 
limited number of the specific examples they learn from, any sort of deep learning—
whether it involves learning a creative skill or just recognizing the difference between a 
dog and a wolf—requires generalization from examples rather than detailed storage of 
them. When dealing with copyright issues, the AI Action Plan should be mindful of the 
similarities between machine and human learning. 
 
The focus of copyright protection should be on AI models’ outputs  
 
When a human learns from ingesting examples in the domain they are trying to master, 
much of that material is typically protected by copyright. Yet that ingestion goes 
unchallenged, being regarded as either fair use or not subject to the Copyright Act at all. 
However, if that human uses their resulting learning to duplicate or produce a derivative 
work from one of the copyrighted examples without authorization, they are liable for 
copyright infringement. 
 
To put it another way, when assessing copyright infringement by humans, the law looks 
at the potentially infringing work the human produced rather than the process used to 
produce it, whether the process is the examples he learned the relevant skills from or 
the tools he used to produce the work.  
 
We suggest the new AI Action Plan encourage a similar approach to assessing 
copyright infringement by generative AI models—that is, a focus on the outputs of the 
                                                
10 700 F . Supp. 3d 853 (N.D. Cal. 2023). 


The Com mittee for Justice  Contact:  | Page | 7model. Where an output is “substantially similar” to any of th e copyright-protected 
training material—or any copyrighted work for that matter—it should be treated as a 
derivative work, subject to liability for infringement.11 
Moreover, while the mere use of copyrighted data in a training dataset should be 
presumed to be fair use, it should be this Administration’s policy that the presumption 
can be rebutted by showing that there was copying and retention of copyrighted training 
material beyond that necessary to train the AI model (more on this later). 
Reasons to rely on human-based policies  
This is a good point at which to explain why the AI Action Plan should rely on analogies 
to human learning and creation in determining how to apply copyright law to potential 
infringement by generative AI. One reason is that analogizing allows policymakers to 
more easily adapt existing law when faced with new technology. Dealing with the many 
legal and policy challenges reflected in the AI and copyright debate is hard enough 
without reinventing the wheel. The Trump Administration should use the similarity 
between human and machine learning to their advantage to guide policy development. 
Similar reasoning should govern the Administration’s reasoning when it weighs in on the 
legal issues presented by litigation concerning generative AI. Courts are required to 
apply existing law rather than creating new policies. So when faced with relatively novel 
legal issues resulting from new technology, courts rely on analogies. For example, while 
the Fourth Amendment’s guarantee of privacy in one’s “persons, houses, papers” does 
not apply directly to mobile phones and email accounts, the courts have analyzed 
privacy in these newer domains by analogizing to homes, documents, and the like. So 
too, this Administration should urge courts to analogize to human learning when 
addressing generative AI. 
There is also much to be said for intellectual consistency. While it may philosophically 
trouble some people to recognize the similarities between human and machine learning, 
the burden should be on those who want to treat human and machine learning as 
incomparable phenomena for copyright purposes, despite the similarities. Considering 
that the distinction between human and machine cognition will surely narrow as AI 
technology progresses, Administration policies that downplay the similarities are unlikely 
to stand the test of time. 
11 The q uestion of which person or entity should be liable—the developers of the model, the developers of 
the training dataset, the user whose prompt resulted in the infringing output, or someone else—is beyond 
the scope of these comments. 


The Com mittee for Justice  Contact:  | Page | 8Finally , consider that the analogy between human and machine learning can work in 
both directions. Any Administration policies that treat the ingestion of copyrighted 
material for learning purposes as infringement when performed by a generative AI 
model may someday blur the lawfulness of the same use of copyrighted material for 
human learning, especially as technology narrows the distinction between the two. 
Providing creators with additional protection against derivative works  
While denying the use of copyrighted training material the protection of the fair use 
doctrine would be disastrous for American leadership in AI, the Action Plan should 
provide balance by looking for ways to protect the rights of creators. Even putting aside 
the human analogy, the approach taken by recent lawsuits—that is, defining the use of 
copyrighted material to train generative AI models as copyright infringement—is unlikely 
to be a robust solution to protecting the rights of creators. But before discussing this in 
more detail in the next section, we discuss how the alternative approach—that is, 
protecting creators’ copyrights by focusing on a model’s outputs—can be strengthened 
by policymakers. Specifically, the AI Action Plan should encourage Congress to make 
two changes to the Copyright Act. 
Congress should specify that a finding that a derivative work is transformative, which 
weighs heavily in favor of finding that the work is fair use, faces a higher bar when the 
work is produced by generative AI, unless the potential infringer can show that the 
transformative quality is the product of a human’s prompts. This modification to existing 
law makes sense when we consider that a transformative work is one with “a further 
purpose or different character” than the original work, as the Supreme Court explained 
in Andy Warhol Foundation for the Visual Arts v. Goldsmith .12 
Determining the “purpose” of a derivative work presumes intent on the part of its 
creator. So too for a “different character” that is intentional. As impressive as generative 
AI models are, it is not claimed that they have anything akin to human intent with regard 
to the nature of the outputs they produce. Therefore, these models’ outputs should be 
subject to a higher standard to meet the definition of a transformative work. 
A second statutory change Congress should make to protect creators is to specify that 
the threshold of “substantial similarity” necessary to find that a work is derivative should 
be lower when that work is produced by generative AI, if there is evidence that the 
original work was in the training dataset. This makes sense because of the possibility 
12 143 S.  Ct. 1258 (2023). 


 
 
The Co mmittee for Justice      Contact:  |  Page | 9  
 that the presence of the original work in the training data indirectly contributed—by 
influencing the relationships learned by the neural network—to the substantial similarity, 
rather than it being a virtual coincidence. 
 
Focusing on training data is not a robust solution for protecting creators’ rights  
 
Recall  that machine learning, like human learning, does not depend on the retention of 
material in the training dataset. Once that data is used to train the weights of the neural 
network, it can be discarded without any degradation in the performance of a generative 
AI model. While more permanent  storage of training material is common—whether by AI 
model builders or dataset curators—and can be an independent basis for copyright 
infringement, this presents a separate issue from whether the use of copyrighted 
material merely for training is, in and of itself, copyright infringement. For training 
purposes, temporary copying is all that is fundamentally necessary. 
 
In pursuit of protecting creators’ copyrights, plaintiffs argue that even temporary copying 
by the developers of AI models is infringement. But that is a weak peg to hang this 
Administration’s policies on. For one thing, it is not fundamentally different from what 
humans do when they learn from examples. For convenience sake, humans often 
intentionally make copies of the material—music, art, articles—that they use as learning 
examples. And even when they don’t, their computers make temporary copies of the 
songs, images, and text they use to master a skill. Yet all of that copying is generally 
accepted as fair use. 
 
As the Electronic Frontier Foundation has pointed out: 
“‘Temporary copying’ of data is fundamental to how computing works in general, 
especia lly on the Internet. For example, … browser cache files are stored on 
servers to speed up the loading of websites, and copies of visited pages are 
stored in a temporary Internet files folder on your hard drive, speeding up the 
loading process for those websites the next time you visit them.”13 
 
In recognition of this fact, as EFF notes, U.S. courts have generally held that temporary 
copying is either not subject to the Copyright Act or is fair use. 
 
It is worth noting that developing a generative AI model doesn’t truly require even a 
temporarily copied training dataset. If copying made the developers liable for 
infringement, they could instead construct a training process that consisted of scrolling 
through the publicly available material stored on the internet, rather than gathering that 
                                                
13 https: //www.eff.org/files/filenode/temporary_copies_fnl.pd f. 


The Com mittee for Justice  Contact:  | Page | 1 0material into a dataset. While it would make for a slower tr aining process, the point is 
that meaningful copying is not fundamentally necessary for training. When looking for 
ways to protect creators’ rights, the AI Action Plan would be advised to look elsewhere. 
Another reason why a focus on the use of copyrighted materials for training is a 
misguided policy strategy is that is not aimed at the real threat to copyright holders. 
Consider that prior to the emergence of generative AI, more simple neural network 
models—typically classification and scoring models—were trained on large amounts of 
data (numerical, visual, acoustic, textual, and the like), some portion of which was 
copyrighted. Yet there was little or no objection from the copyright holders. The recent 
explosion in protests and lawsuits by copyright holders is motivated largely by the fear 
that the outputs of generative AI will negatively affect the potential market for their 
copyrighted works.  
While that is a legitimate, if speculative, concern and is a factor in fair use analysis, it is 
a concern focused entirely on the outputs of generative AI. Competition from generative 
AI would be a concern to human creators whether or not their works were used to train 
AI models. To the extent that the protection of creators’ rights in the AI Action Plan 
focuses on training data, it is flailing at a peripheral issue and distracting policymakers 
and the courts from the actual competitive threat posed by the outputs of generative AI. 


