Response to Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan
The Center for a New American Security (CNAS) welcomes the opportunity to provide input on 
priority policy actions for the Trump administration’s new AI Action Plan. 
CNAS i s an independent, bipartisan organization dedicated to developing bold, pragmatic, and 
principled national security solutions. CNAS has several research initiatives focused on critical and emerging technologies, including a center wide, multi -year initiative  addressing the national security 
risks and opportunities of artificial intelligence (AI).  
This response  includes input from the following authors:1 
●Vivek Chilukuri, Senior Fellow and Director, Technology and National Security Program
●Michael Depp, Research Associate, AI Safety and Stability Project
●Bill Drexel, Fellow, Technology and National Security Program
●Janet Egan, Senior Fellow, Technology and National Security Program
●Paul Scharre, Executive Vice President
●Josh Wallin, Fellow, Defense Program
●Becca Wasser, Senior Fellow and Deputy Director, Defense Program
●Caleb Withers, Research Associate, Technology and National Security Program
CNAS I ntellectual Independence Statement  
As a research and policy institution committed to the highest standards of organizational, intellectual, and personal integrity, CNAS maintains strict intellectual independence and sole editorial direction and control over its ideas, projects, publications, events, and other research activities. CNAS does not take institutional positions on policy issues and the content of CNAS publications reflects the views of their authors alone. In keeping with its mission and values, CNAS does not engage in lobbying ac tivity and complies fully with all applicable federal, state, and local 
laws. CNAS will not engage in any representational activities or advocacy on behalf of any entities or interests and, to the extent that the Center accepts funding from non -U.S. sources, its activities will 
be limited to bona fide scholastic, academic, and research -related activities, consistent with 
applicable federal law. The Center publicly acknowledges on its website annually all donors who 
contribute.  
1 Authors are listed alphabetically  


Introduction 
Strengthening and securing America’s AI dominance is crucial for U.S. national security and economic competitiveness. The authors commend the government for taking steps to define concrete policy actions to achieve this goal.  
While the United States currently leads the world in AI, we cannot take this position for granted. 
China is working aggressively to close the gap, and jurisdictions like the European Union also seek to shape global AI standards. The United States cannot cede international leadership to competitors like China that ride roughshod over human rights. It also cannot allow historic partners, such as the European Union, to shape international rules of the road with well-intentioned but overly burdensome regulatory  frameworks that stifle innovation and limit technological advancement.  
The U nited States has an opportunity to chart a new path: one that cuts through regulatory burdens 
to unleash and promote U.S. AI innovation, while ensuring new capabilities support and not undermine U.S. national security. The federal government can do more to reduce regulatory barriers to domestic AI development and diffusion, while pursuing targeted interventions to effectively harness AI for defense and manage potential risks to national security. A promote and protect approach to American AI dominance will enable the United States to capitalize on its technological advantages and promote a global technology ecosystem underpinned by democratic values such as free speech, transparency, and respect for civil liberties.  
In this subm ission, the authors outline concrete policy actions for the Trump administration to 
secure and strengthen America’s AI dominance across five themes: Promote America’s AI Advantage, Protect America’s AI Edge, Monitor and Shape Frontier AI Development, Secure American AI -Bio Leadership, and Accelerate AI Adoption in the Military. These recommendations 
draw on analysis from a recent CNAS whitepaper The First 100 Days , which outlines actions the 
Trump administration can take to Promote and Protect America’s AI Advantage , as well as several 
CNAS reports on military AI development, biosecurity, and the U.S. -China technology competition. 


Summary of Recommendations  
Promot e America’s AI Advantage 
1.Fast-track the development of secure AI infrastructure to unleash America’s computing
power advantage.
2.Attract top AI talent from around the world.
3.Develop a comprehensive strategy for promoting U.S. AI globally.
4.Develop a system to rapidly remove censorship from Chinese open source AI through
government efforts or private sector partnerships.
5.Establish a President’s Council on Artificial Intelligence, modeled after the President’sCouncil on Bioethics.
Prote ct America’s AI Edge  
6.Improve export controls to better restrict adversaries from accessing leading AI chips.
7.Work with the private sector to uplift security requirements for AI labs and datacenters toprevent adversaries from stealing or interfering with U.S. advanced AI technology.
8.Continue to assess the risks of open weight models and ensure the government has thecapability to protect highly sensitive capabilities, if they do materialize.
Moni tor and Shape Frontier AI Development 
9.Strengthen the government’s capacity to understand and engage with emerging AIopportunities and risks.
10.Leverage the federal government’s AI expertise to implement an agile, pro -innovation
approach to AI risk management.
11.Promote foundational research to improve the robustness and reliability of cutting- edge AI
models.
12.Prioritize regular engagement with China on AI security concerns through the U.S. -China AI
Working Group.
Secure Ame rican AI -Bio Leadership  
13.Enhance screening protocols for cloud laboratories and gene synthesis providers.
14.Revise biodefense investments to emphasize adaptability and speed.
15.Issue a political declaration addressing responsible AI applications in biotechnology.
16.Prioritize research into promising technical safety mechanisms to counter the risks ofadvanced AI systems enhancing non -state actors' bioweapon development capabilities.
Accel erate AI Adoption in the Military  
17.Enhance and accelerate DoD adoption of military AI.


Promote America’s AI Advantage 
Recom mendation 1: Fast -track the development of secure AI infrastructure to unleash 
America’s computing power advantage.  
The U.S. advantage in accessing cutting edge AI chips will be less potent if domestic bottlenecks 
impede their deployment. Training cutting -edge AI models requires massive computing power, with 
projections suggesting that training a leading model could soon require energy equivalent to five nuclear reactors. This unprecedented demand will overwhelm available supply and tax America's aging energy infrastructure, while complex permitting processes create substantial delays in building the requisite energy generation and transmission capacity. Recent executive actions provide partial solutions: President Trump's Executive Order 14154, Unleashing American Energy , significantly 
reduces the regulatory burden of the National Environmental Protection Act, building on Executive Order 14141 that unlocks federal lands for AI infrastructure and energy construction. However, 
energy projects —particularly transmission lines —traverse multiple jurisdictions, subjecting AI 
developments to a cascade of legal challenges and protracted judicial reviews. While U.S. energy 
infrastructure languishes in a quagmire of red tape, China can expeditiously direct large -scale build 
outs, underscored by its unprecedented speed in nuclear power plant construction. Other nations, such as the United Arab Emirates and Saudi Arabia, also have the capital, energy, and government cut-through to expedite AI and energy infrastructure to meet anticipated demand. Paired with 
sufficient access to chips, this creates a risk that they could leapfrog U.S. AI  leadership with world -
leading AI computing infrastructure. Without further efforts to streamline approvals, coordinate jurisdictional authorities, and modernize the U.S. energy grid, America risks ceding technological leadership to other nations. 
Recom mendation 1.1: Convene national, state, and local permitting decision -makers 
to agree on “special compute zones” to enable faster infrastructure buildout.  There is an opportunity to partner with state and local regulators to create designated special 
compute zones that aim to —as much as possible —align permitting and regulatory 
frameworks across jurisdictions and minimize barriers to AI infrastructure development. To 
incentivize participation, state and local governments that join these partnerships could receive an allocation of computing resource s for local research priorities, improved grid 
resiliency, and workforce development funds tailored to their commu nities. This should 
complement, rather than replace, efforts to build on federal lands. Creating geographic clusters that benefit from regulatory certainty and shared infrastructure would help accelerate America's AI development capabilities while managing  jurisdictional authorities. 
Recommen dation 2: Attract top AI talent from around the world.  
The U.S. National Security Commission on AI named science, technology, engineering, and mathematics (STEM) talent as the “most important driver of progress” of a country's technology competitiveness. Nations worldwide now compete to train, attract, and retain top talent to power their AI leadership. With respect to talent, no country has a better hand to play than the United States. The country benefits not only from world- leading academic and research institutions, but a 
reputation as a society that welcom es the world’s brightest minds to contribute to its free, open, and 
dynamic innovation ecosystem.  


The reputation has delivered results: two -thirds of graduate students in AI and semiconductor-
related programs are people born abroad; more than half of Silicon Valley high -tech startups have 
immigrant founders; and over a third of aggregate U.S. innovation in the past 30 years can be tied to 
immigrants. Immigration has long acted as an asymmetric advantage, effectively drawing top tech researchers, innovators, and founders from competitor nations to contribute and create in America instead.   
Beijing recognizes this and has made an all-out effort to boost its domestic STEM workforce, which 
Chinese President Xi Jinping has called “the first resource for innovation.” Beijing has increased spending on STEM education by more than 50 percent in the past decade. Some Chinese provinces now require primary and secondary schools to teach AI. At the same time, China has launched initiatives like the Thousand Talents Program to encourage Chinese-born talent working abroad to return. These efforts are beari ng fruit: China now leads the world in annual STEM graduates and is 
on track to train a STEM workforce twice that of the United States’ this year. China has not only improved the quantity of its STEM graduates but the quality of their work, for instance, d elivering a 
rising share of highly cited AI papers. 
Although efforts to expand America’s domestic STEM talent are necessary and urgent, they cannot 
deliver broad results in the short- term as the AI competition intensifies. To realize the potential of 
the CHIPS and Science Act, one study estimates that Ameri ca will require 300,000 more engineers 
than U.S. universities will graduate by the end of the decade. Over this same period, the United States may face a broader shortage of 1.4 million technicians, computer scientists, and engineers. Almost seven in ten t op AI employers cite visa and immigration issues as a barrier to filling key 
openings. 
Failing to draw on America’s asymmetric immigration advantage would represent a needless self -
inflicted wound on the country’s AI leadership. Targeted executive actions can help leverage America’s talent advantage once more. Specifically, the administratio n should: 
Recommen dation 2.1: Direct the Department of Labor to add high -demand AI jobs 
with demonstrated shortages to the Schedule A List.  Schedule A designates sectors that lack available and qualified U.S. professionals such that 
hiring foreign talent would not harm wages and working conditions for Americans in comparable jobs. Employers in Schedule A categories can hire foreign talent while bypassing  
cumbersome recruitment and labor certifications requirements, filling critical roles more expeditiously. 
Recommen dation 2.2: Clarify guidance and coordination for the O -1A and EB- 1A 
visas.  The O- 1A is a temporary, non -immigrant visa category for foreigners with “extraordinary 
ability” in the sciences, among other fields. The O-1A visa is also uncapped and eligible for indefinite renewal. The EB -1A is similarly for foreigners of extraordinary  ability, but it 
provides permanent residency and work authorization. In practice, ambiguity about what constitutes “extraordinary ability” —combined with onerous application procedures—can 
deter top talent from applying. Greater clarity about eligibility for extraordinary ability in STEM, and AI specifically, could boost applications for both visa categories. The administration could also clarify pathways to convert the O- 1A to the EB -1A. 


Recommendation 2.3: Create or expand visa and talent exchange programs with 
close allies and partners.  
The administration could dramatically broaden the QUAD STEM Fellowship, which allows students from Japan, Australia, and India to study in the United States. It could also work with Congress to establish a narrow, expedited visa for top STEM and AI talent from Five Eyes partner nations with jobs in national security -relevant technology firms and research 
institutions. 
Recommen dation 2.4: Expedite appointments, vetting, and processing for visa 
applicants with job offers in cutting- edge AI research, development, and innovation. 
Given the fierce global competition for top AI talent, the longer the government forces them to wait for a secure legal pathway, the greater the risk they will be poached by another country or give up entirely.  
Recommen dation 3: Develop a comprehensive strategy for promoting U.S. AI globally.  
Just as U.S. control of the financial system allowed it to set global rules and enforce sanctions, the nation that becomes central to global AI deployment will shape the rules of the road for this transformative technology. The United States cannot afford to let other actors, particularly China, become the dominant provider of AI capabilities and infrastructure. To date, the U.S. approach to international AI diffusion has been primarily restrictive, with a strong focus on export controls for advanced AI chips. While these controls should continue, it is imperative that the United States also creates pathways to promote and share benefits from its leading AI models, including through strategic AI deals with key partners.  
It will be important to strike the right balance. The United States need to remain vigilant that vast 
exports of advanced AI chips do not undermine America’s AI advantage: nations like the United Arab Emirates and Saudi Arabia possess abundant cheap energy, sovereign wealth funding, and streamlined regulatory processes to rapidly expand and potentially overtake the U.S. AI computing capacity, which is constrained by energy availability, complex regulation, and lengthy permitting processes. The Department of Commerce’s “Framework for Artificial Intelligence Diffusion” starts to address such risks. However, a more comprehensive approach should extend beyond chip access to encompass cloud computing, AI model partnerships, and downstream applications—from drug discovery to industrial use cases —to demonstrate the benefits of partnering with the United States 
on AI. Through bilateral engagement and bespoke deals that adapt to different partners’ AI needs and risk profiles, the administration has an opportunity to t ailor partnerships that strengthen U.S. 
influence while helping partners access AI capabilities securely.  
Recommen dation 4: Develop a system to rapidly remove censorship from Chinese open 
source AI through government efforts or private sector partnerships.  
DeepSeek -R1 demonstrates China's success in projecting cost- effective, open source AI leadership 
to the world despite embedding authoritarian values in its AI. The United States can counter this strategy by rapidly releasing modified versions of leading open source Chinese models that strip away hidden censorship mechanisms and the “core socialist values” required by Chinese AI regulation. In doing so, the United States can expose the contradiction in China's approach, erode the appeal of Chinese AI, and position America as the legitimate champion of authentic open source AI. 


The United States must move quickly to modify these models. With prompt, systematic responses to 
each major Chinese release, the United States can transform Chinese "open source" offerings into genuinely open tools, positioning the United States as the preferred vendor of even Chinese-developed tools, in addition to American- made open source systems. U.S. companies have already 
shown proof of concept: AE Studio created a "Western DeepSeek" clone hosted on servers outside of Communist Party of China control, and Perplexity released a fine -tuned DeepSeek -R1 stripped of 
censorship and propaganda inclinations. 
The U .S. government should accelerate these efforts through financial grants, server resources, or by 
developing the internal technical capacity to ensure that uncensored versions of leading Chinese open source models launch within days of Chinese releases. This would prevent China from controlling “open” AI while demonstrating U.S. commitment to genuine open source collaboration free from hidden authoritarian influence.  
Recommen dation 5: Establish a President’s Council on Artificial Intelligence, modeled after 
the President’s Council on Bioethics.  This Council should address the most fundamental questions confronting democratic societies in the AI era and develop an agenda leveraging AI to strengthen American democracy.
2 The Council 
should provide holistic guidance on critical governance issues including privacy protection, democratic discourse, civic engagement, and justice administration —presenting a compelling vision 
of AI advancing democratic ideals. Where political d eadlock has hindered discussions about AI-
related civil issues, the Council should reevaluate these themes through America's foundational traditions. The Council should also address emerging bioethics questions enabled by AI and other areas of technological convergence. The goal should be practical guidance on how America’s founding principles can fuel AI's trajectory. 
Prote ct America’s AI Edge  
Recommen dation 6: Improve export controls to better restrict adversaries from accessing 
leading AI chips.  
The lead of the United States and its allies in producing cutting-edge AI chips has proved resilient to date, but it requires active protection. Unlike algorithmic breakthroughs, such as those that allowed greater efficiencies in DeepSeek -R1, specialized s emiconductors offer a physical and controllable 
choke point in the AI supply chain due to their concentrated and complex fabrication processes.  While AI models are becoming more efficient, access to substantial computational resources continues to drive a dvances at the frontier of AI capabilities and determines both a model's 
functionality and scalability. Targeted enhancements to U.S. export control mechanisms are therefore key in preventing China from eroding the U.S. lead and using U.S. technology to support its surveillance state and transform its military.  
Recommen dation 6.1: Adopt a nimbler approach to export control updates.  
The current approach of annual export control updates fails to keep pace with rapid technological change in AI and emerging new evidence. The Bureau of Industry and Security (BIS) should instead adopt a quarterly review process with the authority to make targeted adjustments to controls as new capabilities emerge. This process should include technical 
2 Bill Drexel, Promethean Rivalry: The World -Altering Stakes of Sino-American AI Competition  (CNAS, forthcoming).  


advisors from industry and research institutions who can provide early warnings about 
emerging AI capabilities and technological trends that may warrant adjusted controls.  
Recommen dation 6.2: Restrict China’s access to leading inference chips.  
Existing controls focus primarily on chips used for AI model training but fail to adequately account for the growing strategic importance of “inference compute” —the computational 
power used when deploying AI models. This means that governments and companie s will 
seek a competitive edge not only in model development, but also in model deployment at scale. Accordingly, the United States should tighten controls by implementing restrictions on leading inference chips, particularly NVIDIA's H20, which offers substantial capability for AI deployment while currently falling outside the scope of the strictest export limitations.  
Recom mendation 6.3: Address chip smuggling by resourcing BIS and investing in 
technology -forward export control solutions.  
Illegal transfer of controlled chips into China is widespread and well documented. Some estimates suggest tens of thousands of controlled AI chips are smuggled into China each year through shell companies, intermediaries, and cloud computing providers.
3 Despite its 
critical mandate, BIS operates with insufficient resources. Congress should significantly increase BIS's budget to enhance its monitoring and enforcement capabilities, including hiring additional technical specialists and field investigators.  
There a re also opportunities to boost BIS’s efficacy through technology-forward solutions. 
BIS should pilot a registry system that tracks the intended location and use of individual high- performance chips and maintains chain -of-custody records. Additionall y, the 
Department of Defense (DoD) should direct the Defense Advanced Research Projects Agency (DARPA) to fund research and development efforts into hardware -enabled 
mechanisms (HEMs) for AI chips.
4 These mechanisms would enable BIS to reliably track 
and license foreign chip shipments through built- in verification features, preventing 
unauthorized use and providing real- time visibility when chips are diverted from their 
approved destinations.  
Recommen dation 7: Work with the private sector to uplift security requirements for AI labs 
and datacenters to prevent adversaries from stealing or interfering with U.S. advanced AI technology.  The United States requires stronger security to protect the advantage it has achieved through massive capital investments in AI infrastructure and talent. In addition to the $500 billion Stargate announcement, Microsoft, Meta, Alphabet, and Amazon are each  planning to spend between $60 
and $100 billion in capital expenditure in 2025, largely driven by AI investments. As America’s lead grows, AI datacenters and companies will become increasingly attractive targets for adversarial nations seeking to steal adv anced models or sabotage critical systems. The private sector alone is 
neither equipped nor incentivized to effectively counter sophisticated state actors. The federal government must deploy its security expertise to protect this critical technology and infrastructure. As an immediate priority, the National Security Agency and broader national security community 
3 Tim Fist and Eric Grunwald, Preventing AI Chip Smuggling to China  (CNAS, October 23, 2023), 
https://www.cnas.org/publications/reports/preventing -ai-chip- smuggling- to-china .  
4 Onni Arne, Tim Fist, and Caleb Withers, Secure Governable Chips  (CNAS, January 8, 2024), 
https://www.cnas.org/publications/reports/secure -governable -chips .  


should partner with leading labs and AI datacenters to build resilience against espionage and attacks. 
The National Institute of Standards and Technology should also play an active role in co-developing best practice security standards for model weights —the sensitive intellectual property that 
encapsulates the capability of an AI model. Because security -by-design is significantly more effective 
than retrofitted protections, government and industry must urgently develop and implement stronger security standards into the architecture of new computing clusters from their inception. This approach will also ensure the United States has access to infrastructure secure enough for the national security applications of AI.  
Recommen dation 8: Continue to assess the risks of open weight models and ensure the 
government has the capability to protect highly sensitive capabilities, if they do materialize. A flourishing open- source ecosystem has historically been instrumental in advancing U.S. 
technology innovation, security, and adoption. In the AI domain, publicly available model weights enable a diverse array of researchers, developers, and organizations to tailor models for specialized use cases, aiding diffusion of this technol ogy throughout the economy. However, as AI advances, it 
has the potential to give rise to new and potentially dangerous capabilities that could be misused to the detriment of U.S. security. Making such model weights broadly available could heighten risks, by making it easier for users to remove or weaken built -in safeguards. 
Havin g the capability to assess, and potentially one day restrict, dangerous capabilities from being 
openly published is also critical for protecting the U.S. AI lead over China. While current U.S. open weight AI systems offer no meaningful advantage over China's domestically developed capabilities, the accumulating impacts of chip export controls and a concerted effort to accelerate U.S. AI development could significantly widen this gap. Failing to implement robust protections for these advanced technologies would not only jeopardize U.S. national security but also squander the advantages established through sustained investment. 
Proponent s of open-source software  rightly argue that it aids security improvements: exposing code to 
more eyes, making it easier to identify and patch vulnerabilities. However, security benefits for open source or open weight AI models are much more modest. Whereas typical software features human -
written code, the internal representations learned by deep neural networks are not human -readable. 
The complexity and highly parallel operations of deep neural networks make them very difficult to interpret. As a result, isolating specific “bugs” or backdoors is impractical. Even if vulnerabilities have been broadly identified, mitigating them is not straightforward. This reduces the security benefits of open access for advanced AI models. 
Ensuring  AI diffusion across the economy should remain a key priority. But the government should 
consider how this might be achieved in other ways, such as through structured model access. 
Moni tor and Shape Frontier AI Development  
Recommen dation 9: Strengthen the government’s capacity to understand and engage with 
emerging AI opportunities and risks.  
AI could unlock massive breakthroughs in national security capabilities—from intelligence collection 
and analysis to advanced warfighting systems to dual -use scientific research. Advanced AI 
technologies could therefore offer both unprecedented opportunities to enhance national security 
while introducing novel risks that requi re careful management. Given the stakes, it would be 


unreasonable—and even dangerous—to leave responsibility for managing potential risks to the 
private sector alone. The federal government should thus develop and maintain a deep understanding of advanced AI development in the private sector to both leverage  new capabilities 
and proactively manage potential harms.  
The e xpertise of the AI Safety Institute (AISI) is an important first step in building government 
capacity to better understand advanced AI systems —drawing experience from leading AI companies 
and universities into government. Yet as AI capabilities accelerate, the federal government will require still more capacity. The administration should empower the AISI as a hub of AI expertise for the broader federal government to ensure AI strengthens rather than undermines U.S. national security. The administration  could further support this AI hub of expertise with continued 
implementation of the AI National Security Memorandum, which strengthens engagement with national security agencies to better integrate expertise across classified and non -classified domains. 
Importantly, this center of expertise will also continue to support U.S. AI leadership abroad through the global network of AISIs, countering China’s efforts to shape AI standard setting in its favor. 
Recommen dation 10: Leverage the federal government’s AI expertise to implement an agile, 
pro-innovation approach to AI risk management.   
The United States must avoid overly restrictive regulation that could halt progress and cede dominance to competitors like China. At the same time, the federal government cannot ignore the potential for serious risks. Indeed, waiting for risks to materiali ze could be too late for effective and 
timely responses. Despite tech industry optimism, public wariness of AI persists. As with nuclear energy, a major AI incident could trigger broad backlash that prompts excessive regulation that stifles innovation and the realization of AI's broader potential benefits for society. By contrast, a targeted and adaptive governance approach can identify emerging dangers and respond proportionately while supporting innovation—provided the government has sufficient technical expertise to assess advancing AI capabilities accurately.  
Recom mendation 10.1: Maintain visibility and understanding of risks emerging at 
the frontier of AI development.  The AISI should continue to partner closely with leading AI companies to maintain visibility and understanding of emerging capabilities at the frontier. Evaluations of the most advanced models, like those in development at the AISI with Scale AI, are a cri tical first step. Similarly, 
partnerships between U.S. national security agencies and leading AI companies will be essential for testing how AI capabilities  might affect the cyber, biological, nuclear, and 
radiological capabilities of foreign adversaries.  
Recommen dation 10.2: Establish mechanisms to detect and track real -world AI 
incidents.  
Developing and even requiring AI evaluations is insufficient. As AI systems increasingly integrate with personal, commercial, and governmental functions, the federal government needs a systematic way to track and learn from real -world incidents. A central reporting 
system for AI -related incidents would allow the government to investigate and update its 
approach to evaluations where appropriate. This reporting system would also equip policymakers with evidence to tailor policy measures —substituting broad reg ulatory 
requirements that might constrain innovation with interventions specifically designed to address identified risks.  


Recommen dation 10.3: Develop a public- private coordination framework for 
responding to future AI incidents.  
Should a significant AI incident occur, the public will expect a government response. Yet no 
single federal entity is equipped to manage a major AI incident alone —whether it be a large -
scale system failure or a narrower, sophisticated attack. Just as the U .S. government 
coordinates with industry to respond to national cyber incidents, it should forge similar partnerships to address AI risks that could impact national security. The government should build upon the Department of Homeland Security's Artificial Intelligence Safety and Security Board and identify and engage key stakeholders across public, private, and civil sectors to establish clear roles and responsibilities for AI incident response. 
Recommen dation 11: Promote foundational research to improve the robustness and 
reliability of cutting -edge AI models.   
The national security enterprise is at a critical juncture. Frontier AI systems offer enormous potential for analyzing data at speed and scale across cyber, surveillance, military, and intelligence operations. But significant challenges remain in achieving  the robustness and reliability required for 
transformative national security applications —especially as adversaries will seek to compromise or 
exploit these systems. The national security enterprise cannot be a passive consumer of emerging AI capabilities; it must proactively shape U.S. leadership in safe, secure, and trustworthy AI. DARPA and/or Intelligence Advanced Research Projects Activity (IARPA) should fund high- risk, high -
reward projects aimed at fundamental advances in AI robustness and reliability.
 
Recommen dation 12: Prioritize regular engagement with China on AI security concerns 
through the U.S. -China AI Working Group.  
Even as competitive tensions between the United States and China rise, collaboration to manage AI risks is not only possible but increasingly important. The rapid development and diffusion of advanced AI capabilities poses potential risks to both nations. Anticipating and managing such risks requires regular dialogue, even as the United States pursues AI dominance. The Biden administration created the U.S. -China AI Working Group but it only convened twice, with few 
tangible outcomes. The Trump administration’s new AI Action Plan should reframe this group as a technical expert body to tackle shared AI risks and reduce tensions without undermining America's AI lead.  
This ref ormulated group would serve as a body to discuss shared AI risks, instead of acting as a 
forum for comprehensive political changes in the U.S.-China relationships. This means avoiding politically contentious or overly broad areas of discussion, such AI disinformation or its effect on human rights, and focusing instead on narrow, less politically contentious technical problems ripe for scientific collaboration, such as identifying and responding to dangerous behaviors in AI models, including deception, attempted self -replication, or circumventing human control. To facilitate this 
technical discussion, the group should include mostly AI scientists and government officials responsible for civilian science and technology policy and regulation. 


Secure Ame rican AI -Bio Leadership  
Recommen dation 13: Enhance screening protocols for cloud laboratories and gene synthesis 
providers.5  
The now- revoked October 2023 AI executive order directed the Office of Science and Technology 
Policy to develop frameworks for screening customers and gene sequence orders for potentially 
dangerous activities, and requiring federally-funded life sciences r esearch to utilize services 
implementing these mechanisms. These measures remain incomplete regarding potential bad actors ordering hazardous genetic sequences, as requirements only affect companies working with federally -funded research. Industry support exists for more binding screening mechanisms, 
evidenced by numerous major gene synthesis companies already participating in the voluntary International Gene Synthesis Consortium that mandates order screenings for members. As AI systems democratize biotechnology access —having already demonstrated capacity to help identify 
cloud labs with inadequate safeguards—strengthening protections at this critical digital -to-physical 
junction in biological agent development represents an achievable security improvement. While synthesized sequences pose significant risks, expanded use of cloud labs and AI- automated facilities 
also necessitates broader oversight: automation of viral assembly, CRISPR editing, and mutagenesis presents dual- use concerns that may bypass traditi onal synthesis-focused screening.    
Ameri can legislators should mandate comprehensive order and customer screening by relevant 
companies to identify potential threats, with appropriate suspicious activity reporting mechanisms to law enforcement. Additionally, given advances in benchtop synth esis technologies expanding access 
to dual-use capabilities, relevant agencies should explore policies requiring logging and screening of all synthesized genetic sequences, utilizing encryption to safeguard trade secrets while enabling sequence queries dur ing specific emergencies. The U.S. government should also work to 
internationalize screening standards through diplomatic engagement via the Biological Weapons Convention and other multilateral forums. As AI tools may soon develop methods circumventing conventional screening approaches, lawmakers should anticipate these challenges by investing in next-generation dynamic screening technologies, potentially leveraging new AI systems responsive 
to circumvention attempts, while accounting for anticipated bencht op synthesis capability 
advancements over the coming decade.  
Recommendation 14: Revise biodefense investments to emphasize adaptability and speed.  
As AI revolutionizes biotechnology, the limitations of traditional "one-bug-one-drug" biodefense approaches will only become more acute, requiring a more dynamic approach to biodefense in the AI Action Plan.  
The Do D's "Biodefense Posture Review" already highlights how advancing technologies accelerate 
biological hazard emergence, requiring more flexible solutions for broader biological risks. AI-enhanced biological design tools will likely further heighten this need by enabling novel pathogen creation or modification of existing ones to resist countermeasures. However, current biodefense funding models, including Biomedical Advanced Research and Development Authority (BARDA) programs, remain inconsistent and re active with “boom and bust” cycles during crises like H1N1 
and COVID- 19. 
5 Bill Drexel and Caleb Withers, AI and the Evolution of Biological National Security Risks  (CNAS, August 13, 2024), 
https://s3.us -east-1.amazonaws.com/files.cnas.org/documents/AIBiologicalRisk_2024_Final.pdf.  


This reactive pattern undermines sustained medical countermeasure development, particularly 
impacting ambitious projects like vaccine prototypes covering all known pathogenic viral families. 
Consistent investment is essential for broad- spectrum treatments and technologies enabling rapid 
countermeasure adaptation, as demonstrated during COVID- 19 vaccine development. Additionally, 
pathogen -agnostic approaches should prioritize interventions limiting transmission, such as 
improved indoor air quality and promising innovations like Far- UVC light technology for safely 
neutralizing airborne pathogens.  
Recommen dation 15: Issue a political declaration addressing responsible AI applications in 
biotechnology.  Establishing frameworks for international cooperation and discussion channels for emerging AI-accelerated biotech issues remains crucial, despite anticipated Chinese resistance to joining such an initiative. Following the model of the U.S. “Political Decla ration on Responsible Military Use of AI 
and Autonomy,” articulating guiding principles during early development stages can positively influence technological trajectories for both participating and non -participating nations.  
Recommen dation 16: Prioritize research into promising technical safety mechanisms to 
counter the risks of advanced AI systems enhancing non -state actors’ bioweapon 
development capabilities.   
Recommendation 16.1: Strengthened cloud interface protections.  
Online AI platforms currently employ various safeguards against misuse, including output screening via moderation systems. The AI Action Plan should mandate funds for additional research that could develop more effective defenses against jailbreaks that extract harmful information from advanced systems. For instance, developers might implement AI -driven 
monitoring to flag concerning conversations for human review. Where justified, companies could be mandated to notify authorities about users pursuing dangerous inquiries related to terrorism or security threats.  
Recommen dation 16.2: Information deletion capabilities.   
Researchers are developing techniques to selectively remove knowledge from AI systems, showing initial promise.
 Such methods could eliminate dangerous biological information 
more thoroughly than current reinforcement learning from human feedback approaches, which are vulnerable to circumvention. Google has initiated a competition to advance unlearning methodologies. Microsoft researchers demonstrated some success erasing Harry Potter knowledge from models, while another team developed representation -based 
approaches to remove weapons of mass destruction (WMD) information from frontier models. Further work remains to completely eliminate dangerous biological data relevant to producing biological weapons while preserving scientific utility, an area ripe for investment from the AI Action Plan.  


Recommen dation 16.3: Training data protection strategies.  
The AI Action Plan should also include exploration of methods to exclude publications 
containing sensitive dual- use information from training datasets that could substantially 
mitigate bioterrorism risks associated with frontier AI. While determined actors might partially overcome this by feeding restricted information to models, this approach would still create barriers to entry. Alternatively, deliberately introducing inaccuracies about biological weapons development into biological training data could render any extracted harmful instructions ineffective or counterproductive. 
Accel erate AI Adoption in the Military  
Recommen dation 17: Enhance and accelerate DoD adoption of military AI.  
AI systems are rapidly being integrated into military operations across a range of applications, from targeting to logistics to battlespace management. As the adoption of military AI grows, so do risks stemming from the uneven pace of AI development, poorly adapted test and evaluation processes, technical misalignment between AI -enabled systems, and inconsistent policies regarding their use. 
The United States can reap the full benefits of military AI by enhancing the test and evaluation (T&E) enterprise to ensure these systems are effective while also managing risk. Further, the services and T&E enterprise can work together to develop the interoperability with allies and partners that is needed as coalition partners take a more active role in warfighting.  
Recommen dation 17.1: Improve test and evaluation for military AI and autonomy.  
AI and autonomous systems present new challenges relative to legacy systems, including a lack of explainability and sensitivity to the training data used in developing them.
6 The U.S. 
military can take full advantage of AI and autonomy, but only if DoD develops rigorous and streamlined processes that allow systems to be tested thoroughly and permit warfighters an early and ongoing role. Developing warfighter trust is a complex  process and requires their 
active participation from conception to fielding of an AI -enabled and/or autonomous 
system. Additionally, DoD testers have a strong track record of testing and certifying effective systems safely. Integrating all of these voices  early in development provides 
additional expertise that can improve the efficiency of programs and prevent costly late -stage 
system changes.  
Recommen dation 17.2: Bolster AI interoperability across services and with allies and 
partners.  Unlike crewed platforms, AI -enabled autonomous systems will have to work together 
without the benefit of well -trained human operators serving to resolve potential 
coordination conflicts between friendly military systems. For example, autonomous fighter aircraft will have to know how to avoid colliding with each other or disrupting each other’s ability to engage targets. Managing these conflicts across services is difficult, not to mention when allies and partners are involved. The U.S. military can address these difficulties by working across services to clarify concepts of employment and identify potential points of 
6 Josh Wallin, Safe and Effective: Advancing Department of Defense Test and Evaluation for Artificial Intelligence and Autonomous 
Systems (CNAS, March 13, 2025), https://s3.us -east-1.amazonaws.com/files.cnas.org/documents/AI -Test- and-
Evaluation- Defense -2025- finalb.pdf ; Josh Wallin, Lessons in Learning: Ensuring Interoperability for Autonomous Systems in the 
Department of Defense (CNAS, forthcoming).  


conflict between friendly heterogeneous AI and autonomous systems. Furthermore, the 
United States can take an active role in working with allies and partners to ensure the interoperability of AI and autonomous systems.
7 This will allow highly capable allies and 
partners to step up in coalition operations, reducing the burden on U.S. assets.  
This document is approved for public dissemination. The document contains no business -proprietary or confidential 
information. Document contents may be reused by the government in developing the AI Action Plan and associated documents without attribution.
 
7 Becca Wasser and Josh Wallin, “Build Allied AI or Risk Fighting Alone,” Foreign Policy , February 24, 2025. 
https://foreignpolicy.com/2025/02/24/military -ai-communication- technology -allies-emergency -response/ . 


