Marc h 15, 2025 
Ms. Suz anne H. Plimpton,  
Reports Clearance Officer,  
National Science Foundation. 
RE: B oise State University Response to Federal Register Doc. 2025 –02305 Filed 2–5–25; 
Request for Information on the Development of an Artificial Intelligence (AI) Action Plan  
Dear  Ms. Plimpton, 
We are wri ting in response to the Federal Register Notice (Document Number : 2025–02305), 
dated February 5, 2025 – Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan to  define the priority policy actions needed to sustain and enhance 
America's AI dominance, and to ensure that unnecessarily burdensome requirements do not hamper private sector AI innovation. We appreciate your con sideration of Boise State 
University’s comments and recommendations submitted to this RFI.   
This document is approved for public dissemination. The document contains no business-
proprietary or confidential information. Document contents may be reused by the government in 
developing the AI Action Plan and associated documents without attribution. 
Enab le closer industry -academia collaboration . 
Incentivize universities to think of creative ways of engaging with AI industries, especially startups. The pace of change and growth is more accelerated within the AI industry, which brings up some issues that policy can affect to help keep our lead in the AI space.  
•Universities should create innovative ways for industry, faculty and students to worktogether earlier in a student’s program of study.
•Universities and industry should identify and remove cumbersome barriers to moreindustry- academia collaboration.
•Expected results.  Closer collaborations would lead to quicker knowledge transfer and
more graduating students that would have the experience to help propel AI startups aswell as established companies.
Access to hardware. 
More funding to improve access to cutting edge AI models and computing infrastructure for students and researchers in universities.   
Wider v ariety of programs . 
Support more instances of specialized AI degrees as well as access to AI skills for students from across the majors.  


Ramp up investments . 
Universities have had strong past success in continuously producing the next generation of 
employees for the tech industry - the industry would say that the US needs to ramp up the investment in education and research instead of scaling it back. 
Inter pretability and Robustness of AI Systems  
Regulatory standards for AI explainability should mandate explainability for high- stakes AI 
applications in areas such as healthcare, finance, and criminal justice, requiring models to provide human-interpretable explanations for their decisions. A standardized set of AI transparency metrics should be developed at the national level to ensure consistent 
interpretability assessment across industries. Explainability testing should be a required step before deployment, including third-party audits to validate model transparency. 
For robus tness and reliability, AI models operating in critical infrastructure should undergo 
rigorous stress testing against adversarial attacks and data perturbations. Pre-deployment adversarial defense testing should be mandated to evaluate AI resilien ce. Federal grants should 
be allocated to define methods and metrics to evaluate resiliency.  
Indepe ndent AI model auditing should be required for commercial AI models used in critical 
applications, ensuring fairness, explainability, and adversarial robustness through third-party verification.   
To encour age the development of more trustworthy AI systems, federal grants should be 
allocated to support research in inherently interpretable AI architectures, such as decision trees and causal inference -based models.   
Secur ing the robustness of AI models is critical for their reliable and safe deployment across 
various applications, including healthcare, finance, quantum information, national security, etc. Robustness refers to an AI model’s ability to maintain s table  and expected performance despite 
variations in input data, such as adversarial attacks, or unexpected real-world conditions. A lack of robustness can lead to model failures, security vulnerabilities, and unreliable decision-making, which may bring ne gative  societal and economic consequences. Thus, providing funding to 
support research related to robust AI models is critical to national interests.  
AI Cy bersecurity Applications  
AI-driven cybersecurity enhancements should be mandated in federal agencie s and critical 
infrastructure operations. AI-powered threat detection should be implemented to identify cyber threats in real -time, and automated incident response systems should be standardized to 
autonomously contain threats. Financial institutions and government agencies should integrate AI-enhanced fraud detection systems to combat phishing attacks and financial fraud. 
To defe nd against AI-powered cyber threats, a federal cybersecurity standard should be 
established to protect AI models from adversarial attacks, data poisoning, and prompt injection threats. Digital watermarking for AI -generated content should be implemented to prevent misuse 
in cyberattacks, such as deepfakes and automated misinformation campaigns. AI developers should be required to harden model training environments against data tampering and supply 


chain attacks to prevent adversarial exploitation. 
A nati onal AI cyber defense strategy should be established to ensure coordinated efforts between 
government agencies and the private sector. A public- private AI cybersecurity research 
consortium should focus on AI-driven cyber defense innovations. A federally managed AI-
powered national threat intelligence platform should be developed to integrate real- time cyber 
threat intelligence across industries. International collaboration should be strengthened to counter AI-enhanced cyber threats, including nation- state attacks leveraging AI.  
Policy for Stimulating Research in AI Models That Exhibit Authentic Thinking  
To stimulate research in AI models that demonstrate authentic thinking rather than mere statistical models, the government should establish dedicated funding programs. These initiatives should prioritize the development of AI systems that integrate symbolic reasoning, causal inference, and domain -specific knowledge to enhance decision-making beyond pattern- based 
correlations. A national AI reasoning benchmark should be created to assess and standardize AI models based on their ability to apply logic, learn from fewer examples, and generalize across contexts. 
Colla boration between government, academia, and industry should be encouraged through a 
public- private AI reasoning consortium focused on advancing neurosymbolic AI and explainable 
deep learning. This consortium would drive the development of hybrid AI architectures that combine machine learning with structured reasoning approaches, ensuring AI models can justify their decisions in transparent and interpretable ways. Dedicated AI research centers should be established to facilitate interdisciplinary collaboration, integrating insights from cognitive science and neuroscience into AI development. 
To regu late high -stakes AI applications, policies should mandate transparency and 
interpretability, ensuring AI models used in areas such as healthcare, law, and defense can provide reasoning-based explanations rather than opaque, black-box outputs. These measure s 
will help shift AI research towards the creation of models capable of genuine reasoning, making AI more reliable and aligned with human cognitive processes. 
The int ersection of Quantum and AI  
To advance the development and application of AI at the intersection of quantum computing, the government should establish a national research initiative focused on Quantum AI. This initiative should fund research into quantum algorithms designed to enhance machine learning, optimization, and complex problem-solving capabilities beyond the limits of classical AI. Priority should be given to developing hybrid computing frameworks that integrate quantum and classical AI methods  
Educat ion and Training  
An AI Action Plan should first comprehensively address all key aspe cts related to the research, 
development, deployment, and application of AI across sectors, including business, government, and education. This includes ensuring security against AI model attacks, fostering responsible AI development, and establishing frameworks for safe and effective deployment. 


Addi tionally, educational research and workforce training play pivotal roles in transitioning AI 
from research to real -world deployment efficiently. These efforts help society quickly benefit 
from AI advancements,  driving innovation and competitiveness while enhancing public 
perception and awareness.  
Early education and the introduction of AI to younger generations are crucial for fostering AI 
literacy and cultivating future innovators. Establishing a robust AI ecosystem—encompassing 
research, development, and deployment—is essential to maintaining a competitive and sustainable leadership position in the global AI landscape. 
Futu re of Work  
On 2/25/2025 a diverse group of 30 leaders from government, industry, academia, and nonprofit sectors were convened by Boise State’s Social Impacts of Computing Group in the Boise metro area for a workshop exploring the impacts of artificial intelligence (AI) on jobs. Participants were divided into five groups, each tasked with analyzing one of four AI adoption scenarios—High Industry Adoption/Low Workforce Adoption, Low Industry Adoption/High Workforce Adoption, High Industry Adoption/High Workforce Adoption, Low Industry Adoption/Low Workforce Adoption, plus a com prehensive view across all quadrants. Using a four- scenario 
framework, the groups examined how varying rates of AI adoption by industries and workforces could shape economic, social, and organizational outcomes.  
Group Takeaways: Cross- Cutting Themes from The Scenario Exercise and Natural 
Intelligence Systems  
The workshop revealed a mix of optimism and caution regarding AI’s impact on jobs, with the 
following key takeaways:  
●Opportunities and Strategies: Identifying clear use cases and proving AI’s value ar e
critical to successful adoption. A universal solution for undefined problems risks failure,
while safe switching (vs. high switching costs) encourages experimentation.
●Winners and Losers: Slow adopters—whether industries or employees—risk being leftbehind, widening wealth and productivity gaps. Conversely, rapid adoption offers
competitive advantages and productivity gains.
●Workforce Dynamics: Training and upskilling are essential, yet traditional career pathsand education systems are outdated. Employee empowerment and emerging leaderssignal a shift toward flatter organizations, though retention and turnover remain
challenges.
●Risks and Ethics: Privacy, security (e.g., data leaks), and regulatory gaps pose significantrisks. Values and ethics must guide adoption to avoid moral hazards and biased models.
●Societal Impacts: Fragmentation within institutions, the death of old firms, and the rise ofnew ones reflect an inevitable shift. The question of "who is left behind?" underscores
equity concerns, with no quadrant fully addressing this challenge.


Conclusion and Recommendations from The Scenario Exercise and Natural Intelligence 
Systems  
The workshop highlighted that AI’s impact on jobs hinges on the interplay between industry and 
workforce adoption rates. High adoption scenarios promise innovation and efficiency but risk societal backlash and inequality, while low adoption scenarios preserve stability at the cost of missed opportunities. Participants agreed that change is inevitable—status quo is not maintainable —and success requires:  
1. Strategic Clarity: Define opportunities and measure AI’s value to avoid missteps.
2. Investment in People: Prioritize upskilling and adaptable education to close skill gaps.
3. Technology Investment and Research:  Invest in both classical AI systems as well as
funding the research for what will inevitably replace classical AI systems, such as
neuromorphic AI.
4. Balanced Regulation: Address gaps without stifling innovation, ensuring fairness and
security.
5.Sunlight As Disinfectant: Increase priority, focus and investment on AI systems that areinherently transparent and explainable.
6.Democratization of AI:  Take steps necessary to ensure that the benefits of AI accruebroadly across all segments, sectors and classes of society.
7.Ethical Frameworks: Embed values to mitigate biases and societal risks.
8. National Security:  Ensure the US military has access to the best AI technology in the
hands of war fighters and administrative areas to counter threats from new and traditionaladversaries.
As Boise’s leaders navigate this AI -driven future, collaboration across sectors will be key to 
harnessing its potential while minimizing its pitfalls.  
These comments are derived from concerned citizens located in or near Boise Idaho.  These 
citizens represent industry, not for profit, government and higher education.  The citizens have deep experience in AI and the potential impacts.   Thank you for your consideration of our commentary.  


