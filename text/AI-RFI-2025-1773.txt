PUBLIC SUBMISSIONAs of: March 21, 2025
Received: March 15, 2025
Status: 
Tracking No. m 8a-5xbp-p4lm
Com m ents Due: March 15, 2025
Subm ission Type: API
Docket: NSF_FRDOC_0001
Recently Posted NSF Rules and Notices.
Com m ent On: NSF_FRDOC_0001-3479
Request for Inform ation: Developm ent of an Artificial Intelligence Action Plan
Docum ent: NSF_FRDOC_0001-DRAFT-1773
Com m ent on FR Doc # 2025-02305
Submitter Information
Nam e: Anonym ous Anonym ous
Em ail:  
General Comment
The proposal of OpenAI and Google on training generative AI m ust be rejected to protect the livelihood of the people and ensure a
sustainable econom ic growth due to following reasons:
1. Letting the tech corps to train on data without copyright protection will accentuate the m onopoly of these com panies while putting
independent creators out of work, thus wreaking the havoc over the whole econom y because: 
Generative AI is not fair use and it enables corporations to exploit or put independent creators out of work. Creators including illustrators,
anim ators, writers and m any other creatives use their intellectual labor as their m ain source of incom e to sustain their living and copyright
law is to protect their livelihood from  being exploited by these tech giants. Perm ission to train on copyrighted data without original
creators’ consent gives big corporation the entire control over creators’ works and puts m illion creators at risk of losing jobs by enabling
corporations unfairly com pete with and generate incom e from  the original works without having to pay original creators a fair am ount of
com pensation. 
Copyright sector will be devalued trem endously. The generative m odel is trained on works that require hours, m onths even years of
hum an efforts to create m illions of counterfeits in just seconds. Without protection on on copyright, the original works are prone to be
devalued due to a m ass production of low-quality counterfeits, which eventually hurts the econom y as copyright sector suffers significantly.
The dam age that generative AI causes to the copyright sector is sim ilar to how Chinese counterfeits take a severe toll on US econom y.
2. Open AI and Google’s freely ram paging on internet’s data set will elim inate cyber security and cause social upheaval because: 
The original creators are at risk of being cyber harassed and fabricated identity by these tech giants. Without copyright protection,
creators’ personal data such as face-revealing photos, videos, voice and internet profile are prone to be abused for dishonest, reality-
distorting and fraudulent activities. There have been cases where deepfake videos use owners’ data to create child sexual abuse m aterial.
(https://www.404m edia.co/laion-datasets-rem oved-stanford-csam -child-abuse/?
fbclid=IwY2xjawJCSMdleHRuA2FlbQIxMAABHZsX96m fDpHwHv0CQ7dDDUVnY9NRPoWenDoYd0zs2jIQ_avSAlrNb-
kWCw_aem _Rl6s9zOhH5WossWf2fxo6g)
3. Protecting independent creators by enforcing copyright law and strict regulations on generative AI are the only ways to ensure the well-
being of the society and national security.
If the governm ent enables these giant tech to freely train on copyrighted m aterials, people will greatly doubt whether the governm ent
works for the people or only for the benefit of a few richest. Think about how m essy the governm ent already becam e with the current
president and the oligarchy. This will exacerbate the status quo even worse. Endorsing big corporations with perm ission to do whatever
they want with people’s intellectual properties m eans a governm ent that serves only the billionaires’ m inority, thus create distrust and
resentm ent from  the people. Job loss coupled with lack of trust in the governm ent quickly results in m ass social upheaval the overall
econom y will be sent to its death bed shortly.
“This docum ent is approved for public dissem ination. The docum ent contains no business-proprietary or confidential inform ation.
Docum ent contents m ay be reused by the governm ent in developing the AI Action Plan and associated docum ents without attribution.”


