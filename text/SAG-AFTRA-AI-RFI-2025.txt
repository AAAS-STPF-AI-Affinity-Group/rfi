Erik Passoja  
Los Angeles, CA  
March 15, 2025 
Networking and Information Technology Research and Development (NITRD)  
National Coordination Office (NCO), National Science Foundation 
Re: Response to the Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan 
At the SAG-AFTRA Los Angeles New Technology Committee, we have worked 
extensively on the technical, legal, and operational frameworks needed to protect digital 
identities—including image, likeness, and voice data—from exploitation through artificial 
intelligence.  While my comments draw upon this expertise, I am not submitting this 
response in any official organizational capacity, rather am responding to this RFI as a 
private citizen with specialized knowledge of digital identity protection challenges and 
solutions.  
Performers are the proverbial “canaries in the coal mine” of digital identity, because our 
livelihoods depend on protecting our personas. Yet the deepfake crisis extends far 
beyond entertainment, posing urgent risks to national security. 
In reality, AI-generated synthetic media is advancing at a staggering pace—offering 
enormous potential for American innovation while simultaneously heightening the threat 
of identity theft and malicious impersonation. As directed by Executive Order 14179 
(January 23, 2025), this submission outlines a strategic framework to enhance 
America's AI dominance by establishing digital identity protection as critical 
infrastructure. Erik Passoja  
Co-Chair, SAG-AFTRA Los Angeles New Technology Committee  
(responding as a private citizen) 
This document is approved for public dissemination. The document contains no 
business-proprietary or confidential information. Document contents may be reused by 
the government in developing the AI Action Plan and associated documents without 
attribution. 
1 


Digital Identity Protection as Critical 
Infrastructure for American AI Leadership 
In response to the Request for Information on the Development of an Artificial 
Intelligence (AI) Action Plan 
Executive Summary 
The exponential growth of AI-generated synthetic media requires immediate action to 
protect Americans' digital identities—specifically, their faces, voices, and likenesses. 
This proposal addresses how unauthorized manipulation of these biometric 
characteristics threatens national security, economic stability, and individual rights, while 
creating market opportunities for American technology leadership. 
In accordance with Executive Order 14179 (January 23, 2025), this proposal 
establishes digital identity protection as critical infrastructure—creating a framework that 
addresses security vulnerabilities without hampering innovation. 
Rather than imposing unnecessary regulatory burdens on private sector innovation, we 
advocate for a market-driven approach that creates new opportunities for American 
companies while addressing the urgent security challenges posed by synthetic media. 
By establishing clear standards, creating appropriate market incentives, and focusing on 
critical infrastructure protection, the Administration can catalyze private sector solutions 
to this growing threat while maintaining America's competitive edge. 
This framework directly supports the AI Action Plan's goal of "sustaining and enhancing 
America's AI dominance" while ensuring that "unnecessarily burdensome requirements 
do not hamper private sector AI innovation." 
The Synthetic Media Crisis: Evidence and Impact 
Documented Incidents 
The threat is no longer theoretical. Deepfake scams are responsible for an estimated 
$12 billion in fraud losses globally. Projections suggest these numbers could reach $40 
billion over the next three years.1  In December, 2024, the FBI warned the public that 
criminals exploit generative artificial intelligence (AI) to commit fraud on a larger scale 
which increases the believability of their schemes.2 2 Internet Crime Complaint Center, FBI “PSA241203 ,” IC3, 2024. 1 Chris Westfall, “AI Deepfakes of Elon Musk on the Rise, Causing Billions in Fraud Losses,” Forbes, November 29, 
2024. 
2 


Consider these examples from the past 18 months: 
●January 2024 : Deepfake robocalls impersonating President Biden3 targeted New
Hampshire voters, demonstrating election interference capabilities
●February 2024 : ARUP Engineering Scam4: $25 million lost through deepfaked
CFO audio
●February 2024 : Sexually explicit AI-generated images of Taylor Swift5
●April 2024: School principal targeted by racist deepfake6, damaging community
trust and institutional reputation
The technology enabling these attacks requires minimal expertise, with convincing voice 
replicas possible from just 3 seconds of audio and visual deepfakes achievable from a 
single photograph. 
Economic and National Security Impact 
Digital identity attacks directly threaten America's economic and national security 
interests: 
●22% of critical infrastructure organizations report attempted deepfake-based
social engineering7
●Defense and intelligence communications increasingly targeted by synthetic
impersonation8
●Deloitte’s Center for Financial Services predicts that gen AI could enable fraud
losses to reach US$40 billion in the United States by 20279
As AI capabilities continue to accelerate exponentially, these impacts will intensify. The 
Bipartisan House Task Force Report on Artificial Intelligence (December 2024) 
specifically identified this gap, concluding that "there is currently no single, optimal 
technical solution to content authentication."10 
In addition, China has prioritized the development of synthetic media and deepfake 
technologies, leveraging them for influence operations and disinformation campaigns. 
10 Bipartisan House Task Force on Artificial Intelligence, AI Task Force Report, FINAL (Washington, DC: U.S. Speaker 
of the House, December 2024). 9  Val Srinivas, “How Generative AI Is Making Fraud a Lot Easier—and Cheaper—to Pull Off,” Deloitte Center for 
Financial Services, May 29, 2024 8 CSI: Deepfake Threats,” U.S. Department of Defense, September 12, 2023 7 Cybersecurity Ventures, “Deepfake Fraud: The New Frontier in Cybercrime ,” Cybersecurity Ventures, 2024 6 Deepfake of Principal’s Voice Is the Latest Case of AI Being Used for Harm,” U.S. News & World Report, April 29, 
2024 5Leah Sarnoff, “Taylor Swift and No AI Fraud Act: How Congress Plans to Fight Back Against AI Deepfakes,” ABC 
News 4 David Elliott, “‘This Happens More Frequently Than People Realize ’: Arup Chief on the Lessons Learned from a 
$25m Deepfake Crime,” World Economic Forum, February 4, 2025 3 Associated Press, “New Hampshire Primary: Biden, AI Deepfake Robocall ,” AP News, February 2024. 
3 


U.S. intelligence has documented instances where Chinese operatives prepared 
AI-generated content to mislead voters during the 2020 election11, underscoring their 
capability to amplify false narratives. Additionally, Beijing appears to have a dual stance 
on deepfakes—strict regulation domestically due to potential socio-economic and 
security threats, coupled with an ambition to leverage them for international influence 
operations12. While China enforces strict domestic regulations on deepfake use13, its 
military and intelligence services actively exploit these technologies for international 
influence operations, posing a direct threat to American democratic processes and 
critical infrastructure communications 
Three Critical Framework Gaps 
America's digital identity infrastructure faces three critical gaps that require policy 
attention to ensure continued AI leadership: 
1. Content Provenance Standards
While California SB 942 and the proposed federal COPIED Act address watermarking 
requirements, enforcement mechanisms and technical standards remain undefined. The 
market urgently requires clear, interoperable standards that can function across diverse 
media types and platforms. These standards must establish a reliable chain-of-custody 
for digital content while being resistant to tampering and transformation. Crucially, they 
need to operate with minimal performance impact to ensure widespread adoption 
across the digital ecosystem. 
2. Verification Infrastructure
No standardized system exists to authenticate digital content across platforms. An 
effective verification framework would need to provide real-time authentication before 
content distribution, functioning seamlessly across the entire content ecosystem – from 
social media to messaging platforms to broadcast media. This framework must carefully 
balance robust security with acceptable performance and user experience, preferably 
operating through distributed rather than centralized architecture. 
The technology to steal and manipulate digital identities is already widespread and 
accessible. The technology to protect Americans must be equally robust and universally 
deployed. 13 Giulia Interesse, “China to Regulate Deep Synthesis (Deepfake) Technology Starting 2023,” China Briefing, 
December 20, 2022. 12 Jamestown Foundation, “Deepfakes with Chinese Characteristics: PRC Influence Operations in 2024,” March 29, 
2024. 11 CNN, “US Intelligence Spotted Chinese, Iranian Deepfakes in 2020 Aimed at Influencing Voters,” May 15, 2024. 
4 


3. Consent Mechanisms
While California AB 2602  and the proposed NO FAKES Act establish important consent 
requirements, implementation standards remain critically underdeveloped. A robust 
consent framework must recognize that digital identity is fundamentally personal 
property that individuals have the right to control. Effective consent systems need to 
establish clear, explicit permission boundaries that prevent unauthorized use while 
enabling legitimate applications. 
Such frameworks should provide granular control options tailored to different 
contexts—whether for medical professionals, performers, the military, governance, or 
everyday citizens—while maintaining consistent protection standards. The technical 
implementation must ensure that consent information travels with content across 
platforms and jurisdictions, creating a reliable accountability system that defends 
individual rights without impeding innovation. 
Most importantly, these systems must transform abstract legal protections into practical, 
enforceable mechanisms that ordinary people can understand and digital systems can 
automatically enforce. 
Such a framework can protect fundamental rights that all Americans value: consent, 
identity, and protection from fraud. These are shared values that transcend partisan 
divides. 
Alignment with AI Action Plan Objectives 
This framework directly responds to Executive Order 14179's directive to remove 
barriers to American AI leadership by creating market certainty without imposing 
government mandates that would stifle innovation. ●Enhancing America's AI Dominance: By establishing global leadership in
digital identity verification, America can set standards that are advantageous for
U.S. companies in the global AI marketplace.
●Removing Innovation Barriers : The framework emphasizes market-driven
solutions rather than government-built systems, creating certainty for private
sector innovation without imposing unnecessary technical constraints.
●National Security Enhancement: Digital identity protection directly supports the
national security objectives outlined in Executive Order 14179 by protecting
critical communication systems from synthetic media attacks.
Policy Recommendations 
5 


We recommend the following policy actions to address these critical gaps while 
advancing America's AI leadership: 
1. Designate Digital Identity as Critical Infrastructure
Digital identity verification should be formally designated as critical infrastructure, 
receiving the same priority and protection as other essential systems. This formal 
designation enables coordinated security responses to major incidents from foreign and 
domestic threats while facilitating public-private cooperation on standards. By focusing 
resources on this critical vulnerability, we create market opportunities for American 
companies to lead globally. 
Just as we use multi-factor authentication to protect our financial accounts, we need 
automated systems to verify digital identities at scale for all Americans. 
2. Establish Federal Standards Aligned with State Initiatives
The Administration should establish federal standards that build upon bipartisan, 
state-level initiatives such as California SB 942 and AB 2602, Tennessee’s ELVIS Act, 
and Illinois’ SB 3325 .  These standards should provide technical baseline requirements 
without prescribing specific implementations, ensuring interoperability across state 
boundaries. This approach creates market certainty for technology developers while 
establishing clear compliance timelines that balance security needs with innovation. 
3. Implement Authentication Requirements for Critical Communications
Federal agencies should require authentication for communications in high-risk 
domains: ●Government and military command communications
●Critical infrastructure operational directives
●Emergency management and public safety messaging
●Financial system notifications
4. Create Market Incentives for Verification Systems
Rather than building government-operated systems, the most effective approach is 
creating market incentives for private sector solutions. Federal procurement preferences 
for authenticated content would drive adoption, while targeted tax incentives could 
accelerate investments in verification infrastructure. Implementing risk management 
requirements for regulated industries would further strengthen the ecosystem, 
complemented by research and development funding for fundamental technologies. 
5. Support Statutory Authority for Digital Identity Protection6 


The Administration should provide clear support for pending legislation such as the NO 
FAKES Act and COPIED Act while ensuring robust enforcement mechanisms. This 
legislative framework should establish criminal penalties for malicious identity 
exploitation and create civil remedies for unauthorized use. Additionally, developing 
cross-border enforcement mechanisms is essential, as is protecting legitimate creative 
and fair use expressions to balance innovation with security. 
Implementation Considerations 
Private Sector Leadership 
The most effective implementation path relies on private sector innovation within a clear 
regulatory framework. Rather than government mandates, we should encourage 
industry-led technical standards with government endorsement that create consistency 
without stifling creativity. Market-driven implementation approaches will ensure solutions 
remain competitive and cost-effective. 
The solutions to these challenges, in fact, already exist. ●Digital watermarking has been a digital cinema standard since 200514
●Formalized consent frameworks across multiple industries (e.g. healthcare,
education)
●Authentication systems are already standard in cybersecurity (MFA/KYC)
The adoption process should be driven by competitive advantage. This approach allows 
for phased deployment that naturally prioritizes critical sectors first while giving other 
industries appropriate time to integrate verification technologies into their workflows. 
American companies are uniquely positioned to define global standards in digital 
identity verification, creating export opportunities and ensuring foreign competitors must 
follow U.S.-led approaches. This strengthens America's technological sovereignty while 
simultaneously expanding market reach for domestic firms. 
International Coordination 
Digital identity protection requires international alignment with like-minded nations. 
Harmonizing standards with key allies creates interoperability across borders, while 
specific provisions in trade agreements can accelerate adoption of verification systems. 
Diplomatic engagement on global norms is essential for establishing consistent 
approaches to digital identity protection. These approaches must respect national 14 CreativePro Staff, “Major Movie Studios Specify Digital Watermarking for Digital Cinema,” CreativePro, July 29, 
2005 
7 


sovereignty while enabling effective international cooperation against synthetic media 
threats. Additionally, thoughtful export control considerations for advanced verification 
technologies will help protect American innovations in this critical space while allowing 
beneficial commercial applications to flourish in international markets. 
Balanced Implementation Timeline 
An effective implementation strategy must balance urgency with practical constraints: 
●Critical communications protection: 12-18 months
●Commercial media implementation: 18-36 months
●Comprehensive ecosystem deployment: 36-48 months
Economic Opportunity 
The market for digital identity protection solutions is projected to exceed $500 billion 
globally by 2028, with particularly strong growth in the following sectors: 
Sector Use Case Market Value 
Financial Services Transaction Verification $144B (anti-fraud solutions) 
Government Secure Documentation $89B (global govt contracts) 
Healthcare TeleHealth Reimbursements $78B (global healthcare contracts) 
Media & Entertainment Performer Protection & Licensing $63B (studio compliance, monetization) 
Legal Remote Notarization $19B (legal tech vertical) 
Social Media Content Authenticity $33B (trust & safety tools) 
Manufacturing Industrial Safety Compliance $27B (industrial IoT security) 
Law Enforcement Authentication holds up in court $48B (legal confirmation tools) 
These opportunities translate directly to American jobs - conservative estimates project 
over 350,000 new high-paying positions in digital verification technologies by 2028, with 
particular concentration in heartland states with strong technical universities and lower 
operating costs. 
Conclusion: A Call for American Leadership 
Digital identity protection represents one of the most pressing national security 
challenges facing America today, yet also presents a tremendous opportunity for 
8 


American innovation and leadership. With synthetic media capabilities advancing 
exponentially, the window for establishing effective protections is rapidly closing. 
Fortunately, the technology to address this crisis exists in the private sector. What 
began as work to protect performers has revealed broader implications for all citizens. 
The solutions developed for this specific context can benefit everyone, from protecting 
children against exploitation to preventing election interference and securing critical 
infrastructure. 
What is lacking is the coordinated policy and technology framework necessary to deploy 
these solutions at scale. By establishing clear standards, creating appropriate market 
incentives, and focusing on critical infrastructure protection, the Administration can 
catalyze a market-driven solution to this growing threat. 
America's technological leadership in artificial intelligence depends on establishing 
digital trust. By taking decisive action on digital identity protection, this Administration 
can secure America's position as the global leader in responsible AI development while 
simultaneously protecting our critical national interests. 
9 


